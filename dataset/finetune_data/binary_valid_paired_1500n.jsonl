{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != \"POST\":\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n            return\n        if self._read_started and not hasattr(self, \"_body\"):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == \"multipart/form-data\":\n            if hasattr(self, \"_body\"):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == \"application/x-www-form-urlencoded\":\n            self._post, self._files = (\n                QueryDict(self.body, encoding=self._encoding),\n                MultiValueDict(),\n            )\n        else:\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void UncompressElementOp::Compute(OpKernelContext* ctx) {\n  Tensor tensor = ctx->input(0);\n  const Variant& variant = tensor.scalar<Variant>()();\n  const CompressedElement* compressed = variant.get<CompressedElement>();\n\n  std::vector<Tensor> components;\n  OP_REQUIRES_OK(ctx, UncompressElement(*compressed, &components));\n  OP_REQUIRES(ctx, components.size() == output_types_.size(),\n              errors::FailedPrecondition(\"Expected \", output_types_.size(),\n                                         \" outputs from uncompress, but got \",\n                                         components.size()));\n  for (int i = 0; i < components.size(); ++i) {\n    OP_REQUIRES(\n        ctx, components[i].dtype() == output_types_[i],\n        errors::FailedPrecondition(\"Expected a tensor of type \",\n                                   DataTypeString(output_types_[i]),\n                                   \" but got a tensor of type \",\n                                   DataTypeString(components[i].dtype())));\n    ctx->set_output(i, components[i]);\n  }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& sorted_inputs_t = ctx->input(0);\n    const Tensor& values_t = ctx->input(1);\n\n    // inputs must be at least a matrix\n    OP_REQUIRES(\n        ctx, sorted_inputs_t.shape().dims() >= 2,\n        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n    // must have same batch dim_size for both\n    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                Status(error::INVALID_ARGUMENT,\n                       \"Leading dim_size of both tensors must match.\"));\n\n    // this is required because we do indexing in int32 on the GPU\n    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),\n                Status(error::INVALID_ARGUMENT,\n                       \"values tensor size must less than INT_MAX\"));\n\n    Tensor* output_t;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, values_t.shape(), &output_t));\n\n    if (output_t->dtype() == DT_INT32) {\n      OP_REQUIRES(ctx,\n                  FastBoundsCheck(sorted_inputs_t.dim_size(1),\n                                  std::numeric_limits<int>::max()),\n                  errors::InvalidArgument(\"trailing dim_size must less than \"\n                                          \"INT_MAX for int32 output type, was \",\n                                          sorted_inputs_t.dim_size(1)));\n    }\n\n    auto output = output_t->template flat<OutType>();\n    const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n    const auto values = values_t.template flat<T>();\n    OP_REQUIRES_OK(\n        ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32 lower_diag_index = 0;\n    int32 upper_diag_index = 0;\n    int32 num_rows = -1;\n    int32 num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n      num_rows = context->input(2).flat<int32>()(0);\n      num_cols = context->input(3).flat<int32>()(0);\n      padding_value = context->input(4).flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32 min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32 min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n\n    // MatrixDiagPart and MatrixDiagPartV2 both use this OpKernel.\n    // MatrixDiagPart only has one input, so we have to check the number of\n    // inputs before reading additional parameters in MatrixDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n    T padding_value(0);\n\n    // MatrixDiagPartV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(context, diag_index.NumElements() > 0,\n                  errors::InvalidArgument(\n                      \"Expected diag_index to have at least 1 element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n      padding_value = context->input(2).flat<T>()(0);\n    }\n    const TensorShape& input_shape = input.shape();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const int rank = input_shape.dims();\n    const Eigen::Index num_rows = input_shape.dim_size(rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \". It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    TensorShape output_shape;\n    for (int i = 0; i < rank - 2; ++i) {\n      output_shape.AddDim(input_shape.dim_size(i));\n    }\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    if (num_diags > 1) output_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    output_shape.AddDim(max_diag_len);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat<T>();\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    functor::MatrixDiagPart<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def upload_artifact_handler():\n    args = request.args\n    run_uuid = args.get(\"run_uuid\")\n    if not run_uuid:\n        raise MlflowException(\n            message=\"Request must specify run_uuid.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    path = args.get(\"path\")\n    if not path:\n        raise MlflowException(\n            message=\"Request must specify path.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    validate_path_is_safe(path)\n\n    if request.content_length and request.content_length > 10 * 1024 * 1024:\n        raise MlflowException(\n            message=\"Artifact size is too large. Max size is 10MB.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    data = request.data\n    if not data:\n        raise MlflowException(\n            message=\"Request must specify data.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    run = _get_tracking_store().get_run(run_uuid)\n    artifact_dir = run.info.artifact_uri\n\n    basename = posixpath.basename(path)\n    dirname = posixpath.dirname(path)\n\n    def _log_artifact_to_repo(file, run, dirname, artifact_dir):\n        if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n            artifact_repo = _get_artifact_repo_mlflow_artifacts()\n            path_to_log = (\n                os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\", dirname)\n                if dirname\n                else os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\")\n            )\n        else:\n            artifact_repo = get_artifact_repository(artifact_dir)\n            path_to_log = dirname\n\n        artifact_repo.log_artifact(file, path_to_log)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        dir_path = os.path.join(tmpdir, dirname) if dirname else tmpdir\n        file_path = os.path.join(dir_path, basename)\n\n        os.makedirs(dir_path, exist_ok=True)\n\n        with open(file_path, \"wb\") as f:\n            f.write(data)\n\n        _log_artifact_to_repo(file_path, run, dirname, artifact_dir)\n\n    return Response(mimetype=\"application/json\")\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def extract_ip_or_domain(url):\n    ip_regex = re.compile(\"^(?:http://|https://)(\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3})\")\n    domain_regex = re.compile(\"^(?:http://|https://)([a-zA-Z0-9.-]+)\")\n\n    match = ip_regex.findall(url)\n    if len(match):\n        ip_address = match[0]\n        try:\n            ipaddress.ip_address(ip_address)  # Validate the IP address\n            return ip_address\n        except ValueError:\n            pass\n\n    match = domain_regex.findall(url)\n    if len(match):\n        return match[0]\n\n    return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render(self, context):\n        from pprint import pformat\n        output = [pformat(val) for val in context]\n        output.append('\\n\\n')\n        output.append(pformat(sys.modules))\n        return ''.join(output)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "load_header (XwdLoader *loader) // gconstpointer in, gsize in_max_len, XwdHeader *header_out)\n{\n    XwdHeader *h = &loader->header;\n    XwdHeader in;\n    const guint32 *p = (const guint32 *) &in;\n\n    if (!file_mapping_taste (loader->mapping, &in, 0, sizeof (in)))\n        return FALSE;\n\n    h->header_size = g_ntohl (*(p++));\n    h->file_version = g_ntohl (*(p++));\n    h->pixmap_format = g_ntohl (*(p++));\n    h->pixmap_depth = g_ntohl (*(p++));\n    h->pixmap_width = g_ntohl (*(p++));\n    h->pixmap_height = g_ntohl (*(p++));\n    h->x_offset = g_ntohl (*(p++));\n    h->byte_order = g_ntohl (*(p++));\n    h->bitmap_unit = g_ntohl (*(p++));\n    h->bitmap_bit_order = g_ntohl (*(p++));\n    h->bitmap_pad = g_ntohl (*(p++));\n    h->bits_per_pixel = g_ntohl (*(p++));\n    h->bytes_per_line = g_ntohl (*(p++));\n    h->visual_class = g_ntohl (*(p++));\n    h->red_mask = g_ntohl (*(p++));\n    h->green_mask = g_ntohl (*(p++));\n    h->blue_mask = g_ntohl (*(p++));\n    h->bits_per_rgb = g_ntohl (*(p++));\n    h->color_map_entries = g_ntohl (*(p++));\n    h->n_colors = g_ntohl (*(p++));\n    h->window_width = g_ntohl (*(p++));\n    h->window_height = g_ntohl (*(p++));\n    h->window_x = g_ntohl (*(p++));\n    h->window_y = g_ntohl (*(p++));\n    h->window_border_width = g_ntohl (*(p++));\n\n    /* Only support the most common/useful subset of XWD files out there;\n     * namely, that corresponding to screen dumps from modern X.Org servers. */\n\n    ASSERT_HEADER (h->header_size >= sizeof (XwdHeader));\n    ASSERT_HEADER (h->file_version == 7);\n    ASSERT_HEADER (h->pixmap_depth == 24);\n\n    /* Xvfb sets bits_per_rgb to 8, but 'convert' uses 24 for the same image data. One\n     * of them is likely misunderstanding. Let's be lenient and accept either. */\n    ASSERT_HEADER (h->bits_per_rgb == 8 || h->bits_per_rgb == 24);\n\n    ASSERT_HEADER (h->bytes_per_line >= h->pixmap_width * (h->bits_per_pixel / 8));\n    ASSERT_HEADER (compute_pixel_type (loader) < CHAFA_PIXEL_MAX);\n\n    loader->file_data = file_mapping_get_data (loader->mapping, &loader->file_data_len);\n    if (!loader->file_data)\n        return FALSE;\n\n    ASSERT_HEADER (loader->file_data_len >= h->header_size\n                   + h->n_colors * sizeof (XwdColor)\n                   + h->pixmap_height * h->bytes_per_line);\n\n    loader->image_data = (const guint8 *) loader->file_data\n        + h->header_size + h->n_colors * sizeof (XwdColor);\n\n    return TRUE;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _check_sigs_on_pdus(keyring, room_version, pdus):\n    \"\"\"Check that the given events are correctly signed\n\n    Args:\n        keyring (synapse.crypto.Keyring): keyring object to do the checks\n        room_version (str): the room version of the PDUs\n        pdus (Collection[EventBase]): the events to be checked\n\n    Returns:\n        List[Deferred]: a Deferred for each event in pdus, which will either succeed if\n           the signatures are valid, or fail (with a SynapseError) if not.\n    \"\"\"\n\n    # we want to check that the event is signed by:\n    #\n    # (a) the sender's server\n    #\n    #     - except in the case of invites created from a 3pid invite, which are exempt\n    #     from this check, because the sender has to match that of the original 3pid\n    #     invite, but the event may come from a different HS, for reasons that I don't\n    #     entirely grok (why do the senders have to match? and if they do, why doesn't the\n    #     joining server ask the inviting server to do the switcheroo with\n    #     exchange_third_party_invite?).\n    #\n    #     That's pretty awful, since redacting such an invite will render it invalid\n    #     (because it will then look like a regular invite without a valid signature),\n    #     and signatures are *supposed* to be valid whether or not an event has been\n    #     redacted. But this isn't the worst of the ways that 3pid invites are broken.\n    #\n    # (b) for V1 and V2 rooms, the server which created the event_id\n    #\n    # let's start by getting the domain for each pdu, and flattening the event back\n    # to JSON.\n\n    pdus_to_check = [\n        PduToCheckSig(\n            pdu=p,\n            redacted_pdu_json=prune_event(p).get_pdu_json(),\n            sender_domain=get_domain_from_id(p.sender),\n            deferreds=[],\n        )\n        for p in pdus\n    ]\n\n    v = KNOWN_ROOM_VERSIONS.get(room_version)\n    if not v:\n        raise RuntimeError(\"Unrecognized room version %s\" % (room_version,))\n\n    # First we check that the sender event is signed by the sender's domain\n    # (except if its a 3pid invite, in which case it may be sent by any server)\n    pdus_to_check_sender = [p for p in pdus_to_check if not _is_invite_via_3pid(p.pdu)]\n\n    more_deferreds = keyring.verify_json_objects_for_server(\n        [\n            (\n                p.sender_domain,\n                p.redacted_pdu_json,\n                p.pdu.origin_server_ts if v.enforce_key_validity else 0,\n                p.pdu.event_id,\n            )\n            for p in pdus_to_check_sender\n        ]\n    )\n\n    def sender_err(e, pdu_to_check):\n        errmsg = \"event id %s: unable to verify signature for sender %s: %s\" % (\n            pdu_to_check.pdu.event_id,\n            pdu_to_check.sender_domain,\n            e.getErrorMessage(),\n        )\n        # XX not really sure if these are the right codes, but they are what\n        # we've done for ages\n        raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)\n\n    for p, d in zip(pdus_to_check_sender, more_deferreds):\n        d.addErrback(sender_err, p)\n        p.deferreds.append(d)\n\n    # now let's look for events where the sender's domain is different to the\n    # event id's domain (normally only the case for joins/leaves), and add additional\n    # checks. Only do this if the room version has a concept of event ID domain\n    # (ie, the room version uses old-style non-hash event IDs).\n    if v.event_format == EventFormatVersions.V1:\n        pdus_to_check_event_id = [\n            p\n            for p in pdus_to_check\n            if p.sender_domain != get_domain_from_id(p.pdu.event_id)\n        ]\n\n        more_deferreds = keyring.verify_json_objects_for_server(\n            [\n                (\n                    get_domain_from_id(p.pdu.event_id),\n                    p.redacted_pdu_json,\n                    p.pdu.origin_server_ts if v.enforce_key_validity else 0,\n                    p.pdu.event_id,\n                )\n                for p in pdus_to_check_event_id\n            ]\n        )\n\n        def event_err(e, pdu_to_check):\n            errmsg = (\n                \"event id %s: unable to verify signature for event id domain: %s\"\n                % (pdu_to_check.pdu.event_id, e.getErrorMessage())\n            )\n            # XX as above: not really sure if these are the right codes\n            raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)\n\n        for p, d in zip(pdus_to_check_event_id, more_deferreds):\n            d.addErrback(event_err, p)\n            p.deferreds.append(d)\n\n    # replace lists of deferreds with single Deferreds\n    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def select(self, query: ast.Select) -> pd.DataFrame:\n\n        conditions = extract_comparison_conditions(query.where)\n        urls = []\n        for op, arg1, arg2 in conditions:\n\n            if op == 'or':\n                raise NotImplementedError(f'OR is not supported')\n\n            if arg1 == 'url':\n                url = arg2\n\n                if op == '=':\n                    urls = [str(url)]\n                elif op == 'in':\n                    if type(url) == str:\n                        urls = [str(url)]\n                    else:\n                        urls = url\n                else:\n                    raise NotImplementedError(\n                        f'url can be url = \"someurl\", you can also crawl multiple sites, as follows: url IN (\"url1\", \"url2\", ..)')\n\n            else:\n                pass\n\n        if len(urls) == 0:\n            raise NotImplementedError(\n                f'You must specify what url you want to crawl, for example: SELECT * FROM crawl WHERE url IN (\"someurl\", ..)')\n\n        if query.limit is None:\n            raise NotImplementedError(f'You must specify a LIMIT which defines the number of pages to crawl')\n        limit = query.limit.value\n\n        if limit < 0:\n            limit = 0\n            \n        result = get_all_websites(urls, limit, html=False)\n        if len(result) > limit:\n            result = result[:limit]\n        # filter targets\n        result = project_dataframe(result, query.targets, self.get_columns())\n        return result\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        hs: \"HomeServer\",\n        treq_args: Dict[str, Any] = {},\n        ip_whitelist: Optional[IPSet] = None,\n        ip_blacklist: Optional[IPSet] = None,\n        http_proxy: Optional[bytes] = None,\n        https_proxy: Optional[bytes] = None,\n    ):\n        \"\"\"\n        Args:\n            hs\n            treq_args: Extra keyword arguments to be given to treq.request.\n            ip_blacklist: The IP addresses that are blacklisted that\n                we may not request.\n            ip_whitelist: The whitelisted IP addresses, that we can\n               request if it were otherwise caught in a blacklist.\n            http_proxy: proxy server to use for http connections. host[:port]\n            https_proxy: proxy server to use for https connections. host[:port]\n        \"\"\"\n        self.hs = hs\n\n        self._ip_whitelist = ip_whitelist\n        self._ip_blacklist = ip_blacklist\n        self._extra_treq_args = treq_args\n\n        self.user_agent = hs.version_string\n        self.clock = hs.get_clock()\n        if hs.config.user_agent_suffix:\n            self.user_agent = \"%s %s\" % (self.user_agent, hs.config.user_agent_suffix)\n\n        # We use this for our body producers to ensure that they use the correct\n        # reactor.\n        self._cooperator = Cooperator(scheduler=_make_scheduler(hs.get_reactor()))\n\n        self.user_agent = self.user_agent.encode(\"ascii\")\n\n        if self._ip_blacklist:\n            real_reactor = hs.get_reactor()\n            # If we have an IP blacklist, we need to use a DNS resolver which\n            # filters out blacklisted IP addresses, to prevent DNS rebinding.\n            nameResolver = IPBlacklistingResolver(\n                real_reactor, self._ip_whitelist, self._ip_blacklist\n            )\n\n            @implementer(IReactorPluggableNameResolver)\n            class Reactor:\n                def __getattr__(_self, attr):\n                    if attr == \"nameResolver\":\n                        return nameResolver\n                    else:\n                        return getattr(real_reactor, attr)\n\n            self.reactor = Reactor()\n        else:\n            self.reactor = hs.get_reactor()\n\n        # the pusher makes lots of concurrent SSL connections to sygnal, and\n        # tends to do so in batches, so we need to allow the pool to keep\n        # lots of idle connections around.\n        pool = HTTPConnectionPool(self.reactor)\n        # XXX: The justification for using the cache factor here is that larger instances\n        # will need both more cache and more connections.\n        # Still, this should probably be a separate dial\n        pool.maxPersistentPerHost = max((100 * hs.config.caches.global_factor, 5))\n        pool.cachedConnectionTimeout = 2 * 60\n\n        self.agent = ProxyAgent(\n            self.reactor,\n            connectTimeout=15,\n            contextFactory=self.hs.get_http_client_context_factory(),\n            pool=pool,\n            http_proxy=http_proxy,\n            https_proxy=https_proxy,\n        )\n\n        if self._ip_blacklist:\n            # If we have an IP blacklist, we then install the blacklisting Agent\n            # which prevents direct access to IP addresses, that are not caught\n            # by the DNS resolution.\n            self.agent = BlacklistingAgentWrapper(\n                self.agent,\n                ip_whitelist=self._ip_whitelist,\n                ip_blacklist=self._ip_blacklist,\n            )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus Resize(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteLSHProjectionParams*>(node->builtin_data);\n  TF_LITE_ENSURE(context, NumInputs(node) == 2 || NumInputs(node) == 3);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* hash;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(hash), 2);\n  // Support up to 32 bits.\n  TF_LITE_ENSURE(context, SizeOfDimension(hash, 1) <= 32);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n  TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n\n  if (NumInputs(node) == 3) {\n    const TfLiteTensor* weight;\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &weight));\n    TF_LITE_ENSURE_EQ(context, NumDimensions(weight), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(weight, 0),\n                      SizeOfDimension(input, 0));\n  }\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n  switch (params->type) {\n    case kTfLiteLshProjectionSparse:\n      outputSize->data[0] = SizeOfDimension(hash, 0);\n      break;\n    case kTfLiteLshProjectionDense:\n      outputSize->data[0] = SizeOfDimension(hash, 0) * SizeOfDimension(hash, 1);\n      break;\n    default:\n      return kTfLiteError;\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def collect_request_attributes(environ):\n    \"\"\"Collects HTTP request attributes from the PEP3333-conforming\n    WSGI environ and returns a dictionary to be used as span creation attributes.\n    \"\"\"\n\n    result = {\n        SpanAttributes.HTTP_METHOD: environ.get(\"REQUEST_METHOD\"),\n        SpanAttributes.HTTP_SERVER_NAME: environ.get(\"SERVER_NAME\"),\n        SpanAttributes.HTTP_SCHEME: environ.get(\"wsgi.url_scheme\"),\n    }\n\n    host_port = environ.get(\"SERVER_PORT\")\n    if host_port is not None and not host_port == \"\":\n        result.update({SpanAttributes.NET_HOST_PORT: int(host_port)})\n\n    setifnotnone(result, SpanAttributes.HTTP_HOST, environ.get(\"HTTP_HOST\"))\n    target = environ.get(\"RAW_URI\")\n    if target is None:  # Note: `\"\" or None is None`\n        target = environ.get(\"REQUEST_URI\")\n    if target is not None:\n        result[SpanAttributes.HTTP_TARGET] = target\n    else:\n        result[SpanAttributes.HTTP_URL] = remove_url_credentials(\n            wsgiref_util.request_uri(environ)\n        )\n\n    remote_addr = environ.get(\"REMOTE_ADDR\")\n    if remote_addr:\n        result[SpanAttributes.NET_PEER_IP] = remote_addr\n    remote_host = environ.get(\"REMOTE_HOST\")\n    if remote_host and remote_host != remote_addr:\n        result[SpanAttributes.NET_PEER_NAME] = remote_host\n\n    user_agent = environ.get(\"HTTP_USER_AGENT\")\n    if user_agent is not None and len(user_agent) > 0:\n        result[SpanAttributes.HTTP_USER_AGENT] = user_agent\n\n    setifnotnone(\n        result, SpanAttributes.NET_PEER_PORT, environ.get(\"REMOTE_PORT\")\n    )\n    flavor = environ.get(\"SERVER_PROTOCOL\", \"\")\n    if flavor.upper().startswith(_HTTP_VERSION_PREFIX):\n        flavor = flavor[len(_HTTP_VERSION_PREFIX) :]\n    if flavor:\n        result[SpanAttributes.HTTP_FLAVOR] = flavor\n\n    return result\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_conn(self) -> Connection:\n        \"\"\"Establish a connection to Drillbit.\"\"\"\n        conn_md = self.get_connection(getattr(self, self.conn_name_attr))\n        creds = f\"{conn_md.login}:{conn_md.password}@\" if conn_md.login else \"\"\n        if \"/\" in conn_md.host or \"&\" in conn_md.host:\n            raise ValueError(\"Drill host should not contain '/&' characters\")\n        engine = create_engine(\n            f'{conn_md.extra_dejson.get(\"dialect_driver\", \"drill+sadrill\")}://{creds}'\n            f\"{conn_md.host}:{conn_md.port}/\"\n            f'{conn_md.extra_dejson.get(\"storage_plugin\", \"dfs\")}'\n        )\n\n        self.log.info(\n            \"Connected to the Drillbit at %s:%s as user %s\", conn_md.host, conn_md.port, conn_md.login\n        )\n        return engine.raw_connection()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void PrepareTFPass::runOnOperation() {\n  MLIRContext *ctx = &getContext();\n  RewritePatternSet patterns(ctx);\n  RewritePatternSet phase_2_patterns(ctx);\n  auto func = getOperation();\n\n  // Check illegal ops in a TFLite pipeline (e.g. trainning only ops) , since\n  // PrepareTFPass is the very first TFLite pass in the pipeline.\n  // TODO(jingpu): It might be better to split this check into its own pass\n  // to make things more modular.\n  if (failed(ValidateOp(func))) {\n    func.emitError() << \"tfl-prepare-tf pass failed.\";\n    signalPassFailure();\n    return;\n  }\n\n  if (failed(ConvertTf2XlaOps(func, ctx))) {\n    signalPassFailure();\n    return;\n  }\n\n  // This pattern will try to identify and optimize for dilated convolution.\n  // e.g. Patterns like \"SpaceToBatchND -> Conv2D -> BatchToSpaceND\" will be\n  // replaced with a single Conv op with dilation parameter.\n  patterns.add<ConvertTFDilatedConvOp<TF::Conv2DOp>, FusedBatchNormV3Pat,\n               ConvertTFDilatedConvOp<TF::DepthwiseConv2dNativeOp>>(ctx);\n\n  patterns.add<RemoveIdentity>(ctx);\n  TFL::populateWithGenerated(patterns);\n  // TODO(karimnosseir): Split to separate pass probably after\n  // deciding on long term plan for this optimization.\n  // This will allow optimizing any TF_Mul->TF_Conv in the graph\n  // and any expanded from FusedBatchNorm. We need to do this\n  // before converting TF_Conv to TFL_Conv\n  (void)applyPatternsAndFoldGreedily(func, std::move(patterns));\n\n  // Remove the wrapper of the tf.FakeQuant* ops and also insert the\n  // tfl.quantize and tfl.dequantize to preserve the quantization parameters.\n  // This is done after the first round of optimization to make sure all the\n  // min/max operands of the tf.FakeQuant* are constants to be matched. The\n  // following round of optimization will folding the unwrapped\n  // tf.FakeQuant* ops with the weight constants.\n  if (failed(ConvertFakeQuantOps(func, ctx, use_fake_quant_num_bits_))) {\n    signalPassFailure();\n    return;\n  }\n\n  // Load the generated pattern again, so new quantization pass-through\n  // will be applied.\n  TFL::populateWithGenerated(phase_2_patterns);\n  if (unfold_batch_matmul_) {\n    TF::PopulateUnrollTfBatchMatMul(ctx, phase_2_patterns);\n  }\n  phase_2_patterns\n      .add<TF::ConvertTFEinsumOp, ConvertTFBroadcastTo, ConvertTFStridedSlice,\n           ConvertRfftToRfft2d, RemoveIdentity>(ctx);\n  phase_2_patterns.add<ConvertTFConv2D, ConvertTFDepthwiseConv2dNative>(\n      ctx, allow_bf16_and_f16_type_legalization_);\n\n  (void)applyPatternsAndFoldGreedily(func, std::move(phase_2_patterns));\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def icalc(self, irc, msg, args, text):\n        \"\"\"<math expression>\n\n        This is the same as the calc command except that it allows integer\n        math, and can thus cause the bot to suck up CPU.  Hence it requires\n        the 'trusted' capability to use.\n        \"\"\"\n        if self._calc_match_forbidden_chars.match(text):\n            # Note: this is important to keep this to forbid usage of\n            # __builtins__\n            irc.error(_('There\\'s really no reason why you should have '\n                           'underscores or brackets in your mathematical '\n                           'expression.  Please remove them.'))\n            return\n        # This removes spaces, too, but we'll leave the removal of _[] for\n        # safety's sake.\n        text = self._calc_remover(text)\n        if 'lambda' in text:\n            irc.error(_('You can\\'t use lambda in this command.'))\n            return\n        text = text.replace('lambda', '')\n        try:\n            self.log.info('evaluating %q from %s', text, msg.prefix)\n            irc.reply(str(eval(text, self._mathEnv, self._mathEnv)))\n        except OverflowError:\n            maxFloat = math.ldexp(0.9999999999999999, 1024)\n            irc.error(_('The answer exceeded %s or so.') % maxFloat)\n        except TypeError:\n            irc.error(_('Something in there wasn\\'t a valid number.'))\n        except NameError as e:\n            irc.error(_('%s is not a defined function.') % str(e).split()[1])\n        except Exception as e:\n            irc.error(utils.exnToString(e))\n    icalc = wrap(icalc, [('checkCapability', 'trusted'), 'text'])"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _configure_handlers(cls, app):\n        \"\"\"\n        Register error handlers.\n        \"\"\"\n        for exc, fn in cls.FLASK_ERROR_HANDLERS:\n            app.register_error_handler(exc, fn)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _parse_data(self, data: bytes, *, start: bool) -> tuple[bytes, int, bool]:\n        # Body parts must start with CRLF (or CR or LF)\n        if start:\n            match = LINE_BREAK_RE.match(data)\n            data_start = t.cast(t.Match[bytes], match).end()\n        else:\n            data_start = 0\n\n        if self.buffer.find(b\"--\" + self.boundary) == -1:\n            # No complete boundary in the buffer, but there may be\n            # a partial boundary at the end. As the boundary\n            # starts with either a nl or cr find the earliest and\n            # return up to that as data.\n            data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            more_data = True\n        else:\n            match = self.boundary_re.search(data)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data_end = match.start()\n                del_index = match.end()\n            else:\n                data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            more_data = match is None\n\n        return bytes(data[data_start:data_end]), del_index, more_data\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def pretty(self, n, comment=True):\n        if isinstance(n, str):\n            return repr(n)\n        if not isinstance(n, six.integer_types):\n            return n\n        if isinstance(n, constants.Constant):\n            if comment: return '%s /* %s */' % (n,self.pretty(int(n)))\n            else:       return '%s (%s)'     % (n,self.pretty(int(n)))\n        elif abs(n) < 10:\n            return str(n)\n        else:\n            return hex(n)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ImmutableExecutorState::BuildControlFlowInfo(const Graph* g,\n                                                    ControlFlowInfo* cf_info) {\n  const int num_nodes = g->num_node_ids();\n  cf_info->frame_names.resize(num_nodes);\n  std::vector<Node*> parent_nodes;\n  parent_nodes.resize(num_nodes);\n  std::vector<bool> visited;\n  visited.resize(num_nodes);\n\n  string frame_name;\n  std::deque<Node*> ready;\n\n  // Initialize with the root nodes.\n  for (Node* n : g->nodes()) {\n    if (n->in_edges().empty()) {\n      visited[n->id()] = true;\n      cf_info->unique_frame_names.insert(frame_name);\n      ready.push_back(n);\n    }\n  }\n\n  while (!ready.empty()) {\n    Node* curr_node = ready.front();\n    int curr_id = curr_node->id();\n    ready.pop_front();\n\n    Node* parent = nullptr;\n    if (IsEnter(curr_node)) {\n      // Enter a child frame.\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(curr_node->attrs(), \"frame_name\", &frame_name));\n      parent = curr_node;\n    } else if (IsExit(curr_node)) {\n      // Exit to the parent frame.\n      parent = parent_nodes[curr_id];\n      frame_name = cf_info->frame_names[parent->id()];\n      parent = parent_nodes[parent->id()];\n    } else {\n      parent = parent_nodes[curr_id];\n      frame_name = cf_info->frame_names[curr_id];\n    }\n\n    for (const Edge* out_edge : curr_node->out_edges()) {\n      Node* out = out_edge->dst();\n      if (IsSink(out)) continue;\n      const int out_id = out->id();\n\n      // Add to ready queue if not visited.\n      bool is_visited = visited[out_id];\n      if (!is_visited) {\n        ready.push_back(out);\n        visited[out_id] = true;\n\n        // Process the node 'out'.\n        cf_info->frame_names[out_id] = frame_name;\n        parent_nodes[out_id] = parent;\n        cf_info->unique_frame_names.insert(frame_name);\n      }\n    }\n  }\n\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def needs_clamp(t, encoding):\n    if encoding not in (Encoding.ABI, Encoding.JSON_ABI):\n        return False\n    if isinstance(t, (ByteArrayLike, DArrayType)):\n        if encoding == Encoding.JSON_ABI:\n            # don't have bytestring size bound from json, don't clamp\n            return False\n        return True\n    if isinstance(t, BaseType) and t.typ not in (\"int256\", \"uint256\", \"bytes32\"):\n        return True\n    if isinstance(t, SArrayType):\n        return needs_clamp(t.subtype, encoding)\n    if isinstance(t, TupleLike):\n        return any(needs_clamp(m, encoding) for m in t.tuple_members())\n    return False\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, instance, filename):\n        \"\"\"\n        Apply (if callable) or prepend (if a string) upload_to to the filename,\n        then delegate further processing of the name to the storage backend.\n        Until the storage layer, all file paths are expected to be Unix style\n        (with forward slashes).\n        \"\"\"\n        if callable(self.upload_to):\n            filename = self.upload_to(instance, filename)\n        else:\n            dirname = datetime.datetime.now().strftime(str(self.upload_to))\n            filename = posixpath.join(dirname, filename)\n        return self.storage.generate_filename(filename)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n                  DataType input_dtype, const TensorShape& input_tensor_shape,\n                  absl::Span<const int64_t> block_shape,\n                  const xla::Literal& paddings) {\n  const int input_rank = input_tensor_shape.dims();\n  const absl::InlinedVector<int64_t, 4> input_shape =\n      input_tensor_shape.dim_sizes();\n  const int block_rank = block_shape.size();\n\n  OP_REQUIRES(\n      ctx, input_rank >= 1 + block_rank,\n      errors::InvalidArgument(\"input rank should be >= \", 1 + block_rank,\n                              \" instead of \", input_rank));\n  absl::Span<const int64_t> remainder_shape(input_shape);\n  remainder_shape.remove_prefix(1 + block_rank);\n\n  OP_REQUIRES(\n      ctx,\n      paddings.shape().rank() == 2 &&\n          block_rank == xla::ShapeUtil::GetDimension(paddings.shape(), 0) &&\n          2 == xla::ShapeUtil::GetDimension(paddings.shape(), 1),\n      errors::InvalidArgument(\"paddings should have shape [\", block_rank,\n                              \", 2] instead of \",\n                              xla::ShapeUtil::HumanString(paddings.shape())));\n\n  xla::XlaBuilder* b = ctx->builder();\n\n  // 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n  //  input according to `paddings` to produce `padded` of shape `padded_shape`.\n  xla::PaddingConfig padding_config;\n  std::vector<int64_t> padded_shape(input_shape.begin(), input_shape.end());\n  int64_t block_num_elems = 1LL;\n  padding_config.add_dimensions();  // Don't pad the batch dimension.\n  for (int i = 0; i < block_rank; ++i) {\n    auto* dim = padding_config.add_dimensions();\n    int64_t pad_start = paddings.Get<int64_t>({i, 0});\n    int64_t pad_end = paddings.Get<int64_t>({i, 1});\n    OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,\n                errors::InvalidArgument(\"Paddings must be non-negative\"));\n    dim->set_edge_padding_low(pad_start);\n    dim->set_edge_padding_high(pad_end);\n    padded_shape[1 + i] += pad_start + pad_end;\n    block_num_elems *= block_shape[i];\n  }\n  // Don't pad the remainder dimensions.\n  for (int i = 0; i < remainder_shape.size(); ++i) {\n    padding_config.add_dimensions();\n  }\n  OP_REQUIRES(ctx, block_num_elems > 0,\n              errors::InvalidArgument(\n                  \"The product of the block dimensions must be positive\"));\n\n  xla::XlaOp padded =\n      xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);\n\n  // 2. Reshape `padded` to `reshaped_padded` of shape:\n  //\n  //      [batch] +\n  //      [padded_shape[1] / block_shape[0],\n  //        block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1],\n  //       block_shape[M-1]] +\n  //      remaining_shape\n  const int64_t batch_size = input_shape[0];\n  std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);\n  reshaped_padded_shape[0] = batch_size;\n  for (int i = 0; i < block_rank; ++i) {\n    OP_REQUIRES(ctx, padded_shape[1 + i] % block_shape[i] == 0,\n                errors::InvalidArgument(\"padded_shape[\", 1 + i,\n                                        \"]=\", padded_shape[1 + i],\n                                        \" is not divisible by block_shape[\", i,\n                                        \"]=\", block_shape[i]));\n\n    reshaped_padded_shape[1 + i * 2] = padded_shape[1 + i] / block_shape[i];\n    reshaped_padded_shape[1 + i * 2 + 1] = block_shape[i];\n  }\n  std::copy(remainder_shape.begin(), remainder_shape.end(),\n            reshaped_padded_shape.begin() + 1 + 2 * block_rank);\n\n  xla::XlaOp reshaped_padded = xla::Reshape(padded, reshaped_padded_shape);\n\n  // 3. Permute dimensions of `reshaped_padded` to produce\n  //    `permuted_reshaped_padded` of shape:\n  //\n  //      block_shape +\n  //      [batch] +\n  //      [padded_shape[1] / block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1]] +\n  //      remaining_shape\n  std::vector<int64_t> permutation(reshaped_padded_shape.size());\n  for (int i = 0; i < block_rank; ++i) {\n    permutation[i] = 1 + 2 * i + 1;\n    permutation[block_rank + 1 + i] = 1 + 2 * i;\n  }\n  permutation[block_rank] = 0;\n  std::iota(permutation.begin() + 1 + block_rank * 2, permutation.end(),\n            1 + block_rank * 2);\n  xla::XlaOp permuted_reshaped_padded =\n      xla::Transpose(reshaped_padded, permutation);\n\n  // 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the\n  //    batch dimension, producing an output tensor of shape:\n  //\n  //      [batch * prod(block_shape)] +\n  //      [padded_shape[1] / block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1]] +\n  //      remaining_shape\n  // Determine the length of the prefix of block dims that can be combined\n  // into the batch dimension due to having no padding and block_shape=1.\n  std::vector<int64_t> output_shape(input_rank);\n  output_shape[0] = batch_size * block_num_elems;\n  for (int i = 0; i < block_rank; ++i) {\n    output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];\n  }\n  std::copy(remainder_shape.begin(), remainder_shape.end(),\n            output_shape.begin() + 1 + block_rank);\n\n  xla::XlaOp output = xla::Reshape(permuted_reshaped_padded, output_shape);\n  ctx->SetOutput(0, output);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "inline Status SparseTensor::Split(const SparseTensor& input_tensor,\n                                  const int split_dim, const int num_split,\n                                  std::vector<SparseTensor>* result) {\n  std::vector<Tensor> output_indices;\n  std::vector<Tensor> output_values;\n  std::vector<TensorShape> output_shapes;\n  output_indices.reserve(num_split);\n  output_values.reserve(num_split);\n  output_shapes.reserve(num_split);\n\n  std::vector<typename TTypes<int64>::Matrix> output_indices_t;\n  std::vector<typename TTypes<T>::Vec> output_values_t;\n  output_indices_t.reserve(num_split);\n  output_values_t.reserve(num_split);\n  auto input_values_t = input_tensor.values().vec<T>();\n  auto input_indices_t = input_tensor.indices().matrix<int64>();\n\n  std::vector<int> num_values(num_split, 0);\n  const int num_dim = input_tensor.shape().size();\n  const int split_dim_size = input_tensor.shape()[split_dim];\n  const int split_size = split_dim_size / num_split;\n\n  if (!(num_split > 0 && num_split <= split_dim_size)) {\n    return errors::InvalidArgument(\"num_split must be in the interval (0, \",\n                                   split_dim_size, \"]\");\n  }\n  if (!(split_dim >= 0 && split_dim < num_dim)) {\n    return errors::InvalidArgument(\"num_dim must be in the interval [0, \",\n                                   num_dim, \")\");\n  }\n\n  const int residual = split_dim_size % num_split;\n  for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n    const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\n    int slice_index = GetSliceIndex(dim, split_size, residual);\n    num_values[slice_index]++;\n  }\n\n  for (int i = 0; i < num_split; ++i) {\n    // TODO(ataei): Pass an allocator to avoid allocating large memory buffer.\n    output_indices.emplace_back(DT_INT64,\n                                TensorShape({num_values[i], num_dim}));\n    output_values.emplace_back(DataTypeToEnum<T>::v(),\n                               TensorShape({num_values[i]}));\n    output_shapes.emplace_back(input_tensor.shape());\n    output_indices_t.emplace_back(output_indices[i].matrix<int64>());\n    output_values_t.emplace_back(output_values[i].vec<T>());\n    const int size = GetSliceShape(i, split_size, residual);\n    output_shapes[i].set_dim(split_dim, size);\n  }\n\n  std::vector<int> values_inserted_in_slice(num_split, 0);\n  for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n    const int dim = input_indices_t(i, split_dim);\n    const int slice_index = GetSliceIndex(dim, split_size, residual);\n    const int slice_dim = values_inserted_in_slice[slice_index]++;\n    output_values_t[slice_index](slice_dim) = input_values_t(i);\n    for (int j = 0; j < num_dim; ++j) {\n      const int64 original_dim = input_indices_t(i, j);\n      output_indices_t[slice_index](slice_dim, j) =\n          (j == split_dim)\n              ? GetDimensionInSlice(original_dim, split_size, residual)\n              : original_dim;\n    }\n  }\n\n  result->clear();\n  result->reserve(num_split);\n  for (int i = 0; i < num_split; ++i) {\n    SparseTensor tensor;\n    Status create_status =\n        Create(output_indices[i], output_values[i], output_shapes[i], &tensor);\n    if (!create_status.ok()) {\n      return create_status;\n    }\n    result->push_back(std::move(tensor));\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _recv_packet(self) -> bool:\n        \"\"\"Receive the remainder of an SSH packet and process it\"\"\"\n\n        rem = 4 + self._pktlen + self._recv_macsize - self._recv_blocksize\n        if len(self._inpbuf) < rem:\n            return False\n\n        seq = self._recv_seq\n        rest = self._inpbuf[:rem-self._recv_macsize]\n        mac = self._inpbuf[rem-self._recv_macsize:rem]\n\n        if self._recv_encryption:\n            packet_data = self._recv_encryption.decrypt_packet(\n                seq, self._packet, rest, 4, mac)\n\n            if not packet_data:\n                raise MACError('MAC verification failed')\n        else:\n            packet_data = self._packet[4:] + rest\n\n        self._inpbuf = self._inpbuf[rem:]\n        self._packet = b''\n\n        orig_payload = packet_data[1:-packet_data[0]]\n\n        if self._decompressor and (self._auth_complete or\n                                   not self._decompress_after_auth):\n            payload = self._decompressor.decompress(orig_payload)\n\n            if payload is None:\n                raise CompressionError('Decompression failed')\n        else:\n            payload = orig_payload\n\n        packet = SSHPacket(payload)\n        pkttype = packet.get_byte()\n        handler: SSHPacketHandler = self\n        skip_reason = ''\n        exc_reason = ''\n\n        if MSG_KEX_FIRST <= pkttype <= MSG_KEX_LAST:\n            if self._kex:\n                if self._ignore_first_kex: # pragma: no cover\n                    skip_reason = 'ignored first kex'\n                    self._ignore_first_kex = False\n                else:\n                    handler = self._kex\n            else:\n                skip_reason = 'kex not in progress'\n                exc_reason = 'Key exchange not in progress'\n        elif MSG_USERAUTH_FIRST <= pkttype <= MSG_USERAUTH_LAST:\n            if self._auth:\n                handler = self._auth\n            else:\n                skip_reason = 'auth not in progress'\n                exc_reason = 'Authentication not in progress'\n        elif pkttype > MSG_KEX_LAST and not self._recv_encryption:\n            skip_reason = 'invalid request before kex complete'\n            exc_reason = 'Invalid request before key exchange was complete'\n        elif pkttype > MSG_USERAUTH_LAST and not self._auth_complete:\n            skip_reason = 'invalid request before auth complete'\n            exc_reason = 'Invalid request before authentication was complete'\n        elif MSG_CHANNEL_FIRST <= pkttype <= MSG_CHANNEL_LAST:\n            try:\n                recv_chan = packet.get_uint32()\n            except PacketDecodeError:\n                skip_reason = 'incomplete channel request'\n                exc_reason = 'Incomplete channel request received'\n            else:\n                try:\n                    handler = self._channels[recv_chan]\n                except KeyError:\n                    skip_reason = 'invalid channel number'\n                    exc_reason = 'Invalid channel number %d ' \\\n                                 'received' % recv_chan\n\n        handler.log_received_packet(pkttype, seq, packet, skip_reason)\n\n        if not skip_reason:\n            try:\n                processed = handler.process_packet(pkttype, seq, packet)\n            except PacketDecodeError as exc:\n                raise ProtocolError(str(exc)) from None\n\n            if not processed:\n                self.logger.debug1('Unknown packet type %d received', pkttype)\n                self.send_packet(MSG_UNIMPLEMENTED, UInt32(seq))\n\n        if exc_reason:\n            raise ProtocolError(exc_reason)\n\n        if pkttype > MSG_USERAUTH_LAST:\n            self._auth_final = True\n\n        if self._transport:\n            self._recv_seq = (seq + 1) & 0xffffffff\n            self._recv_handler = self._recv_pkthdr\n\n        return True\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void DoRealForwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                        const Tensor& in, Tensor* out) {\n    // Create the axes (which are always trailing).\n    const auto axes = Eigen::ArrayXi::LinSpaced(FFTRank, 1, FFTRank);\n    auto device = ctx->eigen_device<CPUDevice>();\n    auto input = Tensor(in).flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Slice input to fft_shape on its inner-most dimensions.\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape temp_shape{input_dims[0]};\n    for (int i = 1; i <= FFTRank; ++i) {\n      input_slice_sizes[i] = fft_shape[i - 1];\n      temp_shape.AddDim(fft_shape[i - 1]);\n    }\n\n    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n\n    // Compute the full FFT using a temporary tensor.\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           temp_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n    full_fft.device(device) =\n        input.slice(zero_start_indices, input_slice_sizes)\n            .template fft<Eigen::BothParts, Eigen::FFT_FORWARD>(axes);\n\n    // Slice away the negative frequency components.\n    output.device(device) =\n        full_fft.slice(zero_start_indices, output.dimensions());\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // dense_shape.  Also add check that dense rank > 0.\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def template(request, name, val):\n  template_conf_missing = False\n\n  try:\n    config.check()\n  except OSError as e:\n    if e.errno == errno.ENOENT:\n      template_conf_missing = True\n    else:\n      raise\n\n  initialError = None\n  debug = request.GET.get('debug', False)\n  theme = request.GET.get('theme', config.ui_config['theme'])\n  css_file = finders.find('css/dashboard-%s.css' % theme)\n  if css_file is None:\n    initialError = \"Invalid theme '%s'\" % theme\n    theme = config.ui_config['theme']\n\n  context = {\n    'schemes_json' : json.dumps(config.schemes),\n    'ui_config_json' : json.dumps(config.ui_config),\n    'jsdebug' : debug or settings.JAVASCRIPT_DEBUG,\n    'debug' : debug,\n    'theme' : theme,\n    'initialError' : initialError,\n    'querystring' : json.dumps( dict( request.GET.items() ) ),\n    'template_conf_missing' : template_conf_missing,\n    'userName': '',\n    'permissions': json.dumps(getPermissions(request.user)),\n    'permissionsUnauthenticated': json.dumps(getPermissions(None))\n  }\n\n  user = request.user\n  if user:\n      context['userName'] = user.username\n\n  try:\n    template = Template.objects.get(name=name)\n  except Template.DoesNotExist:\n    context['initialError'] = \"Template '%s' does not exist.\" % name\n  else:\n    state = json.loads(template.loadState(val))\n    state['name'] = '%s/%s' % (name, val)\n    context['initialState'] = json.dumps(state)\n  return render(request, \"dashboard.html\", context)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def get_resolved_ref(self):\n        if hasattr(self, 'resolved_ref'):\n            return self.resolved_ref\n\n        try:\n            # Check if the reference is a valid SHA hash\n            self.sha1_validate(self.unresolved_ref)\n        except ValueError:\n            # The ref is a head/tag and we resolve it using `git ls-remote`\n            command = [\"git\", \"ls-remote\", self.repo, self.unresolved_ref]\n            result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            if result.returncode:\n                raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n            if not result.stdout:\n                return None\n            resolved_ref = result.stdout.split(None, 1)[0]\n            self.sha1_validate(resolved_ref)\n            self.resolved_ref = resolved_ref\n        else:\n            # The ref already was a valid SHA hash\n            self.resolved_ref = self.unresolved_ref\n\n        return self.resolved_ref\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _redirect_safe(self, url, default=None):\n        \"\"\"Redirect if url is on our PATH\n\n        Full-domain redirects are allowed if they pass our CORS origin checks.\n\n        Otherwise use default (self.base_url if unspecified).\n        \"\"\"\n        if default is None:\n            default = self.base_url\n        # protect chrome users from mishandling unescaped backslashes.\n        # \\ is not valid in urls, but some browsers treat it as /\n        # instead of %5C, causing `\\\\` to behave as `//`\n        url = url.replace(\"\\\\\", \"%5C\")\n        parsed = urlparse(url)\n        if parsed.netloc or not (parsed.path + \"/\").startswith(self.base_url):\n            # require that next_url be absolute path within our path\n            allow = False\n            # OR pass our cross-origin check\n            if parsed.netloc:\n                # if full URL, run our cross-origin check:\n                origin = f\"{parsed.scheme}://{parsed.netloc}\"\n                origin = origin.lower()\n                if self.allow_origin:\n                    allow = self.allow_origin == origin\n                elif self.allow_origin_pat:\n                    allow = bool(re.match(self.allow_origin_pat, origin))\n            if not allow:\n                # not allowed, use default\n                self.log.warning(\"Not allowing login redirect to %r\" % url)\n                url = default\n        self.redirect(url)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check(request):\n   \"\"\"\n   Shows a page with the results of 'cobbler check'\n   \"\"\"\n   if not test_user_authenticated(request): return login(request, next=\"/cobbler_web/check\")\n   results = remote.check(request.session['token'])\n   t = get_template('check.tmpl')\n   html = t.render(Context({\n       'version': remote.version(request.session['token']),\n       'username' : username,\n       'results'  : results\n   }))\n   return HttpResponse(html)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def put_file(path):\n    try:\n        dest_path = sanitized_join(\n            path,\n            pathlib.Path(app.config[\"DATA_ROOT\"]),\n        )\n    except ValueError:\n        return flask.Response(\n            \"Not Found\",\n            404,\n            mimetype=\"text/plain\",\n        )\n\n    verification_key = flask.request.args.get(\"v\", \"\")\n    length = int(flask.request.headers.get(\"Content-Length\", 0))\n    hmac_input = \"{} {}\".format(path, length).encode(\"utf-8\")\n    key = app.config[\"SECRET_KEY\"]\n    mac = hmac.new(key, hmac_input, hashlib.sha256)\n    digest = mac.hexdigest()\n\n    if not hmac.compare_digest(digest, verification_key):\n        return flask.Response(\n            \"Invalid verification key\",\n            403,\n            mimetype=\"text/plain\",\n        )\n\n    content_type = flask.request.headers.get(\n        \"Content-Type\",\n        \"application/octet-stream\",\n    )\n\n    dest_path.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n    data_file, metadata_file = get_paths(dest_path)\n\n    try:\n        with write_file(data_file) as fout:\n            stream_file(flask.request.stream, fout, length)\n\n            with metadata_file.open(\"x\") as f:\n                json.dump(\n                    {\n                        \"headers\": {\"Content-Type\": content_type},\n                    },\n                    f,\n                )\n    except EOFError:\n        return flask.Response(\n            \"Bad Request\",\n            400,\n            mimetype=\"text/plain\",\n        )\n    except OSError as exc:\n        if exc.errno == errno.EEXIST:\n            return flask.Response(\n                \"Conflict\",\n                409,\n                mimetype=\"text/plain\",\n            )\n        raise\n\n    return flask.Response(\n        \"Created\",\n        201,\n        mimetype=\"text/plain\",\n    )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  explicit ReverseSequenceOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def delete_service(self, context, service_id):\n        service_ref = self.catalog_api.get_service(context, service_id)\n        if not service_ref:\n            raise exception.ServiceNotFound(service_id=service_id)\n        self.catalog_api.delete_service(context, service_id)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def clone(\n        self,\n        pdf_dest: Any,\n        force_duplicate: bool = False,\n        ignore_fields: Optional[Sequence[Union[str, int]]] = (),\n    ) -> \"ContentStream\":\n        \"\"\"\n        Clone object into pdf_dest.\n\n        Args:\n            pdf_dest:\n            force_duplicate:\n            ignore_fields:\n\n        Returns:\n            The cloned ContentStream\n        \"\"\"\n        try:\n            if self.indirect_reference.pdf == pdf_dest and not force_duplicate:  # type: ignore\n                return self\n        except Exception:\n            pass\n\n        d__ = cast(\n            \"ContentStream\",\n            self._reference_clone(\n                self.__class__(None, None), pdf_dest, force_duplicate\n            ),\n        )\n        if ignore_fields is None:\n            ignore_fields = []\n        d__._clone(self, pdf_dest, force_duplicate, ignore_fields)\n        return d__\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ValidateInputs(OpKernelContext* ctx,\n                      const CSRSparseMatrix& sparse_matrix,\n                      const Tensor& permutation_indices, int* batch_size,\n                      int64* num_rows) {\n    OP_REQUIRES(ctx, sparse_matrix.dtype() == DataTypeToEnum<T>::value,\n                errors::InvalidArgument(\n                    \"Asked for a CSRSparseMatrix of type \",\n                    DataTypeString(DataTypeToEnum<T>::value),\n                    \" but saw dtype: \", DataTypeString(sparse_matrix.dtype())));\n\n    const Tensor& dense_shape = sparse_matrix.dense_shape();\n    const int rank = dense_shape.dim_size(0);\n    OP_REQUIRES(ctx, rank == 2 || rank == 3,\n                errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n                                        \"but dense_shape has size \", rank));\n    const int row_dim = (rank == 2) ? 0 : 1;\n    auto dense_shape_vec = dense_shape.vec<int64>();\n    *num_rows = dense_shape_vec(row_dim);\n    const int64 num_cols = dense_shape_vec(row_dim + 1);\n    OP_REQUIRES(ctx, *num_rows == num_cols,\n                errors::InvalidArgument(\"sparse matrix must be square; got: \",\n                                        *num_rows, \" != \", num_cols));\n    const TensorShape& perm_shape = permutation_indices.shape();\n    OP_REQUIRES(\n        ctx, perm_shape.dims() + 1 == rank,\n        errors::InvalidArgument(\n            \"sparse matrix must have the same rank as permutation; got: \", rank,\n            \" != \", perm_shape.dims(), \" + 1.\"));\n    OP_REQUIRES(\n        ctx, perm_shape.dim_size(rank - 2) == *num_rows,\n        errors::InvalidArgument(\n            \"permutation must have the same number of elements in each batch \"\n            \"as the number of rows in sparse matrix; got: \",\n            perm_shape.dim_size(rank - 2), \" != \", *num_rows));\n\n    *batch_size = sparse_matrix.batch_size();\n    if (*batch_size > 1) {\n      OP_REQUIRES(\n          ctx, perm_shape.dim_size(0) == *batch_size,\n          errors::InvalidArgument(\"permutation must have the same batch size \"\n                                  \"as sparse matrix; got: \",\n                                  perm_shape.dim_size(0), \" != \", *batch_size));\n    }\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def event_from_pdu_json(pdu_json, outlier=False):\n    \"\"\"Construct a FrozenEvent from an event json received over federation\n\n    Args:\n        pdu_json (object): pdu as received over federation\n        outlier (bool): True to mark this event as an outlier\n\n    Returns:\n        FrozenEvent\n\n    Raises:\n        SynapseError: if the pdu is missing required fields\n    \"\"\"\n    # we could probably enforce a bunch of other fields here (room_id, sender,\n    # origin, etc etc)\n    assert_params_in_request(pdu_json, ('event_id', 'type'))\n    event = FrozenEvent(\n        pdu_json\n    )\n\n    event.internal_metadata.outlier = outlier\n\n    return event\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_document_field_display(self, field_name, field):\n        \"\"\"Render a link to a document\"\"\"\n        document = getattr(self.instance, field_name)\n        if document:\n            return mark_safe(\n                '<a href=\"%s\">%s <span class=\"meta\">(%s, %s)</span></a>'\n                % (\n                    document.url,\n                    document.title,\n                    document.file_extension.upper(),\n                    filesizeformat(document.file.size),\n                )\n            )\n        return self.model_admin.get_empty_value_display(field_name)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void ImmutableConstantOp::Compute(OpKernelContext* ctx) {\n  std::unique_ptr<MemmappedTensorAllocator> allocator(\n      new MemmappedTensorAllocator());\n\n  OP_REQUIRES_OK(ctx,\n                 allocator->InitializeFromRegion(region_name_, ctx->env()));\n  ctx->set_output(0, Tensor(allocator.get(), dtype_, shape_));\n  OP_REQUIRES_OK(ctx, allocator->allocation_status());\n  // Allocator is owned by the tensor from this point.\n  allocator.release()->set_delete_on_deallocate();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _wget_download(url, fullname):\n    # using wget to download url\n    tmp_fullname = fullname + \"_tmp\"\n    # \u2013user-agent\n    command = f'wget -O {tmp_fullname} -t {DOWNLOAD_RETRY_LIMIT} {url}'\n    subprc = subprocess.Popen(\n        command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n    )\n    _ = subprc.communicate()\n\n    if subprc.returncode != 0:\n        raise RuntimeError(\n            f'{command} failed. Please make sure `wget` is installed or {url} exists'\n        )\n\n    shutil.move(tmp_fullname, fullname)\n\n    return fullname\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def have_responded(self, transaction):\n        \"\"\" Have we already responded to a transaction with the same id and\n        origin?\n\n        Returns:\n            Deferred: Results in `None` if we have not previously responded to\n            this transaction or a 2-tuple of `(int, dict)` representing the\n            response code and response body.\n        \"\"\"\n        if not transaction.transaction_id:\n            raise RuntimeError(\"Cannot persist a transaction with no \"\n                               \"transaction_id\")\n\n        return self.store.get_received_txn_response(\n            transaction.transaction_id, transaction.origin\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self, *,\n        deserializer: AbstractDeserializer,\n        serializer: AbstractSerializer,\n        connect: AbstractAddress = None,\n        bind: AbstractAddress = None,\n        transport: Type[BaseTransport] = None,\n        authenticator: AbstractAuthenticator = None,\n        transport_opts: Mapping[str, Any] = {},\n        scheduler: AbstractAsyncScheduler = None,\n        compress: bool = True,\n        max_body_size: int = 10 * (2**20),  # 10 MiBytes\n        max_concurrency: int = 100,\n        execute_timeout: float = None,\n        invoke_timeout: float = None,\n        debug_rpc: bool = False,\n    ) -> None:\n        if connect is None and bind is None:\n            raise ValueError('You must specify either the connect or bind address.')\n        self._connect = connect\n        self._bind = bind\n        self._opener = None\n        self._connection = None\n        self._compress = compress\n        self._deserializer = deserializer\n        self._serializer = serializer\n        self._max_concurrency = max_concurrency\n        self._exec_timeout = execute_timeout\n        self._invoke_timeout = invoke_timeout\n\n        self._scheduler = None\n        if transport is None:\n            raise ValueError('You must provide a transport class.')\n        self._transport = transport(authenticator=authenticator,\n                                    transport_opts=transport_opts)\n        self._func_registry = {}\n\n        self._seq_id = 0\n\n        # incoming queues\n        self._invocation_resolver = AsyncResolver()\n        if scheduler is None:\n            scheduler = KeySerializedAsyncScheduler()\n        self._func_scheduler = scheduler\n\n        # there is only one outgoing queue\n        self._outgoing_queue = asyncio.Queue()\n        self._recv_task = None\n        self._send_task = None\n\n        self._log = logging.getLogger(__name__ + '.Peer')\n        self._debug_rpc = debug_rpc\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const auto& input = context->input(0);\n    auto flat_in = input.flat<tstring>();\n\n    int fixed_length;\n    const auto& length_input = context->input(1);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(length_input.shape()),\n                errors::InvalidArgument(\"k must be scalar, got shape \",\n                                        length_input.shape().DebugString()));\n    fixed_length = length_input.scalar<int32>()();\n\n    OP_REQUIRES(\n        context, fixed_length % sizeof(T) == 0,\n        errors::InvalidArgument(\n            \"fixed_length (\", fixed_length,\n            \") must be a multiple of the size of out_type (\", sizeof(T), \")\"));\n\n    OP_REQUIRES(context, fixed_length > 0,\n                errors::InvalidArgument(\"fixed_length (\", fixed_length,\n                                        \") must be greater than zero.\"));\n\n    int width = fixed_length / sizeof(T);\n\n    TensorShape out_shape = input.shape();\n    out_shape.AddDim(width);\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"output\", out_shape, &output_tensor));\n\n    if (flat_in.size() == 0) {  // Empty input\n      return;\n    }\n\n    auto out = output_tensor->flat_inner_dims<T>();\n    T* out_data = out.data();\n\n    // Forcibly clear memory - we're going to copy variable length strings in,\n    // and need to ensure that if we don't write to byte N when we copy, that\n    // we're not getting random data.\n    memset(out_data, 0, fixed_length * flat_in.size());\n\n    // If the data is already in the host's byte order, or if the width of the\n    // output type is a single byte (meaning the ordering doesn't matter), we\n    // can copy the memory directly.\n    if (!convert_data_endianness_ || sizeof(T) == 1) {\n      for (int64 i = 0; i < flat_in.size(); ++i) {\n        const T* in_data = reinterpret_cast<const T*>(flat_in(i).data());\n\n        if (flat_in(i).size() > fixed_length) {\n          memcpy(out_data, in_data, fixed_length);\n        } else {\n          memcpy(out_data, in_data, flat_in(i).size());\n        }\n        out_data += fixed_length;\n      }\n    } else {\n      // Otherwise, the data is not in the host's byte order, and rather than a\n      // direct copy, we need to reverse the byte ordering of each element.\n      for (int64 i = 0; i < flat_in.size(); ++i) {\n        const char* in_data_bytes =\n            reinterpret_cast<const char*>(flat_in(i).data());\n        char* out_data_bytes = reinterpret_cast<char*>(out_data);\n        const char* p_in = in_data_bytes;\n        char* p_out = out_data_bytes;\n        for (; p_in < in_data_bytes + fixed_length;\n             p_in += sizeof(T), p_out += sizeof(T)) {\n          std::reverse_copy(p_in, p_in + sizeof(T), p_out);\n        }\n        out_data += fixed_length;\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def job_buttons(context, obj):\n    \"\"\"\n    Render all applicable job buttons for the given object.\n    \"\"\"\n    content_type = ContentType.objects.get_for_model(obj)\n    buttons = JobButton.objects.filter(content_types=content_type)\n    if not buttons:\n        return \"\"\n\n    # Pass select context data when rendering the JobButton\n    button_context = {\n        \"obj\": obj,\n        \"debug\": context.get(\"debug\", False),  # django.template.context_processors.debug\n        \"request\": context[\"request\"],  # django.template.context_processors.request\n        \"user\": context[\"user\"],  # django.contrib.auth.context_processors.auth\n        \"perms\": context[\"perms\"],  # django.contrib.auth.context_processors.auth\n    }\n    buttons_html = forms_html = mark_safe(\"\")  # noqa: S308\n    group_names = OrderedDict()\n\n    hidden_inputs = format_html(\n        HIDDEN_INPUTS,\n        csrf_token=context[\"csrf_token\"],\n        object_pk=obj.pk,\n        object_model_name=f\"{content_type.app_label}.{content_type.model}\",\n        redirect_path=context[\"request\"].path,\n    )\n\n    for jb in buttons:\n        template_args = {\n            \"button_id\": jb.pk,\n            \"button_text\": jb.text,\n            \"button_class\": jb.button_class,\n            \"button_url\": reverse(\"extras:jobbutton_run\", kwargs={\"pk\": jb.pk}),\n            \"object\": obj,\n            \"job\": jb.job,\n            \"hidden_inputs\": hidden_inputs,\n            \"disabled\": \"\" if context[\"user\"].has_perms((\"extras.run_jobbutton\", \"extras.run_job\")) else \"disabled\",\n        }\n\n        # Organize job buttons by group\n        if jb.group_name:\n            group_names.setdefault(jb.group_name, [])\n            group_names[jb.group_name].append(jb)\n\n        # Add non-grouped buttons\n        else:\n            try:\n                text_rendered = render_jinja2(jb.text, button_context)\n                if text_rendered:\n                    template_args[\"button_text\"] = text_rendered\n                    if jb.confirmation:\n                        buttons_html += format_html(CONFIRM_BUTTON, **template_args)\n                        forms_html += format_html(CONFIRM_MODAL, **template_args)\n                    else:\n                        buttons_html += format_html(NO_CONFIRM_BUTTON, **template_args)\n                        forms_html += format_html(NO_CONFIRM_FORM, **template_args)\n            except Exception as e:\n                buttons_html += format_html(\n                    '<a class=\"btn btn-sm btn-default\" disabled=\"disabled\" title=\"{}\">'\n                    '<i class=\"mdi mdi-alert\"></i> {}</a>\\n',\n                    e,\n                    jb.name,\n                )\n\n    # Add grouped buttons to template\n    for group_name, buttons in group_names.items():\n        group_button_class = buttons[0].button_class\n\n        buttons_rendered = mark_safe(\"\")  # noqa: S308\n\n        for jb in buttons:\n            template_args = {\n                \"button_id\": jb.pk,\n                \"button_text\": jb.text,\n                \"button_class\": \"link\",\n                \"button_url\": reverse(\"extras:jobbutton_run\", kwargs={\"pk\": jb.pk}),\n                \"object\": obj,\n                \"job\": jb.job,\n                \"hidden_inputs\": hidden_inputs,\n                \"disabled\": \"\" if context[\"user\"].has_perms((\"extras.run_jobbutton\", \"extras.run_job\")) else \"disabled\",\n            }\n            try:\n                text_rendered = render_jinja2(jb.text, button_context)\n                if text_rendered:\n                    template_args[\"button_text\"] = text_rendered\n                    if jb.confirmation:\n                        buttons_rendered += (\n                            mark_safe(\"<li>\")  # noqa: S308\n                            + format_html(CONFIRM_BUTTON, **template_args)\n                            + mark_safe(\"</li>\")  # noqa: S308\n                        )\n                        forms_html += format_html(CONFIRM_MODAL, **template_args)\n                    else:\n                        buttons_rendered += (\n                            mark_safe(\"<li>\")  # noqa: S308\n                            + format_html(NO_CONFIRM_BUTTON, **template_args)\n                            + mark_safe(\"</li>\")  # noqa: S308\n                        )\n                        forms_html += format_html(NO_CONFIRM_FORM, **template_args)\n            except Exception as e:\n                buttons_rendered += format_html(\n                    '<li><a disabled=\"disabled\" title=\"{}\"><span class=\"text-muted\">'\n                    '<i class=\"mdi mdi-alert\"></i> {}</span></a></li>',\n                    e,\n                    jb.name,\n                )\n\n        if buttons_rendered:\n            buttons_html += format_html(\n                GROUP_DROPDOWN,\n                group_button_class=group_button_class,\n                group_name=group_name,\n                grouped_buttons=buttons_rendered,\n            )\n\n    # We want all of the buttons first and then any modals and forms so the buttons render properly\n    return buttons_html + forms_html\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_many(self, keys, version=None):\n        key_map = {self.make_key(key, version=version): key for key in keys}\n        ret = self._cache.get_multi(key_map.keys())\n        return {key_map[k]: v for k, v in ret.items()}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // Also add check that dense rank > 0.\n  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n                    done);\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if not url:\n        return False\n    url_info = urlparse(url)\n    return (not url_info.netloc or url_info.netloc == host) and \\\n        (not url_info.scheme or url_info.scheme in ['http', 'https'])\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def to_xml(self) -> Optional[Any]:\n        \"\"\"\n        Convert to xml using dicttoxml.dicttoxml and then pretty print it.\n        \"\"\"\n        if self.data:\n            xml_data = dicttoxml.dicttoxml(\n                self.data,\n                root=self.root,\n                custom_root=self.wrapper,\n                attr_type=self.attr_type,\n                item_wrap=self.item_wrap,\n            )\n            if self.pretty:\n                return parseString(xml_data).toprettyxml()\n            return xml_data\n        return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def project_clone(request):\n    \"\"\"\n    clone project from github\n    :param request: request object\n    :return: json\n    \"\"\"\n    if request.method == 'POST':\n        data = json.loads(request.body)\n        address = data.get('address')\n        if not address.startswith('http'):\n            return JsonResponse({'status': False})\n        address = address + '.git' if not address.endswith('.git') else address\n        cmd = 'git clone {address} {target}'.format(address=address, target=join(PROJECTS_FOLDER, Path(address).stem))\n        logger.debug('clone cmd %s', cmd)\n        p = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\n        logger.debug('clone run result %s', stdout)\n        if stderr: logger.error(stderr)\n        return JsonResponse({'status': True}) if not stderr else JsonResponse({'status': False})\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(\n            context.new_internal_variable(ret_typ),\n            typ=ret_typ,\n            location=MEMORY,\n            annotation=\"concat destination\",\n        )\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    const findHeadingElement = (cell: Cell): void => {\n      model.getCellHeadings(cell).forEach(async heading => {\n        const elementId = await getIdForHeading(heading, this.parser!);\n\n        const selector = elementId\n          ? `h${heading.level}[id=\"${elementId}\"]`\n          : `h${heading.level}`;\n\n        if (heading.outputIndex !== undefined) {\n          // Code cell\n          headingToElement.set(\n            heading,\n            TableOfContentsUtils.addPrefix(\n              (heading.cellRef as CodeCell).outputArea.widgets[\n                heading.outputIndex\n              ].node,\n              selector,\n              heading.prefix ?? ''\n            )\n          );\n        } else {\n          headingToElement.set(\n            heading,\n            TableOfContentsUtils.addPrefix(\n              heading.cellRef.node,\n              selector,\n              heading.prefix ?? ''\n            )\n          );\n        }\n      });\n    };\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sqlalchemy_scheme(self) -> str:\n        \"\"\"Sqlalchemy scheme either from constructor, connection extras or default.\"\"\"\n        return (\n            self._sqlalchemy_scheme\n            or self.connection_extra_lower.get(\"sqlalchemy_scheme\")\n            or self.DEFAULT_SQLALCHEMY_SCHEME\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def authenticate_by_pam(username, password):\n    @pam_conversation\n    def conv(\n        num_msg, msg, resp, appdata_ptr\n    ):  # pylint: disable=unused-argument\n        # it is: *resp = (pam_response *) calloc(num_msg, sizeof(pam_response))\n        resp[0] = cast(\n            calloc(num_msg, sizeof(pam_response)), POINTER(pam_response)\n        )\n        for i in range(num_msg):\n            if msg[i].contents.msg_style == PAM_PROMPT_ECHO_OFF:\n                resp.contents[i].resp = strdup(password.encode(\"utf8\"))\n                resp.contents[i].resp_retcode = 0\n        return 0\n\n    pamh = pam_handle()\n    conversation = pam_conv(conv)\n    returncode = pam_start(\n        PCSD_SERVICE.encode(\"utf8\"),\n        username.encode(\"utf8\"),\n        byref(conversation),\n        byref(pamh),\n    )\n    if returncode == PAM_SUCCESS:\n        returncode = pam_authenticate(pamh, 0)\n    pam_end(pamh, returncode)\n    return returncode == PAM_SUCCESS\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _validate_archive_name(name):\n    if name.startswith(\"/\") or \"..\" in name:\n        raise InvalidLanguagePack(f\"Provided language pack contains invalid name {name}\")\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_image_dimensions(file_or_path, close=False):\n    \"\"\"\n    Returns the (width, height) of an image, given an open file or a path.  Set\n    'close' to True to close the file at the end if it is initially in an open\n    state.\n    \"\"\"\n    # Try to import PIL in either of the two ways it can end up installed.\n    try:\n        from PIL import ImageFile as PILImageFile\n    except ImportError:\n        import ImageFile as PILImageFile\n\n    p = PILImageFile.Parser()\n    if hasattr(file_or_path, 'read'):\n        file = file_or_path\n        file_pos = file.tell()\n        file.seek(0)\n    else:\n        file = open(file_or_path, 'rb')\n        close = True\n    try:\n        while 1:\n            data = file.read(1024)\n            if not data:\n                break\n            p.feed(data)\n            if p.image:\n                return p.image.size\n        return None\n    finally:\n        if close:\n            file.close()\n        else:\n            file.seek(file_pos)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def join(self, timeout=None):\r\n        \"\"\"Join all threads in the graph.\r\n\r\n        Parameters:\r\n            timeout (float): if not none will attempt to join subtasks with\r\n                this value. If a subtask times out, the whole function will\r\n                timeout.\r\n\r\n        Returns:\r\n            True if successful join, False if timed out.\r\n\r\n        \"\"\"\r\n        # if single threaded, nothing to join.\r\n        if self.n_workers < 0:\r\n            return True\r\n        # start delayed execution if necessary:\r\n        self.taskgraph_started_event.set()\r\n        try:\r\n            timedout = False\r\n            for task in self.task_map.values():\r\n                timedout = not task.join(timeout)\r\n                # if the last task timed out then we want to timeout for all\r\n                # of the task graph\r\n                if timedout:\r\n                    break\r\n            return not timedout\r\n        except Exception:\r\n            # If there's an exception on a join it means that a task failed\r\n            # to execute correctly. Print a helpful message then terminate the\r\n            # taskgraph object.\r\n            LOGGER.exception(\r\n                \"Exception raised when joining task %s. It's possible \"\r\n                \"that this task did not cause the exception, rather another \"\r\n                \"exception terminated the task_graph. Check the log to see \"\r\n                \"if there are other exceptions.\", task)\r\n            self._terminate()\r\n            raise\r\n\r"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def allow_cors_options(func):\n    \"\"\"\n    Decorator that adds automatic handling of OPTIONS requests for CORS\n\n    If the request is OPTIONS (i.e. pre flight CORS) construct a OK (200) response\n    in which we explicitly enable the caller and add the custom headers that we support\n    For other requests just add the appropriate CORS headers\n\n    :param func: the original request handler\n    :return: a request handler that shortcuts OPTIONS requests and just returns an OK (CORS allowed)\n    \"\"\"\n\n    @functools.wraps(func)\n    def allow_cors_options_wrapper(self, request: Request, *args, **kwargs):\n        if request.method == \"OPTIONS\":\n            response = HttpResponse(status=200)\n            response[\"Access-Control-Max-Age\"] = \"3600\"  # don't ask for options again for 1 hour\n        else:\n            response = func(self, request, *args, **kwargs)\n\n        allow = \", \".join(self._allowed_methods())\n        response[\"Allow\"] = allow\n        response[\"Access-Control-Allow-Methods\"] = allow\n        response[\"Access-Control-Allow-Headers\"] = (\n            \"X-Sentry-Auth, X-Requested-With, Origin, Accept, \"\n            \"Content-Type, Authentication, Authorization, Content-Encoding, \"\n            \"sentry-trace, baggage, X-CSRFToken\"\n        )\n        response[\"Access-Control-Expose-Headers\"] = \"X-Sentry-Error, Retry-After\"\n\n        if request.META.get(\"HTTP_ORIGIN\") == \"null\":\n            origin = \"null\"  # if ORIGIN header is explicitly specified as 'null' leave it alone\n        else:\n            origin = origin_from_request(request)\n\n        if origin is None or origin == \"null\":\n            response[\"Access-Control-Allow-Origin\"] = \"*\"\n        else:\n            response[\"Access-Control-Allow-Origin\"] = origin\n\n        # If the requesting origin is a subdomain of\n        # the application's base-hostname we should allow cookies\n        # to be sent.\n        basehost = options.get(\"system.base-hostname\")\n        if basehost and origin:\n            if origin.endswith(basehost):\n                response[\"Access-Control-Allow-Credentials\"] = \"true\"\n\n        return response\n\n    return allow_cors_options_wrapper\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    const Tensor& input_max_tensor = ctx->input(3);\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def run(self, modules):\n        # Bind http routes of each module.\n        for c in modules:\n            dashboard_optional_utils.ClassMethodRouteTable.bind(c)\n\n        # Http server should be initialized after all modules loaded.\n        # working_dir uploads for job submission can be up to 100MiB.\n        app = aiohttp.web.Application(\n            client_max_size=100 * 1024**2, middlewares=[self.metrics_middleware]\n        )\n        app.add_routes(routes=routes.bound_routes())\n\n        self.runner = aiohttp.web.AppRunner(\n            app,\n            access_log_format=(\n                \"%a %t '%r' %s %b bytes %D us \" \"'%{Referer}i' '%{User-Agent}i'\"\n            ),\n        )\n        await self.runner.setup()\n        last_ex = None\n        for i in range(1 + self.http_port_retries):\n            try:\n                site = aiohttp.web.TCPSite(self.runner, self.http_host, self.http_port)\n                await site.start()\n                break\n            except OSError as e:\n                last_ex = e\n                self.http_port += 1\n                logger.warning(\"Try to use port %s: %s\", self.http_port, e)\n        else:\n            raise Exception(\n                f\"Failed to find a valid port for dashboard after \"\n                f\"{self.http_port_retries} retries: {last_ex}\"\n            )\n        self.http_host, self.http_port, *_ = site._server.sockets[0].getsockname()\n        self.http_host = (\n            self.ip\n            if ipaddress.ip_address(self.http_host).is_unspecified\n            else self.http_host\n        )\n        logger.info(\n            \"Dashboard head http address: %s:%s\", self.http_host, self.http_port\n        )\n        # Dump registered http routes.\n        dump_routes = [r for r in app.router.routes() if r.method != hdrs.METH_HEAD]\n        for r in dump_routes:\n            logger.info(r)\n        logger.info(\"Registered %s routes.\", len(dump_routes))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        database: \"Database\",\n        query: Optional[\"Query\"] = None,\n        table: Optional[\"SqlaTable\"] = None,\n        extra_cache_keys: Optional[list[Any]] = None,\n        removed_filters: Optional[list[str]] = None,\n        applied_filters: Optional[list[str]] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._database = database\n        self._query = query\n        self._schema = None\n        if query and query.schema:\n            self._schema = query.schema\n        elif table:\n            self._schema = table.schema\n        self._extra_cache_keys = extra_cache_keys\n        self._applied_filters = applied_filters\n        self._removed_filters = removed_filters\n        self._context: dict[str, Any] = {}\n        self._env = SandboxedEnvironment(undefined=DebugUndefined)\n        self.set_context(**kwargs)\n\n        # custom filters\n        self._env.filters[\"where_in\"] = where_in\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        name=None,\n        n_workers=None,\n        threads_per_worker=None,\n        processes=None,\n        loop=None,\n        start=None,\n        host=None,\n        ip=None,\n        scheduler_port=0,\n        silence_logs=logging.WARN,\n        dashboard_address=\":8787\",\n        worker_dashboard_address=None,\n        diagnostics_port=None,\n        services=None,\n        worker_services=None,\n        service_kwargs=None,\n        asynchronous=False,\n        security=None,\n        protocol=None,\n        blocked_handlers=None,\n        interface=None,\n        worker_class=None,\n        scheduler_kwargs=None,\n        scheduler_sync_interval=1,\n        **worker_kwargs,\n    ):\n        if ip is not None:\n            # In the future we should warn users about this move\n            # warnings.warn(\"The ip keyword has been moved to host\")\n            host = ip\n\n        if diagnostics_port is not None:\n            warnings.warn(\n                \"diagnostics_port has been deprecated. \"\n                \"Please use `dashboard_address=` instead\"\n            )\n            dashboard_address = diagnostics_port\n\n        if threads_per_worker == 0:\n            warnings.warn(\n                \"Setting `threads_per_worker` to 0 has been deprecated. \"\n                \"Please set to None or to a specific int.\"\n            )\n            threads_per_worker = None\n\n        if \"dashboard\" in worker_kwargs:\n            warnings.warn(\n                \"Setting `dashboard` is discouraged. \"\n                \"Please set `dashboard_address` to affect the scheduler (more common) \"\n                \"and `worker_dashboard_address` for the worker (less common).\"\n            )\n\n        if processes is None:\n            processes = worker_class is None or issubclass(worker_class, Nanny)\n        if worker_class is None:\n            worker_class = Nanny if processes else Worker\n\n        self.status = None\n        self.processes = processes\n\n        if security is None:\n            # Falsey values load the default configuration\n            security = Security()\n        elif security is True:\n            # True indicates self-signed temporary credentials should be used\n            security = Security.temporary()\n        elif not isinstance(security, Security):\n            raise TypeError(\"security must be a Security object\")\n\n        if protocol is None:\n            if host and \"://\" in host:\n                protocol = host.split(\"://\")[0]\n            elif security and security.require_encryption:\n                protocol = \"tls://\"\n            elif not self.processes and not scheduler_port:\n                protocol = \"inproc://\"\n            else:\n                protocol = \"tcp://\"\n        if not protocol.endswith(\"://\"):\n            protocol = protocol + \"://\"\n\n        if host is None and not protocol.startswith(\"inproc\") and not interface:\n            host = \"127.0.0.1\"\n\n        services = services or {}\n        worker_services = worker_services or {}\n        if n_workers is None and threads_per_worker is None:\n            if processes:\n                n_workers, threads_per_worker = nprocesses_nthreads()\n            else:\n                n_workers = 1\n                threads_per_worker = CPU_COUNT\n        if n_workers is None and threads_per_worker is not None:\n            n_workers = max(1, CPU_COUNT // threads_per_worker) if processes else 1\n        if n_workers and threads_per_worker is None:\n            # Overcommit threads per worker, rather than undercommit\n            threads_per_worker = max(1, int(math.ceil(CPU_COUNT / n_workers)))\n        if n_workers and \"memory_limit\" not in worker_kwargs:\n            worker_kwargs[\"memory_limit\"] = parse_memory_limit(\"auto\", 1, n_workers)\n\n        worker_kwargs.update(\n            {\n                \"nthreads\": threads_per_worker,\n                \"services\": worker_services,\n                \"dashboard_address\": worker_dashboard_address,\n                \"dashboard\": worker_dashboard_address is not None,\n                \"interface\": interface,\n                \"protocol\": protocol,\n                \"security\": security,\n                \"silence_logs\": silence_logs,\n            }\n        )\n\n        scheduler = {\n            \"cls\": Scheduler,\n            \"options\": toolz.merge(\n                dict(\n                    host=host,\n                    services=services,\n                    service_kwargs=service_kwargs,\n                    security=security,\n                    port=scheduler_port,\n                    interface=interface,\n                    protocol=protocol,\n                    dashboard=dashboard_address is not None,\n                    dashboard_address=dashboard_address,\n                    blocked_handlers=blocked_handlers,\n                ),\n                scheduler_kwargs or {},\n            ),\n        }\n\n        worker = {\"cls\": worker_class, \"options\": worker_kwargs}\n        workers = {i: worker for i in range(n_workers)}\n\n        super().__init__(\n            name=name,\n            scheduler=scheduler,\n            workers=workers,\n            worker=worker,\n            loop=loop,\n            asynchronous=asynchronous,\n            silence_logs=silence_logs,\n            security=security,\n            scheduler_sync_interval=scheduler_sync_interval,\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_valid_filename(s):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_password(password, encoded, setter=None, preferred='default'):\n    \"\"\"\n    Returns a boolean of whether the raw password matches the three\n    part encoded digest.\n\n    If setter is specified, it'll be called when you need to\n    regenerate the password.\n    \"\"\"\n    if password is None or not is_password_usable(encoded):\n        return False\n\n    preferred = get_hasher(preferred)\n    hasher = identify_hasher(encoded)\n\n    must_update = hasher.algorithm != preferred.algorithm\n    if not must_update:\n        must_update = preferred.must_update(encoded)\n    is_correct = hasher.verify(password, encoded)\n    if setter and is_correct and must_update:\n        setter(password)\n    return is_correct\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_html(self) -> str:\n        return requests.get(self.url).text\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n        for line in lines:\n            header = HEADER_FIELD.match(line)\n\n            if not header:\n                raise ParsingError(\"Invalid header\")\n\n            key, value = header.group('name', 'value')\n\n            if b\"_\" in key:\n                # TODO(xistence): Should we drop this request instead?\n                continue\n\n            value = value.strip()\n            key1 = tostr(key.upper().replace(b\"-\", b\"_\"))\n            # If a header already exists, we append subsequent values\n            # seperated by a comma. Applications already need to handle\n            # the comma seperated values, as HTTP front ends might do\n            # the concatenation for you (behavior specified in RFC2616).\n            try:\n                headers[key1] += tostr(b\", \" + value)\n            except KeyError:\n                headers[key1] = tostr(value)\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        version = tostr(version)\n        command = tostr(command)\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n\n            encodings = [encoding.strip().lower() for encoding in te.split(\",\") if encoding]\n\n            for encoding in encodings:\n                # Out of the transfer-codings listed in\n                # https://tools.ietf.org/html/rfc7230#section-4 we only support\n                # chunked at this time.\n\n                # Note: the identity transfer-coding was removed in RFC7230:\n                # https://tools.ietf.org/html/rfc7230#appendix-A.2 and is thus\n                # not supported\n                if encoding not in {\"chunked\"}:\n                    raise TransferEncodingNotImplemented(\n                        \"Transfer-Encoding requested is not supported.\"\n                    )\n\n            if encodings and encodings[-1] == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            elif encodings:  # pragma: nocover\n                raise TransferEncodingNotImplemented(\n                    \"Transfer-Encoding requested is not supported.\"\n                )\n\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                raise ParsingError(\"Content-Length is invalid\")\n\n            self.content_length = cl\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_message(self, stream, payload):\n        payload = self.decode_payload(payload)\n        # XXX: Is header really needed?\n        reply = yield self.message_handler(payload)\n        self.stream.send(self.encode_payload(reply))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check(args: list[str]):\n    \"\"\"Run checker/linters on specified files or directories.\"\"\"\n    args2 = []\n    for arg in args:\n        if not Path(arg).exists():\n            typer.secho(f\"{arg} does not exist\", fg=typer.colors.RED)\n        else:\n            args2.append(arg)\n\n    args_str = ' '.join(args2)\n\n    run(f\"ruff {args_str}\")\n    run(f\"flake8 {args_str}\")\n    run(\"mypy --show-error-codes {args_str}\")\n    run(\"pyright\")\n    run(\"vulture --min-confidence 80 .\")\n    run(\"deptry .\")\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "var Pagination = new function() {\n\n    this.init = function(processHash, document_containers, setHash) {\n\t\t// For each pagination node\n        var containers = new Array();\n\n        // Create new containers Array after each initialisation\n        // (init can be called several times, when the pagination is\n        // nested in a tabbed container.)\n\n        for (var i in document_containers)\n            $(document_containers[i]).find('.paginate-container').each(function() {\n                var container = $(this);\n                // Only execute once for each container.\n                // (remember that init() may be called multiple times,\n                // also after content was dynamically changed, because\n                // paginators could be added on the fly.)\n                if (! container.hasClass('paginate-container-initialized'))\n                {\n                    container.addClass('paginate-container-initialized');\n                    containers.push(container);\n                    set_up(container);\n                }\n            });\n\n\t\t// Make setHash = true the default\n        if (setHash == undefined)\n            setHash = true;\n\n        function scroll(hash) {\n            var target = $('[id=' + hash + ']');\n            if (target.length) {\n                  var offset = target.offset().top;\n                  $('html,body').animate({scrollTop: offset}, 350);\n            }\n        }\n\n        function set_up(container) {\n            // Find prev/next links\n            var prev = container.find('.pagination .prev');\n            var next = container.find('.pagination .next');\n\n            var prev_url = null, next_url = null;\n\n            if (prev.length)\n                prev_url = prev.attr('href');\n            if (next.length)\n                next_url = next.attr('href');\n\n            function ajax(url, handler) {\n                // URL should start with a slash, but cannot start with two slashes.\n                // (Otherwise we have an XSS vulnerability.)\n                if (url[0] != '/' || url[1] == '/')\n                    url = (''+location).replace( /[#\\?].*/, '') + url;\n\n                // Append 'xhr' to make sure all content is loaded.\n                if (url.indexOf('&xhr') < 0 && url.indexOf('?xhr') < 0)\n                    if (url.indexOf('?') < 0)\n                        url += '?xhr';\n                    else\n                        url += '&xhr';\n\n                $.ajax({\n                        type: 'GET',\n                        url: url,\n                        datatype: \"html\",\n                        cache: true,\n                        success: handler,\n                        error: function(xhr, ajaxOptions, thrownError) {\n                            handler($('<div/>').append(\n                                    $('<strong>').append(''+xhr.status + ' ' + thrownError)).html());\n                        }\n                });\n            }\n\n            function showLoader() {\n                var loader = $('.paginate-loading').eq(0);\n\n                for (var i in containers)\n                {\n                    // Keep containers height\n                    var height = containers[i].height();\n                    if (height < 50) height = 50;\n                    containers[i].css('height', height + 'px');\n\n                    // Show loader\n                    containers[i].empty();\n                    containers[i].append(loader.html());\n                }\n            }\n\n            // Replace page AJAX handler\n            function replacePage(url, receivedHtml) {\n\t\t\t\t// Set location hash\n\t\t\t\tif (setHash)\n\t\t\t\t\tlocation.hash = 'page:' + url;\n\n\n                for (var i in containers) {\n\t\t\t\t\t// Empty the paginate nodes\n                    containers[i].empty();\n                    containers[i].css('height', '');\n\n                    // Fill the paginate containers with the new content\n                    receivedHtml = $.trim(receivedHtml);\n                    $(receivedHtml).find('.paginate-container').eq(i).each(function() {\n                        containers[i].append($(this).html());\n                        set_up(containers[i]);\n                    });\n                }\n\n                // Trigger event (Only add trigger to $(document) )\n                $(document).trigger('paginatorPageReplaced', [ containers ]);\n\n                // When the URL contains a hash, scroll to that element\n                if (location.hash.substr(1).indexOf('#') > 0) {\n                    var hash = (''+location.hash).replace( /.*#/, '');\n                    scroll(hash);\n                }\n                // Otherwise, make sure that the top of the clicked paginator is visible\n                else {\n                    var paginatorTop = container.offset().top;\n\n                    if (paginatorTop < $(window).scrollTop() || paginatorTop > $(window).scrollTop() + $(window).height()) {\n                        $('html,body').animate({scrollTop: paginatorTop}, 350);\n                    }\n                }\n            }\n\n            // Process hash (link with # opened from bookmark)\n            if (processHash && location.hash.match( /^#page/)) {\n                var url = location.hash.replace( /^#page:/, '');\n                container.empty();\n                ajax(url, function(html) { replacePage(url,html); });\n            }\n            processHash = false; // Never process twice. (set_up is called recursively)\n\n            // Preload previous page\n            var previousPageHtml = null;\n            var nextPageHtml = null;\n            var clickedPrevious = false;\n            var clickedNext = false;\n\n            var preload = $('.pagination_preload').size() > 0;\n\n            if (preload) {\n\t\t\t\tif (prev_url)\n                    ajax(prev_url, function(html) {\n                        previousPageHtml = html;\n                        if (clickedPrevious) replacePage(prev_url, html);\n                    });\n                if (next_url)\n                    ajax(next_url, function(html) {\n                        nextPageHtml = html;\n                        if (clickedNext) replacePage(next_url, html);\n                    });\n\n                // Handle clicks on the prev/next buttons.\n                prev.click(function() {\n                    showLoader();\n                    if (previousPageHtml)\n                        replacePage(prev_url, previousPageHtml);\n                    else\n                        clickedPrevious = true;\n                    return false;\n                });\n\n                next.click(function() {\n                    showLoader();\n                    if (nextPageHtml)\n                        replacePage(next_url, nextPageHtml);\n                    else\n                        clickedNext = true;\n                    return false;\n                });\n            }\n\n            // The digg-paginator also contains direct links to other pages\n            // then only the prev and next page.\n            container.find('.pagination a, .pagination-helper a, a.pagination-helper').each(function() {\n\n                $(this).click(function (){\n                \tvar url = $(this).attr('href');\n                    showLoader();\n\n                    if (url[0] == '#') {\n                        var hash = url.replace( /#/, '');\n                        scroll(hash);\n                    }\n                    else\n                        ajax(url, function(html) {\n\t\t\t\t\t\t\treplacePage(url, html);\n                        });\n                    return false;\n                });\n            });\n\n            // Pagination forms are forms for which the result is displayed in the paginator\n            // They always have method=\"get\" and action=\"?\"\n            container.find('form.pagination-form').each(function() {\n                var form = $(this);\n                if (form.attr('method') == 'get' && form.attr('action').match(/.*?/)) {\n                    // Submit handler\n                    form.submit(function() {\n                        // Build submit query string\n                        var url = form.attr('action') + form.serialize();\n\n                        // AJAX request\n                        ajax(url, function(html) {\n                            replacePage(url, html);\n                        });\n                        return false;\n                    });\n                }\n            });\n        }\n    };\n};\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False):\n        if self.jinja2_native and not isinstance(data, string_types):\n            return data\n\n        # For preserving the number of input newlines in the output (used\n        # later in this method)\n        data_newlines = _count_newlines_from_end(data)\n\n        if fail_on_undefined is None:\n            fail_on_undefined = self._fail_on_undefined_errors\n\n        try:\n            # allows template header overrides to change jinja2 options.\n            if overrides is None:\n                myenv = self.environment\n            else:\n                myenv = self.environment.overlay(overrides)\n\n            # Get jinja env overrides from template\n            if hasattr(data, 'startswith') and data.startswith(JINJA2_OVERRIDE):\n                eol = data.find('\\n')\n                line = data[len(JINJA2_OVERRIDE):eol]\n                data = data[eol + 1:]\n                for pair in line.split(','):\n                    (key, val) = pair.split(':')\n                    key = key.strip()\n                    setattr(myenv, key, ast.literal_eval(val.strip()))\n\n            if escape_backslashes:\n                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".\n                data = _escape_backslashes(data, myenv)\n\n            try:\n                t = myenv.from_string(data)\n            except TemplateSyntaxError as e:\n                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)))\n            except Exception as e:\n                if 'recursion' in to_native(e):\n                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data))\n                else:\n                    return data\n\n            if disable_lookups:\n                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup\n\n            jvars = AnsibleJ2Vars(self, t.globals)\n\n            self.cur_context = new_context = t.new_context(jvars, shared=True)\n            rf = t.root_render_func(new_context)\n\n            try:\n                if self.jinja2_native:\n                    res = ansible_native_concat(rf)\n                else:\n                    res = j2_concat(rf)\n                if getattr(new_context, 'unsafe', False):\n                    res = wrap_var(res)\n            except TypeError as te:\n                if 'AnsibleUndefined' in to_native(te):\n                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)\n                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)\n                    raise AnsibleUndefinedVariable(errmsg)\n                else:\n                    display.debug(\"failing because of a type error, template data is: %s\" % to_text(data))\n                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)))\n\n            if self.jinja2_native and not isinstance(res, string_types):\n                return res\n\n            if preserve_trailing_newlines:\n                # The low level calls above do not preserve the newline\n                # characters at the end of the input data, so we use the\n                # calculate the difference in newlines and append them\n                # to the resulting output for parity\n                #\n                # jinja2 added a keep_trailing_newline option in 2.7 when\n                # creating an Environment.  That would let us make this code\n                # better (remove a single newline if\n                # preserve_trailing_newlines is False).  Once we can depend on\n                # that version being present, modify our code to set that when\n                # initializing self.environment and remove a single trailing\n                # newline here if preserve_newlines is False.\n                res_newlines = _count_newlines_from_end(res)\n                if data_newlines > res_newlines:\n                    res += self.environment.newline_sequence * (data_newlines - res_newlines)\n            return res\n        except (UndefinedError, AnsibleUndefinedVariable) as e:\n            if fail_on_undefined:\n                raise AnsibleUndefinedVariable(e)\n            else:\n                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))\n                return data\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        return self._save(name, content)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def render_markdown(value):\n    \"\"\"\n    Render text as Markdown\n\n    Example:\n        {{ text | render_markdown }}\n    \"\"\"\n    # Strip HTML tags\n    value = strip_tags(value)\n\n    # Sanitize Markdown links\n    schemes = \"|\".join(settings.ALLOWED_URL_SCHEMES)\n    pattern = rf\"\\[(.+)\\]\\((?!({schemes})).*:(.+)\\)\"\n    value = re.sub(pattern, \"[\\\\1](\\\\3)\", value, flags=re.IGNORECASE)\n\n    # Render Markdown\n    html = markdown(value, extensions=[\"fenced_code\", \"tables\"])\n\n    return mark_safe(html)  # noqa: S308  # suspicious-mark-safe-usage, OK here since we sanitized the string earlier\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def deny_uploads_containing_script_tag(uploaded_file):\n    for chunk in uploaded_file.chunks(2048):\n        if chunk.find(b\"<script\") > -1:\n            raise ValidationError(_(\"File contains forbidden <script> tag\"))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_initial_logout(self):\n        \"\"\"\n        Get the initial logout request.\n\n        Return None if no sessions in INIT_LOGOUT state.\n        \"\"\"\n        candidates = self._ss.get_user_sessions(self.user)\n\n        # FIXME: what does it mean if there are multiple in init? We\n        #        just return the first one for now. How do we know\n        #        it's the \"right\" one if multiple logouts are started\n        #        at the same time from different SPs?\n        for c in candidates:\n            key = c.keys()[0]\n            if int(c[key].get('logoutstate', 0)) == INIT_LOGOUT:\n                samlsession = self._data_to_samlsession(key, c[key])\n                return samlsession\n        return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decrypt(self, ciphertext):\n        \"\"\"Decrypt a message with PKCS#1 OAEP.\n\n        :param ciphertext: The encrypted message.\n        :type ciphertext: bytes/bytearray/memoryview\n\n        :returns: The original message (plaintext).\n        :rtype: bytes\n\n        :raises ValueError:\n            if the ciphertext has the wrong length, or if decryption\n            fails the integrity check (in which case, the decryption\n            key is probably wrong).\n        :raises TypeError:\n            if the RSA key has no private half (i.e. you are trying\n            to decrypt using a public key).\n        \"\"\"\n\n        # See 7.1.2 in RFC3447\n        modBits = Crypto.Util.number.size(self._key.n)\n        k = ceil_div(modBits,8) # Convert from bits to bytes\n        hLen = self._hashObj.digest_size\n\n        # Step 1b and 1c\n        if len(ciphertext) != k or k<hLen+2:\n            raise ValueError(\"Ciphertext with incorrect length.\")\n        # Step 2a (O2SIP)\n        ct_int = bytes_to_long(ciphertext)\n        # Step 2b (RSADP) and step 2c (I2OSP)\n        em = self._key._decrypt_to_bytes(ct_int)\n        # Step 3a\n        lHash = self._hashObj.new(self._label).digest()\n        # Step 3b\n        y = em[0]\n        # y must be 0, but we MUST NOT check it here in order not to\n        # allow attacks like Manger's (http://dl.acm.org/citation.cfm?id=704143)\n        maskedSeed = em[1:hLen+1]\n        maskedDB = em[hLen+1:]\n        # Step 3c\n        seedMask = self._mgf(maskedDB, hLen)\n        # Step 3d\n        seed = strxor(maskedSeed, seedMask)\n        # Step 3e\n        dbMask = self._mgf(seed, k-hLen-1)\n        # Step 3f\n        db = strxor(maskedDB, dbMask)\n        # Step 3g\n        one_pos = hLen + db[hLen:].find(b'\\x01')\n        lHash1 = db[:hLen]\n        invalid = bord(y) | int(one_pos < hLen)\n        hash_compare = strxor(lHash1, lHash)\n        for x in hash_compare:\n            invalid |= bord(x)\n        for x in db[hLen:one_pos]:\n            invalid |= bord(x)\n        if invalid != 0:\n            raise ValueError(\"Incorrect decryption.\")\n        # Step 4\n        return db[one_pos + 1:]\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def on_send_leave_request(self, origin, pdu):\n        \"\"\" We have received a leave event for a room. Fully process it.\"\"\"\n        event = pdu\n\n        logger.debug(\n            \"on_send_leave_request: Got event: %s, signatures: %s\",\n            event.event_id,\n            event.signatures,\n        )\n\n        event.internal_metadata.outlier = False\n\n        context = yield self._handle_new_event(origin, event)\n\n        event_allowed = yield self.third_party_event_rules.check_event_allowed(\n            event, context\n        )\n        if not event_allowed:\n            logger.info(\"Sending of leave %s forbidden by third-party rules\", event)\n            raise SynapseError(\n                403, \"This event is not allowed in this context\", Codes.FORBIDDEN\n            )\n\n        logger.debug(\n            \"on_send_leave_request: After _handle_new_event: %s, sigs: %s\",\n            event.event_id,\n            event.signatures,\n        )\n\n        return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def update_user_tenant(self, context, user_id, user):\n        \"\"\"Update the default tenant.\"\"\"\n        # ensure that we're a member of that tenant\n        tenant_id = user.get('tenantId')\n        self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        return self.update_user(context, user_id, user)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  string fixed_prefix = pattern.substr(0, pattern.find_first_of(\"*?[\\\\\"));\n  string eval_pattern = pattern;\n  string dir(io::Dirname(fixed_prefix));\n  // If dir is empty then we need to fix up fixed_prefix and eval_pattern to\n  // include . as the top level directory.\n  if (dir.empty()) {\n    dir = \".\";\n    fixed_prefix = io::JoinPath(dir, fixed_prefix);\n    eval_pattern = io::JoinPath(dir, eval_pattern);\n  }\n  bool is_directory = pattern[pattern.size() - 1] == '/';\n#ifdef PLATFORM_WINDOWS\n  is_directory = is_directory || pattern[pattern.size() - 1] == '\\\\';\n#endif\n  std::vector<string> dirs;\n  if (!is_directory) {\n    dirs.emplace_back(eval_pattern);\n  }\n  StringPiece tmp_dir(io::Dirname(eval_pattern));\n  while (tmp_dir.size() > dir.size()) {\n    dirs.emplace_back(string(tmp_dir));\n    tmp_dir = io::Dirname(tmp_dir);\n  }\n  dirs.emplace_back(dir);\n  std::reverse(dirs.begin(), dirs.end());\n  // Setup a parallel BFS to explore everything under dir.\n  std::deque<std::pair<string, int>> dir_q;\n  std::deque<std::pair<string, int>> next_dir_q;\n  dir_q.emplace_back(std::make_pair(dirs[0], 0));\n  Status ret;  // Status to return.\n  mutex results_mutex;\n  condition_variable results_cond;\n  mutex next_que_mutex;\n  condition_variable next_que_cond;\n  while (!dir_q.empty()) {\n    next_dir_q.clear();\n    std::vector<Status> new_rets(dir_q.size());\n    auto handle_level = [fs, &results, &dir_q, &next_dir_q, &new_rets,\n                         &is_directory, &dirs, &results_mutex, &results_cond,\n                         &next_que_mutex, &next_que_cond](int i) {\n      string current_dir = dir_q.at(i).first;\n      int dir_index = dir_q.at(i).second;\n      dir_index++;\n      std::vector<string> children;\n      Status s = fs->GetChildren(current_dir, &children);\n      // In case PERMISSION_DENIED is encountered, we bail here.\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n      new_rets[i] = s;\n      if (children.empty()) return;\n\n      // children_dir_status holds is_dir status for children. It can have three\n      // possible values: OK for true; FAILED_PRECONDITION for false; CANCELLED\n      // if we don't calculate IsDirectory (we might do that because there isn't\n      // any point in exploring that child path).\n      std::vector<Status> children_dir_status;\n\n      // This IsDirectory call can be expensive for some FS. Parallelizing it.\n      children_dir_status.resize(children.size());\n      auto handle_children = [fs, &current_dir, &children, &dirs, dir_index,\n                              is_directory, &children_dir_status](int j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        if (!fs->Match(child_path, dirs[dir_index])) {\n          children_dir_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else if (dir_index != dirs.size() - 1) {\n          children_dir_status[j] = fs->IsDirectory(child_path);\n        } else {\n          children_dir_status[j] =\n              is_directory ? fs->IsDirectory(child_path) : Status::OK();\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      for (size_t j = 0; j < children.size(); ++j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        // If the IsDirectory call was cancelled we bail.\n        if (children_dir_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n        if (children_dir_status[j].ok()) {\n          if (dir_index != dirs.size() - 1) {\n            mutex_lock lk(next_que_mutex);\n            next_dir_q.emplace_back(std::make_pair(child_path, dir_index));\n            next_que_cond.notify_one();\n          } else {\n            mutex_lock lk(results_mutex);\n            results->emplace_back(child_path);\n            results_cond.notify_one();\n          }\n        }\n      }\n    };\n    ForEach(0, dir_q.size(), handle_level);\n\n    ret.Update(new_rets[dir_q.size() - 1]);\n    std::swap(dir_q, next_dir_q);\n  }\n  return ret;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def create_code_for_user(cls, user, next=None):\n        if not user.is_active:\n            return None\n\n        code = cls.generate_code()\n        login_code = LoginCode(user=user, code=code)\n        if next is not None:\n            login_code.next = next\n        login_code.save()\n        return login_code\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeEasyCases(OpKernelContext* context, bool* done,\n                        std::vector<Tlen>* split_sizes_vec) {\n    const int32_t num_split = context->num_outputs();\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const Tensor& split_tensor = context->input(1);\n    const Tensor& split_dim_tensor = context->input(2);\n\n    OP_REQUIRES(context, split_dim_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"split_dim_tensor must have \"\n                                        \"exactly one element.\"));\n\n    const int32_t split_dim_orig = split_dim_tensor.flat<int32>()(0);\n    const int32_t split_dim =\n        split_dim_orig < 0 ? split_dim_orig + input.dims() : split_dim_orig;\n\n    OP_REQUIRES(\n        context,\n        split_tensor.dims() == 1 && split_tensor.NumElements() == num_split,\n        errors::InvalidArgument(\"size of the split_tensor must be 1-D and have \"\n                                \"the same elements as outputs got \",\n                                split_tensor.dims(), \" -D and \",\n                                split_tensor.NumElements(), \" elements\"));\n\n    auto split_sizes_d = split_tensor.vec<Tlen>();\n\n    split_sizes_vec->resize(split_sizes_d.size());\n\n    std::copy(split_sizes_d.data(), split_sizes_d.data() + split_sizes_d.size(),\n              split_sizes_vec->begin());\n\n    OP_REQUIRES(\n        context, num_split > 0,\n        errors::InvalidArgument(\n            \"Number of ways to split should be > 0, but got \", num_split));\n\n    OP_REQUIRES(\n        context, 0 <= split_dim && split_dim < input.dims(),\n        errors::InvalidArgument(\"-input rank(-\", input.dims(),\n                                \") <= split_dim < input rank (\", input.dims(),\n                                \"), but got \", split_dim_orig));\n\n    Tlen input_size_split_dim = input_shape.dim_size(split_dim);\n\n    // Special case 1: num_split == 1. Nothing to do.\n    if (num_split == 1) {\n      context->set_output(0, context->input(0));\n      OP_REQUIRES(\n          context, (*split_sizes_vec)[0] == input_size_split_dim,\n          errors::InvalidArgument(\"If there is only one output, it must have \"\n                                  \"the same size as the input. Input size: \",\n                                  input_size_split_dim,\n                                  \" output size: \", (*split_sizes_vec)[0]));\n      *done = true;\n      return;\n    }\n\n    // Determine sizes of output, in case of a -1 input value\n    int neg_one_dim = -1;\n    Tlen determined_size = 0;\n    for (int d = 0; d < split_sizes_vec->size(); ++d) {\n      Tlen size = (*split_sizes_vec)[d];\n\n      if (size == -1) {\n        OP_REQUIRES(context, neg_one_dim == -1,\n                    errors::InvalidArgument(\"There can only be one -1 in the \"\n                                            \"input.\"));\n        neg_one_dim = d;\n      } else {\n        determined_size += size;\n      }\n    }\n\n    OP_REQUIRES(\n        context,\n        (neg_one_dim == -1 && determined_size == input_size_split_dim) ||\n            (neg_one_dim >= 0 && determined_size <= input_size_split_dim),\n        errors::InvalidArgument(\"Determined shape must either match \"\n                                \"input shape along split_dim exactly if \"\n                                \"fully specified, or be less than the size of \"\n                                \"the input along split_dim if not fully \"\n                                \"specified.  Got: \",\n                                determined_size));\n\n    if (neg_one_dim >= 0) {\n      (*split_sizes_vec)[neg_one_dim] = input_size_split_dim - determined_size;\n    }\n\n    // Special case 2: split along the 1st dimension. The requirements are that\n    // either we are splitting the outer dimension of two or more such that\n    // every outer subpart is aligned or that the split sizes mean that they are\n    // always aligned. In these cases, we can share the underlying buffer.\n    //\n    // Apply this optimization conservatively: if input is aligned,\n    // the resulting tensors must be aligned. It's conservative\n    // because if the immediate consumer of the resulting tensors are\n    // not using eigen for computation, its perfectly fine to avoid\n    // the copying.\n    if (SplitHasAlignedOutputsInFirstDimension(\n            input_shape, split_dim, absl::MakeConstSpan(*split_sizes_vec))) {\n      Tlen start = 0;\n      for (int i = 0; i < num_split; ++i) {\n        context->set_output(i,\n                            input.Slice(start, start + (*split_sizes_vec)[i]));\n        start += (*split_sizes_vec)[i];\n      }\n      *done = true;\n      return;\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def local_get_cobbler_xmlrpc_url():\n    # Load xmlrpc port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n    return \"http://%s:%s\" % (\"127.0.0.1\",data.get(\"xmlrpc_port\",\"25151\"))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def is_precalculated(self):\r\n        \"\"\"Return true if _call need not be invoked.\r\n\r\n        Returns:\r\n            True if the Task's target paths exist in the same state as the\r\n            last recorded run at the time this function is called. It is\r\n            possible this value could change without running the Task if\r\n            input parameter file stats change. False otherwise.\r\n\r\n        \"\"\"\r\n        # This gets a list of the files and their file stats that can be found\r\n        # in args and kwargs but ignores anything specifically targeted or\r\n        # an expected result. This will allow a task to change its hash in\r\n        # case a different version of a file was passed in.\r\n        if self._precalculated is not None:\r\n            return self._precalculated\r\n        file_stat_list = list(_get_file_stats(\r\n            [self._args, self._kwargs],\r\n            self._target_path_list+self._ignore_path_list,\r\n            self._ignore_directories))\r\n\r\n        # add the file stat list to the already existing reexecution info\r\n        # dictionary that contains stats that should not change whether\r\n        # files have been created/updated/or not.\r\n        self._reexecution_info['file_stat_list'] = pprint.pformat(\r\n            file_stat_list)\r\n        reexecution_string = '%s:%s' % (\r\n            self._task_id_hash, self._reexecution_info['file_stat_list'])\r\n        self._task_reexecution_hash = hashlib.sha1(\r\n            reexecution_string.encode('utf-8')).hexdigest()\r\n        try:\r\n            with sqlite3.connect(self._task_database_path) as conn:\r\n                cursor = conn.cursor()\r\n                cursor.execute(\r\n                    \"\"\"\r\n                        SELECT data_blob from taskgraph_data\r\n                        WHERE (task_hash == ?)\r\n                    \"\"\", (self._task_reexecution_hash,))\r\n                database_result = cursor.fetchone()\r\n            if database_result is None:\r\n                LOGGER.info(\r\n                    \"not precalculated, Task hash does not \"\r\n                    \"exist (%s)\", self.task_name)\r\n                LOGGER.debug(\"is_precalculated full task info: %s\", self)\r\n                self._precalculated = False\r\n                return False\r\n            if database_result:\r\n                result_target_path_stats = pickle.loads(database_result[0])\r\n            mismatched_target_file_list = []\r\n            for path, modified_time, size in result_target_path_stats:\r\n                if not os.path.exists(path):\r\n                    mismatched_target_file_list.append(\r\n                        'Path not found: %s' % path)\r\n                    continue\r\n                target_modified_time = os.path.getmtime(path)\r\n                if modified_time != target_modified_time:\r\n                    mismatched_target_file_list.append(\r\n                        \"Modified times don't match \"\r\n                        \"desired: (%s) target: (%s)\" % (\r\n                            modified_time, target_modified_time))\r\n                    continue\r\n                target_size = os.path.getsize(path)\r\n                if size != target_size:\r\n                    mismatched_target_file_list.append(\r\n                        \"File sizes don't match \"\r\n                        \"desired: (%s) target: (%s)\" % (\r\n                            size, target_size))\r\n            if mismatched_target_file_list:\r\n                LOGGER.warning(\r\n                    \"not precalculated (%s), Task hash exists, \"\r\n                    \"but there are these mismatches: %s\",\r\n                    self.task_name, '\\n'.join(mismatched_target_file_list))\r\n                self._precalculated = False\r\n                return False\r\n            LOGGER.info(\"precalculated (%s)\" % self.task_name)\r\n            self._precalculated = True\r\n            return True\r\n        except EOFError:\r\n            LOGGER.exception(\"not precalculated %s, EOFError\", self.task_name)\r\n            self._precalculated = False\r\n            return False\r\n\r"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& in0 = ctx->input(0);\n    const Tensor& in1 = ctx->input(1);\n    auto in0_flat = in0.flat<Tin>();\n    auto in1_flat = in1.flat<Tin>();\n    const Device& eigen_device = ctx->eigen_device<Device>();\n\n    Tensor* out = nullptr;\n    if (std::is_same<Tin, Tout>::value) {\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0, 1}, 0, in0.shape(), &out));\n    } else {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, in0.shape(), &out));\n    }\n    auto out_flat = out->flat<Tout>();\n    functor::SimpleBinaryFunctor<Device, Functor>()(eigen_device, out_flat,\n                                                    in0_flat, in1_flat);\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def check_secret_key(self) -> None:\n        if self.config[\"SECRET_KEY\"] == CHANGE_ME_SECRET_KEY:\n            top_banner = 80 * \"-\" + \"\\n\" + 36 * \" \" + \"WARNING\\n\" + 80 * \"-\"\n            bottom_banner = 80 * \"-\" + \"\\n\" + 80 * \"-\"\n            logger.warning(top_banner)\n            logger.warning(\n                \"A Default SECRET_KEY was detected, please use superset_config.py \"\n                \"to override it.\\n\"\n                \"Use a strong complex alphanumeric string and use a tool to help\"\n                \" you generate \\n\"\n                \"a sufficiently random sequence, ex: openssl rand -base64 42\"\n            )\n            logger.warning(bottom_banner)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_base_rev_args(rev: str) -> List[str]:\n        return [\"-r\", rev]\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def on_federation_query_user_devices(self, user_id: str) -> JsonDict:\n        stream_id, devices = await self.store.get_e2e_device_keys_for_federation_query(\n            user_id\n        )\n        master_key = await self.store.get_e2e_cross_signing_key(user_id, \"master\")\n        self_signing_key = await self.store.get_e2e_cross_signing_key(\n            user_id, \"self_signing\"\n        )\n\n        # Check if the application services have any results.\n        if self._query_appservices_for_keys:\n            # Query the appservice for all devices for this user.\n            query: Dict[str, Optional[List[str]]] = {user_id: None}\n\n            # Query the appservices for any keys.\n            appservice_results = await self._appservice_handler.query_keys(query)\n\n            # Merge results, overriding anything from the database.\n            appservice_devices = appservice_results.get(\"device_keys\", {}).get(\n                user_id, {}\n            )\n\n            # Filter the database results to only those devices that the appservice has\n            # *not* responded with.\n            devices = [d for d in devices if d[\"device_id\"] not in appservice_devices]\n            # Append the appservice response by wrapping each result in another dictionary.\n            devices.extend(\n                {\"device_id\": device_id, \"keys\": device}\n                for device_id, device in appservice_devices.items()\n            )\n\n            # TODO Handle cross-signing keys.\n\n        return {\n            \"user_id\": user_id,\n            \"stream_id\": stream_id,\n            \"devices\": devices,\n            \"master_key\": master_key,\n            \"self_signing_key\": self_signing_key,\n        }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_payload(token):\n    from rest_framework_jwt.authentication import JSONWebTokenAuthentication\n\n    try:\n        payload = JSONWebTokenAuthentication.jwt_decode_token(token)\n    except jwt.ExpiredSignature:\n        msg = _('Token has expired.')\n        raise serializers.ValidationError(msg)\n    except jwt.DecodeError:\n        msg = _('Error decoding token.')\n        raise serializers.ValidationError(msg)\n\n    return payload\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _complete_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/complete` to complete a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        CompleteMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"upload_id\": [_assert_string],\n            \"parts\": [_assert_required],\n        },\n    )\n    path = request_message.path\n    upload_id = request_message.upload_id\n    parts = [MultipartUploadPart.from_proto(part) for part in request_message.parts]\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    artifact_repo.complete_multipart_upload(\n        path,\n        upload_id,\n        parts,\n        artifact_path,\n    )\n    return _wrap_response(CompleteMultipartUpload.Response())\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n                                 const TfLiteTensor* input,\n                                 const TfLiteTensor* size_splits,\n                                 const TfLiteTensor* axis) {\n  int axis_value = GetTensorData<int>(axis)[0];\n  if (axis_value < 0) {\n    axis_value += NumDimensions(input);\n  }\n\n  std::vector<int64_t> size_splits_vector;\n  if (size_splits->type == kTfLiteInt32) {\n    GetSizeSplitsVector<int32_t>(size_splits, &size_splits_vector);\n  } else if (size_splits->type == kTfLiteInt64) {\n    GetSizeSplitsVector<int64_t>(size_splits, &size_splits_vector);\n  } else {\n    context->ReportError(context, \"size_splits only support type int32|int64.\");\n    return kTfLiteError;\n  }\n\n  int minus_one_index = -1;\n  int64_t size_splits_sum = 0;\n\n  for (int i = 0; i < size_splits_vector.size(); ++i) {\n    if (size_splits_vector.at(i) == -1) {\n      if (minus_one_index == -1) {\n        minus_one_index = i;\n      } else {\n        context->ReportError(context,\n                             \"The size_splits contains more than one -1.\");\n      }\n    } else {\n      size_splits_sum += size_splits_vector.at(i);\n    }\n  }\n\n  const int input_size = SizeOfDimension(input, axis_value);\n\n  if (minus_one_index != -1) {\n    if (size_splits_sum > input_size) {\n      context->ReportError(\n          context,\n          \"The sum of size_splits must be less than the dimension of value.\");\n    } else {\n      size_splits_vector[minus_one_index] = input_size - size_splits_sum;\n    }\n  } else if (size_splits_sum != input_size) {\n    context->ReportError(\n        context,\n        \"The size_splits must sum to the dimension of value along axis.\");\n  }\n\n  for (int i = 0; i < NumOutputs(node); ++i) {\n    TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n    output_dims->data[axis_value] = size_splits_vector.at(i);\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n  }\n\n  return kTfLiteOk;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void WebServer::handleRequest(AsyncWebServerRequest *request) {\n  if (this->using_auth() && !request->authenticate(this->username_, this->password_)) {\n    return request->requestAuthentication();\n  }\n\n  if (request->url() == \"/\") {\n    this->handle_index_request(request);\n    return;\n  }\n\n#ifdef WEBSERVER_CSS_INCLUDE\n  if (request->url() == \"/0.css\") {\n    this->handle_css_request(request);\n    return;\n  }\n#endif\n\n#ifdef WEBSERVER_JS_INCLUDE\n  if (request->url() == \"/0.js\") {\n    this->handle_js_request(request);\n    return;\n  }\n#endif\n\n  UrlMatch match = match_url(request->url().c_str());\n#ifdef USE_SENSOR\n  if (match.domain == \"sensor\") {\n    this->handle_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_SWITCH\n  if (match.domain == \"switch\") {\n    this->handle_switch_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_BINARY_SENSOR\n  if (match.domain == \"binary_sensor\") {\n    this->handle_binary_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_FAN\n  if (match.domain == \"fan\") {\n    this->handle_fan_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_LIGHT\n  if (match.domain == \"light\") {\n    this->handle_light_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_TEXT_SENSOR\n  if (match.domain == \"text_sensor\") {\n    this->handle_text_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_COVER\n  if (match.domain == \"cover\") {\n    this->handle_cover_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_NUMBER\n  if (match.domain == \"number\") {\n    this->handle_number_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_SELECT\n  if (match.domain == \"select\") {\n    this->handle_select_request(request, match);\n    return;\n  }\n#endif\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ImagingSgiRleDecode(Imaging im, ImagingCodecState state, UINT8 *buf, Py_ssize_t bytes) {\n    UINT8 *ptr;\n    SGISTATE *c;\n    int err = 0;\n    int status;\n\n    /* size check */\n    if (im->xsize > INT_MAX / im->bands || im->ysize > INT_MAX / im->bands) {\n        state->errcode = IMAGING_CODEC_MEMORY;\n        return -1;\n    }\n\n    /* Get all data from File descriptor */\n    c = (SGISTATE *)state->context;\n    _imaging_seek_pyFd(state->fd, 0L, SEEK_END);\n    c->bufsize = _imaging_tell_pyFd(state->fd);\n    c->bufsize -= SGI_HEADER_SIZE;\n\n    c->tablen = im->bands * im->ysize;\n    /* below, we populate the starttab and lentab into the bufsize,\n       each with 4 bytes per element of tablen\n       Check here before we allocate any memory\n    */\n    if (c->bufsize < 8 * c->tablen) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = malloc(sizeof(UINT8) * c->bufsize);\n    if (!ptr) {\n        state->errcode = IMAGING_CODEC_MEMORY;\n        return -1;\n    }\n    _imaging_seek_pyFd(state->fd, SGI_HEADER_SIZE, SEEK_SET);\n    _imaging_read_pyFd(state->fd, (char *)ptr, c->bufsize);\n\n    /* decoder initialization */\n    state->count = 0;\n    state->y = 0;\n    if (state->ystep < 0) {\n        state->y = im->ysize - 1;\n    } else {\n        state->ystep = 1;\n    }\n\n    /* Allocate memory for RLE tables and rows */\n    free(state->buffer);\n    state->buffer = NULL;\n    /* malloc overflow check above */\n    state->buffer = calloc(im->xsize * im->bands, sizeof(UINT8) * 2);\n    c->starttab = calloc(c->tablen, sizeof(UINT32));\n    c->lengthtab = calloc(c->tablen, sizeof(UINT32));\n    if (!state->buffer || !c->starttab || !c->lengthtab) {\n        err = IMAGING_CODEC_MEMORY;\n        goto sgi_finish_decode;\n    }\n    /* populate offsets table */\n    for (c->tabindex = 0, c->bufindex = 0; c->tabindex < c->tablen;\n         c->tabindex++, c->bufindex += 4) {\n        read4B(&c->starttab[c->tabindex], &ptr[c->bufindex]);\n    }\n    /* populate lengths table */\n    for (c->tabindex = 0, c->bufindex = c->tablen * sizeof(UINT32);\n         c->tabindex < c->tablen;\n         c->tabindex++, c->bufindex += 4) {\n        read4B(&c->lengthtab[c->tabindex], &ptr[c->bufindex]);\n    }\n\n    state->count += c->tablen * sizeof(UINT32) * 2;\n\n    /* read compressed rows */\n    for (c->rowno = 0; c->rowno < im->ysize; c->rowno++, state->y += state->ystep) {\n        for (c->channo = 0; c->channo < im->bands; c->channo++) {\n            c->rleoffset = c->starttab[c->rowno + c->channo * im->ysize];\n            c->rlelength = c->lengthtab[c->rowno + c->channo * im->ysize];\n            c->rleoffset -= SGI_HEADER_SIZE;\n\n            if (c->rleoffset + c->rlelength > c->bufsize) {\n                state->errcode = IMAGING_CODEC_OVERRUN;\n                goto sgi_finish_decode;\n            }\n\n            /* row decompression */\n            if (c->bpc == 1) {\n                status = expandrow(\n                    &state->buffer[c->channo],\n                    &ptr[c->rleoffset],\n                    c->rlelength,\n                    im->bands,\n                    im->xsize);\n            } else {\n                status = expandrow2(\n                    &state->buffer[c->channo * 2],\n                    &ptr[c->rleoffset],\n                    c->rlelength,\n                    im->bands,\n                    im->xsize);\n            }\n            if (status == -1) {\n                state->errcode = IMAGING_CODEC_OVERRUN;\n                goto sgi_finish_decode;\n            } else if (status == 1) {\n                goto sgi_finish_decode;\n            }\n\n            state->count += c->rlelength;\n        }\n\n        /* store decompressed data in image */\n        state->shuffle((UINT8 *)im->image[state->y], state->buffer, im->xsize);\n    }\n\n    c->bufsize++;\n\nsgi_finish_decode:;\n\n    free(c->starttab);\n    free(c->lengthtab);\n    free(ptr);\n    if (err != 0) {\n        state->errcode = err;\n        return -1;\n    }\n    return state->count - c->bufsize;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def populate_obj(self, user):\n        try:\n            user.set_password(self.new.data, old_password=self.current.data)\n            flash(_(\"Password updated successfully.\"), level='success')\n        except ValueError as e:\n            flash(str(e), level='warning')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def delete_project():\n    g.project.remove_project()\n    flash(_(\"Project successfully deleted\"))\n\n    return redirect(request.headers.get(\"Referer\") or url_for(\".home\"))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ValidatePaddingValues(absl::Span<const int64_t> input_dimensions,\n                             absl::Span<const int64_t> window_dimensions,\n                             absl::Span<const int64_t> window_strides) {\n  bool ok = input_dimensions.size() == window_dimensions.size() &&\n            input_dimensions.size() == window_strides.size();\n  if (!ok) {\n    return InvalidArgument(\n        \"Want input dimensions size %u = window dimensions size %u = window \"\n        \"strides size %u\",\n        input_dimensions.size(), window_dimensions.size(),\n        window_strides.size());\n  }\n  return OkStatus();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def task_created(request):\n   \"\"\"\n   Let's the user know what to expect for event updates.\n   \"\"\"\n   if not test_user_authenticated(request): return login(request, next=\"/cobbler_web/task_created\")\n   t = get_template(\"task_created.tmpl\")\n   html = t.render(Context({\n       'version'  : remote.version(request.session['token']),\n       'username' : username\n   }))\n   return HttpResponse(html)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse_Compare(self):\n        left = Expr.parse_value_expr(self.expr.left, self.context)\n        right = Expr.parse_value_expr(self.expr.right, self.context)\n\n        if right.value is None:\n            return\n\n        if isinstance(self.expr.op, (vy_ast.In, vy_ast.NotIn)):\n            if isinstance(right.typ, ArrayLike):\n                return self.build_in_comparator()\n            return  # pragma: notest\n\n        if isinstance(self.expr.op, vy_ast.Gt):\n            op = \"sgt\"\n        elif isinstance(self.expr.op, vy_ast.GtE):\n            op = \"sge\"\n        elif isinstance(self.expr.op, vy_ast.LtE):\n            op = \"sle\"\n        elif isinstance(self.expr.op, vy_ast.Lt):\n            op = \"slt\"\n        elif isinstance(self.expr.op, vy_ast.Eq):\n            op = \"eq\"\n        elif isinstance(self.expr.op, vy_ast.NotEq):\n            op = \"ne\"\n        else:\n            return  # pragma: notest\n\n        # Compare (limited to 32) byte arrays.\n        if isinstance(left.typ, ByteArrayLike) and isinstance(right.typ, ByteArrayLike):\n            left = Expr(self.expr.left, self.context).ir_node\n            right = Expr(self.expr.right, self.context).ir_node\n\n            length_mismatch = left.typ.maxlen != right.typ.maxlen\n            left_over_32 = left.typ.maxlen > 32\n            right_over_32 = right.typ.maxlen > 32\n\n            if length_mismatch or left_over_32 or right_over_32:\n                left_keccak = keccak256_helper(self.expr, left, self.context)\n                right_keccak = keccak256_helper(self.expr, right, self.context)\n\n                if op == \"eq\" or op == \"ne\":\n                    return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")\n\n                else:\n                    return\n\n            else:\n\n                def load_bytearray(side):\n                    return LOAD(bytes_data_ptr(side))\n\n                return IRnode.from_list(\n                    # CMC 2022-03-24 TODO investigate this.\n                    [op, load_bytearray(left), load_bytearray(right)],\n                    typ=\"bool\",\n                )\n\n        # Compare other types.\n        elif is_numeric_type(left.typ) and is_numeric_type(right.typ):\n            if left.typ.typ == right.typ.typ == \"uint256\":\n                # this works because we only have one unsigned integer type\n                # in the future if others are added, this logic must be expanded\n                op = self._signed_to_unsigned_comparision_op(op)\n\n        elif isinstance(left.typ, BaseType) and isinstance(right.typ, BaseType):\n            if op not in (\"eq\", \"ne\"):\n                return\n        else:\n            # kludge to block behavior in #2638\n            # TODO actually implement equality for complex types\n            raise TypeMismatch(\n                f\"operation not yet supported for {left.typ}, {right.typ}, see issue #2638\",\n                self.expr.op,\n            )\n\n        return IRnode.from_list([op, left, right], typ=\"bool\")\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __new__(cls, obj, *args, **kwargs):\n        # In our usage we should only receive unicode strings.\n        # This conditional and conversion exists to sanity check the values\n        # we're given but we may want to take it out for testing and sanitize\n        # our input instead.\n        if isinstance(obj, string_types):\n            obj = to_text(obj, errors='surrogate_or_strict')\n            return AnsibleUnsafeText(obj)\n        return obj\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, *args, env=None, text=False, **kwargs):\n        if env is None:\n            env = os.environ.copy()\n        self._fix_pyinstaller_ld_path(env)\n\n        self.__text_mode = kwargs.get('encoding') or kwargs.get('errors') or text or kwargs.get('universal_newlines')\n        if text is True:\n            kwargs['universal_newlines'] = True  # For 3.6 compatibility\n            kwargs.setdefault('encoding', 'utf-8')\n            kwargs.setdefault('errors', 'replace')\n        super().__init__(*args, env=env, **kwargs, startupinfo=self._startupinfo)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    // Determine relevant sizes from input and filters.\n    int stride_rows = 0, stride_cols = 0;\n    int rate_rows = 0, rate_cols = 0;\n    int64 pad_top = 0, pad_left = 0;\n    int64 out_rows = 0, out_cols = 0;\n    ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\n               &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\n               &out_cols);\n\n    // Verify that the incoming gradient tensor has the expected size\n    // [ batch, out_rows, out_cols, depth ]\n    const int batch = input.dim_size(0);\n    const int depth = input.dim_size(3);\n    OP_REQUIRES(context,\n                batch == out_backprop.dim_size(0) &&\n                    out_rows == out_backprop.dim_size(1) &&\n                    out_cols == out_backprop.dim_size(2) &&\n                    depth == out_backprop.dim_size(3),\n                errors::InvalidArgument(\"out_backprop has incompatible size.\"));\n\n    // The computed in_backprop has the same dimensions as the input:\n    // [ batch, input_rows, input_cols, depth ]\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input.shape().num_elements() == 0) {\n      return;\n    }\n\n    functor::DilationBackpropInput<Device, T>()(\n        context->eigen_device<Device>(), input.tensor<T, 4>(),\n        filter.tensor<T, 3>(), out_backprop.tensor<T, 4>(), stride_rows,\n        stride_cols, rate_rows, rate_cols, pad_top, pad_left,\n        in_backprop->tensor<T, 4>());\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_host(self):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n            'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = str(self.META['SERVER_PORT'])\n            if server_port != (self.is_secure() and '443' or '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status SpaceToBatchOpCompute(OpKernelContext* context,\n                             const Tensor& orig_input_tensor,\n                             const Tensor& orig_block_shape,\n                             const Tensor& orig_paddings) {\n  const int input_dims = orig_input_tensor.dims();\n  if (!TensorShapeUtils::IsVector(orig_block_shape.shape())) {\n    return errors::InvalidArgument(\"block_shape rank should be 1 instead of \",\n                                   orig_block_shape.dims());\n  }\n\n  const int block_dims = orig_block_shape.dim_size(0);\n  if (orig_input_tensor.dims() < 1 + block_dims) {\n    return errors::InvalidArgument(\"input rank should be >= \", 1 + block_dims,\n                                   \" instead of \", orig_input_tensor.dims());\n  }\n\n  if (!(TensorShapeUtils::IsMatrix(orig_paddings.shape()) &&\n        block_dims == orig_paddings.dim_size(0) &&\n        2 == orig_paddings.dim_size(1))) {\n    return errors::InvalidArgument(\"paddings should have shape [\", block_dims,\n                                   \", 2] instead of \",\n                                   orig_paddings.shape().DebugString());\n  }\n\n  // To avoid out-of-bounds access in the case that the block_shape and/or\n  // paddings tensors are concurrently modified, we must copy the values.\n  gtl::InlinedVector<int64_t, 4> block_shape;\n  gtl::InlinedVector<int64_t, 8> paddings;\n  internal::spacetobatch::SubtleMustCopyFlat(orig_block_shape, &block_shape);\n  internal::spacetobatch::SubtleMustCopyFlat(orig_paddings, &paddings);\n\n  // Determine the length of the prefix of block dims that can be combined\n  // into the batch dimension due to having no padding and block_shape=1.\n  int removed_prefix_block_dims = 0;\n  for (; removed_prefix_block_dims < block_dims; ++removed_prefix_block_dims) {\n    const int dim = removed_prefix_block_dims;\n    if (paddings[2 * dim] != 0 || paddings[2 * dim + 1] != 0 ||\n        block_shape[dim] != 1) {\n      break;\n    }\n  }\n\n  // Determine the length of the suffix of block dims that can be combined\n  // into the depth dimension due to having no padding and block_shape=1.\n  int removed_suffix_block_dims = 0;\n  for (; removed_suffix_block_dims < block_dims - removed_prefix_block_dims;\n       ++removed_suffix_block_dims) {\n    const int dim = block_dims - 1 - removed_suffix_block_dims;\n    if (paddings[dim * 2] != 0 || paddings[dim * 2 + 1] != 0 ||\n        block_shape[dim] != 1) {\n      break;\n    }\n  }\n\n  // Compute the product of the block_shape values.\n  int64_t block_shape_product = 1;\n  for (int block_dim = 0; block_dim < block_dims; ++block_dim) {\n    block_shape_product *= block_shape[block_dim];\n  }\n  if (block_shape_product <= 0) {\n    return errors::InvalidArgument(\n        \"Product of block sizes must be positive, got \", block_shape_product);\n  }\n\n  const int internal_block_dims =\n      block_dims - removed_prefix_block_dims - removed_suffix_block_dims;\n  if (internal_block_dims > kMaxSpaceToBatchBlockDims) {\n    return errors::InvalidArgument(\n        \"Maximum number of non-combined block dimensions is \",\n        internal_block_dims, \" but must not exceed \",\n        kMaxSpaceToBatchBlockDims);\n  }\n\n  if (internal_block_dims == 0) {\n    context->set_output(0, orig_input_tensor);\n    return Status::OK();\n  }\n\n  // For the purpose of computing the result, the input will be treated as\n  // having this shape, of rank 2 + internal_block_dims.\n  TensorShape internal_input_shape;\n\n  // For the purpose of computing the result, the output will be treated as\n  // having this shape, of rank 2 + internal_block_dims.\n  TensorShape internal_output_shape;\n\n  // The actual output shape exposed to callers.\n  TensorShape external_output_shape;\n\n  external_output_shape.AddDim(orig_input_tensor.dim_size(0) *\n                               block_shape_product);\n\n  int64_t input_batch_size = orig_input_tensor.dim_size(0);\n  for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {\n    const int64_t size = orig_input_tensor.dim_size(block_dim + 1);\n    input_batch_size *= size;\n    external_output_shape.AddDim(size);\n  }\n  internal_input_shape.AddDim(input_batch_size);\n  internal_output_shape.AddDim(input_batch_size * block_shape_product);\n\n  for (int block_dim = removed_prefix_block_dims;\n       block_dim < block_dims - removed_suffix_block_dims; ++block_dim) {\n    const int64_t pad_start = paddings[2 * block_dim],\n                  pad_end = paddings[2 * block_dim + 1];\n    if (pad_start < 0 || pad_end < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n    const int64_t input_size = orig_input_tensor.dim_size(block_dim + 1);\n    const int64_t block_shape_value = block_shape[block_dim];\n    const int64_t padded_size = input_size + pad_start + pad_end;\n    if (padded_size % block_shape_value != 0) {\n      return errors::InvalidArgument(\"padded_shape[\", block_dim,\n                                     \"]=\", padded_size,\n                                     \" is not divisible by block_shape[\",\n                                     block_dim, \"]=\", block_shape_value);\n    }\n    internal_input_shape.AddDim(input_size);\n    const int64_t output_size = padded_size / block_shape_value;\n    internal_output_shape.AddDim(output_size);\n    external_output_shape.AddDim(output_size);\n  }\n\n  int64_t depth = 1;\n  for (int dim = block_dims - removed_suffix_block_dims + 1; dim < input_dims;\n       ++dim) {\n    const int64_t size = orig_input_tensor.dim_size(dim);\n    external_output_shape.AddDim(size);\n    depth *= size;\n  }\n  internal_input_shape.AddDim(depth);\n  internal_output_shape.AddDim(depth);\n\n  // Allocate output tensor.\n  Tensor* output_tensor = nullptr;\n  TF_RETURN_IF_ERROR(\n      context->allocate_output(0, external_output_shape, &output_tensor));\n\n  const int64_t* internal_paddings = &paddings[2 * removed_prefix_block_dims];\n  const int64_t* internal_block_shape = &block_shape[removed_prefix_block_dims];\n\n  switch (internal_block_dims) {\n#define TF_SPACETOBATCH_BLOCK_DIMS_CASE(NUM_BLOCK_DIMS)                   \\\n  case NUM_BLOCK_DIMS: {                                                  \\\n    TF_RETURN_IF_ERROR(                                                   \\\n        functor::SpaceToBatchFunctor<Device, T, NUM_BLOCK_DIMS, false>()( \\\n            context->eigen_device<Device>(),                              \\\n            orig_input_tensor.shaped<T, NUM_BLOCK_DIMS + 2>(              \\\n                internal_input_shape.dim_sizes()),                        \\\n            internal_block_shape, internal_paddings,                      \\\n            output_tensor->shaped<T, NUM_BLOCK_DIMS + 2>(                 \\\n                internal_output_shape.dim_sizes())));                     \\\n  } break;                                                                \\\n    /**/\n    TF_SPACETOBATCH_FOR_EACH_NUM_BLOCK_DIMS(TF_SPACETOBATCH_BLOCK_DIMS_CASE)\n#undef TF_SPACETOBATCH_BLOCK_DIMS_CASE\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "        def event_err(e, pdu_to_check):\n            errmsg = (\n                \"event id %s: unable to verify signature for event id domain: %s\"\n                % (pdu_to_check.pdu.event_id, e.getErrorMessage())\n            )\n            # XX as above: not really sure if these are the right codes\n            raise SynapseError(400, errmsg, Codes.UNAUTHORIZED)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_load_finished(self, ok):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        sess_manager = objreg.get('session-manager')\n        sess_manager.save_autosave()\n\n        if ok and not self._has_ssl_errors:\n            if self.url().scheme() == 'https':\n                self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.set_current()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decode(\n        self,\n        types: Iterable[TypeStr],\n        data: Decodable,\n    ) -> Tuple[Any, ...]:\n        \"\"\"\n        Decodes the binary value ``data`` as a sequence of values of the ABI types\n        in ``types`` via the head-tail mechanism into a tuple of equivalent python\n        values.\n\n        :param types: A list or tuple of string representations of the ABI types that\n            will be used for decoding e.g. ``('uint256', 'bytes[]', '(int,int)')``\n        :param data: The binary value to be decoded.\n\n        :returns: A tuple of equivalent python values for the ABI values\n            represented in ``data``.\n        \"\"\"\n        validate_list_like_param(types, \"types\")\n        validate_bytes_param(data, \"data\")\n\n        decoders = [self._registry.get_decoder(type_str) for type_str in types]\n\n        decoder = TupleDecoder(decoders=decoders)\n        stream = self.stream_class(data)\n\n        return decoder(stream)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_snippet_path(self, path):\r\n        \"\"\"Get snippet path.\"\"\"\r\n\r\n        snippet = None\r\n        for base in self.base_path:\r\n            if os.path.exists(base):\r\n                if os.path.isdir(base):\r\n                    filename = os.path.join(base, path)\r\n                    if os.path.exists(filename):\r\n                        snippet = filename\r\n                        break\r\n                else:\r\n                    basename = os.path.basename(base)\r\n                    dirname = os.path.dirname(base)\r\n                    if basename.lower() == path.lower():\r\n                        filename = os.path.join(dirname, path)\r\n                        if os.path.exists(filename):\r\n                            snippet = filename\r\n                            break\r\n        return snippet\r\n\r"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set_password(self, service, username, password):\n        \"\"\"Write the password to the registry\n        \"\"\"\n        # encrypt the password\n        password_encrypted = self.crypt_handler.encrypt(password)\n        # encode with base64\n        password_base64 = base64.encodestring(password_encrypted)\n\n        # store the password\n        from _winreg import HKEY_CURRENT_USER, CreateKey, SetValueEx, REG_SZ\n        hkey = CreateKey(HKEY_CURRENT_USER, r'Software\\%s\\Keyring' % service)\n        SetValueEx(hkey, username, 0, REG_SZ, password_base64)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set_password(self, password, old_password=None):\n        \"\"\"\n        Change the user's password. Raise a ValueError if the username or\n        the password are invalid.\n        \"\"\"\n        assert isinstance(password, str)\n        assert old_password is None or isinstance(old_password, str)\n        if not password:\n            raise ValueError(\"password can't be empty\")\n        cfg = cherrypy.tree.apps[''].cfg\n\n        # Cannot update admin-password if defined\n        if self.username == cfg.admin_user and cfg.admin_password:\n            raise ValueError(_(\"can't update admin-password defined in configuration file\"))\n\n        if old_password and not check_password(old_password, self.hash_password):\n            raise ValueError(_(\"Wrong password\"))\n\n        # Check password length\n        if cfg.password_min_length > len(password) or len(password) > cfg.password_max_length:\n            raise ValueError(\n                _('Password must have between %(min)d and %(max)d characters.')\n                % {'min': cfg.password_min_length, 'max': cfg.password_max_length}\n            )\n\n        # Verify password score using zxcvbn\n        stats = zxcvbn(password)\n        if stats.get('score') < cfg.password_score:\n            msg = _('Password too weak.')\n            warning = stats.get('feedback', {}).get('warning')\n            suggestions = stats.get('feedback', {}).get('suggestions')\n            if warning:\n                msg += ' ' + warning\n            if suggestions:\n                msg += ' ' + ' '.join(suggestions)\n            raise ValueError(msg)\n\n        logger.info(\"updating user password [%s]\", self.username)\n        self.hash_password = hash_password(password)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask(self, text, mode=\"\", *args, **kwargs):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :return: An internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module.\n        \"\"\"\n        return self.font.getmask(text, mode)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set(self, name, value, force=False):\n        \"\"\"Set a form element identified by ``name`` to a specified ``value``.\n        The type of element (input, textarea, select, ...) does not\n        need to be given; it is inferred by the following methods:\n        :func:`~Form.set_checkbox`,\n        :func:`~Form.set_radio`,\n        :func:`~Form.set_input`,\n        :func:`~Form.set_textarea`,\n        :func:`~Form.set_select`.\n        If none of these methods find a matching element, then if ``force``\n        is True, a new element (``<input type=\"text\" ...>``) will be\n        added using :func:`~Form.new_control`.\n\n        Example: filling-in a login/password form with EULA checkbox\n\n        .. code-block:: python\n\n            form.set(\"login\", username)\n            form.set(\"password\", password)\n            form.set(\"eula-checkbox\", True)\n\n        Example: uploading a file through a ``<input type=\"file\"\n        name=\"tagname\">`` field (provide the path to the local file,\n        and its content will be uploaded):\n\n        .. code-block:: python\n\n            form.set(\"tagname\", path_to_local_file)\n\n        \"\"\"\n        for func in (\"checkbox\", \"radio\", \"input\", \"textarea\", \"select\"):\n            try:\n                getattr(self, \"set_\" + func)({name: value})\n                return\n            except InvalidFormMethod:\n                pass\n        if force:\n            self.new_control('text', name, value=value)\n            return\n        raise LinkNotFoundError(\"No valid element named \" + name)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *a_indices_t, *a_values_t, *a_shape_t, *b_indices_t,\n        *b_values_t, *b_shape_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_indices\", &a_indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_values\", &a_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_shape\", &a_shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_indices\", &b_indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_values\", &b_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_shape\", &b_shape_t));\n\n    // Validations.\n    OP_REQUIRES(\n        ctx,\n        TensorShapeUtils::IsMatrix(a_indices_t->shape()) &&\n            TensorShapeUtils::IsMatrix(b_indices_t->shape()),\n        errors::InvalidArgument(\"Inputs a_indices and b_indices should be \"\n                                \"matrices but received shapes: \",\n                                a_indices_t->shape().DebugString(), \", \",\n                                b_indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_values_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_values_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs a_values and b_values should be vectors \"\n                    \"but received shapes: \",\n                    a_values_t->shape().DebugString(), \" and \",\n                    b_values_t->shape().DebugString()));\n\n    const int64 a_nnz = a_indices_t->dim_size(0);\n    const int64 b_nnz = b_indices_t->dim_size(0);\n    const auto a_values = a_values_t->vec<T>();\n    const auto b_values = b_values_t->vec<T>();\n\n    OP_REQUIRES(\n        ctx, a_values.size() == a_nnz && b_values.size() == b_nnz,\n        errors::InvalidArgument(\"Expected \", a_nnz, \" and \", b_nnz,\n                                \" non-empty input values, got \",\n                                a_values.size(), \" and \", b_values.size()));\n\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_shape_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Input shapes should be a vector but received shapes \",\n                    a_shape_t->shape().DebugString(), \" and \",\n                    b_shape_t->shape().DebugString()));\n    OP_REQUIRES(ctx, a_shape_t->IsSameSize(*b_shape_t),\n                errors::InvalidArgument(\n                    \"Operands do not have the same ranks; got shapes: \",\n                    a_shape_t->SummarizeValue(10), \" and \",\n                    b_shape_t->SummarizeValue(10)));\n    const auto a_shape = a_shape_t->flat<int64>();\n    const auto b_shape = b_shape_t->flat<int64>();\n    for (int i = 0; i < a_shape_t->NumElements(); ++i) {\n      OP_REQUIRES(ctx, a_shape(i) == b_shape(i),\n                  errors::InvalidArgument(\"Operands' shapes do not match: got \",\n                                          a_shape(i), \" and \", b_shape(i),\n                                          \" for dimension \", i));\n    }\n\n    OP_REQUIRES(\n        ctx, a_indices_t->dim_size(1) == b_indices_t->dim_size(1),\n        errors::InvalidArgument(\n            \"Indices' dimensions do not match: got \", a_indices_t->dim_size(1),\n            \" and \", b_indices_t->dim_size(1), \" for the second dimension.\"));\n    const int num_dims = a_indices_t->dim_size(1);\n    const auto a_indices_mat = a_indices_t->matrix<int64>();\n    const auto b_indices_mat = b_indices_t->matrix<int64>();\n    std::vector<T> a_augmented_values, b_augmented_values;\n    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx\n    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,\n                                b_values, b_nnz, num_dims, &a_augmented_values,\n                                &b_augmented_values, &entries_to_copy);\n\n    // Allocates and fills output tensors.\n    const int64 sum_nnz = a_augmented_values.size();\n    Tensor *output_indices_t, *output_values_t;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({sum_nnz, num_dims}),\n                                        &output_indices_t));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(1, TensorShape({sum_nnz}), &output_values_t));\n    auto output_indices_mat = output_indices_t->matrix<int64>();\n\n    for (int64 i = 0; i < sum_nnz; ++i) {\n      const bool from_a = entries_to_copy[i].first;\n      const int64 idx = entries_to_copy[i].second;\n      output_indices_mat.chip<0>(i) =\n          from_a ? a_indices_mat.chip<0>(idx) : b_indices_mat.chip<0>(idx);\n    }\n\n    // Performs the functor operation using Eigen.\n    //\n    // Note that the two stack-allocated std::vector's may not be aligned. Using\n    // allocate_temp() would've given us aligned storage, but we do not know\n    // their sizes in advance, so we couldn't use allocate_temp() anyway.\n    //\n    // TODO(zongheng): measure if it's worthwhile to somehow force alignment.\n    using UnalignedTensorMap =\n        Eigen::TensorMap<Eigen::Tensor<const T, 1, Eigen::RowMajor>,\n                         Eigen::Unaligned>;\n    auto a_augmented_values_t =\n        UnalignedTensorMap(a_augmented_values.data(), sum_nnz);\n    auto b_augmented_values_t =\n        UnalignedTensorMap(b_augmented_values.data(), sum_nnz);\n    output_values_t->flat<T>().device(ctx->eigen_device<Device>()) =\n        a_augmented_values_t.binaryExpr(b_augmented_values_t,\n                                        typename Functor::func());\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "var determineWebcamStreamType = function (streamUrl) {\n    if (streamUrl) {\n        if (streamUrl.startsWith(\"webrtc\")) {\n            return \"webrtc\";\n        }\n\n        var lastDotPosition = streamUrl.lastIndexOf(\".\");\n        var firstQuotationSignPosition = streamUrl.indexOf(\"?\");\n        if (\n            lastDotPosition != -1 &&\n            firstQuotationSignPosition != -1 &&\n            lastDotPosition >= firstQuotationSignPosition\n        ) {\n            throw \"Malformed URL. Cannot determine stream type.\";\n        }\n\n        // If we have found a dot, try to extract the extension.\n        if (lastDotPosition > -1) {\n            if (firstQuotationSignPosition > -1) {\n                var extension = streamUrl.slice(\n                    lastDotPosition + 1,\n                    firstQuotationSignPosition - 1\n                );\n            } else {\n                var extension = streamUrl.slice(lastDotPosition + 1);\n            }\n            if (extension.toLowerCase() == \"m3u8\") {\n                return \"hls\";\n            }\n        }\n        // By default, 'mjpg' is the stream type.\n        return \"mjpg\";\n    } else {\n        throw \"Empty streamUrl. Cannot determine stream type.\";\n    }\n};\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static Status Compute(OpKernelContext* context,\n                        const typename TTypes<T, 1>::ConstTensor& values,\n                        const typename TTypes<T, 1>::ConstTensor& value_range,\n                        int32_t nbins, typename TTypes<Tout, 1>::Tensor& out) {\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    Tensor index_to_bin_tensor;\n\n    TF_RETURN_IF_ERROR(context->forward_input_or_allocate_temp(\n        {0}, DataTypeToEnum<int32>::value, TensorShape({values.size()}),\n        &index_to_bin_tensor));\n    auto index_to_bin = index_to_bin_tensor.flat<int32>();\n\n    const double step = static_cast<double>(value_range(1) - value_range(0)) /\n                        static_cast<double>(nbins);\n    const double nbins_minus_1 = static_cast<double>(nbins - 1);\n\n    // The calculation is done by finding the slot of each value in `values`.\n    // With [a, b]:\n    //   step = (b - a) / nbins\n    //   (x - a) / step\n    // , then the entries are mapped to output.\n\n    // Bug fix: Switch the order of cwiseMin and int32-casting to avoid\n    // producing a negative index when casting an big int64 number to int32\n    index_to_bin.device(d) =\n        ((values.cwiseMax(value_range(0)) - values.constant(value_range(0)))\n             .template cast<double>() /\n         step)\n            .cwiseMin(nbins_minus_1)\n            .template cast<int32>();\n\n    out.setZero();\n    for (int32_t i = 0; i < index_to_bin.size(); i++) {\n      out(index_to_bin(i)) += Tout(1);\n    }\n    return Status::OK();\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    # We must decode path before validating it\n    path = _decode(path)\n\n    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)\n    if \"#\" in path:\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_path_with_query_string(scope):\n    path_with_query_string = scope.get(\"root_path\", \"\") + scope[\"path\"]\n    if scope[\"query_string\"]:\n        path_with_query_string = \"{}?{}\".format(\n            path_with_query_string, scope[\"query_string\"].decode(\"ascii\")\n        )\n    return path_with_query_string\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n        state->bytes = row_byte_size * tile_length;\n\n        /* overflow check for malloc */\n        if (state->bytes > INT_MAX - 1) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        /* realloc to fit whole tile */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "new_aubio_pitchyinfft (uint_t samplerate, uint_t bufsize)\n{\n  uint_t i = 0, j = 1;\n  smpl_t freq = 0, a0 = 0, a1 = 0, f0 = 0, f1 = 0;\n  aubio_pitchyinfft_t *p = AUBIO_NEW (aubio_pitchyinfft_t);\n  p->winput = new_fvec (bufsize);\n  p->fft = new_aubio_fft (bufsize);\n  if (!p->fft) goto beach;\n  p->fftout = new_fvec (bufsize);\n  p->sqrmag = new_fvec (bufsize);\n  p->yinfft = new_fvec (bufsize / 2 + 1);\n  p->tol = 0.85;\n  p->peak_pos = 0;\n  p->win = new_aubio_window (\"hanningz\", bufsize);\n  p->weight = new_fvec (bufsize / 2 + 1);\n  for (i = 0; i < p->weight->length; i++) {\n    freq = (smpl_t) i / (smpl_t) bufsize *(smpl_t) samplerate;\n    while (freq > freqs[j]) {\n      j += 1;\n    }\n    a0 = weight[j - 1];\n    f0 = freqs[j - 1];\n    a1 = weight[j];\n    f1 = freqs[j];\n    if (f0 == f1) {           // just in case\n      p->weight->data[i] = a0;\n    } else if (f0 == 0) {     // y = ax+b\n      p->weight->data[i] = (a1 - a0) / f1 * freq + a0;\n    } else {\n      p->weight->data[i] = (a1 - a0) / (f1 - f0) * freq +\n          (a0 - (a1 - a0) / (f1 / f0 - 1.));\n    }\n    while (freq > freqs[j]) {\n      j += 1;\n    }\n    //AUBIO_DBG(\"%f\\n\",p->weight->data[i]);\n    p->weight->data[i] = DB2LIN (p->weight->data[i]);\n    //p->weight->data[i] = SQRT(DB2LIN(p->weight->data[i]));\n  }\n  // check for octave errors above 1300 Hz\n  p->short_period = (uint_t)ROUND(samplerate / 1300.);\n  return p;\n\nbeach:\n  if (p->winput) del_fvec(p->winput);\n  AUBIO_FREE(p);\n  return NULL;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.join(component_root, filename)\n\n        LOGGER.debug(\"ComponentRequestHandler: GET: %s -> %s\", path, abspath)\n\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except (OSError) as e:\n            LOGGER.error(f\"ComponentRequestHandler: GET {path} read error\", exc_info=e)\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_host(self):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if 'HTTP_X_FORWARDED_HOST' in self.META:\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = str(self.META['SERVER_PORT'])\n            if server_port != (self.is_secure() and '443' or '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--project_file\", type=str, default=\"project.yml\", help=\"file to describe FL project\")\n    parser.add_argument(\"-w\", \"--workspace\", type=str, default=\"workspace\", help=\"directory used by provision\")\n    parser.add_argument(\"-c\", \"--custom_folder\", type=str, default=\".\", help=\"additional folder to load python codes\")\n    parser.add_argument(\n        \"-u\",\n        \"--ui_tool\",\n        action=\"store_true\",\n        help=\"Run provisioning UI tool to generate project.yml file\",\n    )\n\n    args = parser.parse_args()\n\n    file_path = pathlib.Path(__file__).parent.absolute()\n    current_path = os.getcwd()\n    custom_folder_path = os.path.join(current_path, args.custom_folder)\n    sys.path.append(custom_folder_path)\n    print(\"Path list (sys.path) for python codes loading: {}\".format(sys.path))\n\n    # main project file\n    project_file = args.project_file\n    current_project_yml = os.path.join(current_path, \"project.yml\")\n    if len(sys.argv) == 1 and not os.path.exists(current_project_yml):\n        answer = input(\n            f\"No project.yml found in current folder.  Is it OK to generate one at {current_project_yml} for you? (y/N) \"\n        )\n        if answer.strip().upper() == \"Y\":\n            shutil.copyfile(os.path.join(file_path, \"project.yml\"), current_project_yml)\n            print(f\"{current_project_yml} was created.  Please edit it to fit your FL configuration.\")\n        exit(0)\n\n    if args.ui_tool:\n        ui_helper_path = os.path.join(file_path, \"provision_helper.html\")\n        ui_helper_url = f\"file://{ui_helper_path}\"\n        webbrowser.open_new_tab(ui_helper_url)\n        print(\n            \"\\n******\\n\"\n            \"Now launching provisioning UI tool.\\n\"\n            \"After generating project.yml in the browser and saving it to your local folder,\\n\"\n            \"please re-run provision with -p option, pointing to the generated project.yml, to generate all packages.\\n******\\n\"\n        )\n        exit(0)\n\n    workspace = args.workspace\n    workspace_full_path = os.path.join(current_path, workspace)\n\n    project_full_path = os.path.join(current_path, project_file)\n    print(f\"Project yaml file: {project_full_path}.\")\n\n    project_dict = yaml.load(open(project_full_path, \"r\"), Loader=yaml.Loader)\n    api_version = project_dict.get(\"api_version\")\n    if api_version not in [3]:\n        raise ValueError(f\"API version expected 3 but found {api_version}\")\n\n    project_name = project_dict.get(\"name\")\n    project_description = project_dict.get(\"description\", \"\")\n    participants = list()\n    for p in project_dict.get(\"participants\"):\n        participants.append(Participant(**p))\n    project = Project(name=project_name, description=project_description, participants=participants)\n\n    builders = list()\n    for b in project_dict.get(\"builders\"):\n        path = b.get(\"path\")\n        args = b.get(\"args\")\n        builders.append(instantiate_class(path, args))\n\n    provisioner = Provisioner(workspace_full_path, builders)\n\n    provisioner.provision(project)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def edit_package():\n    api = flask.current_app.config[\"PYLOAD_API\"]\n    try:\n        id = int(flask.request.form[\"pack_id\"])\n        data = {\n            \"name\": flask.request.form[\"pack_name\"],\n            \"_folder\": flask.request.form[\"pack_folder\"],\n            \"password\": flask.request.form[\"pack_pws\"],\n        }\n\n        api.set_package_data(id, data)\n        return jsonify(response=\"success\")\n\n    except Exception:\n        return jsonify(False), 500\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_audiences(self):\n        \"\"\"\n        Gets the audiences\n\n        :returns: The valid audiences for the SAML Response\n        :rtype: list\n        \"\"\"\n        audience_nodes = self.__query_assertion('/saml:Conditions/saml:AudienceRestriction/saml:Audience')\n        return [node.text for node in audience_nodes if node.text is not None]\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendEmail(sydent, templateName, mailTo, substitutions):\n        mailFrom = sydent.cfg.get('email', 'email.from')\n        mailTemplateFile = sydent.cfg.get('email', templateName)\n\n        myHostname = sydent.cfg.get('email', 'email.hostname')\n        if myHostname == '':\n            myHostname = socket.getfqdn()\n        midRandom = \"\".join([random.choice(string.ascii_letters) for _ in range(16)])\n        messageid = \"<%d%s@%s>\" % (time_msec(), midRandom, myHostname)\n\n        allSubstitutions = {}\n        allSubstitutions.update(substitutions)\n        allSubstitutions.update({\n            'messageid': messageid,\n            'date': email.utils.formatdate(localtime=False),\n            'to': mailTo,\n            'from': mailFrom,\n        })\n\n        for k,v in allSubstitutions.items():\n            allSubstitutions[k] = v.decode('utf8')\n            allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))\n            allSubstitutions[k+\"_forurl\"] = urllib.quote(v)\n\n        mailString = open(mailTemplateFile).read() % allSubstitutions\n        rawFrom = email.utils.parseaddr(mailFrom)[1]\n        rawTo = email.utils.parseaddr(mailTo)[1]\n        if rawFrom == '' or rawTo == '':\n            logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)\n            raise EmailAddressException()\n        mailServer = sydent.cfg.get('email', 'email.smtphost')\n        mailPort = sydent.cfg.get('email', 'email.smtpport')\n        mailUsername = sydent.cfg.get('email', 'email.smtpusername')\n        mailPassword = sydent.cfg.get('email', 'email.smtppassword')\n        mailTLSMode = sydent.cfg.get('email', 'email.tlsmode')\n        logger.info(\"Sending mail to %s with mail server: %s\" % (mailTo, mailServer,))\n        try:\n            if mailTLSMode == 'SSL' or mailTLSMode == 'TLS':\n                smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname)\n            elif mailTLSMode == 'STARTTLS':\n                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n                smtp.starttls()\n            else:\n                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n            if mailUsername != '':\n                smtp.login(mailUsername, mailPassword)\n            smtp.sendmail(rawFrom, rawTo, mailString.encode('utf-8'))\n            smtp.quit()\n        except Exception as origException:\n            twisted.python.log.err()\n            ese = EmailSendException()\n            ese.cause = origException\n            raise ese\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& in0 = context->input(0);\n    const Tensor& in1 = context->input(1);\n    const int dims = in0.dims();\n    constexpr int kMinDims = 0;\n    constexpr int kMaxDims = 5;\n    OP_REQUIRES(context, kMinDims <= dims && dims <= kMaxDims,\n                errors::Unimplemented(\"inputs rank not in [\", kMinDims, \",\",\n                                      kMaxDims, \"]: \", dims));\n    OP_REQUIRES(\n        context,\n        TensorShapeUtils::IsMatrix(in1.shape()) && in1.dim_size(1) == 2,\n        errors::InvalidArgument(\"paddings must be a matrix with 2 columns: \",\n                                in1.shape().DebugString()));\n    OP_REQUIRES(\n        context, dims == in1.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs\",\n            in1.shape().DebugString(), \" \", in0.shape().DebugString()));\n\n    // Compute the shape of the output tensor, and allocate it.\n    TensorShape output_shape;\n    typename TTypes<Tpaddings>::ConstMatrix paddings = in1.matrix<Tpaddings>();\n    for (int d = 0; d < dims; ++d) {\n      const Tpaddings before = paddings(d, 0);  // Pad before existing elements.\n      const Tpaddings after = paddings(d, 1);   // Pad after existing elements.\n      OP_REQUIRES(context, before >= 0 && after >= 0,\n                  errors::InvalidArgument(\n                      \"Paddings must be non-negative: \", before, \", \", after));\n\n      const int64_t out_size = in0.dim_size(d) - (before + after);\n      if (offset_ == 0) {  // SYMMETRIC mode.\n        OP_REQUIRES(context, before <= out_size && after <= out_size,\n                    errors::InvalidArgument(\"paddings must be no greater \"\n                                            \"than the output dimension size: \",\n                                            before, \", \", after,\n                                            \" greater than \", out_size));\n      } else if (offset_ == 1) {  // REFLECT mode.\n        OP_REQUIRES(context, before < out_size && after < out_size,\n                    errors::InvalidArgument(\"paddings must be less than\"\n                                            \" the output dimension size: \",\n                                            before, \", \", after,\n                                            \" not less than \", out_size));\n      }\n      output_shape.AddDim(out_size);\n    }\n\n    if (output_shape == in0.shape()) {\n      context->set_output(0, in0);\n      return;\n    }\n\n    Tensor scratch;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<T>::value,\n                                                   in0.shape(), &scratch));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n\n#define MIRROR_PAD_GRAD_CASE(k)                                           \\\n  case k: {                                                               \\\n    functor::MirrorPadGrad<Device, T, Tpaddings, k>()(                    \\\n        context->eigen_device<Device>(), To32Bit(output->tensor<T, k>()), \\\n        To32Bit(in0.tensor<T, k>()), paddings, offset_,                   \\\n        To32Bit(scratch.tensor<T, k>()));                                 \\\n    break;                                                                \\\n  }\n\n    // Invoke the dims-specific implementation.\n    switch (dims) {\n      MIRROR_PAD_GRAD_CASE(1);\n      MIRROR_PAD_GRAD_CASE(2);\n      MIRROR_PAD_GRAD_CASE(3);\n      MIRROR_PAD_GRAD_CASE(4);\n      MIRROR_PAD_GRAD_CASE(5);\n      default:\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\"Unsupported rank: \",\n                                            in0.shape().DebugString()));\n    }\n#undef MIRROR_PAD_GRAD_CASE\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                SpaceToBatchNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int32* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int32* paddings_data = GetTensorData<int32>(op_context->paddings);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Paddings should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->paddings), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[1], 2);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n\n  // Ensures the input height and width (with padding) is a multiple of block\n  // shape height and width.\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                          paddings_data[dim * 2 + 1]);\n    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n    output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n    output_batch_size *= block_shape[dim];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask2(\n        self,\n        text,\n        mode=\"\",\n        direction=None,\n        features=None,\n        language=None,\n        stroke_width=0,\n        anchor=None,\n        ink=0,\n        start=None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. If the font has embedded color data, the bitmap\n        should have mode ``RGBA``. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n                          .. versionadded:: 4.2.0\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n                         .. versionadded:: 4.2.0\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n                         .. versionadded:: 6.0.0\n\n        :param stroke_width: The width of the text stroke.\n\n                         .. versionadded:: 6.2.0\n\n        :param anchor:  The text anchor alignment. Determines the relative location of\n                        the anchor to the text. The default alignment is top left.\n                        See :ref:`text-anchors` for valid values.\n\n                         .. versionadded:: 8.0.0\n\n        :param ink: Foreground ink for rendering in RGBA mode.\n\n                         .. versionadded:: 8.0.0\n\n        :param start: Tuple of horizontal and vertical offset, as text may render\n                      differently when starting at fractional coordinates.\n\n                         .. versionadded:: 9.4.0\n\n        :return: A tuple of an internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module, and the text offset, the\n                 gap between the starting coordinate and the first marking\n        \"\"\"\n        if start is None:\n            start = (0, 0)\n        im, size, offset = self.font.render(\n            text,\n            Image.core.fill,\n            mode,\n            direction,\n            features,\n            language,\n            stroke_width,\n            anchor,\n            ink,\n            start[0],\n            start[1],\n            Image.MAX_IMAGE_PIXELS,\n        )\n        Image._decompression_bomb_check(size)\n        return im, offset\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _deserialize_index(self):\n        logger.info(f\"Loading index from {self.index_path}\")\n        resolved_index_path = self._resolve_path(self.index_path, self.INDEX_FILENAME + \".index.dpr\")\n        self.index = faiss.read_index(resolved_index_path)\n        resolved_meta_path = self._resolve_path(self.index_path, self.INDEX_FILENAME + \".index_meta.dpr\")\n        with open(resolved_meta_path, \"rb\") as metadata_file:\n            self.index_id_to_db_id = pickle.load(metadata_file)\n        assert (\n            len(self.index_id_to_db_id) == self.index.ntotal\n        ), \"Deserialized index_id_to_db_id should match faiss index size\"\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def execute(self, image_id):\n        \"\"\"Create temp file into store and return path to it\n\n        :param image_id: Glance Image ID\n        \"\"\"\n        # NOTE(flaper87): We've decided to use a separate `work_dir` for\n        # this task - and tasks coming after this one - as a way to expect\n        # users to configure a local store for pre-import works on the image\n        # to happen.\n        #\n        # While using any path should be \"technically\" fine, it's not what\n        # we recommend as the best solution. For more details on this, please\n        # refer to the comment in the `_ImportToStore.execute` method.\n        data = script_utils.get_image_data_iter(self.uri)\n\n        path = self.store.add(image_id, data, 0, context=None)[0]\n        return path\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        special=None,\n        min_freq=0,\n        max_size=None,\n        lower_case=False,\n        delimiter=None,\n        vocab_file=None,\n        pretrained_vocab_file: str = None,\n        never_split=None,\n        unk_token=\"<unk>\",\n        eos_token=\"<eos>\",\n        additional_special_tokens=[\"<formula>\"],\n        language=\"en\",\n        **kwargs,\n    ):\n        logger.error(\n            \"`TransfoXL` was deprecated due to security issues linked to `pickle.load` in `TransfoXLTokenizer`. \"\n            \"See more details on this model's documentation page: \"\n            \"`https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/transfo-xl.md`.\"\n        )\n\n        requires_backends(self, \"sacremoses\")\n        if special is None:\n            special = []\n        self.counter = Counter()\n        self.special = special\n        self.min_freq = min_freq\n        self.max_size = max_size\n        self.lower_case = lower_case\n        self.delimiter = delimiter\n        self.vocab_file = vocab_file\n        self.punctuation_symbols = '!\"#$%&()*+,-./\\\\:;<=>?@[\\\\]^_`{|}~'\n        self.punction_without_space_before_pattern = re.compile(rf\"[^\\s][{self.punctuation_symbols}]\")\n        self.punctuation_with_space_around_pattern = self._compile_space_around_punctuation_pattern()\n        self.language = language\n        self.moses_punct_normalizer = sm.MosesPunctNormalizer(language)\n        self.moses_tokenizer = sm.MosesTokenizer(language)\n        self.moses_detokenizer = sm.MosesDetokenizer(language)\n        self.idx2sym = []\n        self.sym2idx = OrderedDict()\n        # This try... catch... is not beautiful but honestly this tokenizer was not made to be used\n        # in a library like ours, at all.\n        try:\n            vocab_dict = None\n            if pretrained_vocab_file is not None:\n                # Priority on pickle files (support PyTorch and TF)\n                with open(pretrained_vocab_file, \"rb\") as f:\n                    vocab_dict = pickle.load(f)\n\n                # Loading a torch-saved transfo-xl vocab dict with pickle results in an integer\n                # Entering this if statement means that we tried to load a torch-saved file with pickle, and we failed.\n                # We therefore load it with torch, if it's available.\n                if isinstance(vocab_dict, int):\n                    if not is_torch_available():\n                        raise ImportError(\n                            \"Not trying to load dict with PyTorch as you need to install pytorch to load \"\n                            \"from a PyTorch pretrained vocabulary, \"\n                            \"or activate it with environment variables USE_TORCH=1 and USE_TF=0.\"\n                        )\n                    vocab_dict = torch.load(pretrained_vocab_file)\n\n            if vocab_dict is not None:\n                for key, value in vocab_dict.items():\n                    if key not in self.__dict__ or key in [\"sym2idx\", \"idx2sym\"]:\n                        self.__dict__[key] = value\n            elif vocab_file is not None:\n                self.build_vocab()\n\n        except Exception as e:\n            raise ValueError(\n                f\"Unable to parse file {pretrained_vocab_file}. Unknown format. \"\n                \"If you tried to load a model saved through TransfoXLTokenizerFast, \"\n                \"please note they are not compatible.\"\n            ) from e\n\n        if vocab_file is not None:\n            self.build_vocab()\n\n        super().__init__(\n            special=special,\n            min_freq=min_freq,\n            max_size=max_size,\n            lower_case=lower_case,\n            delimiter=delimiter,\n            vocab_file=vocab_file,\n            pretrained_vocab_file=pretrained_vocab_file,\n            never_split=never_split,\n            unk_token=unk_token,\n            eos_token=eos_token,\n            additional_special_tokens=additional_special_tokens,\n            language=language,\n            **kwargs,\n        )\n\n        # these are not required to initialize the parent class as only used when tokenizing.\n        if never_split is None:\n            never_split = self.all_special_tokens\n        self.never_split = never_split\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_package(self, name, links, dest=Destination.QUEUE):\n        \"\"\"\n        Adds a package, with links to desired destination.\n\n        :param name: name of the new package\n        :param links: list of urls\n        :param dest: `Destination`\n        :return: package id of the new package\n        \"\"\"\n        if self.pyload.config.get(\"general\", \"folder_per_package\"):\n            folder = name\n        else:\n            folder = \"\"\n\n        folder = (\n            folder.replace(\"http://\", \"\")\n            .replace(\"https://\", \"\")\n            .replace(\":\", \"\")\n            .replace(\"/\", \"_\")\n            .replace(\"\\\\\", \"_\")\n        )\n\n        package_id = self.pyload.files.add_package(name, folder, Destination(dest))\n\n        self.pyload.files.add_links(links, package_id)\n\n        self.pyload.log.info(\n            self._(\"Added package {name} containing {count:d} links\").format(\n                name=name, count=len(links)\n            )\n        )\n\n        self.pyload.files.save()\n\n        return package_id\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _serve_request(self, environ, start_response):\n        # https://bugs.python.org/issue16679\n        # https://github.com/bottlepy/bottle/blob/f9b1849db4/bottle.py#L984\n        path = environ[\"PATH_INFO\"].encode(\"latin-1\").decode(\"utf-8\", \"ignore\")\n\n        m = re.fullmatch(r\"/livereload/([0-9]+)/[0-9]+\", path)\n        if m:\n            epoch = int(m[1])\n            start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n\n            def condition():\n                return self._visible_epoch > epoch\n\n            with self._epoch_cond:\n                if not condition():\n                    # Stall the browser, respond as soon as there's something new.\n                    # If there's not, respond anyway after a minute.\n                    self._log_poll_request(environ.get(\"HTTP_REFERER\"), request_id=path)\n                    self._epoch_cond.wait_for(condition, timeout=self.poll_response_timeout)\n                return [b\"%d\" % self._visible_epoch]\n\n        if path == \"/js/livereload.js\":\n            file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")\n        elif path.startswith(self.mount_path):\n            if path.endswith(\"/\"):\n                path += \"index.html\"\n            path = path[len(self.mount_path):]\n            file_path = os.path.join(self.root, path.lstrip(\"/\"))\n        elif path == \"/\":\n            start_response(\"302 Found\", [(\"Location\", self.mount_path)])\n            return []\n        else:\n            return None  # Not found\n\n        # Wait until the ongoing rebuild (if any) finishes, so we're not serving a half-built site.\n        with self._epoch_cond:\n            self._epoch_cond.wait_for(lambda: self._visible_epoch == self._wanted_epoch)\n            epoch = self._visible_epoch\n\n        try:\n            file = open(file_path, \"rb\")\n        except OSError:\n            return None  # Not found\n\n        if path.endswith(\".html\"):\n            with file:\n                content = file.read()\n            content = self._inject_js_into_html(content, epoch)\n            file = io.BytesIO(content)\n            content_length = len(content)\n        else:\n            content_length = os.path.getsize(file_path)\n\n        content_type = self._guess_type(file_path)\n        start_response(\n            \"200 OK\", [(\"Content-Type\", content_type), (\"Content-Length\", str(content_length))]\n        )\n        return wsgiref.util.FileWrapper(file)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _test_setup_settings(pxe_once=1):\n\n    # rewrite modules.conf so we know we can use the testing module\n    # for xmlrpc rw testing (Makefile will put the user value back)\n   \n    import yaml\n    import Cheetah.Template as Template\n\n    MODULES_TEMPLATE = \"installer_templates/settings.template\"\n    DEFAULTS = \"installer_templates/defaults\"\n    fh = open(DEFAULTS)\n    data = yaml.load(fh.read())\n    fh.close()\n    data[\"pxe_once\"] = pxe_once\n\n    t = Template.Template(file=MODULES_TEMPLATE, searchList=[data])\n    open(\"/etc/cobbler/settings\",\"w+\").write(t.respond())\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _sentence_split(self, string, settings):\n        abbreviations = self._get_abbreviations(settings=settings)\n        digit_abbreviations = ['[0-9]']  # numeric date with full stop\n        abbreviation_string = ''\n\n        for abbreviation in abbreviations:\n            abbreviation_string += '(?<! ' + abbreviation[:-1] + ')'  # negative lookbehind\n        if self.shortname in ['fi', 'cs', 'hu', 'de', 'da']:\n            for digit_abbreviation in digit_abbreviations:\n                abbreviation_string += '(?<!' + digit_abbreviation + ')'  # negative lookbehind\n\n        splitters_dict = {1: r'[\\.!?;\u2026\\r\\n]+(?:\\s|$)*',  # most European, Tagalog, Hebrew, Georgian,\n                          # Indonesian, Vietnamese\n                          2: r'(?:[\u00a1\u00bf]+|[\\.!?;\u2026\\r\\n]+(?:\\s|$))+',  # Spanish\n                          3: r'[|!?;\\r\\n]+(?:\\s|$)+',  # Hindi and Bangla\n                          4: r'[\u3002\u2026\u2025\\.!?\uff1f\uff01;\\r\\n]+(?:\\s|$)+',  # Japanese and Chinese\n                          5: r'[\\r\\n]+',  # Thai\n                          6: r'[\\r\\n\u061f!\\.\u2026]+(?:\\s|$)+'}  # Arabic and Farsi\n        if 'sentence_splitter_group' not in self.info:\n            split_reg = abbreviation_string + splitters_dict[1]\n            sentences = re.split(split_reg, string)\n        else:\n            split_reg = abbreviation_string + splitters_dict[self.info['sentence_splitter_group']]\n            sentences = re.split(split_reg, string)\n\n        for i in sentences:\n            if not i:\n                sentences.remove(i)\n        return sentences\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_x.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_y must be larger than min_y.\"));\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    // We want the range of the output to be symmetrical around zero so that\n    // adding zero leaves the result unchanged, and to contain the largest of\n    // the two input values with some room to spare.\n    const float smallest_min = std::min(min_x, min_y);\n    const float largest_max = std::max(max_x, max_y);\n    const float biggest_range =\n        std::max(std::abs(smallest_min), std::abs(largest_max));\n    const float output_range = (biggest_range * (1 << 14));\n    const float min_z_value = -output_range;\n    const float max_z_value = output_range;\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, y_data, min_y, max_y,\n                                   y.NumElements(), x_data[0], min_x, max_x,\n                                   min_z_value, max_z_value, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, x_data, min_x, max_x,\n                                   x.NumElements(), y_data[0], min_y, max_y,\n                                   min_z_value, max_z_value, z_data);\n      } else {\n        VectorAddition<T, Toutput>(context, x_data, min_x, max_x, y_data, min_y,\n                                   max_y, x.NumElements(), min_z_value,\n                                   max_z_value, z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      float vector_min;\n      float vector_max;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      float tensor_min;\n      float tensor_max;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_min = min_x;\n        vector_max = max_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_min = min_y;\n        tensor_max = max_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_min = min_y;\n        vector_max = max_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_min = min_x;\n        tensor_max = max_x;\n      }\n      VectorTensorAddition<T, Toutput>(\n          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n          z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      outputs->push_back(Tensor(*context.mutable_output(i)));\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != \"POST\":\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n            return\n        if self._read_started and not hasattr(self, \"_body\"):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == \"multipart/form-data\":\n            if hasattr(self, \"_body\"):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except (MultiPartParserError, TooManyFilesSent):\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == \"application/x-www-form-urlencoded\":\n            self._post, self._files = (\n                QueryDict(self.body, encoding=self._encoding),\n                MultiValueDict(),\n            )\n        else:\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void UncompressElementOp::Compute(OpKernelContext* ctx) {\n  Tensor tensor = ctx->input(0);\n  const Variant& variant = tensor.scalar<Variant>()();\n  const CompressedElement* compressed = variant.get<CompressedElement>();\n  OP_REQUIRES(\n      ctx, compressed != nullptr,\n      errors::InvalidArgument(\n          \"Input does not contain a compressed element. Instead got tensor \",\n          tensor.DebugString()));\n\n  std::vector<Tensor> components;\n  OP_REQUIRES_OK(ctx, UncompressElement(*compressed, &components));\n  OP_REQUIRES(ctx, components.size() == output_types_.size(),\n              errors::FailedPrecondition(\"Expected \", output_types_.size(),\n                                         \" outputs from uncompress, but got \",\n                                         components.size()));\n  for (int i = 0; i < components.size(); ++i) {\n    OP_REQUIRES(\n        ctx, components[i].dtype() == output_types_[i],\n        errors::FailedPrecondition(\"Expected a tensor of type \",\n                                   DataTypeString(output_types_[i]),\n                                   \" but got a tensor of type \",\n                                   DataTypeString(components[i].dtype())));\n    ctx->set_output(i, components[i]);\n  }\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    if not over_chunk:\n                                        break\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& sorted_inputs_t = ctx->input(0);\n    const Tensor& values_t = ctx->input(1);\n\n    // inputs must be at least a matrix\n    OP_REQUIRES(\n        ctx, sorted_inputs_t.shape().dims() >= 2,\n        errors::InvalidArgument(\"sorted input argument must be a matrix\"));\n    // must have same batch dim_size for both\n    OP_REQUIRES(ctx, sorted_inputs_t.dim_size(0) == values_t.dim_size(0),\n                Status(error::INVALID_ARGUMENT,\n                       \"Leading dim_size of both tensors must match.\"));\n\n    // this is required because we do indexing in int32 on the GPU\n    OP_REQUIRES(ctx, values_t.NumElements() < std::numeric_limits<int>::max(),\n                Status(error::INVALID_ARGUMENT,\n                       \"values tensor size must less than INT_MAX\"));\n\n    Tensor* output_t;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, values_t.shape(), &output_t));\n\n    if (output_t->dtype() == DT_INT32) {\n      OP_REQUIRES(ctx,\n                  FastBoundsCheck(sorted_inputs_t.dim_size(1),\n                                  std::numeric_limits<int>::max()),\n                  errors::InvalidArgument(\"trailing dim_size must less than \"\n                                          \"INT_MAX for int32 output type, was \",\n                                          sorted_inputs_t.dim_size(1)));\n    }\n\n    auto output = output_t->template flat<OutType>();\n    const auto sorted_inputs = sorted_inputs_t.template flat<T>();\n    const auto values = values_t.template flat<T>();\n\n    // For empty inputs, all values will be placed at the zeroth position.\n    if (sorted_inputs.size() == 0) {\n      functor::SetZeroFunctor<Device, OutType> set_zero;\n      set_zero(ctx->eigen_device<Device>(), output);\n      return;\n    }\n\n    OP_REQUIRES_OK(\n        ctx, functor::LowerBoundFunctor<Device, T, OutType>::Compute(\n                 ctx, sorted_inputs, values, sorted_inputs_t.dim_size(0),\n                 sorted_inputs_t.dim_size(1), values_t.dim_size(1), &output));\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32 lower_diag_index = 0;\n    int32 upper_diag_index = 0;\n    int32 num_rows = -1;\n    int32 num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n\n      auto& num_rows_tensor = context->input(2);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n      num_rows = num_rows_tensor.flat<int32>()(0);\n\n      auto& num_cols_tensor = context->input(3);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n      num_cols = num_cols_tensor.flat<int32>()(0);\n\n      auto& padding_value_tensor = context->input(4);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n      padding_value = padding_value_tensor.flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32 min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32 min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(\n          context, diag_index.NumElements() > 0,\n          errors::InvalidArgument(\"diag_index must have at least one element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n\n    // MatrixDiagPart and MatrixDiagPartV2 both use this OpKernel.\n    // MatrixDiagPart only has one input, so we have to check the number of\n    // inputs before reading additional parameters in MatrixDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n    T padding_value(0);\n\n    // MatrixDiagPartV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(context, diag_index.NumElements() > 0,\n                  errors::InvalidArgument(\n                      \"Expected diag_index to have at least 1 element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n      const Tensor& padding_in = context->input(2);\n      OP_REQUIRES(context, padding_in.NumElements() == 1,\n                  errors::InvalidArgument(\"Padding must be scalar.\"));\n      padding_value = padding_in.flat<T>()(0);\n    }\n    const TensorShape& input_shape = input.shape();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const int rank = input_shape.dims();\n    const Eigen::Index num_rows = input_shape.dim_size(rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \". It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    TensorShape output_shape;\n    for (int i = 0; i < rank - 2; ++i) {\n      output_shape.AddDim(input_shape.dim_size(i));\n    }\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    if (num_diags > 1) output_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    output_shape.AddDim(max_diag_len);\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat<T>();\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    functor::MatrixDiagPart<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def upload_artifact_handler():\n    args = request.args\n    run_uuid = args.get(\"run_uuid\")\n    if not run_uuid:\n        raise MlflowException(\n            message=\"Request must specify run_uuid.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    path = args.get(\"path\")\n    if not path:\n        raise MlflowException(\n            message=\"Request must specify path.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    path = validate_path_is_safe(path)\n\n    if request.content_length and request.content_length > 10 * 1024 * 1024:\n        raise MlflowException(\n            message=\"Artifact size is too large. Max size is 10MB.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    data = request.data\n    if not data:\n        raise MlflowException(\n            message=\"Request must specify data.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    run = _get_tracking_store().get_run(run_uuid)\n    artifact_dir = run.info.artifact_uri\n\n    basename = posixpath.basename(path)\n    dirname = posixpath.dirname(path)\n\n    def _log_artifact_to_repo(file, run, dirname, artifact_dir):\n        if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n            artifact_repo = _get_artifact_repo_mlflow_artifacts()\n            path_to_log = (\n                os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\", dirname)\n                if dirname\n                else os.path.join(run.info.experiment_id, run.info.run_id, \"artifacts\")\n            )\n        else:\n            artifact_repo = get_artifact_repository(artifact_dir)\n            path_to_log = dirname\n\n        artifact_repo.log_artifact(file, path_to_log)\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        dir_path = os.path.join(tmpdir, dirname) if dirname else tmpdir\n        file_path = os.path.join(dir_path, basename)\n\n        os.makedirs(dir_path, exist_ok=True)\n\n        with open(file_path, \"wb\") as f:\n            f.write(data)\n\n        _log_artifact_to_repo(file_path, run, dirname, artifact_dir)\n\n    return Response(mimetype=\"application/json\")\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def extract_ip_or_domain(url):\n    # Decode the URL to handle percent-encoded characters\n    _url = remove_credentials_from_url(unquote(url))\n\n    ip_regex = re.compile(\"^(?:http://|https://)(\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3}\\\\.\\\\d{1,3})\")\n    domain_regex = re.compile(\"^(?:http://|https://)([a-zA-Z0-9.-]+)\")\n\n    match = ip_regex.findall(_url)\n    if len(match):\n        ip_address = match[0]\n        try:\n            ipaddress.ip_address(ip_address)  # Validate the IP address\n            return ip_address\n        except ValueError:\n            pass\n\n    match = domain_regex.findall(_url)\n    if len(match):\n        return match[0]\n\n    return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render(self, context):\n        if not settings.DEBUG:\n            return ''\n\n        from pprint import pformat\n        output = [escape(pformat(val)) for val in context]\n        output.append('\\n\\n')\n        output.append(escape(pformat(sys.modules)))\n        return ''.join(output)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "load_header (XwdLoader *loader)\n{\n    XwdHeader *h = &loader->header;\n    XwdHeader in;\n    const XwdHeader *inp;\n\n    if (!file_mapping_taste (loader->mapping, &in, 0, sizeof (in)))\n        return FALSE;\n\n    inp = &in;\n\n    UNPACK_FIELD_U32 (h, inp, header_size);\n    UNPACK_FIELD_U32 (h, inp, file_version);\n    UNPACK_FIELD_U32 (h, inp, pixmap_format);\n    UNPACK_FIELD_U32 (h, inp, pixmap_depth);\n    UNPACK_FIELD_U32 (h, inp, pixmap_width);\n    UNPACK_FIELD_U32 (h, inp, pixmap_height);\n    UNPACK_FIELD_U32 (h, inp, x_offset);\n    UNPACK_FIELD_U32 (h, inp, byte_order);\n    UNPACK_FIELD_U32 (h, inp, bitmap_unit);\n    UNPACK_FIELD_U32 (h, inp, bitmap_bit_order);\n    UNPACK_FIELD_U32 (h, inp, bitmap_pad);\n    UNPACK_FIELD_U32 (h, inp, bits_per_pixel);\n    UNPACK_FIELD_U32 (h, inp, bytes_per_line);\n    UNPACK_FIELD_U32 (h, inp, visual_class);\n    UNPACK_FIELD_U32 (h, inp, red_mask);\n    UNPACK_FIELD_U32 (h, inp, green_mask);\n    UNPACK_FIELD_U32 (h, inp, blue_mask);\n    UNPACK_FIELD_U32 (h, inp, bits_per_rgb);\n    UNPACK_FIELD_U32 (h, inp, color_map_entries);\n    UNPACK_FIELD_U32 (h, inp, n_colors);\n    UNPACK_FIELD_U32 (h, inp, window_width);\n    UNPACK_FIELD_U32 (h, inp, window_height);\n    UNPACK_FIELD_S32 (h, inp, window_x);\n    UNPACK_FIELD_S32 (h, inp, window_y);\n    UNPACK_FIELD_U32 (h, inp, window_border_width);\n\n    /* Only support the most common/useful subset of XWD files out there;\n     * namely, that corresponding to screen dumps from modern X.Org servers.\n     * We could check visual_class == 5 too, but the other fields convey all\n     * the info we need. */\n\n    ASSERT_HEADER (h->header_size >= sizeof (XwdHeader));\n    ASSERT_HEADER (h->header_size <= 65535);\n    ASSERT_HEADER (h->file_version == 7);\n    ASSERT_HEADER (h->pixmap_depth == 24);\n\n    /* Should be zero for truecolor/directcolor. Cap it to prevent overflows. */\n    ASSERT_HEADER (h->color_map_entries <= 256);\n\n    /* Xvfb sets bits_per_rgb to 8, but 'convert' uses 24 for the same image data. One\n     * of them is likely misunderstanding. Let's be lenient and accept either. */\n    ASSERT_HEADER (h->bits_per_rgb == 8 || h->bits_per_rgb == 24);\n\n    /* These are the pixel formats we allow. */\n    ASSERT_HEADER (h->bits_per_pixel == 24 || h->bits_per_pixel == 32);\n\n    /* Enforce sane dimensions. */\n    ASSERT_HEADER (h->pixmap_width >= 1 && h->pixmap_width <= 65535);\n    ASSERT_HEADER (h->pixmap_height >= 1 && h->pixmap_height <= 65535);\n\n    /* Make sure rowstride can actually hold a row's worth of data but is not padded to\n     * something ridiculous. */\n    ASSERT_HEADER (h->bytes_per_line >= h->pixmap_width * (h->bits_per_pixel / 8));\n    ASSERT_HEADER (h->bytes_per_line <= h->pixmap_width * (h->bits_per_pixel / 8) + 1024);\n\n    /* Make sure the total allocation/map is not too big. */\n    ASSERT_HEADER (h->bytes_per_line * h->pixmap_height < (1UL << 31) - 65536 - 256 * 32);\n\n    ASSERT_HEADER (compute_pixel_type (loader) < CHAFA_PIXEL_MAX);\n\n    loader->file_data = file_mapping_get_data (loader->mapping, &loader->file_data_len);\n    if (!loader->file_data)\n        return FALSE;\n\n    ASSERT_HEADER (loader->file_data_len >= h->header_size\n                   + h->color_map_entries * sizeof (XwdColor)\n                   + h->pixmap_height * (gsize) h->bytes_per_line);\n\n    loader->image_data = (const guint8 *) loader->file_data\n        + h->header_size + h->color_map_entries * sizeof (XwdColor);\n\n    return TRUE;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _check_sigs_on_pdus(keyring, room_version, pdus):\n    \"\"\"Check that the given events are correctly signed\n\n    Args:\n        keyring (synapse.crypto.Keyring): keyring object to do the checks\n        room_version (str): the room version of the PDUs\n        pdus (Collection[EventBase]): the events to be checked\n\n    Returns:\n        List[Deferred]: a Deferred for each event in pdus, which will either succeed if\n           the signatures are valid, or fail (with a SynapseError) if not.\n    \"\"\"\n\n    # we want to check that the event is signed by:\n    #\n    # (a) the sender's server\n    #\n    #     - except in the case of invites created from a 3pid invite, which are exempt\n    #     from this check, because the sender has to match that of the original 3pid\n    #     invite, but the event may come from a different HS, for reasons that I don't\n    #     entirely grok (why do the senders have to match? and if they do, why doesn't the\n    #     joining server ask the inviting server to do the switcheroo with\n    #     exchange_third_party_invite?).\n    #\n    #     That's pretty awful, since redacting such an invite will render it invalid\n    #     (because it will then look like a regular invite without a valid signature),\n    #     and signatures are *supposed* to be valid whether or not an event has been\n    #     redacted. But this isn't the worst of the ways that 3pid invites are broken.\n    #\n    # (b) for V1 and V2 rooms, the server which created the event_id\n    #\n    # let's start by getting the domain for each pdu, and flattening the event back\n    # to JSON.\n\n    pdus_to_check = [\n        PduToCheckSig(\n            pdu=p,\n            redacted_pdu_json=prune_event(p).get_pdu_json(),\n            sender_domain=get_domain_from_id(p.sender),\n            deferreds=[],\n        )\n        for p in pdus\n    ]\n\n    v = KNOWN_ROOM_VERSIONS.get(room_version)\n    if not v:\n        raise RuntimeError(\"Unrecognized room version %s\" % (room_version,))\n\n    # First we check that the sender event is signed by the sender's domain\n    # (except if its a 3pid invite, in which case it may be sent by any server)\n    pdus_to_check_sender = [p for p in pdus_to_check if not _is_invite_via_3pid(p.pdu)]\n\n    more_deferreds = keyring.verify_json_objects_for_server(\n        [\n            (\n                p.sender_domain,\n                p.redacted_pdu_json,\n                p.pdu.origin_server_ts if v.enforce_key_validity else 0,\n                p.pdu.event_id,\n            )\n            for p in pdus_to_check_sender\n        ]\n    )\n\n    def sender_err(e, pdu_to_check):\n        errmsg = \"event id %s: unable to verify signature for sender %s: %s\" % (\n            pdu_to_check.pdu.event_id,\n            pdu_to_check.sender_domain,\n            e.getErrorMessage(),\n        )\n        raise SynapseError(403, errmsg, Codes.FORBIDDEN)\n\n    for p, d in zip(pdus_to_check_sender, more_deferreds):\n        d.addErrback(sender_err, p)\n        p.deferreds.append(d)\n\n    # now let's look for events where the sender's domain is different to the\n    # event id's domain (normally only the case for joins/leaves), and add additional\n    # checks. Only do this if the room version has a concept of event ID domain\n    # (ie, the room version uses old-style non-hash event IDs).\n    if v.event_format == EventFormatVersions.V1:\n        pdus_to_check_event_id = [\n            p\n            for p in pdus_to_check\n            if p.sender_domain != get_domain_from_id(p.pdu.event_id)\n        ]\n\n        more_deferreds = keyring.verify_json_objects_for_server(\n            [\n                (\n                    get_domain_from_id(p.pdu.event_id),\n                    p.redacted_pdu_json,\n                    p.pdu.origin_server_ts if v.enforce_key_validity else 0,\n                    p.pdu.event_id,\n                )\n                for p in pdus_to_check_event_id\n            ]\n        )\n\n        def event_err(e, pdu_to_check):\n            errmsg = (\n                \"event id %s: unable to verify signature for event id domain: %s\"\n                % (pdu_to_check.pdu.event_id, e.getErrorMessage())\n            )\n            raise SynapseError(403, errmsg, Codes.FORBIDDEN)\n\n        for p, d in zip(pdus_to_check_event_id, more_deferreds):\n            d.addErrback(event_err, p)\n            p.deferreds.append(d)\n\n    # replace lists of deferreds with single Deferreds\n    return [_flatten_deferred_list(p.deferreds) for p in pdus_to_check]\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def select(self, query: ast.Select) -> pd.DataFrame:\n\n        conditions = extract_comparison_conditions(query.where)\n        urls = []\n        for op, arg1, arg2 in conditions:\n\n            if op == 'or':\n                raise NotImplementedError(f'OR is not supported')\n\n            if arg1 == 'url':\n                url = arg2\n\n                if op == '=':\n                    urls = [str(url)]\n                elif op == 'in':\n                    if type(url) == str:\n                        urls = [str(url)]\n                    else:\n                        urls = url\n                else:\n                    raise NotImplementedError(\n                        f'url can be url = \"someurl\", you can also crawl multiple sites, as follows:'\n                        f' url IN (\"url1\", \"url2\", ..)'\n                    )\n\n            else:\n                pass\n\n        if len(urls) == 0:\n            raise NotImplementedError(\n                f'You must specify what url you want to crawl, for example: SELECT * FROM crawl WHERE url IN (\"someurl\", ..)')\n\n        if query.limit is None:\n            raise NotImplementedError(f'You must specify a LIMIT which defines the number of pages to crawl')\n        limit = query.limit.value\n\n        if limit < 0:\n            limit = 0\n\n        config = Config()\n        is_cloud = config.get(\"cloud\", False)\n        if is_cloud:\n            urls = [\n                url\n                for url in urls\n                if not is_private_url(url)\n            ]\n\n        result = get_all_websites(urls, limit, html=False)\n        if len(result) > limit:\n            result = result[:limit]\n        # filter targets\n        result = project_dataframe(result, query.targets, self.get_columns())\n        return result\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        hs: \"HomeServer\",\n        treq_args: Dict[str, Any] = {},\n        ip_whitelist: Optional[IPSet] = None,\n        ip_blacklist: Optional[IPSet] = None,\n        http_proxy: Optional[bytes] = None,\n        https_proxy: Optional[bytes] = None,\n    ):\n        \"\"\"\n        Args:\n            hs\n            treq_args: Extra keyword arguments to be given to treq.request.\n            ip_blacklist: The IP addresses that are blacklisted that\n                we may not request.\n            ip_whitelist: The whitelisted IP addresses, that we can\n               request if it were otherwise caught in a blacklist.\n            http_proxy: proxy server to use for http connections. host[:port]\n            https_proxy: proxy server to use for https connections. host[:port]\n        \"\"\"\n        self.hs = hs\n\n        self._ip_whitelist = ip_whitelist\n        self._ip_blacklist = ip_blacklist\n        self._extra_treq_args = treq_args\n\n        self.user_agent = hs.version_string\n        self.clock = hs.get_clock()\n        if hs.config.user_agent_suffix:\n            self.user_agent = \"%s %s\" % (self.user_agent, hs.config.user_agent_suffix)\n\n        # We use this for our body producers to ensure that they use the correct\n        # reactor.\n        self._cooperator = Cooperator(scheduler=_make_scheduler(hs.get_reactor()))\n\n        self.user_agent = self.user_agent.encode(\"ascii\")\n\n        if self._ip_blacklist:\n            # If we have an IP blacklist, we need to use a DNS resolver which\n            # filters out blacklisted IP addresses, to prevent DNS rebinding.\n            self.reactor = BlacklistingReactorWrapper(\n                hs.get_reactor(), self._ip_whitelist, self._ip_blacklist\n            )\n        else:\n            self.reactor = hs.get_reactor()\n\n        # the pusher makes lots of concurrent SSL connections to sygnal, and\n        # tends to do so in batches, so we need to allow the pool to keep\n        # lots of idle connections around.\n        pool = HTTPConnectionPool(self.reactor)\n        # XXX: The justification for using the cache factor here is that larger instances\n        # will need both more cache and more connections.\n        # Still, this should probably be a separate dial\n        pool.maxPersistentPerHost = max((100 * hs.config.caches.global_factor, 5))\n        pool.cachedConnectionTimeout = 2 * 60\n\n        self.agent = ProxyAgent(\n            self.reactor,\n            connectTimeout=15,\n            contextFactory=self.hs.get_http_client_context_factory(),\n            pool=pool,\n            http_proxy=http_proxy,\n            https_proxy=https_proxy,\n        )\n\n        if self._ip_blacklist:\n            # If we have an IP blacklist, we then install the blacklisting Agent\n            # which prevents direct access to IP addresses, that are not caught\n            # by the DNS resolution.\n            self.agent = BlacklistingAgentWrapper(\n                self.agent,\n                ip_whitelist=self._ip_whitelist,\n                ip_blacklist=self._ip_blacklist,\n            )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus Resize(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteLSHProjectionParams*>(node->builtin_data);\n  TF_LITE_ENSURE(context, NumInputs(node) == 2 || NumInputs(node) == 3);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  const TfLiteTensor* hash;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &hash));\n  TF_LITE_ENSURE_EQ(context, NumDimensions(hash), 2);\n  // Support up to 32 bits.\n  TF_LITE_ENSURE(context, SizeOfDimension(hash, 1) <= 32);\n\n  const TfLiteTensor* input;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &input));\n  TF_LITE_ENSURE(context, NumDimensions(input) >= 1);\n  TF_LITE_ENSURE(context, SizeOfDimension(input, 0) >= 1);\n\n  if (NumInputs(node) == 3) {\n    const TfLiteTensor* weight;\n    TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &weight));\n    TF_LITE_ENSURE_EQ(context, NumDimensions(weight), 1);\n    TF_LITE_ENSURE_EQ(context, SizeOfDimension(weight, 0),\n                      SizeOfDimension(input, 0));\n  }\n\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  TfLiteIntArray* outputSize = TfLiteIntArrayCreate(1);\n  switch (params->type) {\n    case kTfLiteLshProjectionSparse:\n      outputSize->data[0] = SizeOfDimension(hash, 0);\n      break;\n    case kTfLiteLshProjectionDense:\n      outputSize->data[0] = SizeOfDimension(hash, 0) * SizeOfDimension(hash, 1);\n      break;\n    default:\n      return kTfLiteError;\n  }\n  return context->ResizeTensor(context, output, outputSize);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def collect_request_attributes(environ):\n    \"\"\"Collects HTTP request attributes from the PEP3333-conforming\n    WSGI environ and returns a dictionary to be used as span creation attributes.\n    \"\"\"\n\n    result = {\n        SpanAttributes.HTTP_METHOD: sanitize_method(environ.get(\"REQUEST_METHOD\")),\n        SpanAttributes.HTTP_SERVER_NAME: environ.get(\"SERVER_NAME\"),\n        SpanAttributes.HTTP_SCHEME: environ.get(\"wsgi.url_scheme\"),\n    }\n\n    host_port = environ.get(\"SERVER_PORT\")\n    if host_port is not None and not host_port == \"\":\n        result.update({SpanAttributes.NET_HOST_PORT: int(host_port)})\n\n    setifnotnone(result, SpanAttributes.HTTP_HOST, environ.get(\"HTTP_HOST\"))\n    target = environ.get(\"RAW_URI\")\n    if target is None:  # Note: `\"\" or None is None`\n        target = environ.get(\"REQUEST_URI\")\n    if target is not None:\n        result[SpanAttributes.HTTP_TARGET] = target\n    else:\n        result[SpanAttributes.HTTP_URL] = remove_url_credentials(\n            wsgiref_util.request_uri(environ)\n        )\n\n    remote_addr = environ.get(\"REMOTE_ADDR\")\n    if remote_addr:\n        result[SpanAttributes.NET_PEER_IP] = remote_addr\n    remote_host = environ.get(\"REMOTE_HOST\")\n    if remote_host and remote_host != remote_addr:\n        result[SpanAttributes.NET_PEER_NAME] = remote_host\n\n    user_agent = environ.get(\"HTTP_USER_AGENT\")\n    if user_agent is not None and len(user_agent) > 0:\n        result[SpanAttributes.HTTP_USER_AGENT] = user_agent\n\n    setifnotnone(\n        result, SpanAttributes.NET_PEER_PORT, environ.get(\"REMOTE_PORT\")\n    )\n    flavor = environ.get(\"SERVER_PROTOCOL\", \"\")\n    if flavor.upper().startswith(_HTTP_VERSION_PREFIX):\n        flavor = flavor[len(_HTTP_VERSION_PREFIX) :]\n    if flavor:\n        result[SpanAttributes.HTTP_FLAVOR] = flavor\n\n    return result\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_conn(self) -> Connection:\n        \"\"\"Establish a connection to Drillbit.\"\"\"\n        conn_md = self.get_connection(getattr(self, self.conn_name_attr))\n        creds = f\"{conn_md.login}:{conn_md.password}@\" if conn_md.login else \"\"\n        database_url = (\n            f\"{conn_md.extra_dejson.get('dialect_driver', 'drill+sadrill')}://{creds}\"\n            f\"{conn_md.host}:{conn_md.port}/\"\n            f'{conn_md.extra_dejson.get(\"storage_plugin\", \"dfs\")}'\n        )\n        if \"?\" in database_url:\n            raise ValueError(\"Drill database_url should not contain a '?'\")\n        engine = create_engine(database_url)\n\n        self.log.info(\n            \"Connected to the Drillbit at %s:%s as user %s\", conn_md.host, conn_md.port, conn_md.login\n        )\n        return engine.raw_connection()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void PrepareTFPass::runOnOperation() {\n  MLIRContext *ctx = &getContext();\n  RewritePatternSet patterns(ctx);\n  RewritePatternSet phase_2_patterns(ctx);\n  auto func = getOperation();\n\n  // Check illegal ops in a TFLite pipeline (e.g. trainning only ops) , since\n  // PrepareTFPass is the very first TFLite pass in the pipeline.\n  // TODO(jingpu): It might be better to split this check into its own pass\n  // to make things more modular.\n  if (failed(ValidateOp(func))) {\n    func.emitError() << \"tfl-prepare-tf pass failed.\";\n    signalPassFailure();\n    return;\n  }\n\n  if (failed(ConvertTf2XlaOps(func, ctx))) {\n    signalPassFailure();\n    return;\n  }\n\n  // This pattern will try to identify and optimize for dilated convolution.\n  // e.g. Patterns like \"SpaceToBatchND -> Conv2D -> BatchToSpaceND\" will be\n  // replaced with a single Conv op with dilation parameter.\n  patterns.add<ConvertTFDilatedConvOp<TF::Conv2DOp>, FusedBatchNormV3Pat,\n               ConvertTFDilatedConvOp<TF::DepthwiseConv2dNativeOp>>(ctx);\n\n  patterns.add<RemoveIdentity>(ctx);\n  TFL::populateWithGenerated(patterns);\n  // Remove redundant reshape ops.\n  TF::ReshapeOp::getCanonicalizationPatterns(patterns, ctx);\n  // TODO(karimnosseir): Split to separate pass probably after\n  // deciding on long term plan for this optimization.\n  // This will allow optimizing any TF_Mul->TF_Conv in the graph\n  // and any expanded from FusedBatchNorm. We need to do this\n  // before converting TF_Conv to TFL_Conv\n  (void)applyPatternsAndFoldGreedily(func, std::move(patterns));\n\n  // Remove the wrapper of the tf.FakeQuant* ops and also insert the\n  // tfl.quantize and tfl.dequantize to preserve the quantization parameters.\n  // This is done after the first round of optimization to make sure all the\n  // min/max operands of the tf.FakeQuant* are constants to be matched. The\n  // following round of optimization will folding the unwrapped\n  // tf.FakeQuant* ops with the weight constants.\n  if (failed(ConvertFakeQuantOps(func, ctx, use_fake_quant_num_bits_))) {\n    signalPassFailure();\n    return;\n  }\n\n  // Load the generated pattern again, so new quantization pass-through\n  // will be applied.\n  TFL::populateWithGenerated(phase_2_patterns);\n  if (unfold_batch_matmul_) {\n    TF::PopulateUnrollTfBatchMatMul(ctx, phase_2_patterns);\n  }\n  phase_2_patterns\n      .add<TF::ConvertTFEinsumOp, ConvertTFBroadcastTo, ConvertTFStridedSlice,\n           ConvertRfftToRfft2d, RemoveIdentity>(ctx);\n  phase_2_patterns.add<ConvertTFConv2D, ConvertTFDepthwiseConv2dNative>(\n      ctx, allow_bf16_and_f16_type_legalization_);\n  // Remove redundant reshape ops.\n  TF::ReshapeOp::getCanonicalizationPatterns(phase_2_patterns, ctx);\n\n  (void)applyPatternsAndFoldGreedily(func, std::move(phase_2_patterns));\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def icalc(self, irc, msg, args, text):\n        \"\"\"<math expression>\n\n        This is the same as the calc command except that it allows integer\n        math, and can thus cause the bot to suck up CPU.  Hence it requires\n        the 'trusted' capability to use.\n        \"\"\"\n        try:\n            self.log.info('evaluating %q from %s', text, msg.prefix)\n            x = safe_eval(text, allow_ints=True)\n            irc.reply(str(x))\n        except OverflowError:\n            maxFloat = math.ldexp(0.9999999999999999, 1024)\n            irc.error(_('The answer exceeded %s or so.') % maxFloat)\n        except InvalidNode as e:\n            irc.error(_('Invalid syntax: %s') % e.args[0])\n        except NameError as e:\n            irc.error(_('%s is not a defined function.') % str(e).split()[1])\n        except Exception as e:\n            irc.error(utils.exnToString(e))\n    icalc = wrap(icalc, [('checkCapability', 'trusted'), 'text'])"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _configure_handlers(cls, app):\n        \"\"\"\n        Register app handlers.\n        \"\"\"\n        for exc, fn in cls.FLASK_ERROR_HANDLERS:\n            app.register_error_handler(exc, fn)\n\n        @app.after_request\n        def deny_iframe(response):\n            response.headers[\"X-Frame-Options\"] = \"DENY\"\n            return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _parse_data(self, data: bytes, *, start: bool) -> tuple[bytes, int, bool]:\n        # Body parts must start with CRLF (or CR or LF)\n        if start:\n            match = LINE_BREAK_RE.match(data)\n            data_start = t.cast(t.Match[bytes], match).end()\n        else:\n            data_start = 0\n\n        boundary = b\"--\" + self.boundary\n\n        if self.buffer.find(boundary) == -1:\n            # No complete boundary in the buffer, but there may be\n            # a partial boundary at the end. As the boundary\n            # starts with either a nl or cr find the earliest and\n            # return up to that as data.\n            data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            # If amount of data after last newline is far from\n            # possible length of partial boundary, we should\n            # assume that there is no partial boundary in the buffer\n            # and return all pending data.\n            if (len(data) - data_end) > len(b\"\\n\" + boundary):\n                data_end = del_index = len(data)\n            more_data = True\n        else:\n            match = self.boundary_re.search(data)\n            if match is not None:\n                if match.group(1).startswith(b\"--\"):\n                    self.state = State.EPILOGUE\n                else:\n                    self.state = State.PART\n                data_end = match.start()\n                del_index = match.end()\n            else:\n                data_end = del_index = self.last_newline(data[data_start:]) + data_start\n            more_data = match is None\n\n        return bytes(data[data_start:data_end]), del_index, more_data\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def pretty(self, n, comment=True):\n        if isinstance(n, (str, bytes, list, tuple, dict)):\n            r = repr(n)\n            if not comment:  # then it can be inside a comment!\n                r = r.replace('*/', r'\\x2a/')\n            return r\n        if not isinstance(n, six.integer_types):\n            return n\n        if isinstance(n, constants.Constant):\n            if comment: return '%s /* %s */' % (n,self.pretty(int(n)))\n            else:       return '%s (%s)'     % (n,self.pretty(int(n)))\n        elif abs(n) < 10:\n            return str(n)\n        else:\n            return hex(n)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ImmutableExecutorState::BuildControlFlowInfo(const Graph* g,\n                                                    ControlFlowInfo* cf_info) {\n  const int num_nodes = g->num_node_ids();\n  cf_info->frame_names.resize(num_nodes);\n  std::vector<Node*> parent_nodes;\n  parent_nodes.resize(num_nodes);\n  std::vector<bool> visited;\n  visited.resize(num_nodes);\n\n  string frame_name;\n  std::deque<Node*> ready;\n\n  // Initialize with the root nodes.\n  for (Node* n : g->nodes()) {\n    if (n->in_edges().empty()) {\n      visited[n->id()] = true;\n      cf_info->unique_frame_names.insert(frame_name);\n      ready.push_back(n);\n    }\n  }\n\n  while (!ready.empty()) {\n    Node* curr_node = ready.front();\n    int curr_id = curr_node->id();\n    ready.pop_front();\n\n    Node* parent = nullptr;\n    if (IsEnter(curr_node)) {\n      // Enter a child frame.\n      TF_RETURN_IF_ERROR(\n          GetNodeAttr(curr_node->attrs(), \"frame_name\", &frame_name));\n      parent = curr_node;\n    } else if (IsExit(curr_node)) {\n      // Exit to the parent frame.\n      parent = parent_nodes[curr_id];\n      if (!parent) {\n        return errors::InvalidArgument(\n            \"Invalid Exit op: Cannot find a corresponding Enter op.\");\n      }\n      frame_name = cf_info->frame_names[parent->id()];\n      parent = parent_nodes[parent->id()];\n    } else {\n      parent = parent_nodes[curr_id];\n      frame_name = cf_info->frame_names[curr_id];\n    }\n\n    for (const Edge* out_edge : curr_node->out_edges()) {\n      Node* out = out_edge->dst();\n      if (IsSink(out)) continue;\n      const int out_id = out->id();\n\n      // Add to ready queue if not visited.\n      bool is_visited = visited[out_id];\n      if (!is_visited) {\n        ready.push_back(out);\n        visited[out_id] = true;\n\n        // Process the node 'out'.\n        cf_info->frame_names[out_id] = frame_name;\n        parent_nodes[out_id] = parent;\n        cf_info->unique_frame_names.insert(frame_name);\n      }\n    }\n  }\n\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def needs_clamp(t, encoding):\n    if encoding == Encoding.VYPER:\n        return False\n    if encoding != Encoding.ABI:\n        raise CompilerPanic(\"unreachable\")  # pragma: notest\n    if isinstance(t, (ByteArrayLike, DArrayType)):\n        return True\n    if isinstance(t, BaseType):\n        return t.typ not in (\"int256\", \"uint256\", \"bytes32\")\n    if isinstance(t, SArrayType):\n        return needs_clamp(t.subtype, encoding)\n    if isinstance(t, TupleLike):\n        return any(needs_clamp(m, encoding) for m in t.tuple_members())\n\n    raise CompilerPanic(\"unreachable\")  # pragma: notest\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, instance, filename):\n        \"\"\"\n        Apply (if callable) or prepend (if a string) upload_to to the filename,\n        then delegate further processing of the name to the storage backend.\n        Until the storage layer, all file paths are expected to be Unix style\n        (with forward slashes).\n        \"\"\"\n        filename = validate_file_name(filename)\n        if callable(self.upload_to):\n            filename = self.upload_to(instance, filename)\n        else:\n            dirname = datetime.datetime.now().strftime(str(self.upload_to))\n            filename = posixpath.join(dirname, filename)\n        return self.storage.generate_filename(filename)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SpaceToBatch(XlaOpKernelContext* ctx, const xla::XlaOp& input,\n                  DataType input_dtype, const TensorShape& input_tensor_shape,\n                  absl::Span<const int64_t> block_shape,\n                  const xla::Literal& paddings) {\n  const int input_rank = input_tensor_shape.dims();\n  const absl::InlinedVector<int64_t, 4> input_shape =\n      input_tensor_shape.dim_sizes();\n  const int block_rank = block_shape.size();\n\n  OP_REQUIRES(\n      ctx, input_rank >= 1 + block_rank,\n      errors::InvalidArgument(\"input rank should be >= \", 1 + block_rank,\n                              \" instead of \", input_rank));\n  absl::Span<const int64_t> remainder_shape(input_shape);\n  remainder_shape.remove_prefix(1 + block_rank);\n\n  OP_REQUIRES(\n      ctx,\n      paddings.shape().rank() == 2 &&\n          block_rank == xla::ShapeUtil::GetDimension(paddings.shape(), 0) &&\n          2 == xla::ShapeUtil::GetDimension(paddings.shape(), 1),\n      errors::InvalidArgument(\"paddings should have shape [\", block_rank,\n                              \", 2] instead of \",\n                              xla::ShapeUtil::HumanString(paddings.shape())));\n\n  xla::XlaBuilder* b = ctx->builder();\n\n  // 1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n  //  input according to `paddings` to produce `padded` of shape `padded_shape`.\n  xla::PaddingConfig padding_config;\n  std::vector<int64_t> padded_shape(input_shape.begin(), input_shape.end());\n  int64_t block_num_elems = 1LL;\n  padding_config.add_dimensions();  // Don't pad the batch dimension.\n  for (int i = 0; i < block_rank; ++i) {\n    auto* dim = padding_config.add_dimensions();\n    int64_t pad_start = paddings.Get<int64_t>({i, 0});\n    int64_t pad_end = paddings.Get<int64_t>({i, 1});\n    OP_REQUIRES(ctx, pad_start >= 0 && pad_end >= 0,\n                errors::InvalidArgument(\"Paddings must be non-negative\"));\n    OP_REQUIRES(ctx, block_shape[i] >= 1,\n                errors::InvalidArgument(\n                    \"All values in block_shape must be positive, got value, \",\n                    block_shape[i], \" at index \", i, \".\"));\n    dim->set_edge_padding_low(pad_start);\n    dim->set_edge_padding_high(pad_end);\n    padded_shape[1 + i] += pad_start + pad_end;\n    block_num_elems = MultiplyWithoutOverflow(block_num_elems, block_shape[i]);\n  }\n  // Don't pad the remainder dimensions.\n  for (int i = 0; i < remainder_shape.size(); ++i) {\n    padding_config.add_dimensions();\n  }\n  OP_REQUIRES(ctx, block_num_elems > 0,\n              errors::InvalidArgument(\n                  \"The product of the block dimensions must be positive\"));\n  const int64_t batch_size = input_shape[0];\n  const int64_t output_dim =\n      MultiplyWithoutOverflow(batch_size, block_num_elems);\n  if (output_dim < 0) {\n    OP_REQUIRES(\n        ctx, output_dim >= 0,\n        errors::InvalidArgument(\"Negative output dimension size caused by \"\n                                \"overflow when multiplying \",\n                                batch_size, \" and \", block_num_elems));\n  }\n\n  xla::XlaOp padded =\n      xla::Pad(input, XlaHelpers::Zero(b, input_dtype), padding_config);\n\n  // 2. Reshape `padded` to `reshaped_padded` of shape:\n  //\n  //      [batch] +\n  //      [padded_shape[1] / block_shape[0],\n  //        block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1],\n  //       block_shape[M-1]] +\n  //      remaining_shape\n  std::vector<int64_t> reshaped_padded_shape(input_rank + block_rank);\n  reshaped_padded_shape[0] = batch_size;\n  for (int i = 0; i < block_rank; ++i) {\n    OP_REQUIRES(ctx, padded_shape[1 + i] % block_shape[i] == 0,\n                errors::InvalidArgument(\"padded_shape[\", 1 + i,\n                                        \"]=\", padded_shape[1 + i],\n                                        \" is not divisible by block_shape[\", i,\n                                        \"]=\", block_shape[i]));\n\n    reshaped_padded_shape[1 + i * 2] = padded_shape[1 + i] / block_shape[i];\n    reshaped_padded_shape[1 + i * 2 + 1] = block_shape[i];\n  }\n  std::copy(remainder_shape.begin(), remainder_shape.end(),\n            reshaped_padded_shape.begin() + 1 + 2 * block_rank);\n\n  xla::XlaOp reshaped_padded = xla::Reshape(padded, reshaped_padded_shape);\n\n  // 3. Permute dimensions of `reshaped_padded` to produce\n  //    `permuted_reshaped_padded` of shape:\n  //\n  //      block_shape +\n  //      [batch] +\n  //      [padded_shape[1] / block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1]] +\n  //      remaining_shape\n  std::vector<int64_t> permutation(reshaped_padded_shape.size());\n  for (int i = 0; i < block_rank; ++i) {\n    permutation[i] = 1 + 2 * i + 1;\n    permutation[block_rank + 1 + i] = 1 + 2 * i;\n  }\n  permutation[block_rank] = 0;\n  std::iota(permutation.begin() + 1 + block_rank * 2, permutation.end(),\n            1 + block_rank * 2);\n  xla::XlaOp permuted_reshaped_padded =\n      xla::Transpose(reshaped_padded, permutation);\n\n  // 4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the\n  //    batch dimension, producing an output tensor of shape:\n  //\n  //      [batch * prod(block_shape)] +\n  //      [padded_shape[1] / block_shape[0],\n  //       ...,\n  //       padded_shape[M] / block_shape[M-1]] +\n  //      remaining_shape\n  // Determine the length of the prefix of block dims that can be combined\n  // into the batch dimension due to having no padding and block_shape=1.\n  std::vector<int64_t> output_shape(input_rank);\n  output_shape[0] = output_dim;\n  for (int i = 0; i < block_rank; ++i) {\n    output_shape[1 + i] = padded_shape[1 + i] / block_shape[i];\n  }\n  std::copy(remainder_shape.begin(), remainder_shape.end(),\n            output_shape.begin() + 1 + block_rank);\n\n  xla::XlaOp output = xla::Reshape(permuted_reshaped_padded, output_shape);\n  ctx->SetOutput(0, output);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "inline Status SparseTensor::Split(const SparseTensor& input_tensor,\n                                  const int split_dim, const int num_split,\n                                  std::vector<SparseTensor>* result) {\n  std::vector<Tensor> output_indices;\n  std::vector<Tensor> output_values;\n  std::vector<TensorShape> output_shapes;\n  output_indices.reserve(num_split);\n  output_values.reserve(num_split);\n  output_shapes.reserve(num_split);\n\n  std::vector<typename TTypes<int64>::Matrix> output_indices_t;\n  std::vector<typename TTypes<T>::Vec> output_values_t;\n  output_indices_t.reserve(num_split);\n  output_values_t.reserve(num_split);\n  auto input_values_t = input_tensor.values().vec<T>();\n  auto input_indices_t = input_tensor.indices().matrix<int64>();\n\n  std::vector<int> num_values(num_split, 0);\n  const int num_dim = input_tensor.shape().size();\n  const int split_dim_size = input_tensor.shape()[split_dim];\n  const int split_size = split_dim_size / num_split;\n\n  if (!(num_split > 0 && num_split <= split_dim_size)) {\n    return errors::InvalidArgument(\"num_split must be in the interval (0, \",\n                                   split_dim_size, \"]\");\n  }\n  if (!(split_dim >= 0 && split_dim < num_dim)) {\n    return errors::InvalidArgument(\"num_dim must be in the interval [0, \",\n                                   num_dim, \")\");\n  }\n\n  const int residual = split_dim_size % num_split;\n  for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n    const int dim = input_tensor.indices().matrix<int64>()(i, split_dim);\n    int slice_index = GetSliceIndex(dim, split_size, residual);\n    if (slice_index >= num_values.size()) {\n      return errors::InvalidArgument(\"Slice index \", slice_index,\n                                     \" is larger than num_split.\");\n    }\n    num_values[slice_index]++;\n  }\n\n  for (int i = 0; i < num_split; ++i) {\n    // TODO(ataei): Pass an allocator to avoid allocating large memory buffer.\n    output_indices.emplace_back(DT_INT64,\n                                TensorShape({num_values[i], num_dim}));\n    output_values.emplace_back(DataTypeToEnum<T>::v(),\n                               TensorShape({num_values[i]}));\n    output_shapes.emplace_back(input_tensor.shape());\n    output_indices_t.emplace_back(output_indices[i].matrix<int64>());\n    output_values_t.emplace_back(output_values[i].vec<T>());\n    const int size = GetSliceShape(i, split_size, residual);\n    output_shapes[i].set_dim(split_dim, size);\n  }\n\n  std::vector<int> values_inserted_in_slice(num_split, 0);\n  for (int i = 0; i < input_tensor.indices().dim_size(0); ++i) {\n    const int dim = input_indices_t(i, split_dim);\n    const int slice_index = GetSliceIndex(dim, split_size, residual);\n    const int slice_dim = values_inserted_in_slice[slice_index]++;\n    output_values_t[slice_index](slice_dim) = input_values_t(i);\n    for (int j = 0; j < num_dim; ++j) {\n      const int64 original_dim = input_indices_t(i, j);\n      output_indices_t[slice_index](slice_dim, j) =\n          (j == split_dim)\n              ? GetDimensionInSlice(original_dim, split_size, residual)\n              : original_dim;\n    }\n  }\n\n  result->clear();\n  result->reserve(num_split);\n  for (int i = 0; i < num_split; ++i) {\n    SparseTensor tensor;\n    Status create_status =\n        Create(output_indices[i], output_values[i], output_shapes[i], &tensor);\n    if (!create_status.ok()) {\n      return create_status;\n    }\n    result->push_back(std::move(tensor));\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _recv_packet(self) -> bool:\n        \"\"\"Receive the remainder of an SSH packet and process it\"\"\"\n\n        rem = 4 + self._pktlen + self._recv_macsize - self._recv_blocksize\n        if len(self._inpbuf) < rem:\n            return False\n\n        seq = self._recv_seq\n        rest = self._inpbuf[:rem-self._recv_macsize]\n        mac = self._inpbuf[rem-self._recv_macsize:rem]\n\n        if self._recv_encryption:\n            packet_data = self._recv_encryption.decrypt_packet(\n                seq, self._packet, rest, 4, mac)\n\n            if not packet_data:\n                raise MACError('MAC verification failed')\n        else:\n            packet_data = self._packet[4:] + rest\n\n        self._inpbuf = self._inpbuf[rem:]\n        self._packet = b''\n\n        orig_payload = packet_data[1:-packet_data[0]]\n\n        if self._decompressor and (self._auth_complete or\n                                   not self._decompress_after_auth):\n            payload = self._decompressor.decompress(orig_payload)\n\n            if payload is None:\n                raise CompressionError('Decompression failed')\n        else:\n            payload = orig_payload\n\n        packet = SSHPacket(payload)\n        pkttype = packet.get_byte()\n        handler: SSHPacketHandler = self\n        skip_reason = ''\n        exc_reason = ''\n\n        if MSG_KEX_FIRST <= pkttype <= MSG_KEX_LAST:\n            if self._kex:\n                if self._ignore_first_kex: # pragma: no cover\n                    skip_reason = 'ignored first kex'\n                    self._ignore_first_kex = False\n                else:\n                    handler = self._kex\n            else:\n                skip_reason = 'kex not in progress'\n                exc_reason = 'Key exchange not in progress'\n        elif self._strict_kex and not self._recv_encryption and \\\n                MSG_IGNORE <= pkttype <= MSG_DEBUG:\n            skip_reason = 'strict kex violation'\n            exc_reason = 'Strict key exchange violation: ' \\\n                         'unexpected packet type %d received' % pkttype\n        elif MSG_USERAUTH_FIRST <= pkttype <= MSG_USERAUTH_LAST:\n            if self._auth:\n                handler = self._auth\n            else:\n                skip_reason = 'auth not in progress'\n                exc_reason = 'Authentication not in progress'\n        elif pkttype > MSG_KEX_LAST and not self._recv_encryption:\n            skip_reason = 'invalid request before kex complete'\n            exc_reason = 'Invalid request before key exchange was complete'\n        elif pkttype > MSG_USERAUTH_LAST and not self._auth_complete:\n            skip_reason = 'invalid request before auth complete'\n            exc_reason = 'Invalid request before authentication was complete'\n        elif MSG_CHANNEL_FIRST <= pkttype <= MSG_CHANNEL_LAST:\n            try:\n                recv_chan = packet.get_uint32()\n            except PacketDecodeError:\n                skip_reason = 'incomplete channel request'\n                exc_reason = 'Incomplete channel request received'\n            else:\n                try:\n                    handler = self._channels[recv_chan]\n                except KeyError:\n                    skip_reason = 'invalid channel number'\n                    exc_reason = 'Invalid channel number %d ' \\\n                                 'received' % recv_chan\n\n        handler.log_received_packet(pkttype, seq, packet, skip_reason)\n\n        if not skip_reason:\n            try:\n                processed = handler.process_packet(pkttype, seq, packet)\n            except PacketDecodeError as exc:\n                raise ProtocolError(str(exc)) from None\n\n            if not processed:\n                if self._strict_kex and not self._recv_encryption:\n                    exc_reason = 'Strict key exchange violation: ' \\\n                                 'unexpected packet type %d received' % pkttype\n                else:\n                    self.logger.debug1('Unknown packet type %d received',\n                                       pkttype)\n                    self.send_packet(MSG_UNIMPLEMENTED, UInt32(seq))\n\n        if exc_reason:\n            raise ProtocolError(exc_reason)\n\n        if pkttype > MSG_USERAUTH_LAST:\n            self._auth_final = True\n\n        if self._transport:\n            self._recv_handler = self._recv_pkthdr\n\n            if self._recv_seq == 0xffffffff and not self._recv_encryption:\n                raise ProtocolError('Sequence rollover before kex complete')\n\n            if pkttype == MSG_NEWKEYS and self._strict_kex:\n                self._recv_seq = 0\n            else:\n                self._recv_seq = (seq + 1) & 0xffffffff\n\n        return True\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void DoRealForwardFFT(OpKernelContext* ctx, uint64* fft_shape,\n                        const Tensor& in, Tensor* out) {\n    // Create the axes (which are always trailing).\n    const auto axes = Eigen::ArrayXi::LinSpaced(FFTRank, 1, FFTRank);\n    auto device = ctx->eigen_device<CPUDevice>();\n    auto input = Tensor(in).flat_inner_dims<RealT, FFTRank + 1>();\n    const auto input_dims = input.dimensions();\n\n    // Slice input to fft_shape on its inner-most dimensions.\n    Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> input_slice_sizes;\n    input_slice_sizes[0] = input_dims[0];\n    TensorShape temp_shape{input_dims[0]};\n    for (int i = 1; i <= FFTRank; ++i) {\n      input_slice_sizes[i] = fft_shape[i - 1];\n      temp_shape.AddDim(fft_shape[i - 1]);\n    }\n    OP_REQUIRES(ctx, temp_shape.num_elements() > 0,\n                errors::InvalidArgument(\"Obtained a FFT shape of 0 elements: \",\n                                        temp_shape.DebugString()));\n\n    auto output = out->flat_inner_dims<ComplexT, FFTRank + 1>();\n    const Eigen::DSizes<Eigen::DenseIndex, FFTRank + 1> zero_start_indices;\n\n    // Compute the full FFT using a temporary tensor.\n    Tensor temp;\n    OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<ComplexT>::v(),\n                                           temp_shape, &temp));\n    auto full_fft = temp.flat_inner_dims<ComplexT, FFTRank + 1>();\n    full_fft.device(device) =\n        input.slice(zero_start_indices, input_slice_sizes)\n            .template fft<Eigen::BothParts, Eigen::FFT_FORWARD>(axes);\n\n    // Slice away the negative frequency components.\n    output.device(device) =\n        full_fft.slice(zero_start_indices, output.dimensions());\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // Also add check that dense rank > 0.\n  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n                    done);\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def template(request, name, val):\n  name = str_param('name', name)\n  template_conf_missing = False\n\n  try:\n    config.check()\n  except OSError as e:\n    if e.errno == errno.ENOENT:\n      template_conf_missing = True\n    else:\n      raise\n\n  initialError = None\n  debug = request.GET.get('debug', False)\n  theme = request.GET.get('theme', config.ui_config['theme'])\n  css_file = finders.find('css/dashboard-%s.css' % theme)\n  if css_file is None:\n    initialError = \"Invalid theme '%s'\" % theme\n    theme = config.ui_config['theme']\n\n  context = {\n    'schemes_json' : json.dumps(config.schemes),\n    'ui_config_json' : json.dumps(config.ui_config),\n    'jsdebug' : debug or settings.JAVASCRIPT_DEBUG,\n    'debug' : debug,\n    'theme' : theme,\n    'initialError' : initialError,\n    'querystring' : json.dumps( dict( request.GET.items() ) ),\n    'template_conf_missing' : template_conf_missing,\n    'userName': '',\n    'permissions': json.dumps(getPermissions(request.user)),\n    'permissionsUnauthenticated': json.dumps(getPermissions(None))\n  }\n\n  user = request.user\n  if user:\n      context['userName'] = user.username\n\n  try:\n    template = Template.objects.get(name=name)\n  except Template.DoesNotExist:\n    context['initialError'] = \"Template '%s' does not exist.\" % name\n  else:\n    state = json.loads(template.loadState(val))\n    state['name'] = '%s/%s' % (name, val)\n    context['initialState'] = json.dumps(state)\n  return render(request, \"dashboard.html\", context)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def get_resolved_ref(self):\n        if hasattr(self, 'resolved_ref'):\n            return self.resolved_ref\n\n        try:\n            # Check if the reference is a valid SHA hash\n            self.sha1_validate(self.unresolved_ref)\n        except ValueError:\n            # The ref is a head/tag and we resolve it using `git ls-remote`\n            command = [\"git\", \"ls-remote\", \"--\", self.repo, self.unresolved_ref]\n            result = subprocess.run(command, universal_newlines=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            if result.returncode:\n                raise RuntimeError(\"Unable to run git ls-remote to get the `resolved_ref`: {}\".format(result.stderr))\n            if not result.stdout:\n                return None\n            resolved_ref = result.stdout.split(None, 1)[0]\n            self.sha1_validate(resolved_ref)\n            self.resolved_ref = resolved_ref\n        else:\n            # The ref already was a valid SHA hash\n            self.resolved_ref = self.unresolved_ref\n\n        return self.resolved_ref\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _redirect_safe(self, url, default=None):\n        \"\"\"Redirect if url is on our PATH\n\n        Full-domain redirects are allowed if they pass our CORS origin checks.\n\n        Otherwise use default (self.base_url if unspecified).\n        \"\"\"\n        if default is None:\n            default = self.base_url\n        # protect chrome users from mishandling unescaped backslashes.\n        # \\ is not valid in urls, but some browsers treat it as /\n        # instead of %5C, causing `\\\\` to behave as `//`\n        url = url.replace(\"\\\\\", \"%5C\")\n        # urllib and browsers interpret extra '/' in the scheme separator (`scheme:///host/path`)\n        # differently.\n        # urllib gives scheme=scheme, netloc='', path='/host/path', while\n        # browsers get scheme=scheme, netloc='host', path='/path'\n        # so make sure ':///*' collapses to '://' by splitting and stripping any additional leading slash\n        # don't allow any kind of `:/` shenanigans by splitting on ':' only\n        # and replacing `:/*` with exactly `://`\n        if \":\" in url:\n            scheme, _, rest = url.partition(\":\")\n            url = f\"{scheme}://{rest.lstrip('/')}\"\n        parsed = urlparse(url)\n        # full url may be `//host/path` (empty scheme == same scheme as request)\n        # or `https://host/path`\n        # or even `https:///host/path` (invalid, but accepted and ambiguously interpreted)\n        if (parsed.scheme or parsed.netloc) or not (parsed.path + \"/\").startswith(self.base_url):\n            # require that next_url be absolute path within our path\n            allow = False\n            # OR pass our cross-origin check\n            if parsed.scheme or parsed.netloc:\n                # if full URL, run our cross-origin check:\n                origin = f\"{parsed.scheme}://{parsed.netloc}\"\n                origin = origin.lower()\n                if self.allow_origin:\n                    allow = self.allow_origin == origin\n                elif self.allow_origin_pat:\n                    allow = bool(re.match(self.allow_origin_pat, origin))\n            if not allow:\n                # not allowed, use default\n                self.log.warning(\"Not allowing login redirect to %r\" % url)\n                url = default\n        self.redirect(url)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    // Only create one, if one does not exist already. Report status for all\n    // other exceptions. If one already exists, it unrefs the new one.\n    // An epsilon value of zero could cause performance issues and is therefore,\n    // disallowed.\n    const Tensor* epsilon_t;\n    OP_REQUIRES_OK(context, context->input(kEpsilonName, &epsilon_t));\n    float epsilon = epsilon_t->scalar<float>()();\n    OP_REQUIRES(\n        context, epsilon > 0,\n        errors::InvalidArgument(\"An epsilon value of zero is not allowed.\"));\n\n    const Tensor* num_streams_t;\n    OP_REQUIRES_OK(context, context->input(kNumStreamsName, &num_streams_t));\n    int64_t num_streams = num_streams_t->scalar<int64>()();\n    OP_REQUIRES(context, num_streams >= 0,\n                errors::InvalidArgument(\n                    \"Num_streams input cannot be a negative integer\"));\n\n    auto result =\n        new QuantileStreamResource(epsilon, max_elements_, num_streams);\n    auto status = CreateResource(context, HandleFromInput(context, 0), result);\n    if (!status.ok() && status.code() != tensorflow::error::ALREADY_EXISTS) {\n      OP_REQUIRES(context, false, status);\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check(request):\n   \"\"\"\n   Shows a page with the results of 'cobbler check'\n   \"\"\"\n   if not test_user_authenticated(request): return login(request, next=\"/cobbler_web/check\")\n   results = remote.check(request.session['token'])\n   t = get_template('check.tmpl')\n   html = t.render(RequestContext(request,{\n       'version': remote.version(request.session['token']),\n       'username' : username,\n       'results'  : results\n   }))\n   return HttpResponse(html)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def put_file(path):\n    try:\n        data_file, metadata_file = get_paths(app.config[\"DATA_ROOT\"], path)\n    except werkzeug.exceptions.NotFound:\n        return flask.Response(\n            \"Not Found\",\n            404,\n            mimetype=\"text/plain\",\n        )\n\n    verification_key = flask.request.args.get(\"v\", \"\")\n    length = int(flask.request.headers.get(\"Content-Length\", 0))\n    hmac_input = \"{} {}\".format(path, length).encode(\"utf-8\")\n    key = app.config[\"SECRET_KEY\"]\n    mac = hmac.new(key, hmac_input, hashlib.sha256)\n    digest = mac.hexdigest()\n\n    if not hmac.compare_digest(digest, verification_key):\n        return flask.Response(\n            \"Invalid verification key\",\n            403,\n            mimetype=\"text/plain\",\n        )\n\n    content_type = flask.request.headers.get(\n        \"Content-Type\",\n        \"application/octet-stream\",\n    )\n\n    data_file.parent.mkdir(parents=True, exist_ok=True, mode=0o770)\n\n    try:\n        with write_file(data_file) as fout:\n            stream_file(flask.request.stream, fout, length)\n\n            with metadata_file.open(\"x\") as f:\n                json.dump(\n                    {\n                        \"headers\": {\"Content-Type\": content_type},\n                    },\n                    f,\n                )\n    except EOFError:\n        return flask.Response(\n            \"Bad Request\",\n            400,\n            mimetype=\"text/plain\",\n        )\n    except OSError as exc:\n        if exc.errno == errno.EEXIST:\n            return flask.Response(\n                \"Conflict\",\n                409,\n                mimetype=\"text/plain\",\n            )\n        raise\n\n    return flask.Response(\n        \"Created\",\n        201,\n        mimetype=\"text/plain\",\n    )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  explicit ReverseSequenceOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"batch_dim\", &batch_dim_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"seq_dim\", &seq_dim_));\n    OP_REQUIRES(context, batch_dim_ >= 0,\n                errors::InvalidArgument(\"Invalid batch_dim \", batch_dim_));\n    OP_REQUIRES(context, seq_dim_ >= 0,\n                errors::InvalidArgument(\"Invalid seq_dim \", seq_dim_));\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def delete_service(self, context, service_id):\n        self.assert_admin(context)\n        service_ref = self.catalog_api.get_service(context, service_id)\n        if not service_ref:\n            raise exception.ServiceNotFound(service_id=service_id)\n        self.catalog_api.delete_service(context, service_id)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def clone(\n        self,\n        pdf_dest: Any,\n        force_duplicate: bool = False,\n        ignore_fields: Optional[Sequence[Union[str, int]]] = (),\n    ) -> \"ContentStream\":\n        \"\"\"\n        Clone object into pdf_dest.\n\n        Args:\n            pdf_dest:\n            force_duplicate:\n            ignore_fields:\n\n        Returns:\n            The cloned ContentStream\n        \"\"\"\n        try:\n            if self.indirect_reference.pdf == pdf_dest and not force_duplicate:  # type: ignore\n                return self\n        except Exception:\n            pass\n\n        visited: Set[Tuple[int, int]] = set()\n        d__ = cast(\n            \"ContentStream\",\n            self._reference_clone(\n                self.__class__(None, None), pdf_dest, force_duplicate\n            ),\n        )\n        if ignore_fields is None:\n            ignore_fields = []\n        d__._clone(self, pdf_dest, force_duplicate, ignore_fields, visited)\n        return d__\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  Status ValidateInputs(const CSRSparseMatrix& sparse_matrix,\n                        const Tensor& permutation_indices, int* batch_size,\n                        int64* num_rows) {\n    if (sparse_matrix.dtype() != DataTypeToEnum<T>::value)\n      return errors::InvalidArgument(\n          \"Asked for a CSRSparseMatrix of type \",\n          DataTypeString(DataTypeToEnum<T>::value),\n          \" but saw dtype: \", DataTypeString(sparse_matrix.dtype()));\n\n    const Tensor& dense_shape = sparse_matrix.dense_shape();\n    const int rank = dense_shape.dim_size(0);\n    if (rank < 2 || rank > 3)\n      return errors::InvalidArgument(\"sparse matrix must have rank 2 or 3; \",\n                                     \"but dense_shape has size \", rank);\n    const int row_dim = (rank == 2) ? 0 : 1;\n    auto dense_shape_vec = dense_shape.vec<int64>();\n    *num_rows = dense_shape_vec(row_dim);\n    const int64 num_cols = dense_shape_vec(row_dim + 1);\n    if (*num_rows != num_cols)\n      return errors::InvalidArgument(\n          \"sparse matrix must be square; got: \", *num_rows, \" != \", num_cols);\n    const TensorShape& perm_shape = permutation_indices.shape();\n    if (perm_shape.dims() + 1 != rank)\n      return errors::InvalidArgument(\n          \"sparse matrix must have the same rank as permutation; got: \", rank,\n          \" != \", perm_shape.dims(), \" + 1.\");\n    if (perm_shape.dim_size(rank - 2) != *num_rows)\n      return errors::InvalidArgument(\n          \"permutation must have the same number of elements in each batch \"\n          \"as the number of rows in sparse matrix; got: \",\n          perm_shape.dim_size(rank - 2), \" != \", *num_rows);\n\n    *batch_size = sparse_matrix.batch_size();\n    if (*batch_size > 1) {\n      if (perm_shape.dim_size(0) != *batch_size)\n        return errors::InvalidArgument(\n            \"permutation must have the same batch size \"\n            \"as sparse matrix; got: \",\n            perm_shape.dim_size(0), \" != \", *batch_size);\n    }\n\n    return Status::OK();\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def event_from_pdu_json(pdu_json, outlier=False):\n    \"\"\"Construct a FrozenEvent from an event json received over federation\n\n    Args:\n        pdu_json (object): pdu as received over federation\n        outlier (bool): True to mark this event as an outlier\n\n    Returns:\n        FrozenEvent\n\n    Raises:\n        SynapseError: if the pdu is missing required fields or is otherwise\n            not a valid matrix event\n    \"\"\"\n    # we could probably enforce a bunch of other fields here (room_id, sender,\n    # origin, etc etc)\n    assert_params_in_request(pdu_json, ('event_id', 'type', 'depth'))\n\n    depth = pdu_json['depth']\n    if not isinstance(depth, six.integer_types):\n        raise SynapseError(400, \"Depth %r not an intger\" % (depth, ),\n                           Codes.BAD_JSON)\n\n    if depth < 0:\n        raise SynapseError(400, \"Depth too small\", Codes.BAD_JSON)\n    elif depth > MAX_DEPTH:\n        raise SynapseError(400, \"Depth too large\", Codes.BAD_JSON)\n\n    event = FrozenEvent(\n        pdu_json\n    )\n\n    event.internal_metadata.outlier = outlier\n\n    return event\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_document_field_display(self, field_name, field):\n        \"\"\"Render a link to a document\"\"\"\n        document = getattr(self.instance, field_name)\n        if document:\n            return format_html(\n                '<a href=\"{}\">{} <span class=\"meta\">({}, {})</span></a>',\n                document.url,\n                document.title,\n                document.file_extension.upper(),\n                filesizeformat(document.file.size),\n            )\n        return self.model_admin.get_empty_value_display(field_name)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void ImmutableConstantOp::Compute(OpKernelContext* ctx) {\n  std::unique_ptr<MemmappedTensorAllocator> allocator(\n      new MemmappedTensorAllocator());\n\n  OP_REQUIRES_OK(ctx,\n                 allocator->InitializeFromRegion(region_name_, ctx->env()));\n  OP_REQUIRES(ctx, dtype_ != DT_STRING,\n              errors::Unimplemented(\"Sorry, DT_STRING is not currently \"\n                                    \"supported for ImmutableConstOp.\"));\n  ctx->set_output(0, Tensor(allocator.get(), dtype_, shape_));\n  OP_REQUIRES_OK(ctx, allocator->allocation_status());\n  // Allocator is owned by the tensor from this point.\n  allocator.release()->set_delete_on_deallocate();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _wget_download(url: str, fullname: str):\n    try:\n        assert urlparse(url).scheme in (\n            'http',\n            'https',\n        ), 'Only support https and http url'\n        # using wget to download url\n        tmp_fullname = fullname + \"_tmp\"\n        # \u2013user-agent\n        command = f'wget -O {tmp_fullname} -t {DOWNLOAD_RETRY_LIMIT} {url}'\n        subprc = subprocess.Popen(\n            command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        _ = subprc.communicate()\n\n        if subprc.returncode != 0:\n            raise RuntimeError(\n                f'{command} failed. Please make sure `wget` is installed or {url} exists'\n            )\n\n        shutil.move(tmp_fullname, fullname)\n\n    except Exception as e:  # requests.exceptions.ConnectionError\n        logger.info(f\"Downloading {url} failed with exception {str(e)}\")\n        return False\n\n    return fullname\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def have_responded(self, origin, transaction):\n        \"\"\" Have we already responded to a transaction with the same id and\n        origin?\n\n        Returns:\n            Deferred: Results in `None` if we have not previously responded to\n            this transaction or a 2-tuple of `(int, dict)` representing the\n            response code and response body.\n        \"\"\"\n        if not transaction.transaction_id:\n            raise RuntimeError(\"Cannot persist a transaction with no \"\n                               \"transaction_id\")\n\n        return self.store.get_received_txn_response(\n            transaction.transaction_id, origin\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self, *,\n        deserializer: AbstractDeserializer,\n        serializer: AbstractSerializer,\n        connect: AbstractAddress = None,\n        bind: AbstractAddress = None,\n        transport: Type[BaseTransport] = None,\n        authenticator: AbstractAuthenticator = None,\n        transport_opts: Mapping[str, Any] = {},\n        scheduler: AbstractAsyncScheduler = None,\n        compress: bool = True,\n        max_body_size: int = 10 * (2**20),  # 10 MiBytes\n        max_concurrency: int = 100,\n        execute_timeout: float = None,\n        invoke_timeout: float = None,\n        debug_rpc: bool = False,\n    ) -> None:\n        if connect is None and bind is None:\n            raise ValueError('You must specify either the connect or bind address.')\n        self._connect = connect\n        self._bind = bind\n        self._opener = None\n        self._connection = None\n        self._compress = compress\n        self._deserializer = deserializer\n        self._serializer = serializer\n        self._max_concurrency = max_concurrency\n        self._exec_timeout = execute_timeout\n        self._invoke_timeout = invoke_timeout\n\n        self._scheduler = None\n        if transport is None:\n            raise ValueError('You must provide a transport class.')\n        self._transport = transport(authenticator=authenticator,\n                                    transport_opts=transport_opts)\n        self._func_registry = {}\n\n        self._client_seq_id = 0\n        self._server_seq_id = 0\n        self._req_idmap = {}\n\n        # incoming queues\n        self._invocation_resolver = AsyncResolver()\n        if scheduler is None:\n            scheduler = KeySerializedAsyncScheduler()\n        self._func_scheduler = scheduler\n\n        # there is only one outgoing queue\n        self._outgoing_queue = asyncio.Queue()\n        self._recv_task = None\n        self._send_task = None\n\n        self._log = logging.getLogger(__name__ + '.Peer')\n        self._debug_rpc = debug_rpc\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const auto& input = context->input(0);\n    auto flat_in = input.flat<tstring>();\n\n    int fixed_length;\n    const auto& length_input = context->input(1);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(length_input.shape()),\n                errors::InvalidArgument(\"k must be scalar, got shape \",\n                                        length_input.shape().DebugString()));\n    fixed_length = length_input.scalar<int32>()();\n\n    OP_REQUIRES(\n        context, fixed_length % sizeof(T) == 0,\n        errors::InvalidArgument(\n            \"fixed_length (\", fixed_length,\n            \") must be a multiple of the size of out_type (\", sizeof(T), \")\"));\n\n    OP_REQUIRES(context, fixed_length > 0,\n                errors::InvalidArgument(\"fixed_length (\", fixed_length,\n                                        \") must be greater than zero.\"));\n\n    int width = fixed_length / sizeof(T);\n\n    TensorShape out_shape = input.shape();\n    out_shape.AddDim(width);\n    Tensor* output_tensor = nullptr;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(\"output\", out_shape, &output_tensor));\n\n    if (flat_in.size() == 0) {  // Empty input\n      return;\n    }\n\n    auto out = output_tensor->flat_inner_dims<T>();\n    T* out_data = out.data();\n\n    // Forcibly clear memory - we're going to copy variable length strings in,\n    // and need to ensure that if we don't write to byte N when we copy, that\n    // we're not getting random data.\n    memset(out_data, 0, fixed_length * flat_in.size());\n\n    // If the data is already in the host's byte order, or if the width of the\n    // output type is a single byte (meaning the ordering doesn't matter), we\n    // can copy the memory directly.\n    if (!convert_data_endianness_ || sizeof(T) == 1) {\n      for (int64 i = 0; i < flat_in.size(); ++i) {\n        const auto to_copy =\n            std::min(flat_in(i).size(), static_cast<size_t>(fixed_length));\n        memcpy(out_data, flat_in(i).data(), to_copy);\n        // Note: increase out_data by width since it's already of type T* so\n        // each shift amount is implicitly multiplied by sizeof(T) according to\n        // pointer arithmetic rules.\n        out_data += width;\n      }\n    } else {\n      // Otherwise, the data is not in the host's byte order, and rather than a\n      // direct copy, we need to reverse the byte ordering of each element.\n      for (int64 i = 0; i < flat_in.size(); ++i) {\n        const char* in_data_bytes =\n            reinterpret_cast<const char*>(flat_in(i).data());\n        char* out_data_bytes = reinterpret_cast<char*>(out_data);\n        const char* p_in = in_data_bytes;\n        char* p_out = out_data_bytes;\n        for (; p_in < in_data_bytes + fixed_length;\n             p_in += sizeof(T), p_out += sizeof(T)) {\n          std::reverse_copy(p_in, p_in + sizeof(T), p_out);\n        }\n        // Note: increase out_data by width since it's already of type T* so\n        // each shift amount is implicitly multiplied by sizeof(T) according to\n        // pointer arithmetic rules.\n        out_data += width;\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def job_buttons(context, obj):\n    \"\"\"\n    Render all applicable job buttons for the given object.\n    \"\"\"\n    content_type = ContentType.objects.get_for_model(obj)\n    # We will enforce \"run\" permission later in deciding which buttons to show as disabled.\n    buttons = JobButton.objects.filter(content_types=content_type)\n    if not buttons:\n        return SAFE_EMPTY_STR\n\n    buttons_html = forms_html = SAFE_EMPTY_STR\n    group_names = OrderedDict()\n\n    for jb in buttons:\n        # Organize job buttons by group for later processing\n        if jb.group_name:\n            group_names.setdefault(jb.group_name, []).append(jb)\n\n        # Render and add non-grouped buttons\n        else:\n            button_html, form_html = _render_job_button_for_obj(jb, obj, context, content_type)\n            buttons_html += button_html\n            forms_html += form_html\n\n    # Add grouped buttons to template\n    for group_name, buttons in group_names.items():\n        group_button_class = buttons[0].button_class\n\n        buttons_rendered = SAFE_EMPTY_STR\n\n        for jb in buttons:\n            # Render grouped buttons as list items\n            button_html, form_html = _render_job_button_for_obj(jb, obj, context, content_type)\n            buttons_rendered += format_html(\"<li>{}</li>\", button_html)\n            forms_html += form_html\n\n        if buttons_rendered:\n            buttons_html += format_html(\n                GROUP_DROPDOWN,\n                group_button_class=group_button_class,\n                group_name=group_name,\n                grouped_buttons=buttons_rendered,\n            )\n\n    # We want all of the buttons first and then any modals and forms so the buttons render properly\n    return buttons_html + forms_html\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_many(self, keys, version=None):\n        key_map = {self.make_key(key, version=version): key for key in keys}\n        for key in key_map:\n            self.validate_key(key)\n        ret = self._cache.get_multi(key_map.keys())\n        return {key_map[k]: v for k, v in ret.items()}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void SparseFillEmptyRowsOpImpl(OpKernelContext* context,\n                               AsyncOpKernel::DoneCallback done = nullptr) {\n  // Note that setting this empty lambda as the default parameter value directly\n  // can cause strange compiler/linker errors, so we do it like this instead.\n  if (!done) {\n    done = [] {};\n  }\n\n  const int kIndicesInput = 0;\n  const int kValuesInput = 1;\n  const int kDenseShapeInput = 2;\n  const int kDefaultValueInput = 3;\n\n  const Tensor& indices_t = context->input(kIndicesInput);\n  const Tensor& values_t = context->input(kValuesInput);\n  const Tensor& dense_shape_t = context->input(kDenseShapeInput);\n  const Tensor& default_value_t = context->input(kDefaultValueInput);\n\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsVector(dense_shape_t.shape()),\n      errors::InvalidArgument(\"dense_shape must be a vector, saw: \",\n                              dense_shape_t.shape().DebugString()),\n      done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsMatrix(indices_t.shape()),\n                    errors::InvalidArgument(\"indices must be a matrix, saw: \",\n                                            indices_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(context, TensorShapeUtils::IsVector(values_t.shape()),\n                    errors::InvalidArgument(\"values must be a vector, saw: \",\n                                            values_t.shape().DebugString()),\n                    done);\n  OP_REQUIRES_ASYNC(\n      context, indices_t.dim_size(0) == values_t.dim_size(0),\n      errors::InvalidArgument(\"The length of `values` (\", values_t.dim_size(0),\n                              \") must match the first dimension of `indices` (\",\n                              indices_t.dim_size(0), \").\"),\n      done);\n  OP_REQUIRES_ASYNC(\n      context, TensorShapeUtils::IsScalar(default_value_t.shape()),\n      errors::InvalidArgument(\"default_value must be a scalar, saw: \",\n                              default_value_t.shape().DebugString()),\n      done);\n  // TODO(ebrevdo): add shape checks between values, indices,\n  // Also add check that dense rank > 0.\n  OP_REQUIRES_ASYNC(context, dense_shape_t.NumElements() != 0,\n                    errors::InvalidArgument(\"Dense shape cannot be empty.\"),\n                    done);\n\n  using FunctorType = functor::SparseFillEmptyRows<Device, T, Tindex>;\n  OP_REQUIRES_OK_ASYNC(context,\n                       FunctorType()(context, default_value_t, indices_t,\n                                     values_t, dense_shape_t, done),\n                       done);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if not url:\n        return False\n    # Chrome treats \\ completely as /\n    url = url.replace('\\\\', '/')\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlaprse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    return (not url_info.netloc or url_info.netloc == host) and \\\n        (not url_info.scheme or url_info.scheme in ['http', 'https'])\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def to_xml(self) -> Optional[Any]:\n        \"\"\"\n        Convert to xml using dicttoxml.dicttoxml and then pretty print it.\n        \"\"\"\n        if self.data:\n            xml_data = dicttoxml.dicttoxml(\n                self.data,\n                root=self.root,\n                custom_root=self.wrapper,\n                attr_type=self.attr_type,\n                item_wrap=self.item_wrap,\n            )\n            if self.pretty:\n                try:\n                    result = parseString(xml_data).toprettyxml()\n                except ExpatError as e:\n                    raise InvalidDataError\n                return result\n            return xml_data\n        return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def project_clone(request):\n    \"\"\"\n    clone project from github\n    :param request: request object\n    :return: json\n    \"\"\"\n    if request.method == 'POST':\n        data = json.loads(request.body)\n        address = data.get('address')\n        if not address.startswith('http'):\n            return JsonResponse({'status': False})\n        address = address + '.git' if not address.endswith('.git') else address\n        cmd = ['git', 'clone', 'address', join(PROJECTS_FOLDER, Path(address).stem)]\n        logger.debug('clone cmd %s', cmd)\n        p = Popen(cmd, shell=False, stdin=PIPE, stdout=PIPE, stderr=PIPE)\n        stdout, stderr = bytes2str(p.stdout.read()), bytes2str(p.stderr.read())\n        logger.debug('clone run result %s', stdout)\n        if stderr:\n            logger.error(stderr)\n        return JsonResponse({'status': True}) if not stderr else JsonResponse({'status': False})\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def build_IR(self, expr, context):\n        args = [Expr(arg, context).ir_node for arg in expr.args]\n        if len(args) < 2:\n            raise StructureException(\"Concat expects at least two arguments\", expr)\n\n        # Maximum length of the output\n        dst_maxlen = sum(\n            [arg.typ.maxlen if isinstance(arg.typ, _BytestringT) else arg.typ.m for arg in args]\n        )\n\n        # TODO: try to grab these from semantic analysis\n        if isinstance(args[0].typ, StringT):\n            ret_typ = StringT(dst_maxlen)\n        else:\n            ret_typ = BytesT(dst_maxlen)\n\n        # respect API of copy_bytes\n        bufsize = dst_maxlen + 32\n        buf = context.new_internal_variable(BytesT(bufsize))\n\n        # Node representing the position of the output in memory\n        dst = IRnode.from_list(buf, typ=ret_typ, location=MEMORY, annotation=\"concat destination\")\n\n        ret = [\"seq\"]\n        # stack item representing our current offset in the dst buffer\n        ofst = \"concat_ofst\"\n\n        # TODO: optimize for the case where all lengths are statically known.\n        for arg in args:\n            dst_data = add_ofst(bytes_data_ptr(dst), ofst)\n\n            if isinstance(arg.typ, _BytestringT):\n                # Ignore empty strings\n                if arg.typ.maxlen == 0:\n                    continue\n\n                with arg.cache_when_complex(\"arg\") as (b1, arg):\n                    argdata = bytes_data_ptr(arg)\n\n                    with get_bytearray_length(arg).cache_when_complex(\"len\") as (b2, arglen):\n                        do_copy = [\n                            \"seq\",\n                            copy_bytes(dst_data, argdata, arglen, arg.typ.maxlen),\n                            [\"set\", ofst, [\"add\", ofst, arglen]],\n                        ]\n                        ret.append(b1.resolve(b2.resolve(do_copy)))\n\n            else:\n                ret.append(STORE(dst_data, unwrap_location(arg)))\n                ret.append([\"set\", ofst, [\"add\", ofst, arg.typ.m]])\n\n        ret.append(STORE(dst, ofst))\n\n        # Memory location of the output\n        ret.append(dst)\n\n        return IRnode.from_list(\n            [\"with\", ofst, 0, ret], typ=ret_typ, location=MEMORY, annotation=\"concat\"\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    const findHeadingElement = (cell: Cell): void => {\n      model.getCellHeadings(cell).forEach(async heading => {\n        const elementId = await getIdForHeading(\n          heading,\n          this.parser!,\n          this.sanitizer\n        );\n\n        const selector = elementId\n          ? `h${heading.level}[id=\"${CSS.escape(elementId)}\"]`\n          : `h${heading.level}`;\n\n        if (heading.outputIndex !== undefined) {\n          // Code cell\n          headingToElement.set(\n            heading,\n            TableOfContentsUtils.addPrefix(\n              (heading.cellRef as CodeCell).outputArea.widgets[\n                heading.outputIndex\n              ].node,\n              selector,\n              heading.prefix ?? ''\n            )\n          );\n        } else {\n          headingToElement.set(\n            heading,\n            TableOfContentsUtils.addPrefix(\n              heading.cellRef.node,\n              selector,\n              heading.prefix ?? ''\n            )\n          );\n        }\n      });\n    };\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sqlalchemy_scheme(self) -> str:\n        \"\"\"Sqlalchemy scheme either from constructor, connection extras or default.\"\"\"\n        extra_scheme = self.connection_extra_lower.get(\"sqlalchemy_scheme\")\n        if not self._sqlalchemy_scheme and extra_scheme and (\":\" in extra_scheme or \"/\" in extra_scheme):\n            raise RuntimeError(\"sqlalchemy_scheme in connection extra should not contain : or / characters\")\n        return self._sqlalchemy_scheme or extra_scheme or self.DEFAULT_SQLALCHEMY_SCHEME\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def authenticate_by_pam(username, password):\n    @pam_conversation\n    def conv(\n        num_msg, msg, resp, appdata_ptr\n    ):  # pylint: disable=unused-argument\n        # it is: *resp = (pam_response *) calloc(num_msg, sizeof(pam_response))\n        resp[0] = cast(\n            calloc(num_msg, sizeof(pam_response)), POINTER(pam_response)\n        )\n        for i in range(num_msg):\n            if msg[i].contents.msg_style == PAM_PROMPT_ECHO_OFF:\n                resp.contents[i].resp = strdup(password.encode(\"utf8\"))\n                resp.contents[i].resp_retcode = 0\n        return 0\n\n    pamh = pam_handle()\n    conversation = pam_conv(conv)\n    returncode = pam_start(\n        PCSD_SERVICE.encode(\"utf8\"),\n        username.encode(\"utf8\"),\n        byref(conversation),\n        byref(pamh),\n    )\n    if returncode == PAM_SUCCESS:\n        returncode = pam_authenticate(pamh, 0)\n    if returncode == PAM_SUCCESS:\n        returncode = pam_acct_mgmt(pamh, 0)\n    pam_end(pamh, returncode)\n    return returncode == PAM_SUCCESS\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _validate_archive_name(name, target):\n    if not os.path.abspath(os.path.join(target, name)).startswith(target + os.path.sep):\n        raise InvalidLanguagePack(f\"Provided language pack contains invalid name {name}\")\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_image_dimensions(file_or_path, close=False):\n    \"\"\"\n    Returns the (width, height) of an image, given an open file or a path.  Set\n    'close' to True to close the file at the end if it is initially in an open\n    state.\n    \"\"\"\n    # Try to import PIL in either of the two ways it can end up installed.\n    try:\n        from PIL import ImageFile as PILImageFile\n    except ImportError:\n        import ImageFile as PILImageFile\n\n    p = PILImageFile.Parser()\n    if hasattr(file_or_path, 'read'):\n        file = file_or_path\n        file_pos = file.tell()\n        file.seek(0)\n    else:\n        file = open(file_or_path, 'rb')\n        close = True\n    try:\n        # Most of the time PIL only needs a small chunk to parse the image and\n        # get the dimensions, but with some TIFF files PIL needs to parse the\n        # whole file.\n        chunk_size = 1024\n        while 1:\n            data = file.read(chunk_size)\n            if not data:\n                break\n            p.feed(data)\n            if p.image:\n                return p.image.size\n            chunk_size = chunk_size*2\n        return None\n    finally:\n        if close:\n            file.close()\n        else:\n            file.seek(file_pos)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def join(self, timeout=None):\r\n        \"\"\"Join all threads in the graph.\r\n\r\n        Parameters:\r\n            timeout (float): if not none will attempt to join subtasks with\r\n                this value. If a subtask times out, the whole function will\r\n                timeout.\r\n\r\n        Returns:\r\n            True if successful join, False if timed out.\r\n\r\n        \"\"\"\r\n        # if single threaded, nothing to join.\r\n        if self.terminated:\r\n            return True\r\n        if self.n_workers < 0:\r\n            return True\r\n        # start delayed execution if necessary:\r\n        self.taskgraph_started_event.set()\r\n        try:\r\n            timedout = False\r\n            for task in self.task_map.values():\r\n                timedout = not task.join(timeout)\r\n                # if the last task timed out then we want to timeout for all\r\n                # of the task graph\r\n                if timedout:\r\n                    break\r\n            if not timedout and self.closed:\r\n                # join all the workers and the worker pool\r\n                if self.n_workers >= 0:\r\n                    # there's only something to clean up if there's a worker\r\n                    LOGGER.info(\"joining all the task executors\")\r\n                    for task_executor_thread in (\r\n                            self.task_executor_thread_list):\r\n                        try:\r\n                            task_executor_thread.join(timeout)\r\n                        except RuntimeError:\r\n                            LOGGER.info(\r\n                                \"task_executor_thread already complete %s\",\r\n                                task_executor_thread)\r\n                    # run through any leftover tasks that are still running\r\n                    # after executor is dead\r\n                    for task in self.task_map.values():\r\n                        timedout = not task.join(timeout)\r\n                        if timedout:\r\n                            break\r\n                    if self.worker_pool and not timedout:\r\n                        LOGGER.info(\"joining the worker_pool\")\r\n                        self.worker_pool.close()\r\n                        self.worker_pool.join()\r\n            return not timedout\r\n        except Exception:\r\n            # If there's an exception on a join it means that a task failed\r\n            # to execute correctly. Print a helpful message then terminate the\r\n            # taskgraph object.\r\n            LOGGER.exception(\r\n                \"Exception raised when joining task %s. It's possible \"\r\n                \"that this task did not cause the exception, rather another \"\r\n                \"exception terminated the task_graph. Check the log to see \"\r\n                \"if there are other exceptions.\", task)\r\n            self._terminate()\r\n            raise\r\n\r"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def allow_cors_options(func):\n    \"\"\"\n    Decorator that adds automatic handling of OPTIONS requests for CORS\n\n    If the request is OPTIONS (i.e. pre flight CORS) construct a OK (200) response\n    in which we explicitly enable the caller and add the custom headers that we support\n    For other requests just add the appropriate CORS headers\n\n    :param func: the original request handler\n    :return: a request handler that shortcuts OPTIONS requests and just returns an OK (CORS allowed)\n    \"\"\"\n\n    @functools.wraps(func)\n    def allow_cors_options_wrapper(self, request: Request, *args, **kwargs):\n        if request.method == \"OPTIONS\":\n            response = HttpResponse(status=200)\n            response[\"Access-Control-Max-Age\"] = \"3600\"  # don't ask for options again for 1 hour\n        else:\n            response = func(self, request, *args, **kwargs)\n\n        allow = \", \".join(self._allowed_methods())\n        response[\"Allow\"] = allow\n        response[\"Access-Control-Allow-Methods\"] = allow\n        response[\"Access-Control-Allow-Headers\"] = (\n            \"X-Sentry-Auth, X-Requested-With, Origin, Accept, \"\n            \"Content-Type, Authentication, Authorization, Content-Encoding, \"\n            \"sentry-trace, baggage, X-CSRFToken\"\n        )\n        response[\"Access-Control-Expose-Headers\"] = \"X-Sentry-Error, Retry-After\"\n\n        if request.META.get(\"HTTP_ORIGIN\") == \"null\":\n            origin = \"null\"  # if ORIGIN header is explicitly specified as 'null' leave it alone\n        else:\n            origin = origin_from_request(request)\n\n        if origin is None or origin == \"null\":\n            response[\"Access-Control-Allow-Origin\"] = \"*\"\n        else:\n            response[\"Access-Control-Allow-Origin\"] = origin\n\n        # If the requesting origin is a subdomain of\n        # the application's base-hostname we should allow cookies\n        # to be sent.\n        basehost = options.get(\"system.base-hostname\")\n        if basehost and origin:\n            if origin.endswith((\"://\" + basehost, \".\" + basehost)):\n                response[\"Access-Control-Allow-Credentials\"] = \"true\"\n\n        return response\n\n    return allow_cors_options_wrapper\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& gradient = ctx->input(0);\n    const Tensor& input = ctx->input(1);\n    Tensor* input_backprop = nullptr;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, input.shape(), &input_backprop));\n\n    OP_REQUIRES(\n        ctx, input.IsSameSize(gradient),\n        errors::InvalidArgument(\"gradient and input must be the same size\"));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    const Tensor& input_min_tensor = ctx->input(2);\n    OP_REQUIRES(ctx,\n                input_min_tensor.dims() == 0 || input_min_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input min tensor must have dimension 1. Recieved \",\n                    input_min_tensor.dims(), \".\"));\n    const Tensor& input_max_tensor = ctx->input(3);\n    OP_REQUIRES(ctx,\n                input_max_tensor.dims() == 0 || input_max_tensor.dims() == 1,\n                errors::InvalidArgument(\n                    \"Input max tensor must have dimension 1. Recieved \",\n                    input_max_tensor.dims(), \".\"));\n    if (axis_ != -1) {\n      OP_REQUIRES(\n          ctx, input_min_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"min has incorrect size, expected \", depth,\n                                  \" was \", input_min_tensor.dim_size(0)));\n      OP_REQUIRES(\n          ctx, input_max_tensor.dim_size(0) == depth,\n          errors::InvalidArgument(\"max has incorrect size, expected \", depth,\n                                  \" was \", input_max_tensor.dim_size(0)));\n    }\n\n    TensorShape min_max_shape(input_min_tensor.shape());\n    Tensor* input_min_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(1, min_max_shape, &input_min_backprop));\n\n    Tensor* input_max_backprop;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(2, min_max_shape, &input_max_backprop));\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), gradient.template flat<T>(),\n        input.template flat<T>(), input_min_tensor.scalar<T>(),\n        input_max_tensor.scalar<T>(), input_backprop->template flat<T>(),\n        input_min_backprop->template scalar<T>(),\n        input_max_backprop->template scalar<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelGradientFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        gradient.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        &input_min_tensor, &input_max_tensor,\n        input_backprop->template flat_inner_outer_dims<T, 3>(axis_ - 1),\n        input_min_backprop->template flat<T>(),\n        input_max_backprop->template flat<T>());\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        filename = str(filename).replace('\\\\', '/')\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def run(self, modules):\n        # Bind http routes of each module.\n        for c in modules:\n            dashboard_optional_utils.ClassMethodRouteTable.bind(c)\n\n        # Http server should be initialized after all modules loaded.\n        # working_dir uploads for job submission can be up to 100MiB.\n        app = aiohttp.web.Application(\n            client_max_size=100 * 1024**2,\n            middlewares=[self.metrics_middleware, self.path_clean_middleware],\n        )\n        app.add_routes(routes=routes.bound_routes())\n\n        self.runner = aiohttp.web.AppRunner(\n            app,\n            access_log_format=(\n                \"%a %t '%r' %s %b bytes %D us \" \"'%{Referer}i' '%{User-Agent}i'\"\n            ),\n        )\n        await self.runner.setup()\n        last_ex = None\n        for i in range(1 + self.http_port_retries):\n            try:\n                site = aiohttp.web.TCPSite(self.runner, self.http_host, self.http_port)\n                await site.start()\n                break\n            except OSError as e:\n                last_ex = e\n                self.http_port += 1\n                logger.warning(\"Try to use port %s: %s\", self.http_port, e)\n        else:\n            raise Exception(\n                f\"Failed to find a valid port for dashboard after \"\n                f\"{self.http_port_retries} retries: {last_ex}\"\n            )\n        self.http_host, self.http_port, *_ = site._server.sockets[0].getsockname()\n        self.http_host = (\n            self.ip\n            if ipaddress.ip_address(self.http_host).is_unspecified\n            else self.http_host\n        )\n        logger.info(\n            \"Dashboard head http address: %s:%s\", self.http_host, self.http_port\n        )\n        # Dump registered http routes.\n        dump_routes = [r for r in app.router.routes() if r.method != hdrs.METH_HEAD]\n        for r in dump_routes:\n            logger.info(r)\n        logger.info(\"Registered %s routes.\", len(dump_routes))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        database: \"Database\",\n        query: Optional[\"Query\"] = None,\n        table: Optional[\"SqlaTable\"] = None,\n        extra_cache_keys: Optional[list[Any]] = None,\n        removed_filters: Optional[list[str]] = None,\n        applied_filters: Optional[list[str]] = None,\n        **kwargs: Any,\n    ) -> None:\n        self._database = database\n        self._query = query\n        self._schema = None\n        if query and query.schema:\n            self._schema = query.schema\n        elif table:\n            self._schema = table.schema\n        self._extra_cache_keys = extra_cache_keys\n        self._applied_filters = applied_filters\n        self._removed_filters = removed_filters\n        self._context: dict[str, Any] = {}\n        self._env = SandboxedEnvironment(undefined=DebugUndefined)\n        self.set_context(**kwargs)\n\n        # custom filters\n        self._env.filters[\"where_in\"] = WhereInMacro(database.get_dialect())\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        name=None,\n        n_workers=None,\n        threads_per_worker=None,\n        processes=None,\n        loop=None,\n        start=None,\n        host=None,\n        ip=None,\n        scheduler_port=0,\n        silence_logs=logging.WARN,\n        dashboard_address=\":8787\",\n        worker_dashboard_address=None,\n        diagnostics_port=None,\n        services=None,\n        worker_services=None,\n        service_kwargs=None,\n        asynchronous=False,\n        security=None,\n        protocol=None,\n        blocked_handlers=None,\n        interface=None,\n        worker_class=None,\n        scheduler_kwargs=None,\n        scheduler_sync_interval=1,\n        **worker_kwargs,\n    ):\n        if ip is not None:\n            # In the future we should warn users about this move\n            # warnings.warn(\"The ip keyword has been moved to host\")\n            host = ip\n\n        if diagnostics_port is not None:\n            warnings.warn(\n                \"diagnostics_port has been deprecated. \"\n                \"Please use `dashboard_address=` instead\"\n            )\n            dashboard_address = diagnostics_port\n\n        if threads_per_worker == 0:\n            warnings.warn(\n                \"Setting `threads_per_worker` to 0 has been deprecated. \"\n                \"Please set to None or to a specific int.\"\n            )\n            threads_per_worker = None\n\n        if \"dashboard\" in worker_kwargs:\n            warnings.warn(\n                \"Setting `dashboard` is discouraged. \"\n                \"Please set `dashboard_address` to affect the scheduler (more common) \"\n                \"and `worker_dashboard_address` for the worker (less common).\"\n            )\n\n        if processes is None:\n            processes = worker_class is None or issubclass(worker_class, Nanny)\n        if worker_class is None:\n            worker_class = Nanny if processes else Worker\n\n        self.status = None\n        self.processes = processes\n\n        if security is None:\n            # Falsey values load the default configuration\n            security = Security()\n        elif security is True:\n            # True indicates self-signed temporary credentials should be used\n            security = Security.temporary()\n        elif not isinstance(security, Security):\n            raise TypeError(\"security must be a Security object\")\n\n        if protocol is None:\n            if host and \"://\" in host:\n                protocol = host.split(\"://\")[0]\n            elif security and security.require_encryption:\n                protocol = \"tls://\"\n            elif not self.processes and not scheduler_port:\n                protocol = \"inproc://\"\n            else:\n                protocol = \"tcp://\"\n        if not protocol.endswith(\"://\"):\n            protocol = protocol + \"://\"\n\n        if host is None and not protocol.startswith(\"inproc\") and not interface:\n            host = \"127.0.0.1\"\n\n        services = services or {}\n        worker_services = worker_services or {}\n        if n_workers is None and threads_per_worker is None:\n            if processes:\n                n_workers, threads_per_worker = nprocesses_nthreads()\n            else:\n                n_workers = 1\n                threads_per_worker = CPU_COUNT\n        if n_workers is None and threads_per_worker is not None:\n            n_workers = max(1, CPU_COUNT // threads_per_worker) if processes else 1\n        if n_workers and threads_per_worker is None:\n            # Overcommit threads per worker, rather than undercommit\n            threads_per_worker = max(1, int(math.ceil(CPU_COUNT / n_workers)))\n        if n_workers and \"memory_limit\" not in worker_kwargs:\n            worker_kwargs[\"memory_limit\"] = parse_memory_limit(\"auto\", 1, n_workers)\n\n        worker_kwargs.update(\n            {\n                \"host\": host,\n                \"nthreads\": threads_per_worker,\n                \"services\": worker_services,\n                \"dashboard_address\": worker_dashboard_address,\n                \"dashboard\": worker_dashboard_address is not None,\n                \"interface\": interface,\n                \"protocol\": protocol,\n                \"security\": security,\n                \"silence_logs\": silence_logs,\n            }\n        )\n\n        scheduler = {\n            \"cls\": Scheduler,\n            \"options\": toolz.merge(\n                dict(\n                    host=host,\n                    services=services,\n                    service_kwargs=service_kwargs,\n                    security=security,\n                    port=scheduler_port,\n                    interface=interface,\n                    protocol=protocol,\n                    dashboard=dashboard_address is not None,\n                    dashboard_address=dashboard_address,\n                    blocked_handlers=blocked_handlers,\n                ),\n                scheduler_kwargs or {},\n            ),\n        }\n\n        worker = {\"cls\": worker_class, \"options\": worker_kwargs}\n        workers = {i: worker for i in range(n_workers)}\n\n        super().__init__(\n            name=name,\n            scheduler=scheduler,\n            workers=workers,\n            worker=worker,\n            loop=loop,\n            asynchronous=asynchronous,\n            silence_logs=silence_logs,\n            security=security,\n            scheduler_sync_interval=scheduler_sync_interval,\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices_tensor = ctx->input(0);\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(indices_tensor.shape()) ||\n                    TensorShapeUtils::IsScalar(indices_tensor.shape()),\n                errors::InvalidArgument(\n                    \"The indices can only be scalar or vector, got \\\"\",\n                    indices_tensor.shape().DebugString(), \"\\\"\"));\n\n    const Tensor& dims_tensor = ctx->input(1);\n    OP_REQUIRES(\n        ctx, TensorShapeUtils::IsVector(dims_tensor.shape()),\n        errors::InvalidArgument(\"The indices can only be 1-D, got \\\"\",\n                                dims_tensor.shape().DebugString(), \"\\\"\"));\n\n    auto dims = dims_tensor.vec<Tidx>();\n    // Make sure dims does not contain a zero\n    for (int i = 0; i < dims.size(); i++) {\n      OP_REQUIRES(\n          ctx, dims(i) != 0,\n          errors::InvalidArgument(\"Input dims cannot contain a dim of zero, \"\n                                  \"but dims contains zero at index \",\n                                  i));\n    }\n\n    // Chek to make sure indices is not out of boundary\n    Eigen::Tensor<Tidx, 0, Eigen::RowMajor> dims_prod_eigen = dims.prod();\n    Tidx dims_prod = dims_prod_eigen();\n    const Tidx* indices = indices_tensor.flat<Tidx>().data();\n    int64 size = indices_tensor.NumElements();\n    bool check = std::all_of(indices, indices + size,\n                             [&](Tidx index) { return index < dims_prod; });\n    OP_REQUIRES(ctx, check,\n                errors::InvalidArgument(\"index is out of bound as with dims\"));\n\n    Eigen::array<bool, 1> reverse({true});\n\n    Tensor strides_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_tensor));\n\n    auto strides = strides_tensor.vec<Tidx>();\n    strides = dims.reverse(reverse)\n                  .scan(0, Eigen::internal::ProdReducer<Tidx>(), false)\n                  .reverse(reverse);\n\n    Tensor strides_shifted_tensor;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_temp(DataTypeToEnum<Tidx>::value,\n                                      TensorShape({dims_tensor.NumElements()}),\n                                      &strides_shifted_tensor));\n\n    auto strides_shifted = strides_shifted_tensor.vec<Tidx>();\n    strides_shifted = dims.reverse(reverse)\n                          .scan(0, Eigen::internal::ProdReducer<Tidx>(), true)\n                          .reverse(reverse);\n\n    Tensor* output_tensor = nullptr;\n    if (TensorShapeUtils::IsScalar(indices_tensor.shape())) {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({dims_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->vec<Tidx>();\n\n      output = output.constant(indices_tensor.scalar<Tidx>()());\n      output = output.binaryExpr(strides, mod_op<Tidx>()) / strides_shifted;\n    } else {\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0,\n                                    TensorShape({dims_tensor.NumElements(),\n                                                 indices_tensor.NumElements()}),\n                                    &output_tensor));\n\n      auto output = output_tensor->matrix<Tidx>();\n\n      Eigen::array<Eigen::Index, 2> reshape{\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1}};\n      Eigen::array<Eigen::Index, 2> bcast(\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())});\n      Eigen::array<Eigen::Index, 2> indices_reshape{\n          {1, static_cast<Eigen::Index>(indices_tensor.NumElements())}};\n      Eigen::array<Eigen::Index, 2> indices_bcast(\n          {static_cast<Eigen::Index>(dims_tensor.NumElements()), 1});\n\n      output = indices_tensor.vec<Tidx>()\n                   .reshape(indices_reshape)\n                   .broadcast(indices_bcast);\n      output = output.binaryExpr(strides.reshape(reshape).broadcast(bcast),\n                                 mod_op<Tidx>()) /\n               strides_shifted.reshape(reshape).broadcast(bcast);\n    }\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_valid_filename(name):\n    \"\"\"\n    Return the given string converted to a string that can be used for a clean\n    filename. Remove leading and trailing spaces; convert other spaces to\n    underscores; and remove anything that is not an alphanumeric, dash,\n    underscore, or dot.\n    >>> get_valid_filename(\"john's portrait in 2004.jpg\")\n    'johns_portrait_in_2004.jpg'\n    \"\"\"\n    s = str(name).strip().replace(' ', '_')\n    s = re.sub(r'(?u)[^-\\w.]', '', s)\n    if s in {'', '.', '..'}:\n        raise SuspiciousFileOperation(\"Could not derive file name from '%s'\" % name)\n    return s\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Ensure the saved path is always relative to the storage root.\n        name = os.path.relpath(full_path, self.location)\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_password(password, encoded, setter=None, preferred='default'):\n    \"\"\"\n    Returns a boolean of whether the raw password matches the three\n    part encoded digest.\n\n    If setter is specified, it'll be called when you need to\n    regenerate the password.\n    \"\"\"\n    if password is None or not is_password_usable(encoded):\n        return False\n\n    preferred = get_hasher(preferred)\n    hasher = identify_hasher(encoded)\n\n    hasher_changed = hasher.algorithm != preferred.algorithm\n    must_update = hasher_changed or preferred.must_update(encoded)\n    is_correct = hasher.verify(password, encoded)\n\n    # If the hasher didn't change (we don't protect against enumeration if it\n    # does) and the password should get updated, try to close the timing gap\n    # between the work factor of the current encoded password and the default\n    # work factor.\n    if not is_correct and not hasher_changed and must_update:\n        hasher.harden_runtime(password, encoded)\n\n    if setter and is_correct and must_update:\n        setter(password)\n    return is_correct\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    /* Don't do any checks at all with an excessively large modulus */\n    if (BN_num_bits(dh->params.p) > OPENSSL_DH_CHECK_MAX_MODULUS_BITS) {\n        ERR_raise(ERR_LIB_DH, DH_R_MODULUS_TOO_LARGE);\n        *ret = DH_MODULUS_TOO_LARGE | DH_CHECK_PUBKEY_INVALID;\n        return 0;\n    }\n\n    if (dh->params.q != NULL && BN_ucmp(dh->params.p, dh->params.q) < 0) {\n        *ret |= DH_CHECK_INVALID_Q_VALUE | DH_CHECK_PUBKEY_INVALID;\n        return 1;\n    }\n\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_html(self) -> str:\n        return safe_scrape_html(self.url)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse_header(self, header_plus):\n        \"\"\"\n        Parses the header_plus block of text (the headers plus the\n        first line of the request).\n        \"\"\"\n        index = header_plus.find(b\"\\r\\n\")\n        if index >= 0:\n            first_line = header_plus[:index].rstrip()\n            header = header_plus[index + 2 :]\n        else:\n            raise ParsingError(\"HTTP message header invalid\")\n\n        if b\"\\r\" in first_line or b\"\\n\" in first_line:\n            raise ParsingError(\"Bare CR or LF found in HTTP message\")\n\n        self.first_line = first_line  # for testing\n\n        lines = get_header_lines(header)\n\n        headers = self.headers\n        for line in lines:\n            header = HEADER_FIELD.match(line)\n\n            if not header:\n                raise ParsingError(\"Invalid header\")\n\n            key, value = header.group(\"name\", \"value\")\n\n            if b\"_\" in key:\n                # TODO(xistence): Should we drop this request instead?\n                continue\n\n            # Only strip off whitespace that is considered valid whitespace by\n            # RFC7230, don't strip the rest\n            value = value.strip(b\" \\t\")\n            key1 = tostr(key.upper().replace(b\"-\", b\"_\"))\n            # If a header already exists, we append subsequent values\n            # seperated by a comma. Applications already need to handle\n            # the comma seperated values, as HTTP front ends might do\n            # the concatenation for you (behavior specified in RFC2616).\n            try:\n                headers[key1] += tostr(b\", \" + value)\n            except KeyError:\n                headers[key1] = tostr(value)\n\n        # command, uri, version will be bytes\n        command, uri, version = crack_first_line(first_line)\n        version = tostr(version)\n        command = tostr(command)\n        self.command = command\n        self.version = version\n        (\n            self.proxy_scheme,\n            self.proxy_netloc,\n            self.path,\n            self.query,\n            self.fragment,\n        ) = split_uri(uri)\n        self.url_scheme = self.adj.url_scheme\n        connection = headers.get(\"CONNECTION\", \"\")\n\n        if version == \"1.0\":\n            if connection.lower() != \"keep-alive\":\n                self.connection_close = True\n\n        if version == \"1.1\":\n            # since the server buffers data from chunked transfers and clients\n            # never need to deal with chunked requests, downstream clients\n            # should not see the HTTP_TRANSFER_ENCODING header; we pop it\n            # here\n            te = headers.pop(\"TRANSFER_ENCODING\", \"\")\n\n            # NB: We can not just call bare strip() here because it will also\n            # remove other non-printable characters that we explicitly do not\n            # want removed so that if someone attempts to smuggle a request\n            # with these characters we don't fall prey to it.\n            #\n            # For example \\x85 is stripped by default, but it is not considered\n            # valid whitespace to be stripped by RFC7230.\n            encodings = [\n                encoding.strip(\" \\t\").lower() for encoding in te.split(\",\") if encoding\n            ]\n\n            for encoding in encodings:\n                # Out of the transfer-codings listed in\n                # https://tools.ietf.org/html/rfc7230#section-4 we only support\n                # chunked at this time.\n\n                # Note: the identity transfer-coding was removed in RFC7230:\n                # https://tools.ietf.org/html/rfc7230#appendix-A.2 and is thus\n                # not supported\n                if encoding not in {\"chunked\"}:\n                    raise TransferEncodingNotImplemented(\n                        \"Transfer-Encoding requested is not supported.\"\n                    )\n\n            if encodings and encodings[-1] == \"chunked\":\n                self.chunked = True\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = ChunkedReceiver(buf)\n            elif encodings:  # pragma: nocover\n                raise TransferEncodingNotImplemented(\n                    \"Transfer-Encoding requested is not supported.\"\n                )\n\n            expect = headers.get(\"EXPECT\", \"\").lower()\n            self.expect_continue = expect == \"100-continue\"\n            if connection.lower() == \"close\":\n                self.connection_close = True\n\n        if not self.chunked:\n            try:\n                cl = int(headers.get(\"CONTENT_LENGTH\", 0))\n            except ValueError:\n                raise ParsingError(\"Content-Length is invalid\")\n\n            self.content_length = cl\n            if cl > 0:\n                buf = OverflowableBuffer(self.adj.inbuf_overflow)\n                self.body_rcv = FixedStreamReceiver(cl, buf)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_message(self, stream, payload):\n        try:\n            payload = self.decode_payload(payload)\n        except salt.exceptions.SaltDeserializationError:\n            self.stream.send(self.encode_payload({\"msg\": \"bad load\"}))\n            return\n        # XXX: Is header really needed?\n        reply = yield self.message_handler(payload)\n        self.stream.send(self.encode_payload(reply))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check(args: list[str]):\n    \"\"\"Run checker/linters on specified files or directories.\"\"\"\n    args2 = []\n    for arg in args:\n        if not Path(arg).exists():\n            typer.secho(f\"{arg} does not exist\", fg=typer.colors.RED)\n        else:\n            args2.append(arg)\n\n    args_str = \" \".join(args2)\n\n    run(f\"ruff {args_str}\")\n    run(f\"flake8 {args_str}\")\n    run(f\"mypy --show-error-codes {args_str}\")\n    run(\"pyright\")\n    run(\"vulture --min-confidence 80 .\")\n    run(\"deptry .\")\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "var Pagination = new function() {\n\n    this.init = function(processHash, document_containers, setHash) {\n\t\t// For each pagination node\n        var containers = new Array();\n\n        // Create new containers Array after each initialisation\n        // (init can be called several times, when the pagination is\n        // nested in a tabbed container.)\n\n        for (var i in document_containers)\n            $(document_containers[i]).find('.paginate-container').each(function() {\n                var container = $(this);\n                // Only execute once for each container.\n                // (remember that init() may be called multiple times,\n                // also after content was dynamically changed, because\n                // paginators could be added on the fly.)\n                if (! container.hasClass('paginate-container-initialized'))\n                {\n                    container.addClass('paginate-container-initialized');\n                    containers.push(container);\n                    set_up(container);\n                }\n            });\n\n\t\t// Make setHash = true the default\n        if (setHash == undefined)\n            setHash = true;\n\n        function scroll(hash) {\n            var target = $('[id=' + hash + ']');\n            if (target.length) {\n                  var offset = target.offset().top;\n                  $('html,body').animate({scrollTop: offset}, 350);\n            }\n        }\n\n        function set_up(container) {\n            // Find prev/next links\n            var prev = container.find('.pagination .prev');\n            var next = container.find('.pagination .next');\n\n            var prev_url = null, next_url = null;\n\n            if (prev.length)\n                prev_url = prev.attr('href');\n            if (next.length)\n                next_url = next.attr('href');\n\n            function ajax(url, handler) {\n                // URL should start with a slash, but cannot start with two slashes.\n\t\t// we cannot start with \"/\\\". Modern browsers handle backslashes as normal slashes.\n                // (Otherwise we have an XSS vulnerability.)\n                if (url[0] != '/' || url[1] == '/' || url.startsWith(\"/\\\\\")\n                    url = (''+location).replace( /[#\\?].*/, '') + url;\n\n                // Append 'xhr' to make sure all content is loaded.\n                if (url.indexOf('&xhr') < 0 && url.indexOf('?xhr') < 0)\n                    if (url.indexOf('?') < 0)\n                        url += '?xhr';\n                    else\n                        url += '&xhr';\n\n                $.ajax({\n                        type: 'GET',\n                        url: url,\n                        datatype: \"html\",\n                        cache: true,\n                        success: handler,\n                        error: function(xhr, ajaxOptions, thrownError) {\n                            handler($('<div/>').append(\n                                    $('<strong>').append(''+xhr.status + ' ' + thrownError)).html());\n                        }\n                });\n            }\n\n            function showLoader() {\n                var loader = $('.paginate-loading').eq(0);\n\n                for (var i in containers)\n                {\n                    // Keep containers height\n                    var height = containers[i].height();\n                    if (height < 50) height = 50;\n                    containers[i].css('height', height + 'px');\n\n                    // Show loader\n                    containers[i].empty();\n                    containers[i].append(loader.html());\n                }\n            }\n\n            // Replace page AJAX handler\n            function replacePage(url, receivedHtml) {\n\t\t\t\t// Set location hash\n\t\t\t\tif (setHash)\n\t\t\t\t\tlocation.hash = 'page:' + url;\n\n\n                for (var i in containers) {\n\t\t\t\t\t// Empty the paginate nodes\n                    containers[i].empty();\n                    containers[i].css('height', '');\n\n                    // Fill the paginate containers with the new content\n                    receivedHtml = $.trim(receivedHtml);\n                    $(receivedHtml).find('.paginate-container').eq(i).each(function() {\n                        containers[i].append($(this).html());\n                        set_up(containers[i]);\n                    });\n                }\n\n                // Trigger event (Only add trigger to $(document) )\n                $(document).trigger('paginatorPageReplaced', [ containers ]);\n\n                // When the URL contains a hash, scroll to that element\n                if (location.hash.substr(1).indexOf('#') > 0) {\n                    var hash = (''+location.hash).replace( /.*#/, '');\n                    scroll(hash);\n                }\n                // Otherwise, make sure that the top of the clicked paginator is visible\n                else {\n                    var paginatorTop = container.offset().top;\n\n                    if (paginatorTop < $(window).scrollTop() || paginatorTop > $(window).scrollTop() + $(window).height()) {\n                        $('html,body').animate({scrollTop: paginatorTop}, 350);\n                    }\n                }\n            }\n\n            // Process hash (link with # opened from bookmark)\n            if (processHash && location.hash.match( /^#page/)) {\n                var url = location.hash.replace( /^#page:/, '');\n                container.empty();\n                ajax(url, function(html) { replacePage(url,html); });\n            }\n            processHash = false; // Never process twice. (set_up is called recursively)\n\n            // Preload previous page\n            var previousPageHtml = null;\n            var nextPageHtml = null;\n            var clickedPrevious = false;\n            var clickedNext = false;\n\n            var preload = $('.pagination_preload').size() > 0;\n\n            if (preload) {\n\t\t\t\tif (prev_url)\n                    ajax(prev_url, function(html) {\n                        previousPageHtml = html;\n                        if (clickedPrevious) replacePage(prev_url, html);\n                    });\n                if (next_url)\n                    ajax(next_url, function(html) {\n                        nextPageHtml = html;\n                        if (clickedNext) replacePage(next_url, html);\n                    });\n\n                // Handle clicks on the prev/next buttons.\n                prev.click(function() {\n                    showLoader();\n                    if (previousPageHtml)\n                        replacePage(prev_url, previousPageHtml);\n                    else\n                        clickedPrevious = true;\n                    return false;\n                });\n\n                next.click(function() {\n                    showLoader();\n                    if (nextPageHtml)\n                        replacePage(next_url, nextPageHtml);\n                    else\n                        clickedNext = true;\n                    return false;\n                });\n            }\n\n            // The digg-paginator also contains direct links to other pages\n            // then only the prev and next page.\n            container.find('.pagination a, .pagination-helper a, a.pagination-helper').each(function() {\n\n                $(this).click(function (){\n                \tvar url = $(this).attr('href');\n                    showLoader();\n\n                    if (url[0] == '#') {\n                        var hash = url.replace( /#/, '');\n                        scroll(hash);\n                    }\n                    else\n                        ajax(url, function(html) {\n\t\t\t\t\t\t\treplacePage(url, html);\n                        });\n                    return false;\n                });\n            });\n\n            // Pagination forms are forms for which the result is displayed in the paginator\n            // They always have method=\"get\" and action=\"?\"\n            container.find('form.pagination-form').each(function() {\n                var form = $(this);\n                if (form.attr('method') == 'get' && form.attr('action').match(/.*?/)) {\n                    // Submit handler\n                    form.submit(function() {\n                        // Build submit query string\n                        var url = form.attr('action') + form.serialize();\n\n                        // AJAX request\n                        ajax(url, function(html) {\n                            replacePage(url, html);\n                        });\n                        return false;\n                    });\n                }\n            });\n        }\n    };\n};\n\n\n(function() {\n    Pagination.init(true, [ $(document) ]);\n\n    // When a XHR block has been loaded, call init() again,\n    // because it may contain a paginator.\n        // The location may have been filled with the tab url, so\n        // don't process it. (xhr can be nested inside tabs, so even in that case.\n    $(document).bind('xhrLoaded', function(e, containers) { Pagination.init(false, containers); });\n    $(document).bind('tabLoaded', function(e, containers) { Pagination.init(false, containers); });\n}) ();\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def do_template(self, data, preserve_trailing_newlines=True, escape_backslashes=True, fail_on_undefined=None, overrides=None, disable_lookups=False):\n        if self.jinja2_native and not isinstance(data, string_types):\n            return data\n\n        # For preserving the number of input newlines in the output (used\n        # later in this method)\n        data_newlines = _count_newlines_from_end(data)\n\n        if fail_on_undefined is None:\n            fail_on_undefined = self._fail_on_undefined_errors\n\n        try:\n            # allows template header overrides to change jinja2 options.\n            if overrides is None:\n                myenv = self.environment\n            else:\n                myenv = self.environment.overlay(overrides)\n\n            # Get jinja env overrides from template\n            if hasattr(data, 'startswith') and data.startswith(JINJA2_OVERRIDE):\n                eol = data.find('\\n')\n                line = data[len(JINJA2_OVERRIDE):eol]\n                data = data[eol + 1:]\n                for pair in line.split(','):\n                    (key, val) = pair.split(':')\n                    key = key.strip()\n                    setattr(myenv, key, ast.literal_eval(val.strip()))\n\n            if escape_backslashes:\n                # Allow users to specify backslashes in playbooks as \"\\\\\" instead of as \"\\\\\\\\\".\n                data = _escape_backslashes(data, myenv)\n\n            try:\n                t = myenv.from_string(data)\n            except TemplateSyntaxError as e:\n                raise AnsibleError(\"template error while templating string: %s. String: %s\" % (to_native(e), to_native(data)))\n            except Exception as e:\n                if 'recursion' in to_native(e):\n                    raise AnsibleError(\"recursive loop detected in template string: %s\" % to_native(data))\n                else:\n                    return data\n\n            if disable_lookups:\n                t.globals['query'] = t.globals['q'] = t.globals['lookup'] = self._fail_lookup\n\n            jvars = AnsibleJ2Vars(self, t.globals)\n\n            self.cur_context = new_context = t.new_context(jvars, shared=True)\n            rf = t.root_render_func(new_context)\n\n            try:\n                if self.jinja2_native:\n                    res = ansible_native_concat(rf)\n                else:\n                    res = j2_concat(rf)\n                unsafe = getattr(new_context, 'unsafe', False)\n                if unsafe:\n                    res = wrap_var(res)\n            except TypeError as te:\n                if 'AnsibleUndefined' in to_native(te):\n                    errmsg = \"Unable to look up a name or access an attribute in template string (%s).\\n\" % to_native(data)\n                    errmsg += \"Make sure your variable name does not contain invalid characters like '-': %s\" % to_native(te)\n                    raise AnsibleUndefinedVariable(errmsg)\n                else:\n                    display.debug(\"failing because of a type error, template data is: %s\" % to_text(data))\n                    raise AnsibleError(\"Unexpected templating type error occurred on (%s): %s\" % (to_native(data), to_native(te)))\n\n            if self.jinja2_native and not isinstance(res, string_types):\n                return res\n\n            if preserve_trailing_newlines:\n                # The low level calls above do not preserve the newline\n                # characters at the end of the input data, so we use the\n                # calculate the difference in newlines and append them\n                # to the resulting output for parity\n                #\n                # jinja2 added a keep_trailing_newline option in 2.7 when\n                # creating an Environment.  That would let us make this code\n                # better (remove a single newline if\n                # preserve_trailing_newlines is False).  Once we can depend on\n                # that version being present, modify our code to set that when\n                # initializing self.environment and remove a single trailing\n                # newline here if preserve_newlines is False.\n                res_newlines = _count_newlines_from_end(res)\n                if data_newlines > res_newlines:\n                    res += self.environment.newline_sequence * (data_newlines - res_newlines)\n                    if unsafe:\n                        res = wrap_var(res)\n            return res\n        except (UndefinedError, AnsibleUndefinedVariable) as e:\n            if fail_on_undefined:\n                raise AnsibleUndefinedVariable(e)\n            else:\n                display.debug(\"Ignoring undefined failure: %s\" % to_text(e))\n                return data\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        name = self._save(name, content)\n        # Ensure that the name returned from the storage system is still valid.\n        validate_file_name(name, allow_relative_path=True)\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def render_markdown(value):\n    \"\"\"\n    Render text as Markdown\n\n    Example:\n        {{ text | render_markdown }}\n    \"\"\"\n    # Render Markdown\n    html = markdown(value, extensions=[\"fenced_code\", \"tables\"])\n\n    # Sanitize rendered HTML\n    html = nautobot_logging.clean_html(html)\n\n    return mark_safe(html)  # noqa: S308  # suspicious-mark-safe-usage, OK here since we sanitized the string earlier\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def deny_uploads_containing_script_tag(uploaded_file):\n    for chunk in uploaded_file.chunks(2048):\n        if chunk.lower().find(b\"<script\") > -1:\n            raise ValidationError(_(\"File contains forbidden <script> tag\"))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_initial_logout(self, user):\n        \"\"\"\n        Get the initial logout request.\n\n        Return None if no sessions in INIT_LOGOUT state.\n        \"\"\"\n        candidates = self._ss.get_user_sessions(user)\n\n        # FIXME: what does it mean if there are multiple in init? We\n        #        just return the first one for now. How do we know\n        #        it's the \"right\" one if multiple logouts are started\n        #        at the same time from different SPs?\n        for c in candidates:\n            key = c.keys()[0]\n            if int(c[key].get('logoutstate', 0)) == INIT_LOGOUT:\n                samlsession = self._data_to_samlsession(key, c[key])\n                return samlsession\n        return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decrypt(self, ciphertext):\n        \"\"\"Decrypt a message with PKCS#1 OAEP.\n\n        :param ciphertext: The encrypted message.\n        :type ciphertext: bytes/bytearray/memoryview\n\n        :returns: The original message (plaintext).\n        :rtype: bytes\n\n        :raises ValueError:\n            if the ciphertext has the wrong length, or if decryption\n            fails the integrity check (in which case, the decryption\n            key is probably wrong).\n        :raises TypeError:\n            if the RSA key has no private half (i.e. you are trying\n            to decrypt using a public key).\n        \"\"\"\n\n        # See 7.1.2 in RFC3447\n        modBits = Crypto.Util.number.size(self._key.n)\n        k = ceil_div(modBits, 8)            # Convert from bits to bytes\n        hLen = self._hashObj.digest_size\n\n        # Step 1b and 1c\n        if len(ciphertext) != k or k < hLen+2:\n            raise ValueError(\"Ciphertext with incorrect length.\")\n        # Step 2a (O2SIP)\n        ct_int = bytes_to_long(ciphertext)\n        # Step 2b (RSADP) and step 2c (I2OSP)\n        em = self._key._decrypt_to_bytes(ct_int)\n        # Step 3a\n        lHash = self._hashObj.new(self._label).digest()\n        # y must be 0, but we MUST NOT check it here in order not to\n        # allow attacks like Manger's (http://dl.acm.org/citation.cfm?id=704143)\n        maskedSeed = em[1:hLen+1]\n        maskedDB = em[hLen+1:]\n        # Step 3c\n        seedMask = self._mgf(maskedDB, hLen)\n        # Step 3d\n        seed = strxor(maskedSeed, seedMask)\n        # Step 3e\n        dbMask = self._mgf(seed, k-hLen-1)\n        # Step 3f\n        db = strxor(maskedDB, dbMask)\n        # Step 3b + 3g\n        res = oaep_decode(em, lHash, db)\n        if res <= 0:\n            raise ValueError(\"Incorrect decryption.\")\n        # Step 4\n        return db[res:]\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def on_send_leave_request(self, origin, pdu):\n        \"\"\" We have received a leave event for a room. Fully process it.\"\"\"\n        event = pdu\n\n        logger.debug(\n            \"on_send_leave_request: Got event: %s, signatures: %s\",\n            event.event_id,\n            event.signatures,\n        )\n\n        if get_domain_from_id(event.sender) != origin:\n            logger.info(\n                \"Got /send_leave request for user %r from different origin %s\",\n                event.sender,\n                origin,\n            )\n            raise SynapseError(403, \"User not from origin\", Codes.FORBIDDEN)\n\n        event.internal_metadata.outlier = False\n\n        context = yield self._handle_new_event(origin, event)\n\n        event_allowed = yield self.third_party_event_rules.check_event_allowed(\n            event, context\n        )\n        if not event_allowed:\n            logger.info(\"Sending of leave %s forbidden by third-party rules\", event)\n            raise SynapseError(\n                403, \"This event is not allowed in this context\", Codes.FORBIDDEN\n            )\n\n        logger.debug(\n            \"on_send_leave_request: After _handle_new_event: %s, sigs: %s\",\n            event.event_id,\n            event.signatures,\n        )\n\n        return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    /* Don't do any checks at all with an excessively large modulus */\n    if (BN_num_bits(dh->params.p) > OPENSSL_DH_CHECK_MAX_MODULUS_BITS) {\n        ERR_raise(ERR_LIB_DH, DH_R_MODULUS_TOO_LARGE);\n        *ret = DH_MODULUS_TOO_LARGE | DH_CHECK_PUBKEY_INVALID;\n        return 0;\n    }\n\n    if (dh->params.q != NULL && BN_ucmp(dh->params.p, dh->params.q) < 0) {\n        *ret |= DH_CHECK_INVALID_Q_VALUE | DH_CHECK_PUBKEY_INVALID;\n        return 1;\n    }\n\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def update_user_tenant(self, context, user_id, user):\n        \"\"\"Update the default tenant.\"\"\"\n        self.assert_admin(context)\n        # ensure that we're a member of that tenant\n        tenant_id = user.get('tenantId')\n        self.identity_api.add_user_to_tenant(context, tenant_id, user_id)\n        return self.update_user(context, user_id, user)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  // Check that `fs`, `env` and `results` are non-null.\n  if (fs == nullptr || env == nullptr || results == nullptr) {\n    return Status(tensorflow::error::INVALID_ARGUMENT,\n                  \"Filesystem calls GetMatchingPaths with nullptr arguments\");\n  }\n\n  // By design, we don't match anything on empty pattern\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  // The pattern can contain globbing characters at multiple levels, e.g.:\n  //\n  //   foo/ba?/baz/f*r\n  //\n  // To match the full pattern, we must match every prefix subpattern and then\n  // operate on the children for each match. Thus, we separate all subpatterns\n  // in the `dirs` vector below.\n  std::vector<std::string> dirs = AllDirectoryPrefixes(pattern);\n\n  // We can have patterns that have several parents where no globbing is being\n  // done, for example, `foo/bar/baz/*`. We don't need to expand the directories\n  // which don't contain the globbing characters.\n  int matching_index = GetFirstGlobbingEntry(dirs);\n\n  // If we don't have globbing characters in the pattern then it specifies a\n  // path in the filesystem. We add it to the result set if it exists.\n  if (matching_index == dirs.size()) {\n    if (fs->FileExists(pattern).ok()) {\n      results->emplace_back(pattern);\n    }\n    return Status::OK();\n  }\n\n  // To expand the globbing, we do a BFS from `dirs[matching_index-1]`.\n  // At every step, we work on a pair `{dir, ix}` such that `dir` is a real\n  // directory, `ix < dirs.size() - 1` and `dirs[ix+1]` is a globbing pattern.\n  // To expand the pattern, we select from all the children of `dir` only those\n  // that match against `dirs[ix+1]`.\n  // If there are more entries in `dirs` after `dirs[ix+1]` this mean we have\n  // more patterns to match. So, we add to the queue only those children that\n  // are also directories, paired with `ix+1`.\n  // If there are no more entries in `dirs`, we return all children as part of\n  // the answer.\n  // Since we can get into a combinatorial explosion issue (e.g., pattern\n  // `/*/*/*`), we process the queue in parallel. Each parallel processing takes\n  // elements from `expand_queue` and adds them to `next_expand_queue`, after\n  // which we swap these two queues (similar to double buffering algorithms).\n  // PRECONDITION: `IsGlobbingPattern(dirs[0]) == false`\n  // PRECONDITION: `matching_index > 0`\n  // INVARIANT: If `{d, ix}` is in queue, then `d` and `dirs[ix]` are at the\n  //            same level in the filesystem tree.\n  // INVARIANT: If `{d, _}` is in queue, then `IsGlobbingPattern(d) == false`.\n  // INVARIANT: If `{d, _}` is in queue, then `d` is a real directory.\n  // INVARIANT: If `{_, ix}` is in queue, then `ix < dirs.size() - 1`.\n  // INVARIANT: If `{_, ix}` is in queue, `IsGlobbingPattern(dirs[ix + 1])`.\n  std::deque<std::pair<string, int>> expand_queue;\n  std::deque<std::pair<string, int>> next_expand_queue;\n  expand_queue.emplace_back(dirs[matching_index - 1], matching_index - 1);\n\n  // Adding to `result` or `new_expand_queue` need to be protected by mutexes\n  // since there are multiple threads writing to these.\n  mutex result_mutex;\n  mutex queue_mutex;\n\n  while (!expand_queue.empty()) {\n    next_expand_queue.clear();\n\n    // The work item for every item in `expand_queue`.\n    // pattern, we process them in parallel.\n    auto handle_level = [&fs, &results, &dirs, &expand_queue,\n                         &next_expand_queue, &result_mutex,\n                         &queue_mutex](int i) {\n      // See invariants above, all of these are valid accesses.\n      const auto& queue_item = expand_queue.at(i);\n      const std::string& parent = queue_item.first;\n      const int index = queue_item.second + 1;\n      const std::string& match_pattern = dirs[index];\n\n      // Get all children of `parent`. If this fails, return early.\n      std::vector<std::string> children;\n      Status s = fs->GetChildren(parent, &children);\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n\n      // Also return early if we don't have any children\n      if (children.empty()) {\n        return;\n      }\n\n      // Since we can get extremely many children here and on some filesystems\n      // `IsDirectory` is expensive, we process the children in parallel.\n      // We also check that children match the pattern in parallel, for speedup.\n      // We store the status of the match and `IsDirectory` in\n      // `children_status` array, one element for each children.\n      std::vector<Status> children_status(children.size());\n      auto handle_children = [&fs, &match_pattern, &parent, &children,\n                              &children_status](int j) {\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (!fs->Match(path, match_pattern)) {\n          children_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else {\n          children_status[j] = fs->IsDirectory(path);\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      // At this point, pairing `children` with `children_status` will tell us\n      // if a children:\n      //   * does not match the pattern\n      //   * matches the pattern and is a directory\n      //   * matches the pattern and is not a directory\n      // We fully ignore the first case.\n      // If we matched the last pattern (`index == dirs.size() - 1`) then all\n      // remaining children get added to the result.\n      // Otherwise, only the directories get added to the next queue.\n      for (size_t j = 0; j < children.size(); j++) {\n        if (children_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (index == dirs.size() - 1) {\n          mutex_lock l(result_mutex);\n          results->emplace_back(path);\n        } else if (children_status[j].ok()) {\n          mutex_lock l(queue_mutex);\n          next_expand_queue.emplace_back(path, index);\n        }\n      }\n    };\n    ForEach(0, expand_queue.size(), handle_level);\n\n    // After evaluating one level, swap the \"buffers\"\n    std::swap(expand_queue, next_expand_queue);\n  }\n\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def create_code_for_user(cls, user, next=None):\n        if not user.is_active:\n            return None\n\n        login_code = LoginCode(user=user)\n        if next is not None:\n            login_code.next = next\n        login_code.save()\n        return login_code\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeEasyCases(OpKernelContext* context, bool* done,\n                        std::vector<Tlen>* split_sizes_vec) {\n    const int32_t num_split = context->num_outputs();\n    const Tensor& input = context->input(0);\n    const TensorShape& input_shape = input.shape();\n    const Tensor& split_tensor = context->input(1);\n    const Tensor& split_dim_tensor = context->input(2);\n\n    OP_REQUIRES(context, split_dim_tensor.NumElements() == 1,\n                errors::InvalidArgument(\"split_dim_tensor must have \"\n                                        \"exactly one element.\"));\n\n    const int32_t split_dim_orig = split_dim_tensor.flat<int32>()(0);\n    const int32_t split_dim =\n        split_dim_orig < 0 ? split_dim_orig + input.dims() : split_dim_orig;\n\n    OP_REQUIRES(\n        context,\n        split_tensor.dims() == 1 && split_tensor.NumElements() == num_split,\n        errors::InvalidArgument(\"size of the split_tensor must be 1-D and have \"\n                                \"the same elements as outputs got \",\n                                split_tensor.dims(), \" -D and \",\n                                split_tensor.NumElements(), \" elements\"));\n\n    auto split_sizes_d = split_tensor.vec<Tlen>();\n\n    split_sizes_vec->resize(split_sizes_d.size());\n\n    std::copy(split_sizes_d.data(), split_sizes_d.data() + split_sizes_d.size(),\n              split_sizes_vec->begin());\n\n    OP_REQUIRES(\n        context, num_split > 0,\n        errors::InvalidArgument(\n            \"Number of ways to split should be > 0, but got \", num_split));\n\n    OP_REQUIRES(\n        context, 0 <= split_dim && split_dim < input.dims(),\n        errors::InvalidArgument(\"-input rank(-\", input.dims(),\n                                \") <= split_dim < input rank (\", input.dims(),\n                                \"), but got \", split_dim_orig));\n\n    Tlen input_size_split_dim = input_shape.dim_size(split_dim);\n\n    // Special case 1: num_split == 1. Nothing to do.\n    if (num_split == 1) {\n      context->set_output(0, context->input(0));\n      OP_REQUIRES(\n          context, (*split_sizes_vec)[0] == input_size_split_dim,\n          errors::InvalidArgument(\"If there is only one output, it must have \"\n                                  \"the same size as the input. Input size: \",\n                                  input_size_split_dim,\n                                  \" output size: \", (*split_sizes_vec)[0]));\n      *done = true;\n      return;\n    }\n\n    // Determine sizes of output, in case of a -1 input value\n    int neg_one_dim = -1;\n    Tlen determined_size = 0;\n    for (int d = 0; d < split_sizes_vec->size(); ++d) {\n      Tlen size = (*split_sizes_vec)[d];\n\n      if (size == -1) {\n        OP_REQUIRES(context, neg_one_dim == -1,\n                    errors::InvalidArgument(\"There can only be one -1 in the \"\n                                            \"input.\"));\n        neg_one_dim = d;\n      } else {\n        determined_size += size;\n      }\n    }\n\n    OP_REQUIRES(\n        context,\n        (neg_one_dim == -1 && determined_size == input_size_split_dim) ||\n            (neg_one_dim >= 0 && determined_size <= input_size_split_dim),\n        errors::InvalidArgument(\"Determined shape must either match \"\n                                \"input shape along split_dim exactly if \"\n                                \"fully specified, or be less than the size of \"\n                                \"the input along split_dim if not fully \"\n                                \"specified.  Got: \",\n                                determined_size));\n\n    if (neg_one_dim >= 0) {\n      (*split_sizes_vec)[neg_one_dim] = input_size_split_dim - determined_size;\n    }\n\n    for (int i = 0; i < split_sizes_vec->size(); ++i) {\n      const Tlen& split_size = (*split_sizes_vec)[i];\n      OP_REQUIRES(context, split_size >= Tlen(0),\n                  errors::InvalidArgument(\"Split size at index \", i,\n                                          \" must be >= 0. Got: \", split_size));\n    }\n\n    // Special case 2: split along the 1st dimension. The requirements are that\n    // either we are splitting the outer dimension of two or more such that\n    // every outer subpart is aligned or that the split sizes mean that they are\n    // always aligned. In these cases, we can share the underlying buffer.\n    //\n    // Apply this optimization conservatively: if input is aligned,\n    // the resulting tensors must be aligned. It's conservative\n    // because if the immediate consumer of the resulting tensors are\n    // not using eigen for computation, its perfectly fine to avoid\n    // the copying.\n    if (SplitHasAlignedOutputsInFirstDimension(\n            input_shape, split_dim, absl::MakeConstSpan(*split_sizes_vec))) {\n      Tlen start = 0;\n      for (int i = 0; i < num_split; ++i) {\n        context->set_output(i,\n                            input.Slice(start, start + (*split_sizes_vec)[i]));\n        start += (*split_sizes_vec)[i];\n      }\n      *done = true;\n      return;\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def local_get_cobbler_xmlrpc_url():\n    # Load xmlrpc port\n    try:\n        fh = open(\"/etc/cobbler/settings\")\n        data = yaml.safe_load(fh.read())\n        fh.close()\n    except:\n       traceback.print_exc()\n       raise CX(\"/etc/cobbler/settings is not a valid YAML file\")\n    return \"http://%s:%s\" % (\"127.0.0.1\",data.get(\"xmlrpc_port\",\"25151\"))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def is_precalculated(self):\r\n        \"\"\"Return true if _call need not be invoked.\r\n\r\n        Returns:\r\n            True if the Task's target paths exist in the same state as the\r\n            last recorded run at the time this function is called. It is\r\n            possible this value could change without running the Task if\r\n            input parameter file stats change. False otherwise.\r\n\r\n        \"\"\"\r\n        # This gets a list of the files and their file stats that can be found\r\n        # in args and kwargs but ignores anything specifically targeted or\r\n        # an expected result. This will allow a task to change its hash in\r\n        # case a different version of a file was passed in.\r\n        if self._precalculated is not None:\r\n            return self._precalculated\r\n        file_stat_list = list(_get_file_stats(\r\n            [self._args, self._kwargs],\r\n            self._target_path_list+self._ignore_path_list,\r\n            self._ignore_directories))\r\n\r\n        # add the file stat list to the already existing reexecution info\r\n        # dictionary that contains stats that should not change whether\r\n        # files have been created/updated/or not.\r\n        self._reexecution_info['file_stat_list'] = pprint.pformat(\r\n            file_stat_list)\r\n        reexecution_string = '%s:%s' % (\r\n            self._task_id_hash, self._reexecution_info['file_stat_list'])\r\n        self._task_reexecution_hash = hashlib.sha1(\r\n            reexecution_string.encode('utf-8')).hexdigest()\r\n        try:\r\n            with self._task_database_lock:\r\n                with sqlite3.connect(self._task_database_path) as conn:\r\n                    cursor = conn.cursor()\r\n                    cursor.execute(\r\n                        \"\"\"\r\n                            SELECT data_blob from taskgraph_data\r\n                            WHERE (task_hash == ?)\r\n                        \"\"\", (self._task_reexecution_hash,))\r\n                    database_result = cursor.fetchone()\r\n            if database_result is None:\r\n                LOGGER.info(\r\n                    \"not precalculated, Task hash does not \"\r\n                    \"exist (%s)\", self.task_name)\r\n                LOGGER.debug(\"is_precalculated full task info: %s\", self)\r\n                self._precalculated = False\r\n                return False\r\n            if database_result:\r\n                result_target_path_stats = pickle.loads(database_result[0])\r\n            mismatched_target_file_list = []\r\n            for path, modified_time, size in result_target_path_stats:\r\n                if not os.path.exists(path):\r\n                    mismatched_target_file_list.append(\r\n                        'Path not found: %s' % path)\r\n                    continue\r\n                target_modified_time = os.path.getmtime(path)\r\n                if modified_time != target_modified_time:\r\n                    mismatched_target_file_list.append(\r\n                        \"Modified times don't match \"\r\n                        \"desired: (%s) target: (%s)\" % (\r\n                            modified_time, target_modified_time))\r\n                    continue\r\n                target_size = os.path.getsize(path)\r\n                if size != target_size:\r\n                    mismatched_target_file_list.append(\r\n                        \"File sizes don't match \"\r\n                        \"desired: (%s) target: (%s)\" % (\r\n                            size, target_size))\r\n            if mismatched_target_file_list:\r\n                LOGGER.warning(\r\n                    \"not precalculated (%s), Task hash exists, \"\r\n                    \"but there are these mismatches: %s\",\r\n                    self.task_name, '\\n'.join(mismatched_target_file_list))\r\n                self._precalculated = False\r\n                return False\r\n            LOGGER.info(\"precalculated (%s)\" % self.task_name)\r\n            self._precalculated = True\r\n            return True\r\n        except EOFError:\r\n            LOGGER.exception(\"not precalculated %s, EOFError\", self.task_name)\r\n            self._precalculated = False\r\n            return False\r\n\r"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& in0 = ctx->input(0);\n    const Tensor& in1 = ctx->input(1);\n    OP_REQUIRES(\n        ctx, in0.NumElements() == in1.NumElements(),\n        errors::InvalidArgument(\"The two arguments to a cwise op must have \"\n                                \"same number of elements, got \",\n                                in0.NumElements(), \" and \", in1.NumElements()));\n    auto in0_flat = in0.flat<Tin>();\n    auto in1_flat = in1.flat<Tin>();\n    const Device& eigen_device = ctx->eigen_device<Device>();\n\n    Tensor* out = nullptr;\n    if (std::is_same<Tin, Tout>::value) {\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0, 1}, 0, in0.shape(), &out));\n    } else {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, in0.shape(), &out));\n    }\n    auto out_flat = out->flat<Tout>();\n    functor::SimpleBinaryFunctor<Device, Functor>()(eigen_device, out_flat,\n                                                    in0_flat, in1_flat);\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def check_secret_key(self) -> None:\n        def log_default_secret_key_warning() -> None:\n            top_banner = 80 * \"-\" + \"\\n\" + 36 * \" \" + \"WARNING\\n\" + 80 * \"-\"\n            bottom_banner = 80 * \"-\" + \"\\n\" + 80 * \"-\"\n            logger.warning(top_banner)\n            logger.warning(\n                \"A Default SECRET_KEY was detected, please use superset_config.py \"\n                \"to override it.\\n\"\n                \"Use a strong complex alphanumeric string and use a tool to help\"\n                \" you generate \\n\"\n                \"a sufficiently random sequence, ex: openssl rand -base64 42\"\n            )\n            logger.warning(bottom_banner)\n\n        if self.config[\"SECRET_KEY\"] == CHANGE_ME_SECRET_KEY:\n            if (\n                self.superset_app.debug\n                or self.superset_app.config[\"TESTING\"]\n                # There must be a better way\n                or \"pytest\" in sys.modules\n            ):\n                logger.warning(\"Debug mode identified with default secret key\")\n                log_default_secret_key_warning()\n                return\n            log_default_secret_key_warning()\n            logger.error(\"Refusing to start due to insecure SECRET_KEY\")\n            sys.exit(1)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_base_rev_args(rev: str) -> List[str]:\n        return [f\"-r={rev}\"]\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def on_federation_query_user_devices(self, user_id: str) -> JsonDict:\n        if not self.hs.is_mine(UserID.from_string(user_id)):\n            raise SynapseError(400, \"User is not hosted on this homeserver\")\n\n        stream_id, devices = await self.store.get_e2e_device_keys_for_federation_query(\n            user_id\n        )\n        master_key = await self.store.get_e2e_cross_signing_key(user_id, \"master\")\n        self_signing_key = await self.store.get_e2e_cross_signing_key(\n            user_id, \"self_signing\"\n        )\n\n        # Check if the application services have any results.\n        if self._query_appservices_for_keys:\n            # Query the appservice for all devices for this user.\n            query: Dict[str, Optional[List[str]]] = {user_id: None}\n\n            # Query the appservices for any keys.\n            appservice_results = await self._appservice_handler.query_keys(query)\n\n            # Merge results, overriding anything from the database.\n            appservice_devices = appservice_results.get(\"device_keys\", {}).get(\n                user_id, {}\n            )\n\n            # Filter the database results to only those devices that the appservice has\n            # *not* responded with.\n            devices = [d for d in devices if d[\"device_id\"] not in appservice_devices]\n            # Append the appservice response by wrapping each result in another dictionary.\n            devices.extend(\n                {\"device_id\": device_id, \"keys\": device}\n                for device_id, device in appservice_devices.items()\n            )\n\n            # TODO Handle cross-signing keys.\n\n        return {\n            \"user_id\": user_id,\n            \"stream_id\": stream_id,\n            \"devices\": devices,\n            \"master_key\": master_key,\n            \"self_signing_key\": self_signing_key,\n        }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_payload(token):\n    from rest_framework_jwt.authentication import JSONWebTokenAuthentication\n\n    if apps.is_installed('rest_framework_jwt.blacklist'):\n        if BlacklistedToken.objects.filter(token=force_str(token)).exists():\n            msg = _('Token is blacklisted.')\n            raise serializers.ValidationError(msg)\n\n    try:\n        payload = JSONWebTokenAuthentication.jwt_decode_token(token)\n    except jwt.ExpiredSignature:\n        msg = _('Token has expired.')\n        raise serializers.ValidationError(msg)\n    except jwt.DecodeError:\n        msg = _('Error decoding token.')\n        raise serializers.ValidationError(msg)\n\n    return payload\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _complete_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/complete` to complete a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    artifact_path = validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        CompleteMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"upload_id\": [_assert_string],\n            \"parts\": [_assert_required],\n        },\n    )\n    path = request_message.path\n    upload_id = request_message.upload_id\n    parts = [MultipartUploadPart.from_proto(part) for part in request_message.parts]\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    artifact_repo.complete_multipart_upload(\n        path,\n        upload_id,\n        parts,\n        artifact_path,\n    )\n    return _wrap_response(CompleteMultipartUpload.Response())\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    StagingMap<Ordered>* map = nullptr;\n    OP_REQUIRES_OK(ctx, GetStagingMap(ctx, def(), &map));\n    core::ScopedUnref scope(map);\n    typename StagingMap<Ordered>::OptionalTuple tuple;\n\n    const Tensor* key_tensor;\n    const Tensor* indices_tensor;\n    OpInputList values_tensor;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"key\", &key_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices_tensor));\n    OP_REQUIRES_OK(ctx, ctx->input_list(\"values\", &values_tensor));\n    OP_REQUIRES(ctx, key_tensor->NumElements() > 0,\n                errors::InvalidArgument(\"key must not be empty\"));\n\n    // Create copy for insertion into Staging Area\n    Tensor key(*key_tensor);\n\n    // Create the tuple to store\n    for (std::size_t i = 0; i < values_tensor.size(); ++i) {\n      tuple.push_back(values_tensor[i]);\n    }\n\n    // Store the tuple in the map\n    OP_REQUIRES_OK(ctx, map->put(&key, indices_tensor, &tuple));\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus ResizeOutputTensors(TfLiteContext* context, TfLiteNode* node,\n                                 const TfLiteTensor* input,\n                                 const TfLiteTensor* size_splits,\n                                 const TfLiteTensor* axis) {\n  int axis_value = GetTensorData<int>(axis)[0];\n  if (axis_value < 0) {\n    axis_value += NumDimensions(input);\n  }\n\n  std::vector<int64_t> size_splits_vector;\n  if (size_splits->type == kTfLiteInt32) {\n    GetSizeSplitsVector<int32_t>(size_splits, &size_splits_vector);\n  } else if (size_splits->type == kTfLiteInt64) {\n    GetSizeSplitsVector<int64_t>(size_splits, &size_splits_vector);\n  } else {\n    context->ReportError(context, \"size_splits only support type int32|int64.\");\n    return kTfLiteError;\n  }\n\n  int minus_one_index = -1;\n  int64_t size_splits_sum = 0;\n\n  for (int i = 0; i < size_splits_vector.size(); ++i) {\n    if (size_splits_vector.at(i) == -1) {\n      if (minus_one_index == -1) {\n        minus_one_index = i;\n      } else {\n        context->ReportError(context,\n                             \"The size_splits contains more than one -1.\");\n      }\n    } else {\n      size_splits_sum += size_splits_vector.at(i);\n    }\n  }\n\n  TF_LITE_ENSURE(context, axis_value >= 0);\n  TF_LITE_ENSURE(context, axis_value < NumDimensions(input));\n  const int input_size = SizeOfDimension(input, axis_value);\n\n  if (minus_one_index != -1) {\n    if (size_splits_sum > input_size) {\n      context->ReportError(\n          context,\n          \"The sum of size_splits must be less than the dimension of value.\");\n    } else {\n      size_splits_vector[minus_one_index] = input_size - size_splits_sum;\n    }\n  } else if (size_splits_sum != input_size) {\n    context->ReportError(\n        context,\n        \"The size_splits must sum to the dimension of value along axis.\");\n  }\n\n  for (int i = 0; i < NumOutputs(node); ++i) {\n    TfLiteIntArray* output_dims = TfLiteIntArrayCopy(input->dims);\n    output_dims->data[axis_value] = size_splits_vector.at(i);\n    TfLiteTensor* output;\n    TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, i, &output));\n    TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_dims));\n  }\n\n  return kTfLiteOk;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void WebServer::handleRequest(AsyncWebServerRequest *request) {\n  if (request->url() == \"/\") {\n    this->handle_index_request(request);\n    return;\n  }\n\n#ifdef WEBSERVER_CSS_INCLUDE\n  if (request->url() == \"/0.css\") {\n    this->handle_css_request(request);\n    return;\n  }\n#endif\n\n#ifdef WEBSERVER_JS_INCLUDE\n  if (request->url() == \"/0.js\") {\n    this->handle_js_request(request);\n    return;\n  }\n#endif\n\n  UrlMatch match = match_url(request->url().c_str());\n#ifdef USE_SENSOR\n  if (match.domain == \"sensor\") {\n    this->handle_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_SWITCH\n  if (match.domain == \"switch\") {\n    this->handle_switch_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_BINARY_SENSOR\n  if (match.domain == \"binary_sensor\") {\n    this->handle_binary_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_FAN\n  if (match.domain == \"fan\") {\n    this->handle_fan_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_LIGHT\n  if (match.domain == \"light\") {\n    this->handle_light_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_TEXT_SENSOR\n  if (match.domain == \"text_sensor\") {\n    this->handle_text_sensor_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_COVER\n  if (match.domain == \"cover\") {\n    this->handle_cover_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_NUMBER\n  if (match.domain == \"number\") {\n    this->handle_number_request(request, match);\n    return;\n  }\n#endif\n\n#ifdef USE_SELECT\n  if (match.domain == \"select\") {\n    this->handle_select_request(request, match);\n    return;\n  }\n#endif\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ImagingSgiRleDecode(Imaging im, ImagingCodecState state, UINT8 *buf, Py_ssize_t bytes) {\n    UINT8 *ptr;\n    SGISTATE *c;\n    int err = 0;\n    int status;\n\n    /* size check */\n    if (im->xsize > INT_MAX / im->bands || im->ysize > INT_MAX / im->bands) {\n        state->errcode = IMAGING_CODEC_MEMORY;\n        return -1;\n    }\n\n    /* Get all data from File descriptor */\n    c = (SGISTATE *)state->context;\n    _imaging_seek_pyFd(state->fd, 0L, SEEK_END);\n    c->bufsize = _imaging_tell_pyFd(state->fd);\n    c->bufsize -= SGI_HEADER_SIZE;\n\n    c->tablen = im->bands * im->ysize;\n    /* below, we populate the starttab and lentab into the bufsize,\n       each with 4 bytes per element of tablen\n       Check here before we allocate any memory\n    */\n    if (c->bufsize < 8 * c->tablen) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = malloc(sizeof(UINT8) * c->bufsize);\n    if (!ptr) {\n        state->errcode = IMAGING_CODEC_MEMORY;\n        return -1;\n    }\n    _imaging_seek_pyFd(state->fd, SGI_HEADER_SIZE, SEEK_SET);\n    if (_imaging_read_pyFd(state->fd, (char *)ptr, c->bufsize) != c->bufsize) {\n        state->errcode = IMAGING_CODEC_UNKNOWN;\n        return -1;\n    }\n\n\n    /* decoder initialization */\n    state->count = 0;\n    state->y = 0;\n    if (state->ystep < 0) {\n        state->y = im->ysize - 1;\n    } else {\n        state->ystep = 1;\n    }\n\n    /* Allocate memory for RLE tables and rows */\n    free(state->buffer);\n    state->buffer = NULL;\n    /* malloc overflow check above */\n    state->buffer = calloc(im->xsize * im->bands, sizeof(UINT8) * 2);\n    c->starttab = calloc(c->tablen, sizeof(UINT32));\n    c->lengthtab = calloc(c->tablen, sizeof(UINT32));\n    if (!state->buffer || !c->starttab || !c->lengthtab) {\n        err = IMAGING_CODEC_MEMORY;\n        goto sgi_finish_decode;\n    }\n    /* populate offsets table */\n    for (c->tabindex = 0, c->bufindex = 0; c->tabindex < c->tablen;\n         c->tabindex++, c->bufindex += 4) {\n        read4B(&c->starttab[c->tabindex], &ptr[c->bufindex]);\n    }\n    /* populate lengths table */\n    for (c->tabindex = 0, c->bufindex = c->tablen * sizeof(UINT32);\n         c->tabindex < c->tablen;\n         c->tabindex++, c->bufindex += 4) {\n        read4B(&c->lengthtab[c->tabindex], &ptr[c->bufindex]);\n    }\n\n    /* read compressed rows */\n    for (c->rowno = 0; c->rowno < im->ysize; c->rowno++, state->y += state->ystep) {\n        for (c->channo = 0; c->channo < im->bands; c->channo++) {\n            c->rleoffset = c->starttab[c->rowno + c->channo * im->ysize];\n            c->rlelength = c->lengthtab[c->rowno + c->channo * im->ysize];\n\n            // Check for underflow of rleoffset-SGI_HEADER_SIZE\n            if (c->rleoffset < SGI_HEADER_SIZE) {\n                state->errcode = IMAGING_CODEC_OVERRUN;\n                goto sgi_finish_decode;\n            }\n\n            c->rleoffset -= SGI_HEADER_SIZE;\n\n            /* row decompression */\n            if (c->bpc == 1) {\n                status = expandrow(\n                    &state->buffer[c->channo],\n                    &ptr[c->rleoffset],\n                    c->rlelength,\n                    im->bands,\n                    im->xsize,\n                    &ptr[c->bufsize-1]);\n            } else {\n                status = expandrow2(\n                    &state->buffer[c->channo * 2],\n                    &ptr[c->rleoffset],\n                    c->rlelength,\n                    im->bands,\n                    im->xsize,\n                    &ptr[c->bufsize-1]);\n            }\n            if (status == -1) {\n                state->errcode = IMAGING_CODEC_OVERRUN;\n                goto sgi_finish_decode;\n            } else if (status == 1) {\n                goto sgi_finish_decode;\n            }\n\n        }\n\n        /* store decompressed data in image */\n        state->shuffle((UINT8 *)im->image[state->y], state->buffer, im->xsize);\n    }\n\nsgi_finish_decode:;\n\n    free(c->starttab);\n    free(c->lengthtab);\n    free(ptr);\n    if (err != 0) {\n        state->errcode = err;\n        return -1;\n    }\n    return 0;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def populate_obj(self, user):\n        # Check if current password is \"valid\" if Not, rate limit the\n        # number of attempts and logout user after too many invalid attempts.\n        if not user.validate_password(self.current.data):\n            cherrypy.session[CHANGE_PASSWORD_ATTEMPTS] = cherrypy.session.get(CHANGE_PASSWORD_ATTEMPTS, 0) + 1\n            attempts = cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]\n            if attempts >= CHANGE_PASSWORD_MAX_ATTEMPT:\n                cherrypy.session.clear()\n                cherrypy.session.regenerate()\n                flash(\n                    _(\"You were logged out because you entered the wrong password too many times.\"),\n                    level='warning',\n                )\n                raise cherrypy.HTTPRedirect('/login/')\n            flash(_(\"Wrong current password.\"), level='warning')\n        else:\n            # Clear number of attempts\n            if CHANGE_PASSWORD_ATTEMPTS in cherrypy.session:\n                del cherrypy.session[CHANGE_PASSWORD_ATTEMPTS]\n            # If Valid, update password\n            try:\n                user.set_password(self.new.data)\n                flash(_(\"Password updated successfully.\"), level='success')\n            except ValueError as e:\n                flash(str(e), level='warning')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def delete_project():\n    form = DeleteProjectForm(id=g.project.id)\n    if form.validate():\n        g.project.remove_project()\n        flash(_(\"Project successfully deleted\"))\n        return redirect(url_for(\".home\"))\n    else:\n        flash(\n            _(\"Error deleting project: wrong private code or wrong CSRF token\"),\n            category=\"danger\",\n        )\n    return redirect(request.headers.get(\"Referer\") or url_for(\".home\"))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ValidatePaddingValues(absl::Span<const int64_t> input_dimensions,\n                             absl::Span<const int64_t> window_dimensions,\n                             absl::Span<const int64_t> window_strides) {\n  bool ok = input_dimensions.size() == window_dimensions.size() &&\n            input_dimensions.size() == window_strides.size();\n  if (!ok) {\n    return InvalidArgument(\n        \"Want input dimensions size %u = window dimensions size %u = window \"\n        \"strides size %u\",\n        input_dimensions.size(), window_dimensions.size(),\n        window_strides.size());\n  }\n  for (size_t i = 0; i < input_dimensions.size(); ++i) {\n    if (window_dimensions[i] <= 0) {\n      return InvalidArgument(\"Window dimension %u has non-positive size %d\", i,\n                             window_dimensions[i]);\n    }\n    if (window_strides[i] <= 0) {\n      return InvalidArgument(\"Window dimension %u has non-positive stride %d\",\n                             i, window_strides[i]);\n    }\n  }\n  return OkStatus();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def task_created(request):\n   \"\"\"\n   Let's the user know what to expect for event updates.\n   \"\"\"\n   if not test_user_authenticated(request): return login(request, next=\"/cobbler_web/task_created\")\n   t = get_template(\"task_created.tmpl\")\n   html = t.render(RequestContext(request,{\n       'version'  : remote.version(request.session['token']),\n       'username' : username\n   }))\n   return HttpResponse(html)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse_Compare(self):\n        left = Expr.parse_value_expr(self.expr.left, self.context)\n        right = Expr.parse_value_expr(self.expr.right, self.context)\n\n        if right.value is None:\n            return\n\n        if isinstance(self.expr.op, (vy_ast.In, vy_ast.NotIn)):\n            if isinstance(right.typ, ArrayLike):\n                return self.build_in_comparator()\n            return  # pragma: notest\n\n        if isinstance(self.expr.op, vy_ast.Gt):\n            op = \"sgt\"\n        elif isinstance(self.expr.op, vy_ast.GtE):\n            op = \"sge\"\n        elif isinstance(self.expr.op, vy_ast.LtE):\n            op = \"sle\"\n        elif isinstance(self.expr.op, vy_ast.Lt):\n            op = \"slt\"\n        elif isinstance(self.expr.op, vy_ast.Eq):\n            op = \"eq\"\n        elif isinstance(self.expr.op, vy_ast.NotEq):\n            op = \"ne\"\n        else:\n            return  # pragma: notest\n\n        # Compare (limited to 32) byte arrays.\n        if isinstance(left.typ, ByteArrayLike) and isinstance(right.typ, ByteArrayLike):\n            left = Expr(self.expr.left, self.context).ir_node\n            right = Expr(self.expr.right, self.context).ir_node\n\n            left_keccak = keccak256_helper(self.expr, left, self.context)\n            right_keccak = keccak256_helper(self.expr, right, self.context)\n\n            if op not in (\"eq\", \"ne\"):\n                return  # raises\n            else:\n                # use hash even for Bytes[N<=32], because there could be dirty\n                # bytes past the bytes data.\n                return IRnode.from_list([op, left_keccak, right_keccak], typ=\"bool\")\n\n        # Compare other types.\n        elif is_numeric_type(left.typ) and is_numeric_type(right.typ):\n            if left.typ.typ == right.typ.typ == \"uint256\":\n                # this works because we only have one unsigned integer type\n                # in the future if others are added, this logic must be expanded\n                op = self._signed_to_unsigned_comparision_op(op)\n\n        elif isinstance(left.typ, BaseType) and isinstance(right.typ, BaseType):\n            if op not in (\"eq\", \"ne\"):\n                return\n        else:\n            # kludge to block behavior in #2638\n            # TODO actually implement equality for complex types\n            raise TypeMismatch(\n                f\"operation not yet supported for {left.typ}, {right.typ}, see issue #2638\",\n                self.expr.op,\n            )\n\n        return IRnode.from_list([op, left, right], typ=\"bool\")\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __new__(cls, obj, *args, **kwargs):\n        if isinstance(obj, AnsibleUnsafe):\n            # Already marked unsafe\n            return obj\n\n        # In our usage we should only receive unicode strings.\n        # This conditional and conversion exists to sanity check the values\n        # we're given but we may want to take it out for testing and sanitize\n        # our input instead.\n        # Note that this does the wrong thing if we're *intentionall* passing a byte string to this\n        # function.\n        if isinstance(obj, string_types):\n            obj = AnsibleUnsafeText(to_text(obj, errors='surrogate_or_strict'))\n        return obj\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, args, *remaining, env=None, text=False, shell=False, **kwargs):\n        if env is None:\n            env = os.environ.copy()\n        self._fix_pyinstaller_ld_path(env)\n\n        self.__text_mode = kwargs.get('encoding') or kwargs.get('errors') or text or kwargs.get('universal_newlines')\n        if text is True:\n            kwargs['universal_newlines'] = True  # For 3.6 compatibility\n            kwargs.setdefault('encoding', 'utf-8')\n            kwargs.setdefault('errors', 'replace')\n\n        if shell and compat_os_name == 'nt' and kwargs.get('executable') is None:\n            if not isinstance(args, str):\n                args = ' '.join(compat_shlex_quote(a) for a in args)\n            shell = False\n            args = f'{self.__comspec()} /Q /S /D /V:OFF /C \"{args}\"'\n\n        super().__init__(args, *remaining, env=env, shell=shell, **kwargs, startupinfo=self._startupinfo)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& filter = context->input(1);\n    const Tensor& out_backprop = context->input(2);\n\n    // Determine relevant sizes from input and filters.\n    int stride_rows = 0, stride_cols = 0;\n    int rate_rows = 0, rate_cols = 0;\n    int64 pad_top = 0, pad_left = 0;\n    int64 out_rows = 0, out_cols = 0;\n    ParseSizes(context, strides_, rates_, padding_, &stride_rows, &stride_cols,\n               &rate_rows, &rate_cols, &pad_top, &pad_left, &out_rows,\n               &out_cols);\n    if (!context->status().ok()) return;\n\n    // Verify that the incoming gradient tensor has the expected size\n    // [ batch, out_rows, out_cols, depth ]\n    const int batch = input.dim_size(0);\n    const int depth = input.dim_size(3);\n    OP_REQUIRES(context,\n                batch == out_backprop.dim_size(0) &&\n                    out_rows == out_backprop.dim_size(1) &&\n                    out_cols == out_backprop.dim_size(2) &&\n                    depth == out_backprop.dim_size(3),\n                errors::InvalidArgument(\"out_backprop has incompatible size.\"));\n\n    // The computed in_backprop has the same dimensions as the input:\n    // [ batch, input_rows, input_cols, depth ]\n    Tensor* in_backprop = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, input.shape(), &in_backprop));\n\n    // If there is nothing to compute, return.\n    if (input.shape().num_elements() == 0) {\n      return;\n    }\n\n    functor::DilationBackpropInput<Device, T>()(\n        context->eigen_device<Device>(), input.tensor<T, 4>(),\n        filter.tensor<T, 3>(), out_backprop.tensor<T, 4>(), stride_rows,\n        stride_cols, rate_rows, rate_cols, pad_top, pad_left,\n        in_backprop->tensor<T, 4>());\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_host(self):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n            'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = str(self.META['SERVER_PORT'])\n            if server_port != (self.is_secure() and '443' or '80'):\n                host = '%s:%s' % (host, server_port)\n\n        # Disallow potentially poisoned hostnames.\n        if set(';/?@&=+$,').intersection(host):\n            raise SuspiciousOperation('Invalid HTTP_HOST header: %s' % host)\n\n        return host\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus EvalGatherNd(TfLiteContext* context, const TfLiteTensor* params,\n                          const TfLiteTensor* indices, TfLiteTensor* output) {\n  bool indices_has_only_positive_elements = true;\n  const auto* indices_values = GetTensorData<IndicesT>(indices);\n  const size_t num_indices = indices->bytes / sizeof(IndicesT);\n  for (size_t i = 0; i < num_indices; i++) {\n    if (indices_values[i] < 0) {\n      indices_has_only_positive_elements = false;\n      break;\n    }\n  }\n  TF_LITE_ENSURE(context, indices_has_only_positive_elements);\n\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n    case kTfLiteUInt8:\n      return GatherNd<uint8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n    case kTfLiteInt16:\n      return GatherNd<int16_t, IndicesT>(params, indices, output);\n    case kTfLiteInt32:\n      return GatherNd<int32_t, IndicesT>(params, indices, output);\n    case kTfLiteInt64:\n      return GatherNd<int64_t, IndicesT>(params, indices, output);\n    case kTfLiteString:\n      return GatherNdString<IndicesT>(params, indices, output);\n    default:\n      context->ReportError(context,\n                           \"Params type '%s' are not supported by gather_nd.\",\n                           TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status SpaceToBatchOpCompute(OpKernelContext* context,\n                             const Tensor& orig_input_tensor,\n                             const Tensor& orig_block_shape,\n                             const Tensor& orig_paddings) {\n  const int input_dims = orig_input_tensor.dims();\n  if (!TensorShapeUtils::IsVector(orig_block_shape.shape())) {\n    return errors::InvalidArgument(\"block_shape rank should be 1 instead of \",\n                                   orig_block_shape.dims());\n  }\n\n  const int block_dims = orig_block_shape.dim_size(0);\n  if (orig_input_tensor.dims() < 1 + block_dims) {\n    return errors::InvalidArgument(\"input rank should be >= \", 1 + block_dims,\n                                   \" instead of \", orig_input_tensor.dims());\n  }\n\n  if (!(TensorShapeUtils::IsMatrix(orig_paddings.shape()) &&\n        block_dims == orig_paddings.dim_size(0) &&\n        2 == orig_paddings.dim_size(1))) {\n    return errors::InvalidArgument(\"paddings should have shape [\", block_dims,\n                                   \", 2] instead of \",\n                                   orig_paddings.shape().DebugString());\n  }\n\n  // To avoid out-of-bounds access in the case that the block_shape and/or\n  // paddings tensors are concurrently modified, we must copy the values.\n  gtl::InlinedVector<int64_t, 4> block_shape;\n  gtl::InlinedVector<int64_t, 8> paddings;\n  internal::spacetobatch::SubtleMustCopyFlat(orig_block_shape, &block_shape);\n  internal::spacetobatch::SubtleMustCopyFlat(orig_paddings, &paddings);\n\n  // Determine the length of the prefix of block dims that can be combined\n  // into the batch dimension due to having no padding and block_shape=1.\n  int removed_prefix_block_dims = 0;\n  for (; removed_prefix_block_dims < block_dims; ++removed_prefix_block_dims) {\n    const int dim = removed_prefix_block_dims;\n    if (paddings[2 * dim] != 0 || paddings[2 * dim + 1] != 0 ||\n        block_shape[dim] != 1) {\n      break;\n    }\n  }\n\n  // Determine the length of the suffix of block dims that can be combined\n  // into the depth dimension due to having no padding and block_shape=1.\n  int removed_suffix_block_dims = 0;\n  for (; removed_suffix_block_dims < block_dims - removed_prefix_block_dims;\n       ++removed_suffix_block_dims) {\n    const int dim = block_dims - 1 - removed_suffix_block_dims;\n    if (paddings[dim * 2] != 0 || paddings[dim * 2 + 1] != 0 ||\n        block_shape[dim] != 1) {\n      break;\n    }\n  }\n\n  // Compute the product of the block_shape values.\n  int64_t block_shape_product = 1;\n  for (int block_dim = 0; block_dim < block_dims; ++block_dim) {\n    if (block_shape[block_dim] < 1) {\n      return errors::InvalidArgument(\n          \"All values in block_shape must be positive, got value, \",\n          block_shape[block_dim], \" at index \", block_dim, \".\");\n    }\n    block_shape_product =\n        MultiplyWithoutOverflow(block_shape_product, block_shape[block_dim]);\n  }\n  if (block_shape_product <= 0) {\n    return errors::InvalidArgument(\n        \"Product of block sizes must be positive, got \", block_shape_product);\n  }\n\n  const int internal_block_dims =\n      block_dims - removed_prefix_block_dims - removed_suffix_block_dims;\n  if (internal_block_dims > kMaxSpaceToBatchBlockDims) {\n    return errors::InvalidArgument(\n        \"Maximum number of non-combined block dimensions is \",\n        internal_block_dims, \" but must not exceed \",\n        kMaxSpaceToBatchBlockDims);\n  }\n\n  if (internal_block_dims == 0) {\n    context->set_output(0, orig_input_tensor);\n    return Status::OK();\n  }\n\n  // For the purpose of computing the result, the input will be treated as\n  // having this shape, of rank 2 + internal_block_dims.\n  TensorShape internal_input_shape;\n\n  // For the purpose of computing the result, the output will be treated as\n  // having this shape, of rank 2 + internal_block_dims.\n  TensorShape internal_output_shape;\n\n  // The actual output shape exposed to callers.\n  TensorShape external_output_shape;\n\n  const int64_t output_shape = MultiplyWithoutOverflow(\n      orig_input_tensor.dim_size(0), block_shape_product);\n  if (output_shape < 0) {\n    return errors::InvalidArgument(\n        \"Negative output dimension size caused by overflow when multiplying \",\n        orig_input_tensor.dim_size(0), \" and \", block_shape_product);\n  }\n  external_output_shape.AddDim(output_shape);\n\n  int64_t input_batch_size = orig_input_tensor.dim_size(0);\n  for (int block_dim = 0; block_dim < removed_prefix_block_dims; ++block_dim) {\n    const int64_t size = orig_input_tensor.dim_size(block_dim + 1);\n    input_batch_size *= size;\n    external_output_shape.AddDim(size);\n  }\n  internal_input_shape.AddDim(input_batch_size);\n  internal_output_shape.AddDim(input_batch_size * block_shape_product);\n\n  for (int block_dim = removed_prefix_block_dims;\n       block_dim < block_dims - removed_suffix_block_dims; ++block_dim) {\n    const int64_t pad_start = paddings[2 * block_dim],\n                  pad_end = paddings[2 * block_dim + 1];\n    if (pad_start < 0 || pad_end < 0) {\n      return errors::InvalidArgument(\"Paddings must be non-negative\");\n    }\n    const int64_t input_size = orig_input_tensor.dim_size(block_dim + 1);\n    const int64_t block_shape_value = block_shape[block_dim];\n    const int64_t padded_size = input_size + pad_start + pad_end;\n    if (padded_size % block_shape_value != 0) {\n      return errors::InvalidArgument(\"padded_shape[\", block_dim,\n                                     \"]=\", padded_size,\n                                     \" is not divisible by block_shape[\",\n                                     block_dim, \"]=\", block_shape_value);\n    }\n    internal_input_shape.AddDim(input_size);\n    const int64_t output_size = padded_size / block_shape_value;\n    internal_output_shape.AddDim(output_size);\n    external_output_shape.AddDim(output_size);\n  }\n\n  int64_t depth = 1;\n  for (int dim = block_dims - removed_suffix_block_dims + 1; dim < input_dims;\n       ++dim) {\n    const int64_t size = orig_input_tensor.dim_size(dim);\n    external_output_shape.AddDim(size);\n    depth *= size;\n  }\n  internal_input_shape.AddDim(depth);\n  internal_output_shape.AddDim(depth);\n\n  // Allocate output tensor.\n  Tensor* output_tensor = nullptr;\n  TF_RETURN_IF_ERROR(\n      context->allocate_output(0, external_output_shape, &output_tensor));\n\n  const int64_t* internal_paddings = &paddings[2 * removed_prefix_block_dims];\n  const int64_t* internal_block_shape = &block_shape[removed_prefix_block_dims];\n\n  switch (internal_block_dims) {\n#define TF_SPACETOBATCH_BLOCK_DIMS_CASE(NUM_BLOCK_DIMS)                   \\\n  case NUM_BLOCK_DIMS: {                                                  \\\n    TF_RETURN_IF_ERROR(                                                   \\\n        functor::SpaceToBatchFunctor<Device, T, NUM_BLOCK_DIMS, false>()( \\\n            context->eigen_device<Device>(),                              \\\n            orig_input_tensor.shaped<T, NUM_BLOCK_DIMS + 2>(              \\\n                internal_input_shape.dim_sizes()),                        \\\n            internal_block_shape, internal_paddings,                      \\\n            output_tensor->shaped<T, NUM_BLOCK_DIMS + 2>(                 \\\n                internal_output_shape.dim_sizes())));                     \\\n  } break;                                                                \\\n    /**/\n    TF_SPACETOBATCH_FOR_EACH_NUM_BLOCK_DIMS(TF_SPACETOBATCH_BLOCK_DIMS_CASE)\n#undef TF_SPACETOBATCH_BLOCK_DIMS_CASE\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "        def event_err(e, pdu_to_check):\n            errmsg = (\n                \"event id %s: unable to verify signature for event id domain: %s\"\n                % (pdu_to_check.pdu.event_id, e.getErrorMessage())\n            )\n            raise SynapseError(403, errmsg, Codes.FORBIDDEN)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_load_finished(self, ok):\n        if sip.isdeleted(self._widget):\n            # https://github.com/qutebrowser/qutebrowser/issues/3498\n            return\n\n        sess_manager = objreg.get('session-manager')\n        sess_manager.save_autosave()\n\n        if ok:\n            if self.url().scheme() == 'https':\n                if self.url().host() in self._insecure_hosts:\n                    self._set_load_status(usertypes.LoadStatus.warn)\n                else:\n                    self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n\n        self.load_finished.emit(ok)\n\n        if not self.title():\n            self.title_changed.emit(self.url().toDisplayString())\n\n        self.zoom.set_current()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decode(\n        self,\n        types: Iterable[TypeStr],\n        data: Decodable,\n    ) -> Tuple[Any, ...]:\n        \"\"\"\n        Decodes the binary value ``data`` as a sequence of values of the ABI types\n        in ``types`` via the head-tail mechanism into a tuple of equivalent python\n        values.\n\n        :param types: A list or tuple of string representations of the ABI types that\n            will be used for decoding e.g. ``('uint256', 'bytes[]', '(int,int)')``\n        :param data: The binary value to be decoded.\n\n        :returns: A tuple of equivalent python values for the ABI values\n            represented in ``data``.\n        \"\"\"\n        # validate decode types\n        validate_codec_types(types)\n\n        # validate decode data\n        validate_bytes_param(data, \"data\")\n\n        decoders = [self._registry.get_decoder(type_str) for type_str in types]\n\n        decoder = TupleDecoder(decoders=decoders)\n        stream = self.stream_class(data)\n\n        return decoder(stream)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_snippet_path(self, path):\r\n        \"\"\"Get snippet path.\"\"\"\r\n\r\n        snippet = None\r\n        for base in self.base_path:\r\n            if os.path.exists(base):\r\n                if os.path.isdir(base):\r\n                    if self.restrict_base_path:\r\n                        filename = os.path.abspath(os.path.join(base, path))\r\n                        # If the absolute path is no longer under the specified base path, reject the file\r\n                        if not os.path.samefile(base, os.path.dirname(filename)):\r\n                            continue\r\n                    else:\r\n                        filename = os.path.join(base, path)\r\n                    if os.path.exists(filename):\r\n                        snippet = filename\r\n                        break\r\n                else:\r\n                    dirname = os.path.dirname(base)\r\n                    filename = os.path.join(dirname, path)\r\n                    if os.path.exists(filename) and os.path.samefile(filename, base):\r\n                        snippet = filename\r\n                        break\r\n        return snippet\r\n\r"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set_password(self, service, username, password):\n        \"\"\"Save the password in the file.\n        \"\"\"\n\n        self._relocate_file()\n        service = escape_for_ini(service)\n        username = escape_for_ini(username)\n\n        config, keyring_password = self._read_config()\n\n        password = password.encode('utf-8')\n        # write the modification\n        if not config.has_section(service):\n            config.add_section(service)\n        config.set(service, username, password)\n\n        self._write_config(config, keyring_password)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set_password(self, password):\n        \"\"\"\n        Change the user's password. Raise a ValueError if the username or\n        the password are invalid.\n        \"\"\"\n        assert isinstance(password, str)\n        if not password:\n            raise ValueError(\"password can't be empty\")\n        cfg = cherrypy.tree.apps[''].cfg\n\n        # Cannot update admin-password if defined\n        if self.username == cfg.admin_user and cfg.admin_password:\n            raise ValueError(_(\"can't update admin-password defined in configuration file\"))\n\n        # Check password length\n        if cfg.password_min_length > len(password) or len(password) > cfg.password_max_length:\n            raise ValueError(\n                _('Password must have between %(min)d and %(max)d characters.')\n                % {'min': cfg.password_min_length, 'max': cfg.password_max_length}\n            )\n\n        # Verify password score using zxcvbn\n        stats = zxcvbn(password)\n        if stats.get('score') < cfg.password_score:\n            msg = _('Password too weak.')\n            warning = stats.get('feedback', {}).get('warning')\n            suggestions = stats.get('feedback', {}).get('suggestions')\n            if warning:\n                msg += ' ' + warning\n            if suggestions:\n                msg += ' ' + ' '.join(suggestions)\n            raise ValueError(msg)\n\n        logger.info(\"updating user password [%s]\", self.username)\n        self.hash_password = hash_password(password)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask(self, text, mode=\"\", *args, **kwargs):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :return: An internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module.\n        \"\"\"\n        _string_length_check(text)\n        return self.font.getmask(text, mode)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def set(self, name, value, force=False):\n        \"\"\"Set a form element identified by ``name`` to a specified ``value``.\n        The type of element (input, textarea, select, ...) does not\n        need to be given; it is inferred by the following methods:\n        :func:`~Form.set_checkbox`,\n        :func:`~Form.set_radio`,\n        :func:`~Form.set_input`,\n        :func:`~Form.set_textarea`,\n        :func:`~Form.set_select`.\n        If none of these methods find a matching element, then if ``force``\n        is True, a new element (``<input type=\"text\" ...>``) will be\n        added using :func:`~Form.new_control`.\n\n        Example: filling-in a login/password form with EULA checkbox\n\n        .. code-block:: python\n\n            form.set(\"login\", username)\n            form.set(\"password\", password)\n            form.set(\"eula-checkbox\", True)\n\n        Example: uploading a file through a ``<input type=\"file\"\n        name=\"tagname\">`` field (provide an open file object,\n        and its content will be uploaded):\n\n        .. code-block:: python\n\n            form.set(\"tagname\", open(path_to_local_file, \"rb\"))\n\n        \"\"\"\n        for func in (\"checkbox\", \"radio\", \"input\", \"textarea\", \"select\"):\n            try:\n                getattr(self, \"set_\" + func)({name: value})\n                return\n            except InvalidFormMethod:\n                pass\n        if force:\n            self.new_control('text', name, value=value)\n            return\n        raise LinkNotFoundError(\"No valid element named \" + name)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext *ctx) override {\n    const Tensor *a_indices_t, *a_values_t, *a_shape_t, *b_indices_t,\n        *b_values_t, *b_shape_t;\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_indices\", &a_indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_values\", &a_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_shape\", &a_shape_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_indices\", &b_indices_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_values\", &b_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_shape\", &b_shape_t));\n\n    // Validations.\n    OP_REQUIRES(\n        ctx,\n        TensorShapeUtils::IsMatrix(a_indices_t->shape()) &&\n            TensorShapeUtils::IsMatrix(b_indices_t->shape()),\n        errors::InvalidArgument(\"Inputs a_indices and b_indices should be \"\n                                \"matrices but received shapes: \",\n                                a_indices_t->shape().DebugString(), \", \",\n                                b_indices_t->shape().DebugString()));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_values_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_values_t->shape()),\n                errors::InvalidArgument(\n                    \"Inputs a_values and b_values should be vectors \"\n                    \"but received shapes: \",\n                    a_values_t->shape().DebugString(), \" and \",\n                    b_values_t->shape().DebugString()));\n\n    const int64 a_nnz = a_indices_t->dim_size(0);\n    const int64 b_nnz = b_indices_t->dim_size(0);\n\n    const auto a_values = a_values_t->vec<T>();\n    const auto b_values = b_values_t->vec<T>();\n\n    OP_REQUIRES(\n        ctx, a_values.size() == a_nnz && b_values.size() == b_nnz,\n        errors::InvalidArgument(\"Expected \", a_nnz, \" and \", b_nnz,\n                                \" non-empty input values, got \",\n                                a_values.size(), \" and \", b_values.size()));\n\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_shape_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_shape_t->shape()),\n                errors::InvalidArgument(\n                    \"Input shapes should be a vector but received shapes \",\n                    a_shape_t->shape().DebugString(), \" and \",\n                    b_shape_t->shape().DebugString()));\n    const int num_dims = a_indices_t->dim_size(1);\n    OP_REQUIRES(\n        ctx, a_shape_t->NumElements() == num_dims,\n        errors::InvalidArgument(\"Second dimension of a_indices and length of \"\n                                \"a_shape must match, got \",\n                                num_dims, \" and \", a_shape_t->NumElements()));\n    OP_REQUIRES(ctx, num_dims > 0,\n                errors::InvalidArgument(\"Tensors must not be empty\"));\n    OP_REQUIRES(ctx, a_shape_t->IsSameSize(*b_shape_t),\n                errors::InvalidArgument(\n                    \"Operands do not have the same ranks; got shapes: \",\n                    a_shape_t->SummarizeValue(10), \" and \",\n                    b_shape_t->SummarizeValue(10)));\n    const auto a_shape = a_shape_t->flat<int64>();\n    const auto b_shape = b_shape_t->flat<int64>();\n    for (int i = 0; i < a_shape_t->NumElements(); ++i) {\n      OP_REQUIRES(ctx, a_shape(i) == b_shape(i),\n                  errors::InvalidArgument(\"Operands' shapes do not match: got \",\n                                          a_shape(i), \" and \", b_shape(i),\n                                          \" for dimension \", i));\n    }\n\n    const auto a_indices_mat = a_indices_t->matrix<int64>();\n    const auto b_indices_mat = b_indices_t->matrix<int64>();\n    std::vector<T> a_augmented_values, b_augmented_values;\n    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx\n    UnionSparseIndicesAndValues(a_indices_mat, a_values, a_nnz, b_indices_mat,\n                                b_values, b_nnz, num_dims, &a_augmented_values,\n                                &b_augmented_values, &entries_to_copy);\n\n    // Allocates and fills output tensors.\n    const int64 sum_nnz = a_augmented_values.size();\n    Tensor *output_indices_t, *output_values_t;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({sum_nnz, num_dims}),\n                                        &output_indices_t));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(1, TensorShape({sum_nnz}), &output_values_t));\n    auto output_indices_mat = output_indices_t->matrix<int64>();\n\n    for (int64 i = 0; i < sum_nnz; ++i) {\n      const bool from_a = entries_to_copy[i].first;\n      const int64 idx = entries_to_copy[i].second;\n      output_indices_mat.chip<0>(i) =\n          from_a ? a_indices_mat.chip<0>(idx) : b_indices_mat.chip<0>(idx);\n    }\n\n    // Performs the functor operation using Eigen.\n    //\n    // Note that the two stack-allocated std::vector's may not be aligned. Using\n    // allocate_temp() would've given us aligned storage, but we do not know\n    // their sizes in advance, so we couldn't use allocate_temp() anyway.\n    //\n    // TODO(zongheng): measure if it's worthwhile to somehow force alignment.\n    using UnalignedTensorMap =\n        Eigen::TensorMap<Eigen::Tensor<const T, 1, Eigen::RowMajor>,\n                         Eigen::Unaligned>;\n    auto a_augmented_values_t =\n        UnalignedTensorMap(a_augmented_values.data(), sum_nnz);\n    auto b_augmented_values_t =\n        UnalignedTensorMap(b_augmented_values.data(), sum_nnz);\n    output_values_t->flat<T>().device(ctx->eigen_device<Device>()) =\n        a_augmented_values_t.binaryExpr(b_augmented_values_t,\n                                        typename Functor::func());\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "var determineWebcamStreamType = function (streamUrl) {\n    if (!streamUrl) {\n        throw \"Empty streamUrl. Cannot determine stream type.\";\n    }\n\n    var parsed = validateWebcamUrl(streamUrl);\n    if (!parsed) {\n        throw \"Invalid streamUrl. Cannot determine stream type.\";\n    }\n\n    if (parsed.protocol === \"webrtc:\") {\n        return \"webrtc\";\n    }\n\n    var lastDotPosition = parsed.pathname.lastIndexOf(\".\");\n    if (lastDotPosition !== -1) {\n        var extension = parsed.pathname.substring(lastDotPosition + 1);\n        if (extension.toLowerCase() === \"m3u8\") {\n            return \"hls\";\n        }\n    }\n\n    // By default, 'mjpg' is the stream type.\n    return \"mjpg\";\n};\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static Status Compute(OpKernelContext* context,\n                        const typename TTypes<T, 1>::ConstTensor& values,\n                        const typename TTypes<T, 1>::ConstTensor& value_range,\n                        int32_t nbins, typename TTypes<Tout, 1>::Tensor& out) {\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    Tensor index_to_bin_tensor;\n\n    TF_RETURN_IF_ERROR(context->forward_input_or_allocate_temp(\n        {0}, DataTypeToEnum<int32>::value, TensorShape({values.size()}),\n        &index_to_bin_tensor));\n    auto index_to_bin = index_to_bin_tensor.flat<int32>();\n\n    const double step = static_cast<double>(value_range(1) - value_range(0)) /\n                        static_cast<double>(nbins);\n    const double nbins_minus_1 = static_cast<double>(nbins - 1);\n\n    // We cannot handle NANs in the algorithm below (due to the case to int32)\n    const Eigen::Tensor<int32, 1, 1> nans_tensor =\n        values.isnan().template cast<int32>();\n    const Eigen::Tensor<int32, 0, 1> reduced_tensor = nans_tensor.sum();\n    const int num_nans = reduced_tensor(0);\n    if (num_nans > 0) {\n      return errors::InvalidArgument(\"Histogram values must not contain NaN\");\n    }\n\n    // The calculation is done by finding the slot of each value in `values`.\n    // With [a, b]:\n    //   step = (b - a) / nbins\n    //   (x - a) / step\n    // , then the entries are mapped to output.\n\n    // Bug fix: Switch the order of cwiseMin and int32-casting to avoid\n    // producing a negative index when casting an big int64 number to int32\n    index_to_bin.device(d) =\n        ((values.cwiseMax(value_range(0)) - values.constant(value_range(0)))\n             .template cast<double>() /\n         step)\n            .cwiseMin(nbins_minus_1)\n            .template cast<int32>();\n\n    out.setZero();\n    for (int32_t i = 0; i < index_to_bin.size(); i++) {\n      out(index_to_bin(i)) += Tout(1);\n    }\n    return Status::OK();\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    # We must decode path before validating it\n    path = _decode(path)\n\n    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)\n    if \"#\" in path:\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n\n    return path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_path_with_query_string(scope):\n    path_with_query_string = urllib.parse.quote(\n        scope.get(\"root_path\", \"\") + scope[\"path\"]\n    )\n    if scope[\"query_string\"]:\n        path_with_query_string = \"{}?{}\".format(\n            path_with_query_string, scope[\"query_string\"].decode(\"ascii\")\n        )\n    return path_with_query_string\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < tile_length) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = row_byte_size * tile_length;\n\n        /* realloc to fit whole tile */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < rows_per_strip) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "new_aubio_pitchyinfft (uint_t samplerate, uint_t bufsize)\n{\n  uint_t i = 0, j = 1;\n  smpl_t freq = 0, a0 = 0, a1 = 0, f0 = 0, f1 = 0;\n  aubio_pitchyinfft_t *p = AUBIO_NEW (aubio_pitchyinfft_t);\n  p->winput = new_fvec (bufsize);\n  p->fft = new_aubio_fft (bufsize);\n  if (!p->fft) goto beach;\n  p->fftout = new_fvec (bufsize);\n  p->sqrmag = new_fvec (bufsize);\n  p->yinfft = new_fvec (bufsize / 2 + 1);\n  p->tol = 0.85;\n  p->peak_pos = 0;\n  p->win = new_aubio_window (\"hanningz\", bufsize);\n  p->weight = new_fvec (bufsize / 2 + 1);\n  for (i = 0; i < p->weight->length; i++) {\n    freq = (smpl_t) i / (smpl_t) bufsize *(smpl_t) samplerate;\n    while (freq > freqs[j] && freqs[j] > 0) {\n      AUBIO_DBG(\"freq %3.5f > %3.5f \\tsamplerate %d (Hz) \\t(weight length %d, bufsize %d) %d %d\\n\", freq, freqs[j], samplerate, p->weight->length, bufsize, i, j);\n      j += 1;\n    }\n    a0 = weight[j - 1];\n    f0 = freqs[j - 1];\n    a1 = weight[j];\n    f1 = freqs[j];\n    if (f0 == f1) {           // just in case\n      p->weight->data[i] = a0;\n    } else if (f0 == 0) {     // y = ax+b\n      p->weight->data[i] = (a1 - a0) / f1 * freq + a0;\n    } else {\n      p->weight->data[i] = (a1 - a0) / (f1 - f0) * freq +\n          (a0 - (a1 - a0) / (f1 / f0 - 1.));\n    }\n    while (freq > freqs[j]) {\n      j += 1;\n    }\n    //AUBIO_DBG(\"%f\\n\",p->weight->data[i]);\n    p->weight->data[i] = DB2LIN (p->weight->data[i]);\n    //p->weight->data[i] = SQRT(DB2LIN(p->weight->data[i]));\n  }\n  // check for octave errors above 1300 Hz\n  p->short_period = (uint_t)ROUND(samplerate / 1300.);\n  return p;\n\nbeach:\n  if (p->winput) del_fvec(p->winput);\n  AUBIO_FREE(p);\n  return NULL;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        # follow symlinks to get an accurate normalized path\n        component_root = os.path.realpath(component_root)\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.realpath(os.path.join(component_root, filename))\n\n        # Do NOT expose anything outside of the component root.\n        if os.path.commonprefix([component_root, abspath]) != component_root:\n            self.write(\"forbidden\")\n            self.set_status(403)\n            return\n\n        LOGGER.debug(\"ComponentRequestHandler: GET: %s -> %s\", path, abspath)\n\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except (OSError) as e:\n            LOGGER.error(f\"ComponentRequestHandler: GET {path} read error\", exc_info=e)\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_host(self):\n        \"\"\"Returns the HTTP host using the environment or request headers.\"\"\"\n        # We try three options, in order of decreasing preference.\n        if settings.USE_X_FORWARDED_HOST and (\n            'HTTP_X_FORWARDED_HOST' in self.META):\n            host = self.META['HTTP_X_FORWARDED_HOST']\n        elif 'HTTP_HOST' in self.META:\n            host = self.META['HTTP_HOST']\n        else:\n            # Reconstruct the host using the algorithm from PEP 333.\n            host = self.META['SERVER_NAME']\n            server_port = str(self.META['SERVER_PORT'])\n            if server_port != (self.is_secure() and '443' or '80'):\n                host = '%s:%s' % (host, server_port)\n        return host\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-p\", \"--project_file\", type=str, default=\"project.yml\", help=\"file to describe FL project\")\n    parser.add_argument(\"-w\", \"--workspace\", type=str, default=\"workspace\", help=\"directory used by provision\")\n    parser.add_argument(\"-c\", \"--custom_folder\", type=str, default=\".\", help=\"additional folder to load python codes\")\n    parser.add_argument(\n        \"-u\",\n        \"--ui_tool\",\n        action=\"store_true\",\n        help=\"Run provisioning UI tool to generate project.yml file\",\n    )\n\n    args = parser.parse_args()\n\n    file_path = pathlib.Path(__file__).parent.absolute()\n    current_path = os.getcwd()\n    custom_folder_path = os.path.join(current_path, args.custom_folder)\n    sys.path.append(custom_folder_path)\n    print(\"Path list (sys.path) for python codes loading: {}\".format(sys.path))\n\n    # main project file\n    project_file = args.project_file\n    current_project_yml = os.path.join(current_path, \"project.yml\")\n    if len(sys.argv) == 1 and not os.path.exists(current_project_yml):\n        answer = input(\n            f\"No project.yml found in current folder.  Is it OK to generate one at {current_project_yml} for you? (y/N) \"\n        )\n        if answer.strip().upper() == \"Y\":\n            shutil.copyfile(os.path.join(file_path, \"project.yml\"), current_project_yml)\n            print(f\"{current_project_yml} was created.  Please edit it to fit your FL configuration.\")\n        exit(0)\n\n    if args.ui_tool:\n        ui_helper_path = os.path.join(file_path, \"provision_helper.html\")\n        ui_helper_url = f\"file://{ui_helper_path}\"\n        webbrowser.open_new_tab(ui_helper_url)\n        print(\n            \"\\n******\\n\"\n            \"Now launching provisioning UI tool.\\n\"\n            \"After generating project.yml in the browser and saving it to your local folder,\\n\"\n            \"please re-run provision with -p option, pointing to the generated project.yml, to generate all packages.\\n******\\n\"\n        )\n        exit(0)\n\n    workspace = args.workspace\n    workspace_full_path = os.path.join(current_path, workspace)\n\n    project_full_path = os.path.join(current_path, project_file)\n    print(f\"Project yaml file: {project_full_path}.\")\n\n    project_dict = load_yaml(project_full_path)\n    api_version = project_dict.get(\"api_version\")\n    if api_version not in [3]:\n        raise ValueError(f\"API version expected 3 but found {api_version}\")\n\n    project_name = project_dict.get(\"name\")\n    project_description = project_dict.get(\"description\", \"\")\n    participants = list()\n    for p in project_dict.get(\"participants\"):\n        participants.append(Participant(**p))\n    project = Project(name=project_name, description=project_description, participants=participants)\n\n    builders = list()\n    for b in project_dict.get(\"builders\"):\n        path = b.get(\"path\")\n        args = b.get(\"args\")\n        builders.append(instantiate_class(path, args))\n\n    provisioner = Provisioner(workspace_full_path, builders)\n\n    provisioner.provision(project)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def edit_package():\n    api = flask.current_app.config[\"PYLOAD_API\"]\n    try:\n        pack_id = int(flask.request.form[\"pack_id\"])\n        pack_folder = flask.request.form[\"pack_folder\"].lstrip(f\"{os.path.sep}\").replace(f\"..{os.path.sep}\", f\"\")\n        data = {\n            \"name\": flask.request.form[\"pack_name\"],\n            \"_folder\": pack_folder,\n            \"password\": flask.request.form[\"pack_pws\"],\n        }\n\n        api.set_package_data(pack_id, data)\n        return jsonify(response=\"success\")\n\n    except Exception:\n        return jsonify(False), 500\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_audiences(self):\n        \"\"\"\n        Gets the audiences\n\n        :returns: The valid audiences for the SAML Response\n        :rtype: list\n        \"\"\"\n        audience_nodes = self.__query_assertion('/saml:Conditions/saml:AudienceRestriction/saml:Audience')\n        return [OneLogin_Saml2_Utils.element_text(node) for node in audience_nodes if OneLogin_Saml2_Utils.element_text(node) is not None]\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendEmail(sydent, templateName, mailTo, substitutions):\n        mailFrom = sydent.cfg.get('email', 'email.from')\n        mailTemplateFile = sydent.cfg.get('email', templateName)\n\n        myHostname = sydent.cfg.get('email', 'email.hostname')\n        if myHostname == '':\n            myHostname = socket.getfqdn()\n        midRandom = \"\".join([random.choice(string.ascii_letters) for _ in range(16)])\n        messageid = \"<%d%s@%s>\" % (time_msec(), midRandom, myHostname)\n\n        allSubstitutions = {}\n        allSubstitutions.update(substitutions)\n        allSubstitutions.update({\n            'messageid': messageid,\n            'date': email.utils.formatdate(localtime=False),\n            'to': mailTo,\n            'from': mailFrom,\n        })\n\n        for k,v in allSubstitutions.items():\n            allSubstitutions[k] = v.decode('utf8')\n            allSubstitutions[k+\"_forhtml\"] = cgi.escape(v.decode('utf8'))\n            allSubstitutions[k+\"_forurl\"] = urllib.quote(v)\n\n        mailString = open(mailTemplateFile).read().decode('utf8') % allSubstitutions\n        parsedFrom = email.utils.parseaddr(mailFrom)[1]\n        parsedTo = email.utils.parseaddr(mailTo)[1]\n        if parsedFrom == '' or parsedTo == '':\n            logger.info(\"Couldn't parse from / to address %s / %s\", mailFrom, mailTo)\n            raise EmailAddressException()\n\n        mailServer = sydent.cfg.get('email', 'email.smtphost')\n        mailPort = sydent.cfg.get('email', 'email.smtpport')\n        mailUsername = sydent.cfg.get('email', 'email.smtpusername')\n        mailPassword = sydent.cfg.get('email', 'email.smtppassword')\n        mailTLSMode = sydent.cfg.get('email', 'email.tlsmode')\n        logger.info(\"Sending mail to %s with mail server: %s\" % (mailTo, mailServer,))\n        try:\n            if mailTLSMode == 'SSL' or mailTLSMode == 'TLS':\n                smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname)\n            elif mailTLSMode == 'STARTTLS':\n                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n                smtp.starttls()\n            else:\n                smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n            if mailUsername != '':\n                smtp.login(mailUsername, mailPassword)\n\n            # We're using the parsing above to do basic validation, but instead of\n            # failing it may munge the address it returns. So we should *not* use\n            # that parsed address, as it may not match any validation done\n            # elsewhere.\n            smtp.sendmail(mailFrom, mailTo, mailString.encode('utf-8'))\n            smtp.quit()\n        except Exception as origException:\n            twisted.python.log.err()\n            ese = EmailSendException()\n            ese.cause = origException\n            raise ese\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& in0 = context->input(0);\n    const Tensor& in1 = context->input(1);\n    const int dims = in0.dims();\n    constexpr int kMinDims = 0;\n    constexpr int kMaxDims = 5;\n    OP_REQUIRES(context, kMinDims <= dims && dims <= kMaxDims,\n                errors::Unimplemented(\"inputs rank not in [\", kMinDims, \",\",\n                                      kMaxDims, \"]: \", dims));\n    OP_REQUIRES(\n        context,\n        TensorShapeUtils::IsMatrix(in1.shape()) && in1.dim_size(1) == 2,\n        errors::InvalidArgument(\"paddings must be a matrix with 2 columns: \",\n                                in1.shape().DebugString()));\n    OP_REQUIRES(\n        context, dims == in1.dim_size(0),\n        errors::InvalidArgument(\n            \"The first dimension of paddings must be the rank of inputs\",\n            in1.shape().DebugString(), \" \", in0.shape().DebugString()));\n\n    // Compute the shape of the output tensor, and allocate it.\n    TensorShape output_shape;\n    typename TTypes<Tpaddings>::ConstMatrix paddings = in1.matrix<Tpaddings>();\n    for (int d = 0; d < dims; ++d) {\n      const int64_t before = paddings(d, 0);  // Pad before existing elements.\n      const int64_t after = paddings(d, 1);   // Pad after existing elements.\n      OP_REQUIRES(context, before >= 0 && after >= 0,\n                  errors::InvalidArgument(\n                      \"Paddings must be non-negative: \", before, \", \", after));\n\n      const int64_t in_size = in0.dim_size(d);\n      const int64_t total_padding = before + after;\n      OP_REQUIRES(\n          context, total_padding < in_size && total_padding >= 0,\n          errors::InvalidArgument(\n              \"Total paddings must be less than the input dimension size: \",\n              total_padding, \" was not less than \", in_size));\n\n      const int64_t out_size = in_size - total_padding;\n      if (offset_ == 0) {  // SYMMETRIC mode.\n        OP_REQUIRES(context, before <= out_size && after <= out_size,\n                    errors::InvalidArgument(\"paddings must be no greater \"\n                                            \"than the output dimension size: \",\n                                            before, \", \", after,\n                                            \" greater than \", out_size));\n      } else if (offset_ == 1) {  // REFLECT mode.\n        OP_REQUIRES(context, before < out_size && after < out_size,\n                    errors::InvalidArgument(\"paddings must be less than\"\n                                            \" the output dimension size: \",\n                                            before, \", \", after,\n                                            \" not less than \", out_size));\n      }\n      output_shape.AddDim(out_size);\n    }\n\n    if (output_shape == in0.shape()) {\n      context->set_output(0, in0);\n      return;\n    }\n\n    Tensor scratch;\n    OP_REQUIRES_OK(context, context->allocate_temp(DataTypeToEnum<T>::value,\n                                                   in0.shape(), &scratch));\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n\n#define MIRROR_PAD_GRAD_CASE(k)                                           \\\n  case k: {                                                               \\\n    functor::MirrorPadGrad<Device, T, Tpaddings, k>()(                    \\\n        context->eigen_device<Device>(), To32Bit(output->tensor<T, k>()), \\\n        To32Bit(in0.tensor<T, k>()), paddings, offset_,                   \\\n        To32Bit(scratch.tensor<T, k>()));                                 \\\n    break;                                                                \\\n  }\n\n    // Invoke the dims-specific implementation.\n    switch (dims) {\n      MIRROR_PAD_GRAD_CASE(1);\n      MIRROR_PAD_GRAD_CASE(2);\n      MIRROR_PAD_GRAD_CASE(3);\n      MIRROR_PAD_GRAD_CASE(4);\n      MIRROR_PAD_GRAD_CASE(5);\n      default:\n        OP_REQUIRES(context, false,\n                    errors::InvalidArgument(\"Unsupported rank: \",\n                                            in0.shape().DebugString()));\n    }\n#undef MIRROR_PAD_GRAD_CASE\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                SpaceToBatchNDContext* op_context) {\n  TfLiteIntArray* input_size = op_context->input->dims;\n  const int32* block_shape = GetTensorData<int32>(op_context->block_shape);\n  const int32* paddings_data = GetTensorData<int32>(op_context->paddings);\n\n  int spatial_dims_num = input_size->size - 2;\n  // Block_shape should be a 1D tensor with dimension [spatial_dims_num].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->block_shape), 1);\n  TF_LITE_ENSURE_EQ(context, op_context->block_shape->dims->data[0],\n                    spatial_dims_num);\n  // Paddings should be a 2D tensor with dimension [spatial_dims_num, 2].\n  TF_LITE_ENSURE_EQ(context, NumDimensions(op_context->paddings), 2);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[0],\n                    spatial_dims_num);\n  TF_LITE_ENSURE_EQ(context, op_context->paddings->dims->data[1], 2);\n\n  TfLiteIntArray* output_size = TfLiteIntArrayCopy(input_size);\n\n  // Ensures the input height and width (with padding) is a multiple of block\n  // shape height and width.\n  int output_batch_size = input_size->data[0];\n  for (int dim = 0; dim < spatial_dims_num; ++dim) {\n    int final_dim_size = (input_size->data[dim + 1] + paddings_data[dim * 2] +\n                          paddings_data[dim * 2 + 1]);\n    TF_LITE_ENSURE(context, block_shape[dim] != 0);\n    TF_LITE_ENSURE_EQ(context, final_dim_size % block_shape[dim], 0);\n    output_size->data[dim + 1] = final_dim_size / block_shape[dim];\n    output_batch_size *= block_shape[dim];\n  }\n\n  output_size->data[0] = output_batch_size;\n  output_size->data[input_size->size - 1] =\n      input_size->data[input_size->size - 1];\n\n  return context->ResizeTensor(context, op_context->output, output_size);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask2(\n        self,\n        text,\n        mode=\"\",\n        direction=None,\n        features=None,\n        language=None,\n        stroke_width=0,\n        anchor=None,\n        ink=0,\n        start=None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. If the font has embedded color data, the bitmap\n        should have mode ``RGBA``. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n                          .. versionadded:: 4.2.0\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n                         .. versionadded:: 4.2.0\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n                         .. versionadded:: 6.0.0\n\n        :param stroke_width: The width of the text stroke.\n\n                         .. versionadded:: 6.2.0\n\n        :param anchor:  The text anchor alignment. Determines the relative location of\n                        the anchor to the text. The default alignment is top left.\n                        See :ref:`text-anchors` for valid values.\n\n                         .. versionadded:: 8.0.0\n\n        :param ink: Foreground ink for rendering in RGBA mode.\n\n                         .. versionadded:: 8.0.0\n\n        :param start: Tuple of horizontal and vertical offset, as text may render\n                      differently when starting at fractional coordinates.\n\n                         .. versionadded:: 9.4.0\n\n        :return: A tuple of an internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module, and the text offset, the\n                 gap between the starting coordinate and the first marking\n        \"\"\"\n        _string_length_check(text)\n        if start is None:\n            start = (0, 0)\n        im, size, offset = self.font.render(\n            text,\n            Image.core.fill,\n            mode,\n            direction,\n            features,\n            language,\n            stroke_width,\n            anchor,\n            ink,\n            start[0],\n            start[1],\n            Image.MAX_IMAGE_PIXELS,\n        )\n        Image._decompression_bomb_check(size)\n        return im, offset\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _deserialize_index(self):\n        logger.info(f\"Loading index from {self.index_path}\")\n        resolved_index_path = self._resolve_path(self.index_path, self.INDEX_FILENAME + \".index.dpr\")\n        self.index = faiss.read_index(resolved_index_path)\n        resolved_meta_path = self._resolve_path(self.index_path, self.INDEX_FILENAME + \".index_meta.dpr\")\n        if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n            raise ValueError(\n                \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n                \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n                \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n                \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n            )\n        with open(resolved_meta_path, \"rb\") as metadata_file:\n            self.index_id_to_db_id = pickle.load(metadata_file)\n        assert (\n            len(self.index_id_to_db_id) == self.index.ntotal\n        ), \"Deserialized index_id_to_db_id should match faiss index size\"\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def execute(self, image_id):\n        \"\"\"Create temp file into store and return path to it\n\n        :param image_id: Glance Image ID\n        \"\"\"\n        # NOTE(flaper87): We've decided to use a separate `work_dir` for\n        # this task - and tasks coming after this one - as a way to expect\n        # users to configure a local store for pre-import works on the image\n        # to happen.\n        #\n        # While using any path should be \"technically\" fine, it's not what\n        # we recommend as the best solution. For more details on this, please\n        # refer to the comment in the `_ImportToStore.execute` method.\n        data = script_utils.get_image_data_iter(self.uri)\n\n        path = self.store.add(image_id, data, 0, context=None)[0]\n\n        try:\n            # NOTE(flaper87): Consider moving this code to a common\n            # place that other tasks can consume as well.\n            stdout, stderr = putils.trycmd('qemu-img', 'info',\n                                           '--output=json', path,\n                                           log_errors=putils.LOG_ALL_ERRORS)\n        except OSError as exc:\n            with excutils.save_and_reraise_exception():\n                msg = (_LE('Failed to execute security checks on the image '\n                           '%(task_id)s: %(exc)s') %\n                       {'task_id': self.task_id, 'exc': exc.message})\n                LOG.error(msg)\n\n        metadata = json.loads(stdout)\n\n        backing_file = metadata.get('backing-filename')\n        if backing_file is not None:\n            msg = _(\"File %(path)s has invalid backing file \"\n                    \"%(bfile)s, aborting.\") % {'path': path,\n                                               'bfile': backing_file}\n            raise RuntimeError(msg)\n\n        return path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        special=None,\n        min_freq=0,\n        max_size=None,\n        lower_case=False,\n        delimiter=None,\n        vocab_file=None,\n        pretrained_vocab_file: str = None,\n        never_split=None,\n        unk_token=\"<unk>\",\n        eos_token=\"<eos>\",\n        additional_special_tokens=[\"<formula>\"],\n        language=\"en\",\n        **kwargs,\n    ):\n        logger.error(\n            \"`TransfoXL` was deprecated due to security issues linked to `pickle.load` in `TransfoXLTokenizer`. \"\n            \"See more details on this model's documentation page: \"\n            \"`https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/transfo-xl.md`.\"\n        )\n\n        requires_backends(self, \"sacremoses\")\n        if special is None:\n            special = []\n        self.counter = Counter()\n        self.special = special\n        self.min_freq = min_freq\n        self.max_size = max_size\n        self.lower_case = lower_case\n        self.delimiter = delimiter\n        self.vocab_file = vocab_file\n        self.punctuation_symbols = '!\"#$%&()*+,-./\\\\:;<=>?@[\\\\]^_`{|}~'\n        self.punction_without_space_before_pattern = re.compile(rf\"[^\\s][{self.punctuation_symbols}]\")\n        self.punctuation_with_space_around_pattern = self._compile_space_around_punctuation_pattern()\n        self.language = language\n        self.moses_punct_normalizer = sm.MosesPunctNormalizer(language)\n        self.moses_tokenizer = sm.MosesTokenizer(language)\n        self.moses_detokenizer = sm.MosesDetokenizer(language)\n        self.idx2sym = []\n        self.sym2idx = OrderedDict()\n        # This try... catch... is not beautiful but honestly this tokenizer was not made to be used\n        # in a library like ours, at all.\n        try:\n            vocab_dict = None\n            if pretrained_vocab_file is not None:\n                # Priority on pickle files (support PyTorch and TF)\n                if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n                    raise ValueError(\n                        \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is \"\n                        \"potentially malicious. It's recommended to never unpickle data that could have come from an \"\n                        \"untrusted source, or that could have been tampered with. If you already verified the pickle \"\n                        \"data and decided to use it, you can set the environment variable \"\n                        \"`TRUST_REMOTE_CODE` to `True` to allow it.\"\n                    )\n                with open(pretrained_vocab_file, \"rb\") as f:\n                    vocab_dict = pickle.load(f)\n\n                # Loading a torch-saved transfo-xl vocab dict with pickle results in an integer\n                # Entering this if statement means that we tried to load a torch-saved file with pickle, and we failed.\n                # We therefore load it with torch, if it's available.\n                if isinstance(vocab_dict, int):\n                    if not is_torch_available():\n                        raise ImportError(\n                            \"Not trying to load dict with PyTorch as you need to install pytorch to load \"\n                            \"from a PyTorch pretrained vocabulary, \"\n                            \"or activate it with environment variables USE_TORCH=1 and USE_TF=0.\"\n                        )\n                    vocab_dict = torch.load(pretrained_vocab_file)\n\n            if vocab_dict is not None:\n                for key, value in vocab_dict.items():\n                    if key not in self.__dict__ or key in [\"sym2idx\", \"idx2sym\"]:\n                        self.__dict__[key] = value\n            elif vocab_file is not None:\n                self.build_vocab()\n\n        except Exception as e:\n            raise ValueError(\n                f\"Unable to parse file {pretrained_vocab_file}. Unknown format. \"\n                \"If you tried to load a model saved through TransfoXLTokenizerFast, \"\n                \"please note they are not compatible.\"\n            ) from e\n\n        if vocab_file is not None:\n            self.build_vocab()\n\n        super().__init__(\n            special=special,\n            min_freq=min_freq,\n            max_size=max_size,\n            lower_case=lower_case,\n            delimiter=delimiter,\n            vocab_file=vocab_file,\n            pretrained_vocab_file=pretrained_vocab_file,\n            never_split=never_split,\n            unk_token=unk_token,\n            eos_token=eos_token,\n            additional_special_tokens=additional_special_tokens,\n            language=language,\n            **kwargs,\n        )\n\n        # these are not required to initialize the parent class as only used when tokenizing.\n        if never_split is None:\n            never_split = self.all_special_tokens\n        self.never_split = never_split\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_package(self, name, links, dest=Destination.QUEUE):\n        \"\"\"\n        Adds a package, with links to desired destination.\n\n        :param name: name of the new package\n        :param links: list of urls\n        :param dest: `Destination`\n        :return: package id of the new package\n        \"\"\"\n        if self.pyload.config.get(\"general\", \"folder_per_package\"):\n            folder = name\n        else:\n            folder = \"\"\n\n        folder = (\n            folder.replace(\"http://\", \"\")\n            .replace(\"https://\", \"\")\n            .replace(\"../\", \"_\")\n            .replace(\"..\\\\\", \"_\")\n            .replace(\":\", \"\")\n            .replace(\"/\", \"_\")\n            .replace(\"\\\\\", \"_\")\n        )\n\n        package_id = self.pyload.files.add_package(name, folder, Destination(dest))\n\n        self.pyload.files.add_links(links, package_id)\n\n        self.pyload.log.info(\n            self._(\"Added package {name} containing {count:d} links\").format(\n                name=name, count=len(links)\n            )\n        )\n\n        self.pyload.files.save()\n\n        return package_id\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _serve_request(self, environ, start_response):\n        # https://bugs.python.org/issue16679\n        # https://github.com/bottlepy/bottle/blob/f9b1849db4/bottle.py#L984\n        path = environ[\"PATH_INFO\"].encode(\"latin-1\").decode(\"utf-8\", \"ignore\")\n\n        m = re.fullmatch(r\"/livereload/([0-9]+)/[0-9]+\", path)\n        if m:\n            epoch = int(m[1])\n            start_response(\"200 OK\", [(\"Content-Type\", \"text/plain\")])\n\n            def condition():\n                return self._visible_epoch > epoch\n\n            with self._epoch_cond:\n                if not condition():\n                    # Stall the browser, respond as soon as there's something new.\n                    # If there's not, respond anyway after a minute.\n                    self._log_poll_request(environ.get(\"HTTP_REFERER\"), request_id=path)\n                    self._epoch_cond.wait_for(condition, timeout=self.poll_response_timeout)\n                return [b\"%d\" % self._visible_epoch]\n\n        if path == \"/js/livereload.js\":\n            file_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"livereload.js\")\n        elif path.startswith(self.mount_path):\n            rel_file_path = path[len(self.mount_path):].lstrip(\"/\")\n            if path.endswith(\"/\"):\n                rel_file_path += \"index.html\"\n            file_path = os.path.join(self.root, rel_file_path)\n        elif path == \"/\":\n            start_response(\"302 Found\", [(\"Location\", self.mount_path)])\n            return []\n        else:\n            return None  # Not found\n\n        # Wait until the ongoing rebuild (if any) finishes, so we're not serving a half-built site.\n        with self._epoch_cond:\n            self._epoch_cond.wait_for(lambda: self._visible_epoch == self._wanted_epoch)\n            epoch = self._visible_epoch\n\n        try:\n            file = open(file_path, \"rb\")\n        except OSError:\n            if not path.endswith(\"/\") and os.path.isfile(os.path.join(file_path, \"index.html\")):\n                start_response(\"302 Found\", [(\"Location\", path + \"/\")])\n                return []\n            return None  # Not found\n\n        if file_path.endswith(\".html\"):\n            with file:\n                content = file.read()\n            content = self._inject_js_into_html(content, epoch)\n            file = io.BytesIO(content)\n            content_length = len(content)\n        else:\n            content_length = os.path.getsize(file_path)\n\n        content_type = self._guess_type(file_path)\n        start_response(\n            \"200 OK\", [(\"Content-Type\", content_type), (\"Content-Length\", str(content_length))]\n        )\n        return wsgiref.util.FileWrapper(file)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _test_setup_settings(pxe_once=1):\n\n    # rewrite modules.conf so we know we can use the testing module\n    # for xmlrpc rw testing (Makefile will put the user value back)\n   \n    import yaml\n    import Cheetah.Template as Template\n\n    MODULES_TEMPLATE = \"installer_templates/settings.template\"\n    DEFAULTS = \"installer_templates/defaults\"\n    fh = open(DEFAULTS)\n    data = yaml.safe_load(fh.read())\n    fh.close()\n    data[\"pxe_once\"] = pxe_once\n\n    t = Template.Template(file=MODULES_TEMPLATE, searchList=[data])\n    open(\"/etc/cobbler/settings\",\"w+\").write(t.respond())\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _sentence_split(self, string, settings):\n        abbreviations = self._get_abbreviations(settings=settings)\n        digit_abbreviations = ['[0-9]']  # numeric date with full stop\n        abbreviation_string = ''\n\n        for abbreviation in abbreviations:\n            abbreviation_string += '(?<! ' + abbreviation[:-1] + ')'  # negative lookbehind\n        if self.shortname in ['fi', 'cs', 'hu', 'de', 'da']:\n            for digit_abbreviation in digit_abbreviations:\n                abbreviation_string += '(?<!' + digit_abbreviation + ')'  # negative lookbehind\n\n        splitters_dict = {1: r'[\\.!?;\u2026\\r\\n]+(?:\\s|$)*',  # most European, Tagalog, Hebrew, Georgian,\n                          # Indonesian, Vietnamese\n                          2: r'[\\.!?;\u2026\\r\\n]+(\\s*[\u00a1\u00bf]*|$)|[\u00a1\u00bf]+',  # Spanish\n                          3: r'[|!?;\\r\\n]+(?:\\s|$)+',  # Hindi and Bangla\n                          4: r'[\u3002\u2026\u2025\\.!?\uff1f\uff01;\\r\\n]+(?:\\s|$)+',  # Japanese and Chinese\n                          5: r'[\\r\\n]+',  # Thai\n                          6: r'[\\r\\n\u061f!\\.\u2026]+(?:\\s|$)+'}  # Arabic and Farsi\n        if 'sentence_splitter_group' not in self.info:\n            split_reg = abbreviation_string + splitters_dict[1]\n            sentences = re.split(split_reg, string)\n        else:\n            split_reg = abbreviation_string + splitters_dict[self.info['sentence_splitter_group']]\n            sentences = re.split(split_reg, string)\n\n        sentences = filter(None, sentences)\n        return sentences\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& x = context->input(0);\n    const Tensor& y = context->input(1);\n    const float min_x = context->input(2).flat<float>()(0);\n    const float max_x = context->input(3).flat<float>()(0);\n    const float min_y = context->input(4).flat<float>()(0);\n    const float max_y = context->input(5).flat<float>()(0);\n\n    BCast bcast(BCast::FromShape(x.shape()), BCast::FromShape(y.shape()));\n    if (!bcast.IsValid()) {\n      context->SetStatus(errors::InvalidArgument(\n          \"Incompatible shapes: \", x.shape().DebugString(), \" vs. \",\n          y.shape().DebugString()));\n      return;\n    }\n    Tensor* z;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                0, BCast::ToShape(bcast.output_shape()), &z));\n\n    // Make sure that we have valid quantization ranges for the input buffers.\n    // If the difference between the min and max is negative or zero, it makes\n    // it hard to do meaningful intermediate operations on the values.\n    OP_REQUIRES(context, (max_x > min_x),\n                errors::InvalidArgument(\"max_x must be larger than min_x.\"));\n    OP_REQUIRES(context, (max_y > min_y),\n                errors::InvalidArgument(\"max_y must be larger than min_y.\"));\n    const T* x_data = x.flat<T>().data();\n    const T* y_data = y.flat<T>().data();\n    Toutput* z_data = z->flat<Toutput>().data();\n\n    // We want the range of the output to be symmetrical around zero so that\n    // adding zero leaves the result unchanged, and to contain the largest of\n    // the two input values with some room to spare.\n    const float smallest_min = std::min(min_x, min_y);\n    const float largest_max = std::max(max_x, max_y);\n    const float biggest_range =\n        std::max(std::abs(smallest_min), std::abs(largest_max));\n    const float output_range = (biggest_range * (1 << 14));\n    const float min_z_value = -output_range;\n    const float max_z_value = output_range;\n\n    const int ndims = bcast.x_reshape().size();\n    if (ndims <= 1) {\n      if (x.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, y_data, min_y, max_y,\n                                   y.NumElements(), x_data[0], min_x, max_x,\n                                   min_z_value, max_z_value, z_data);\n      } else if (y.NumElements() == 1) {\n        ScalarAddition<T, Toutput>(context, x_data, min_x, max_x,\n                                   x.NumElements(), y_data[0], min_y, max_y,\n                                   min_z_value, max_z_value, z_data);\n      } else {\n        VectorAddition<T, Toutput>(context, x_data, min_x, max_x, y_data, min_y,\n                                   max_y, x.NumElements(), min_z_value,\n                                   max_z_value, z_data);\n      }\n    } else if (ndims == 2) {\n      const T* vector_data;\n      int64 vector_num_elements;\n      float vector_min;\n      float vector_max;\n      const T* tensor_data;\n      int64 tensor_num_elements;\n      float tensor_min;\n      float tensor_max;\n      if (x.NumElements() < y.NumElements()) {\n        vector_data = x_data;\n        vector_num_elements = x.NumElements();\n        vector_min = min_x;\n        vector_max = max_x;\n        tensor_data = y_data;\n        tensor_num_elements = y.NumElements();\n        tensor_min = min_y;\n        tensor_max = max_y;\n      } else {\n        vector_data = y_data;\n        vector_num_elements = y.NumElements();\n        vector_min = min_y;\n        vector_max = max_y;\n        tensor_data = x_data;\n        tensor_num_elements = x.NumElements();\n        tensor_min = min_x;\n        tensor_max = max_x;\n      }\n      OP_REQUIRES(context, vector_num_elements > 0,\n                  errors::InvalidArgument(\"Must have some elements to add\"));\n      VectorTensorAddition<T, Toutput>(\n          vector_data, vector_min, vector_max, vector_num_elements, tensor_data,\n          tensor_min, tensor_max, tensor_num_elements, min_z_value, max_z_value,\n          z_data);\n    } else {\n      LOG(INFO) << \"ndims=\" << ndims;\n      LOG(INFO) << \"bcast.x_reshape()=\"\n                << TensorShape(bcast.x_reshape()).DebugString();\n      LOG(INFO) << \"bcast.y_reshape()=\"\n                << TensorShape(bcast.y_reshape()).DebugString();\n      LOG(INFO) << \"bcast.x_bcast()=\"\n                << TensorShape(bcast.x_bcast()).DebugString();\n      LOG(INFO) << \"bcast.y_bcast()=\"\n                << TensorShape(bcast.y_bcast()).DebugString();\n\n      context->SetStatus(errors::Unimplemented(\n          \"Broadcast between \", context->input(0).shape().DebugString(),\n          \" and \", context->input(1).shape().DebugString(),\n          \" is not supported yet.\"));\n      return;\n    }\n\n    Tensor* z_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &z_min));\n    z_min->flat<float>()(0) = min_z_value;\n\n    Tensor* z_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &z_max));\n    z_max->flat<float>()(0) = max_z_value;\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status KernelAndDeviceOp::Run(\n    ScopedStepContainer* step_container, const EagerKernelArgs& inputs,\n    std::vector<EagerKernelRet>* outputs,\n    CancellationManager* cancellation_manager,\n    const absl::optional<EagerRemoteFunctionParams>& remote_func_params) {\n  OpKernelContext::Params params;\n  params.device = device_;\n  params.frame_iter = FrameAndIter(0, 0);\n  params.inputs = inputs.GetTensorValues();\n  params.op_kernel = kernel_.get();\n  params.resource_manager = device_->resource_manager();\n  params.input_alloc_attrs = &input_alloc_attrs_;\n  params.output_attr_array = output_alloc_attrs_.data();\n  params.function_library = flr_;\n  params.slice_reader_cache = &slice_reader_cache_;\n  params.rendezvous = rendezvous_;\n  OpExecutionState* op_execution_state = nullptr;\n\n  CancellationManager default_cancellation_manager;\n  if (cancellation_manager) {\n    params.cancellation_manager = cancellation_manager;\n  } else if (kernel_->is_deferred()) {\n    op_execution_state = new OpExecutionState;\n    params.cancellation_manager = &op_execution_state->cancellation_manager;\n    params.inc_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Ref();\n    };\n    params.dec_num_deferred_ops_function = [op_execution_state]() {\n      op_execution_state->Unref();\n    };\n  } else {\n    params.cancellation_manager = &default_cancellation_manager;\n  }\n\n  params.log_memory = log_memory_;\n\n  params.runner = get_runner();\n\n  params.step_container =\n      step_container == nullptr ? &step_container_ : step_container;\n  auto step_container_cleanup = gtl::MakeCleanup([step_container, this] {\n    if (step_container == nullptr) {\n      this->step_container_.CleanUp();\n    }\n  });\n\n  params.collective_executor =\n      collective_executor_ ? collective_executor_->get() : nullptr;\n\n  OpKernelContext context(&params);\n\n  {\n    port::ScopedFlushDenormal flush;\n    port::ScopedSetRound round(FE_TONEAREST);\n    // 'AnnotatedTraceMe' will trace both scheduling time on host and execution\n    // time on device of the OpKernel.\n    profiler::AnnotatedTraceMe activity(\n        [&] { return kernel_->TraceString(context, /*verbose=*/false); },\n        profiler::TraceMeLevel::kInfo);\n    device_->Compute(kernel_.get(), &context);\n  }\n\n  // Clean up execution op_execution_state if deferred ops aren't running.\n  if (op_execution_state != nullptr) {\n    op_execution_state->Unref();\n  }\n\n  if (!context.status().ok()) return context.status();\n\n  if (outputs != nullptr) {\n    outputs->clear();\n    for (int i = 0; i < context.num_outputs(); ++i) {\n      const auto* output_tensor = context.mutable_output(i);\n      if (output_tensor != nullptr) {\n        outputs->push_back(Tensor(*output_tensor));\n      } else {\n        outputs->push_back(Tensor());\n      }\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
