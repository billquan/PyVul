{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32 lower_diag_index = 0;\n    int32 upper_diag_index = 0;\n    int32 num_rows = -1;\n    int32 num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n      num_rows = context->input(2).flat<int32>()(0);\n      num_cols = context->input(3).flat<int32>()(0);\n      padding_value = context->input(4).flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32 min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32 min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\n  if (sq_op.getType().cast<ShapedType>().getRank() - 1 ==\n          *axis.getValues<int>().begin() ||\n      *axis.getValues<int>().begin() == -1) {\n    return true;\n  }\n  if (sq_op.getType().cast<ShapedType>().getRank() != axis.getNumElements()) {\n    return false;\n  }\n  auto shape = sq_op.getType().cast<ShapedType>();\n  SmallVector<int, 4> elems{axis.getValues<int>().begin(),\n                            axis.getValues<int>().end()};\n  for (int i = 0; i < shape.getRank(); ++i) {\n    if (i != elems[i]) return false;\n  }\n  return true;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "aubio_notes_t * new_aubio_notes (const char_t * method,\n    uint_t buf_size, uint_t hop_size, uint_t samplerate) {\n  aubio_notes_t *o = AUBIO_NEW(aubio_notes_t);\n\n  const char_t * onset_method = \"default\";\n  const char_t * pitch_method = \"default\";\n\n  o->onset_buf_size = buf_size;\n  o->pitch_buf_size = buf_size * 4;\n  o->hop_size = hop_size;\n\n  o->onset_threshold = 0.;\n  o->pitch_tolerance = 0.;\n\n  o->samplerate = samplerate;\n\n  o->median = 6;\n\n  o->isready = 0;\n\n  o->onset = new_aubio_onset (onset_method, o->onset_buf_size, o->hop_size, o->samplerate);\n  if (o->onset_threshold != 0.) aubio_onset_set_threshold (o->onset, o->onset_threshold);\n  o->onset_output = new_fvec (1);\n\n  o->pitch = new_aubio_pitch (pitch_method, o->pitch_buf_size, o->hop_size, o->samplerate);\n  if (o->pitch == NULL) goto fail;\n  if (o->pitch_tolerance != 0.) aubio_pitch_set_tolerance (o->pitch, o->pitch_tolerance);\n  aubio_pitch_set_unit (o->pitch, \"midi\");\n  o->pitch_output = new_fvec (1);\n\n  if (strcmp(method, \"default\") != 0) {\n    AUBIO_ERR(\"notes: unknown notes detection method \\\"%s\\\"\\n\", method);\n    goto fail;\n  }\n  o->note_buffer = new_fvec(o->median);\n  o->note_buffer2 = new_fvec(o->median);\n\n  o->curnote = -1.;\n  o->newnote = 0.;\n\n  aubio_notes_set_silence(o, AUBIO_DEFAULT_NOTES_SILENCE);\n  aubio_notes_set_minioi_ms (o, AUBIO_DEFAULT_NOTES_MINIOI_MS);\n\n  o->last_onset_level = AUBIO_DEFAULT_NOTES_SILENCE;\n  o->release_drop_level = AUBIO_DEFAULT_NOTES_RELEASE_DROP;\n\n  return o;\n\nfail:\n  del_aubio_notes(o);\n  return NULL;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status UncompressElement(const CompressedElement& compressed,\n                         std::vector<Tensor>* out) {\n  int num_components = compressed.component_metadata_size();\n  out->clear();\n  out->reserve(num_components);\n\n  // Step 1: Prepare the memory that we will uncompress into.\n  std::vector<struct iovec> iov(num_components);\n  // We use tstring for access to resize_uninitialized.\n  std::vector<tstring> tensor_proto_strs;\n  // num_components is a conservative estimate. It is important to reserve\n  // vector space so that the vector doesn't resize itself, which could\n  // invalidate pointers to its strings' data.\n  tensor_proto_strs.reserve(num_components);\n  int64 total_size = 0;\n  for (int i = 0; i < num_components; ++i) {\n    const CompressedComponentMetadata& metadata =\n        compressed.component_metadata(i);\n    if (DataTypeCanUseMemcpy(metadata.dtype())) {\n      out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n      TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n      iov[i].iov_base = buffer->data();\n      iov[i].iov_len = buffer->size();\n    } else {\n      // Allocate an empty Tensor. We will fill it out later after\n      // uncompressing into the tensor_proto_str.\n      out->emplace_back();\n      tensor_proto_strs.emplace_back();\n      tstring& tensor_proto_str = tensor_proto_strs.back();\n      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());\n      iov[i].iov_base = tensor_proto_str.mdata();\n      iov[i].iov_len = tensor_proto_str.size();\n    }\n    total_size += iov[i].iov_len;\n  }\n\n  // Step 2: Uncompress into the iovec.\n  const std::string& compressed_data = compressed.data();\n  size_t uncompressed_size;\n  if (!port::Snappy_GetUncompressedLength(\n          compressed_data.data(), compressed_data.size(), &uncompressed_size)) {\n    return errors::Internal(\n        \"Could not get snappy uncompressed length. Compressed data size: \",\n        compressed_data.size());\n  }\n  if (uncompressed_size != static_cast<size_t>(total_size)) {\n    return errors::Internal(\n        \"Uncompressed size mismatch. Snappy expects \", uncompressed_size,\n        \" whereas the tensor metadata suggests \", total_size);\n  }\n  if (!port::Snappy_UncompressToIOVec(compressed_data.data(),\n                                      compressed_data.size(), iov.data(),\n                                      num_components)) {\n    return errors::Internal(\"Failed to perform snappy decompression.\");\n  }\n\n  // Step 3: Deserialize tensor proto strings to tensors.\n  int tensor_proto_strs_index = 0;\n  for (int i = 0; i < num_components; ++i) {\n    if (DataTypeCanUseMemcpy(compressed.component_metadata(i).dtype())) {\n      continue;\n    }\n    TensorProto tp;\n    if (!tp.ParseFromString(tensor_proto_strs[tensor_proto_strs_index++])) {\n      return errors::Internal(\"Could not parse TensorProto\");\n    }\n    if (!out->at(i).FromProto(tp)) {\n      return errors::Internal(\"Could not parse Tensor\");\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_pkcs7_certificates(self, p7) -> typing.List[x509.Certificate]:\n        nid = self._lib.OBJ_obj2nid(p7.type)\n        self.openssl_assert(nid != self._lib.NID_undef)\n        if nid != self._lib.NID_pkcs7_signed:\n            raise UnsupportedAlgorithm(\n                \"Only basic signed structures are currently supported. NID\"\n                \" for this data was {}\".format(nid),\n                _Reasons.UNSUPPORTED_SERIALIZATION,\n            )\n\n        sk_x509 = p7.d.sign.cert\n        num = self._lib.sk_X509_num(sk_x509)\n        certs = []\n        for i in range(num):\n            x509 = self._lib.sk_X509_value(sk_x509, i)\n            self.openssl_assert(x509 != self._ffi.NULL)\n            cert = self._ossl2cert(x509)\n            certs.append(cert)\n\n        return certs\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    Tensor val;\n    OP_REQUIRES_OK(ctx, ctx->session_state()->GetTensor(name, &val));\n    ctx->set_output(0, val);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \"elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status GraphDefImporter::ConvertNodeDef(OpBuilder &builder, ConversionState &s,\n                                        const NodeDef &node) {\n  VLOG(4) << \"Importing: \" << node.name();\n  OperationState state(ConvertLocation(node), absl::StrCat(\"tfg.\", node.op()));\n\n  // The GraphImporter does light shape inference, but here we will defer all of\n  // that to the shape inference pass.\n  const OpDef *op_def;\n  const OpRegistrationData *op_reg_data = nullptr;\n  if ((op_reg_data = registry_.LookUp(node.op()))) {\n    op_def = &op_reg_data->op_def;\n  } else {\n    auto it = function_op_defs_.find(node.op());\n    if (it == function_op_defs_.end())\n      return InvalidArgument(\"Unable to find OpDef for \", node.op());\n    op_def = it->second;\n  }\n\n  // Import the attributes. Reserve `+3` for `device`,`name`, and `fulltype`.\n  state.attributes.reserve(node.attr_size() + 3);\n  if (!node.device().empty()) {\n    state.addAttribute(dialect_->getDeviceAttrIdentifier(),\n                       b_.getStringAttr(node.device()));\n  }\n  if (!node.name().empty()) {\n    state.addAttribute(dialect_->getNameAttrIdentifier(),\n                       b_.getStringAttr(node.name()));\n  }\n\n  // If the op doesn't have a FullType, try to infer one.\n  const auto add_full_type = [&](const FullTypeDef &full_type_def) {\n    TF_ASSIGN_OR_RETURN(tf_type::FullTypeAttr full_type,\n                        ConvertAttribute(full_type_def, b_, dialect_));\n    state.addAttribute(dialect_->getFullTypeAttrIdentifier(), full_type);\n    return ::tensorflow::OkStatus();\n  };\n  if (node.has_experimental_type()) {\n    TF_RETURN_IF_ERROR(add_full_type(node.experimental_type()));\n  } else if (op_reg_data && op_reg_data->type_ctor) {\n    FullTypeDef full_type_def;\n    TF_RETURN_IF_ERROR(\n        tensorflow::full_type::SpecializeType(node, *op_def, full_type_def));\n    TF_RETURN_IF_ERROR(add_full_type(full_type_def));\n  }\n\n  for (auto &name_attr : node.attr()) {\n    if (name_attr.first.empty())\n      return InvalidArgument(\"Node \", node.name(), \" has an empty attr name\");\n    TF_ASSIGN_OR_RETURN(Attribute attr,\n                        ConvertAttributeValue(name_attr.second, b_, dialect_));\n    state.addAttribute(name_attr.first, attr);\n  }\n\n  // Add missing default attributes.\n  for (const auto &attr_def : op_def->attr()) {\n    if (attr_def.has_default_value() &&\n        !state.attributes.get(attr_def.name())) {\n      TF_ASSIGN_OR_RETURN(\n          Attribute attr,\n          ConvertAttributeValue(attr_def.default_value(), b_, dialect_));\n      state.addAttribute(attr_def.name(), attr);\n    }\n  }\n\n  // Get the result types. Ops can have multiple named results. Track the\n  // segment sizes.\n  SmallVector<std::pair<unsigned, unsigned>> result_segments;\n  result_segments.reserve(op_def->output_arg_size());\n  state.types.reserve(op_def->output_arg_size() + 1);\n  for (const OpDef::ArgDef &def : op_def->output_arg()) {\n    unsigned index = state.types.size();\n    TF_ASSIGN_OR_RETURN(unsigned size,\n                        ArgNumType(state.attributes, def, state.types));\n    result_segments.emplace_back(index, size);\n  }\n  state.types.push_back(dialect_->getControlType());\n\n  // Collect the operands. Set backedges to a placeholder and resolve them\n  // later.\n  state.operands.reserve(node.input_size());\n  SmallVector<Value> control_operands;\n  struct BackedgeResolution {\n    ResultInfo *info;\n    size_t operand_index;\n    ResultId id;\n  };\n  SmallVector<BackedgeResolution> unresolved_data_operands,\n      unresolved_control_operands;\n  for (const std::string &input : node.input()) {\n    TF_ASSIGN_OR_RETURN(Result result, GetResult(s, input));\n    if (result.control) {\n      if (result.info) {\n        unresolved_control_operands.push_back(BackedgeResolution{\n            result.info, control_operands.size(), result.id});\n      }\n      control_operands.push_back(result.control);\n    } else {\n      if (result.info) {\n        unresolved_data_operands.push_back(\n            BackedgeResolution{result.info, state.operands.size(), result.id});\n      }\n      state.operands.push_back(result.data);\n    }\n  }\n  unsigned num_data_operands = state.operands.size();\n  state.addOperands(control_operands);\n\n  // Create the op and record any unresolved operands.\n  Operation *op = builder.create(state);\n  for (const BackedgeResolution &r : unresolved_data_operands) {\n    r.info->backedges.push_back(\n        Backedge{r.id, &op->getOpOperand(r.operand_index)});\n  }\n  for (const BackedgeResolution &r : unresolved_control_operands) {\n    r.info->backedges.push_back(\n        Backedge{r.id, &op->getOpOperand(num_data_operands + r.operand_index)});\n  }\n\n  std::unique_ptr<ResultInfo> &info = s[node.name()];\n  if (!info) {\n    info = std::make_unique<ResultInfo>();\n  }\n  info->resolved = true;\n  info->control = *std::prev(op->result_end());\n  info->data = op->getResults().drop_back();\n  for (auto it : llvm::zip(result_segments, op_def->output_arg())) {\n    const std::pair<unsigned, unsigned> &segment = std::get<0>(it);\n    info->outputs.emplace(std::get<1>(it).name(),\n                          info->data.slice(segment.first, segment.second));\n  }\n\n  // Resolve any associated backedges.\n  for (const Backedge &backedge : info->backedges) {\n    Value value;\n    if (backedge.id.IsControl()) {\n      value = info->control;\n    } else {\n      TF_ASSIGN_OR_RETURN(value, ResolveDataResult(backedge.id, info.get()));\n    }\n    backedge.operand->set(value);\n  }\n  info->backedges.clear();\n\n  return ::tensorflow::OkStatus();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status CompressElement(const std::vector<Tensor>& element,\n                       CompressedElement* out) {\n  // Step 1: Determine the total uncompressed size. This requires serializing\n  // non-memcopyable tensors, which we save to use again later.\n  std::vector<TensorProto> non_memcpy_components;\n  int64 total_size = 0;\n  for (auto& component : element) {\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      // Some datatypes can be memcopied, allowing us to save two copies\n      // (AsProtoTensorContent and SerializeToArray).\n      total_size += DMAHelper::buffer(&component)->size();\n    } else {\n      non_memcpy_components.emplace_back();\n      component.AsProtoTensorContent(&non_memcpy_components.back());\n      total_size += non_memcpy_components.back().ByteSizeLong();\n    }\n  }\n\n  // Step 2: Write the tensor data to a buffer, and compress that buffer.\n  // We use tstring for access to resize_uninitialized.\n  tstring uncompressed;\n  uncompressed.resize_uninitialized(total_size);\n  // Position in `uncompressed` to write the next component.\n  char* position = uncompressed.mdata();\n  int non_memcpy_component_index = 0;\n  for (auto& component : element) {\n    CompressedComponentMetadata* metadata =\n        out->mutable_component_metadata()->Add();\n    metadata->set_dtype(component.dtype());\n    component.shape().AsProto(metadata->mutable_tensor_shape());\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      memcpy(position, buffer->data(), buffer->size());\n      metadata->set_tensor_size_bytes(buffer->size());\n    } else {\n      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n      proto.SerializeToArray(position, proto.ByteSizeLong());\n      metadata->set_tensor_size_bytes(proto.ByteSizeLong());\n    }\n    position += metadata->tensor_size_bytes();\n  }\n  DCHECK_EQ(position, uncompressed.mdata() + total_size);\n\n  if (!port::Snappy_Compress(uncompressed.mdata(), total_size,\n                             out->mutable_data())) {\n    return errors::Internal(\"Failed to compress using snappy.\");\n  }\n  VLOG(3) << \"Compressed element from \" << total_size << \" bytes to \"\n          << out->data().size() << \" bytes\";\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& diagonal = context->input(0);\n\n    // MatrixDiag and MatrixDiagV2 both use this OpKernel. MatrixDiag only has\n    // one input, so we have to check the number of inputs before reading\n    // additional parameters in MatrixDiagV2.\n    int32 lower_diag_index = 0;\n    int32 upper_diag_index = 0;\n    int32 num_rows = -1;\n    int32 num_cols = -1;\n    T padding_value(0);\n\n    // MatrixDiagOpV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(1);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n\n      auto& num_rows_tensor = context->input(2);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_rows_tensor.shape()),\n                  errors::InvalidArgument(\"num_rows must be a scalar\"));\n      num_rows = num_rows_tensor.flat<int32>()(0);\n\n      auto& num_cols_tensor = context->input(3);\n      OP_REQUIRES(context, TensorShapeUtils::IsScalar(num_cols_tensor.shape()),\n                  errors::InvalidArgument(\"num_cols must be a scalar\"));\n      num_cols = num_cols_tensor.flat<int32>()(0);\n\n      auto& padding_value_tensor = context->input(4);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(padding_value_tensor.shape()),\n                  errors::InvalidArgument(\"padding_value must be a scalar\"));\n      padding_value = padding_value_tensor.flat<T>()(0);\n    }\n\n    // Size validations.\n    const TensorShape& diagonal_shape = diagonal.shape();\n    const int diag_rank = diagonal_shape.dims();\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diagonal_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diagonal.shape().DebugString()));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n    OP_REQUIRES(context,\n                lower_diag_index == upper_diag_index ||\n                    diagonal_shape.dim_size(diag_rank - 2) == num_diags,\n                errors::InvalidArgument(\n                    \"The number of diagonals provided in the input does not \"\n                    \"match the lower_diag_index and upper_diag_index range.\"));\n\n    const Eigen::Index max_diag_len = diagonal_shape.dim_size(diag_rank - 1);\n    const int32 min_num_rows = max_diag_len - std::min(upper_diag_index, 0);\n    const int32 min_num_cols = max_diag_len + std::max(lower_diag_index, 0);\n    OP_REQUIRES(context, num_rows == -1 || num_rows >= min_num_rows,\n                errors::InvalidArgument(\"The number of rows is too small.\"));\n    OP_REQUIRES(context, num_cols == -1 || num_cols >= min_num_cols,\n                errors::InvalidArgument(\"The number of columns is too small.\"));\n\n    // If both num_rows and num_cols are unknown, assume that output is square.\n    // Otherwise, use smallest possible values.\n    if (num_rows == -1 && num_cols == -1) {\n      num_rows = std::max(min_num_rows, min_num_cols);\n      num_cols = num_rows;\n    } else if (num_rows == -1) {\n      num_rows = min_num_rows;\n    } else if (num_cols == -1) {\n      num_cols = min_num_cols;\n    }\n    OP_REQUIRES(context, num_rows == min_num_rows || num_cols == min_num_cols,\n                errors::InvalidArgument(\n                    \"The number of rows or columns is not consistent with \"\n                    \"the specified d_lower, d_upper, and diagonal.\"));\n\n    TensorShape output_shape = diagonal_shape;\n    if (num_diags == 1) {  // Output has rank `rank+1`.\n      output_shape.set_dim(diag_rank - 1, num_rows);\n      output_shape.AddDim(num_cols);\n    } else {  // Output has rank `rank`.\n      output_shape.set_dim(diag_rank - 2, num_rows);\n      output_shape.set_dim(diag_rank - 1, num_cols);\n    }\n\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(0, output_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    auto diag_reshaped = diagonal.flat<T>();\n    functor::MatrixDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        padding_value, left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool L2NormalizeReduceAxis(Value sq_op, DenseElementsAttr axis) {\n  if (axis.getNumElements() == 0) {\n    return false;\n  }\n  if (sq_op.getType().cast<ShapedType>().getRank() - 1 ==\n          *axis.getValues<int>().begin() ||\n      *axis.getValues<int>().begin() == -1) {\n    return true;\n  }\n  if (sq_op.getType().cast<ShapedType>().getRank() != axis.getNumElements()) {\n    return false;\n  }\n  auto shape = sq_op.getType().cast<ShapedType>();\n  SmallVector<int, 4> elems{axis.getValues<int>().begin(),\n                            axis.getValues<int>().end()};\n  for (int i = 0; i < shape.getRank(); ++i) {\n    if (i != elems[i]) return false;\n  }\n  return true;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "aubio_notes_t * new_aubio_notes (const char_t * method,\n    uint_t buf_size, uint_t hop_size, uint_t samplerate) {\n  aubio_notes_t *o = AUBIO_NEW(aubio_notes_t);\n\n  const char_t * onset_method = \"default\";\n  const char_t * pitch_method = \"default\";\n\n  o->onset_buf_size = buf_size;\n  o->pitch_buf_size = buf_size * 4;\n  o->hop_size = hop_size;\n\n  o->onset_threshold = 0.;\n  o->pitch_tolerance = 0.;\n\n  o->samplerate = samplerate;\n\n  o->median = 6;\n\n  o->isready = 0;\n\n  o->onset = new_aubio_onset (onset_method, o->onset_buf_size, o->hop_size, o->samplerate);\n  if (o->onset == NULL) goto fail;\n  if (o->onset_threshold != 0.) aubio_onset_set_threshold (o->onset, o->onset_threshold);\n  o->onset_output = new_fvec (1);\n\n  o->pitch = new_aubio_pitch (pitch_method, o->pitch_buf_size, o->hop_size, o->samplerate);\n  if (o->pitch == NULL) goto fail;\n  if (o->pitch_tolerance != 0.) aubio_pitch_set_tolerance (o->pitch, o->pitch_tolerance);\n  aubio_pitch_set_unit (o->pitch, \"midi\");\n  o->pitch_output = new_fvec (1);\n\n  if (strcmp(method, \"default\") != 0) {\n    AUBIO_ERR(\"notes: unknown notes detection method \\\"%s\\\"\\n\", method);\n    goto fail;\n  }\n  o->note_buffer = new_fvec(o->median);\n  o->note_buffer2 = new_fvec(o->median);\n\n  if (!o->onset_output || !o->pitch_output ||\n      !o->note_buffer || !o->note_buffer2) goto fail;\n\n  o->curnote = -1.;\n  o->newnote = 0.;\n\n  aubio_notes_set_silence(o, AUBIO_DEFAULT_NOTES_SILENCE);\n  aubio_notes_set_minioi_ms (o, AUBIO_DEFAULT_NOTES_MINIOI_MS);\n\n  o->last_onset_level = AUBIO_DEFAULT_NOTES_SILENCE;\n  o->release_drop_level = AUBIO_DEFAULT_NOTES_RELEASE_DROP;\n\n  return o;\n\nfail:\n  del_aubio_notes(o);\n  return NULL;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status UncompressElement(const CompressedElement& compressed,\n                         std::vector<Tensor>* out) {\n  int num_components = compressed.component_metadata_size();\n  out->clear();\n  out->reserve(num_components);\n\n  // Step 1: Prepare the memory that we will uncompress into.\n  std::vector<struct iovec> iov(num_components);\n  // We use tstring for access to resize_uninitialized.\n  std::vector<tstring> tensor_proto_strs;\n  // num_components is a conservative estimate. It is important to reserve\n  // vector space so that the vector doesn't resize itself, which could\n  // invalidate pointers to its strings' data.\n  tensor_proto_strs.reserve(num_components);\n  int64 total_size = 0;\n  for (int i = 0; i < num_components; ++i) {\n    const CompressedComponentMetadata& metadata =\n        compressed.component_metadata(i);\n    if (DataTypeCanUseMemcpy(metadata.dtype())) {\n      out->emplace_back(metadata.dtype(), metadata.tensor_shape());\n      TensorBuffer* buffer = DMAHelper::buffer(&out->back());\n      if (buffer) {\n        iov[i].iov_base = buffer->data();\n        iov[i].iov_len = buffer->size();\n      } else {\n        iov[i].iov_base = nullptr;\n        iov[i].iov_len = 0;\n      }\n    } else {\n      // Allocate an empty Tensor. We will fill it out later after\n      // uncompressing into the tensor_proto_str.\n      out->emplace_back();\n      tensor_proto_strs.emplace_back();\n      tstring& tensor_proto_str = tensor_proto_strs.back();\n      tensor_proto_str.resize_uninitialized(metadata.tensor_size_bytes());\n      iov[i].iov_base = tensor_proto_str.mdata();\n      iov[i].iov_len = tensor_proto_str.size();\n    }\n    total_size += iov[i].iov_len;\n  }\n\n  // Step 2: Uncompress into the iovec.\n  const std::string& compressed_data = compressed.data();\n  size_t uncompressed_size;\n  if (!port::Snappy_GetUncompressedLength(\n          compressed_data.data(), compressed_data.size(), &uncompressed_size)) {\n    return errors::Internal(\n        \"Could not get snappy uncompressed length. Compressed data size: \",\n        compressed_data.size());\n  }\n  if (uncompressed_size != static_cast<size_t>(total_size)) {\n    return errors::Internal(\n        \"Uncompressed size mismatch. Snappy expects \", uncompressed_size,\n        \" whereas the tensor metadata suggests \", total_size);\n  }\n  if (!port::Snappy_UncompressToIOVec(compressed_data.data(),\n                                      compressed_data.size(), iov.data(),\n                                      num_components)) {\n    return errors::Internal(\"Failed to perform snappy decompression.\");\n  }\n\n  // Step 3: Deserialize tensor proto strings to tensors.\n  int tensor_proto_strs_index = 0;\n  for (int i = 0; i < num_components; ++i) {\n    if (DataTypeCanUseMemcpy(compressed.component_metadata(i).dtype())) {\n      continue;\n    }\n    TensorProto tp;\n    if (!tp.ParseFromString(tensor_proto_strs[tensor_proto_strs_index++])) {\n      return errors::Internal(\"Could not parse TensorProto\");\n    }\n    if (!out->at(i).FromProto(tp)) {\n      return errors::Internal(\"Could not parse Tensor\");\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool DependencyOptimizer::SafeToRemoveIdentity(const NodeDef& node) const {\n  if (!IsIdentity(node) && !IsIdentityN(node)) {\n    return true;\n  }\n\n  if (nodes_to_preserve_.find(node.name()) != nodes_to_preserve_.end()) {\n    return false;\n  }\n  if (!fetch_nodes_known_) {\n    // The output values of this node may be needed.\n    return false;\n  }\n\n  if (node.input_size() < 1) {\n    // Node lacks input, is invalid\n    return false;\n  }\n\n  const NodeDef* input = node_map_->GetNode(NodeName(node.input(0)));\n  CHECK(input != nullptr) << \"node = \" << node.name()\n                          << \" input = \" << node.input(0);\n  // Don't remove Identity nodes corresponding to Variable reads or following\n  // Recv.\n  if (IsVariable(*input) || IsRecv(*input)) {\n    return false;\n  }\n  for (const auto& consumer : node_map_->GetOutputs(node.name())) {\n    if (node.input_size() > 1 && (IsRetval(*consumer) || IsMerge(*consumer))) {\n      return false;\n    }\n    if (IsSwitch(*input)) {\n      for (const string& consumer_input : consumer->input()) {\n        if (consumer_input == AsControlDependency(node.name())) {\n          return false;\n        }\n      }\n    }\n  }\n  return true;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_pkcs7_certificates(self, p7) -> typing.List[x509.Certificate]:\n        nid = self._lib.OBJ_obj2nid(p7.type)\n        self.openssl_assert(nid != self._lib.NID_undef)\n        if nid != self._lib.NID_pkcs7_signed:\n            raise UnsupportedAlgorithm(\n                \"Only basic signed structures are currently supported. NID\"\n                \" for this data was {}\".format(nid),\n                _Reasons.UNSUPPORTED_SERIALIZATION,\n            )\n\n        certs: list[x509.Certificate] = []\n        if p7.d.sign == self._ffi.NULL:\n            return certs\n\n        sk_x509 = p7.d.sign.cert\n        num = self._lib.sk_X509_num(sk_x509)\n        for i in range(num):\n            x509 = self._lib.sk_X509_value(sk_x509, i)\n            self.openssl_assert(x509 != self._ffi.NULL)\n            cert = self._ossl2cert(x509)\n            certs.append(cert)\n\n        return certs\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    Tensor val;\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\n    ctx->set_output(0, val);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::Initialize(OpKernelContext* const context,\n                            const ModelWeights& weights,\n                            const int num_sparse_features,\n                            const int num_sparse_features_with_values,\n                            const int num_dense_features) {\n  num_features_ = num_sparse_features + num_dense_features;\n\n  OpInputList sparse_example_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_example_indices\",\n                                         &sparse_example_indices_inputs));\n  if (sparse_example_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_example_indices but got \",\n        sparse_example_indices_inputs.size());\n  OpInputList sparse_feature_indices_inputs;\n  TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_indices\",\n                                         &sparse_feature_indices_inputs));\n  if (sparse_feature_indices_inputs.size() != num_sparse_features)\n    return errors::InvalidArgument(\n        \"Expected \", num_sparse_features,\n        \" tensors in sparse_feature_indices but got \",\n        sparse_feature_indices_inputs.size());\n  OpInputList sparse_feature_values_inputs;\n  if (num_sparse_features_with_values > 0) {\n    TF_RETURN_IF_ERROR(context->input_list(\"sparse_feature_values\",\n                                           &sparse_feature_values_inputs));\n    if (sparse_feature_values_inputs.size() != num_sparse_features_with_values)\n      return errors::InvalidArgument(\n          \"Expected \", num_sparse_features_with_values,\n          \" tensors in sparse_feature_values but got \",\n          sparse_feature_values_inputs.size());\n  }\n\n  const Tensor* example_weights_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_weights\", &example_weights_t));\n  auto example_weights = example_weights_t->flat<float>();\n\n  if (example_weights.size() >= std::numeric_limits<int>::max()) {\n    return errors::InvalidArgument(strings::Printf(\n        \"Too many examples in a mini-batch: %zu > %d\", example_weights.size(),\n        std::numeric_limits<int>::max()));\n  }\n\n  // The static_cast here is safe since num_examples can be at max an int.\n  const int num_examples = static_cast<int>(example_weights.size());\n  const Tensor* example_labels_t;\n  TF_RETURN_IF_ERROR(context->input(\"example_labels\", &example_labels_t));\n  auto example_labels = example_labels_t->flat<float>();\n\n  OpInputList dense_features_inputs;\n  TF_RETURN_IF_ERROR(\n      context->input_list(\"dense_features\", &dense_features_inputs));\n\n  examples_.clear();\n  examples_.resize(num_examples);\n  probabilities_.resize(num_examples);\n  sampled_index_.resize(num_examples);\n  sampled_count_.resize(num_examples);\n  for (int example_id = 0; example_id < num_examples; ++example_id) {\n    Example* const example = &examples_[example_id];\n    example->sparse_features_.resize(num_sparse_features);\n    example->dense_vectors_.resize(num_dense_features);\n    example->example_weight_ = example_weights(example_id);\n    example->example_label_ = example_labels(example_id);\n  }\n  const DeviceBase::CpuWorkerThreads& worker_threads =\n      *context->device()->tensorflow_cpu_worker_threads();\n  TF_RETURN_IF_ERROR(CreateSparseFeatureRepresentation(\n      worker_threads, num_examples, num_sparse_features, weights,\n      sparse_example_indices_inputs, sparse_feature_indices_inputs,\n      sparse_feature_values_inputs, &examples_));\n  TF_RETURN_IF_ERROR(CreateDenseFeatureRepresentation(\n      worker_threads, num_examples, num_dense_features, weights,\n      dense_features_inputs, &examples_));\n  TF_RETURN_IF_ERROR(ComputeSquaredNormPerExample(\n      worker_threads, num_examples, num_sparse_features, num_dense_features,\n      &examples_));\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void RestoreTensor(OpKernelContext* context,\n                   checkpoint::TensorSliceReader::OpenTableFunction open_func,\n                   int preferred_shard, bool restore_slice, int restore_index) {\n  const Tensor& file_pattern_t = context->input(0);\n  {\n    const int64_t size = file_pattern_t.NumElements();\n    OP_REQUIRES(\n        context, size == 1,\n        errors::InvalidArgument(\n            \"Input 0 (file_pattern) must be a string scalar; got a tensor of \",\n            size, \" elements\"));\n  }\n  const string& file_pattern = file_pattern_t.flat<tstring>()(0);\n\n  const Tensor& tensor_name_t = context->input(1);\n  {\n    const int64_t size = tensor_name_t.NumElements();\n    OP_REQUIRES(context, size > restore_index,\n                errors::InvalidArgument(\n                    \"Input 1 (file_pattern) must be a have at least \",\n                    restore_index + 1, \" elements\"));\n  }\n  const string& tensor_name = tensor_name_t.flat<tstring>()(restore_index);\n\n  // If we cannot find a cached reader we will allocate our own.\n  std::unique_ptr<checkpoint::TensorSliceReader> allocated_reader;\n\n  const checkpoint::TensorSliceReader* reader = nullptr;\n\n  if (context->slice_reader_cache()) {\n    reader = context->slice_reader_cache()->GetReader(file_pattern, open_func,\n                                                      preferred_shard);\n  }\n  if (!reader) {\n    allocated_reader.reset(new checkpoint::TensorSliceReader(\n        file_pattern, open_func, preferred_shard));\n    reader = allocated_reader.get();\n  }\n  OP_REQUIRES_OK(context, CHECK_NOTNULL(reader)->status());\n\n  // Get the shape and type from the save file.\n  DataType type;\n  TensorShape saved_shape;\n  OP_REQUIRES(\n      context, reader->HasTensor(tensor_name, &saved_shape, &type),\n      errors::NotFound(\"Tensor name \\\"\", tensor_name,\n                       \"\\\" not found in checkpoint files \", file_pattern));\n  OP_REQUIRES(\n      context, type == context->expected_output_dtype(restore_index),\n      errors::InvalidArgument(\"Expected to restore a tensor of type \",\n                              DataTypeString(context->expected_output_dtype(0)),\n                              \", got a tensor of type \", DataTypeString(type),\n                              \" instead: tensor_name = \", tensor_name));\n\n  // Shape of the output and slice to load.\n  TensorShape output_shape(saved_shape);\n  TensorSlice slice_to_load(saved_shape.dims());\n  if (restore_slice) {\n    const tstring& shape_spec =\n        context->input(2).flat<tstring>()(restore_index);\n    if (!shape_spec.empty()) {\n      TensorShape parsed_shape;\n      OP_REQUIRES_OK(context, checkpoint::ParseShapeAndSlice(\n                                  shape_spec, &parsed_shape, &slice_to_load,\n                                  &output_shape));\n      OP_REQUIRES(\n          context, parsed_shape.IsSameSize(saved_shape),\n          errors::InvalidArgument(\n              \"Shape in shape_and_slice spec does not match the shape in the \"\n              \"save file: \",\n              parsed_shape.DebugString(),\n              \", save file shape: \", saved_shape.DebugString()));\n    }\n  }\n\n  Tensor* t = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(restore_index, output_shape, &t));\n\n  if (output_shape.num_elements() == 0) return;\n\n#define READER_COPY(T)                                                \\\n  case DataTypeToEnum<T>::value:                                      \\\n    OP_REQUIRES(context,                                              \\\n                reader->CopySliceData(tensor_name, slice_to_load,     \\\n                                      t->flat<T>().data()),           \\\n                errors::InvalidArgument(\"Error copying slice data\")); \\\n    break;\n\n  switch (type) {\n    TF_CALL_SAVE_RESTORE_TYPES(READER_COPY)\n    default:\n      context->SetStatus(errors::Unimplemented(\n          \"Restoring data type \", DataTypeString(type), \" not yet supported\"));\n  }\n#undef READER_COPY\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status GraphDefImporter::ConvertNodeDef(OpBuilder &builder, ConversionState &s,\n                                        const NodeDef &node) {\n  VLOG(4) << \"Importing: \" << node.name();\n  if (node.op().empty())\n    return InvalidArgument(\"Node \", node.name(), \" has an empty op name\");\n\n  OperationState state(ConvertLocation(node), absl::StrCat(\"tfg.\", node.op()));\n\n  // The GraphImporter does light shape inference, but here we will defer all of\n  // that to the shape inference pass.\n  const OpDef *op_def;\n  const OpRegistrationData *op_reg_data = nullptr;\n  if ((op_reg_data = registry_.LookUp(node.op()))) {\n    op_def = &op_reg_data->op_def;\n  } else {\n    auto it = function_op_defs_.find(node.op());\n    if (it == function_op_defs_.end())\n      return InvalidArgument(\"Unable to find OpDef for \", node.op());\n    op_def = it->second;\n  }\n\n  // Import the attributes. Reserve `+3` for `device`,`name`, and `fulltype`.\n  state.attributes.reserve(node.attr_size() + 3);\n  if (!node.device().empty()) {\n    state.addAttribute(dialect_->getDeviceAttrIdentifier(),\n                       b_.getStringAttr(node.device()));\n  }\n  if (!node.name().empty()) {\n    state.addAttribute(dialect_->getNameAttrIdentifier(),\n                       b_.getStringAttr(node.name()));\n  }\n\n  // If the op doesn't have a FullType, try to infer one.\n  const auto add_full_type = [&](const FullTypeDef &full_type_def) {\n    TF_ASSIGN_OR_RETURN(tf_type::FullTypeAttr full_type,\n                        ConvertAttribute(full_type_def, b_, dialect_));\n    state.addAttribute(dialect_->getFullTypeAttrIdentifier(), full_type);\n    return ::tensorflow::OkStatus();\n  };\n  if (node.has_experimental_type()) {\n    TF_RETURN_IF_ERROR(add_full_type(node.experimental_type()));\n  } else if (op_reg_data && op_reg_data->type_ctor) {\n    FullTypeDef full_type_def;\n    TF_RETURN_IF_ERROR(\n        tensorflow::full_type::SpecializeType(node, *op_def, full_type_def));\n    TF_RETURN_IF_ERROR(add_full_type(full_type_def));\n  }\n\n  for (auto &name_attr : node.attr()) {\n    if (name_attr.first.empty())\n      return InvalidArgument(\"Node \", node.name(), \" has an empty attr name\");\n    TF_ASSIGN_OR_RETURN(Attribute attr,\n                        ConvertAttributeValue(name_attr.second, b_, dialect_));\n    state.addAttribute(name_attr.first, attr);\n  }\n\n  // Add missing default attributes.\n  for (const auto &attr_def : op_def->attr()) {\n    if (attr_def.has_default_value() &&\n        !state.attributes.get(attr_def.name())) {\n      TF_ASSIGN_OR_RETURN(\n          Attribute attr,\n          ConvertAttributeValue(attr_def.default_value(), b_, dialect_));\n      state.addAttribute(attr_def.name(), attr);\n    }\n  }\n\n  // Get the result types. Ops can have multiple named results. Track the\n  // segment sizes.\n  SmallVector<std::pair<unsigned, unsigned>> result_segments;\n  result_segments.reserve(op_def->output_arg_size());\n  state.types.reserve(op_def->output_arg_size() + 1);\n  for (const OpDef::ArgDef &def : op_def->output_arg()) {\n    unsigned index = state.types.size();\n    TF_ASSIGN_OR_RETURN(unsigned size,\n                        ArgNumType(state.attributes, def, state.types));\n    result_segments.emplace_back(index, size);\n  }\n  state.types.push_back(dialect_->getControlType());\n\n  // Collect the operands. Set backedges to a placeholder and resolve them\n  // later.\n  state.operands.reserve(node.input_size());\n  SmallVector<Value> control_operands;\n  struct BackedgeResolution {\n    ResultInfo *info;\n    size_t operand_index;\n    ResultId id;\n  };\n  SmallVector<BackedgeResolution> unresolved_data_operands,\n      unresolved_control_operands;\n  for (const std::string &input : node.input()) {\n    TF_ASSIGN_OR_RETURN(Result result, GetResult(s, input));\n    if (result.control) {\n      if (result.info) {\n        unresolved_control_operands.push_back(BackedgeResolution{\n            result.info, control_operands.size(), result.id});\n      }\n      control_operands.push_back(result.control);\n    } else {\n      if (result.info) {\n        unresolved_data_operands.push_back(\n            BackedgeResolution{result.info, state.operands.size(), result.id});\n      }\n      state.operands.push_back(result.data);\n    }\n  }\n  unsigned num_data_operands = state.operands.size();\n  state.addOperands(control_operands);\n\n  // Create the op and record any unresolved operands.\n  Operation *op = builder.create(state);\n  for (const BackedgeResolution &r : unresolved_data_operands) {\n    r.info->backedges.push_back(\n        Backedge{r.id, &op->getOpOperand(r.operand_index)});\n  }\n  for (const BackedgeResolution &r : unresolved_control_operands) {\n    r.info->backedges.push_back(\n        Backedge{r.id, &op->getOpOperand(num_data_operands + r.operand_index)});\n  }\n\n  std::unique_ptr<ResultInfo> &info = s[node.name()];\n  if (!info) {\n    info = std::make_unique<ResultInfo>();\n  }\n  info->resolved = true;\n  info->control = *std::prev(op->result_end());\n  info->data = op->getResults().drop_back();\n  for (auto it : llvm::zip(result_segments, op_def->output_arg())) {\n    const std::pair<unsigned, unsigned> &segment = std::get<0>(it);\n    info->outputs.emplace(std::get<1>(it).name(),\n                          info->data.slice(segment.first, segment.second));\n  }\n\n  // Resolve any associated backedges.\n  for (const Backedge &backedge : info->backedges) {\n    Value value;\n    if (backedge.id.IsControl()) {\n      value = info->control;\n    } else {\n      TF_ASSIGN_OR_RETURN(value, ResolveDataResult(backedge.id, info.get()));\n    }\n    backedge.operand->set(value);\n  }\n  info->backedges.clear();\n\n  return ::tensorflow::OkStatus();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status CompressElement(const std::vector<Tensor>& element,\n                       CompressedElement* out) {\n  // Step 1: Determine the total uncompressed size. This requires serializing\n  // non-memcopyable tensors, which we save to use again later.\n  std::vector<TensorProto> non_memcpy_components;\n  int64 total_size = 0;\n  for (auto& component : element) {\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        total_size += buffer->size();\n      }\n    } else {\n      non_memcpy_components.emplace_back();\n      component.AsProtoTensorContent(&non_memcpy_components.back());\n      total_size += non_memcpy_components.back().ByteSizeLong();\n    }\n  }\n\n  // Step 2: Write the tensor data to a buffer, and compress that buffer.\n  // We use tstring for access to resize_uninitialized.\n  tstring uncompressed;\n  uncompressed.resize_uninitialized(total_size);\n  // Position in `uncompressed` to write the next component.\n  char* position = uncompressed.mdata();\n  int non_memcpy_component_index = 0;\n  for (auto& component : element) {\n    CompressedComponentMetadata* metadata =\n        out->mutable_component_metadata()->Add();\n    metadata->set_dtype(component.dtype());\n    component.shape().AsProto(metadata->mutable_tensor_shape());\n    if (DataTypeCanUseMemcpy(component.dtype())) {\n      const TensorBuffer* buffer = DMAHelper::buffer(&component);\n      if (buffer) {\n        memcpy(position, buffer->data(), buffer->size());\n        metadata->set_tensor_size_bytes(buffer->size());\n      }\n    } else {\n      TensorProto& proto = non_memcpy_components[non_memcpy_component_index++];\n      proto.SerializeToArray(position, proto.ByteSizeLong());\n      metadata->set_tensor_size_bytes(proto.ByteSizeLong());\n    }\n    position += metadata->tensor_size_bytes();\n  }\n  DCHECK_EQ(position, uncompressed.mdata() + total_size);\n\n  if (!port::Snappy_Compress(uncompressed.mdata(), total_size,\n                             out->mutable_data())) {\n    return errors::Internal(\"Failed to compress using snappy.\");\n  }\n  VLOG(3) << \"Compressed element from \" << total_size << \" bytes to \"\n          << out->data().size() << \" bytes\";\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
