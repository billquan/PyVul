{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def start(self):\n        \"\"\"\n        Prepare the server to start serving connections.\n\n        Configure the server socket handler and establish a TLS wrapping\n        socket from which all client connections descend. Bind this TLS\n        socket to the specified network address for the server.\n\n        Raises:\n            NetworkingError: Raised if the TLS socket cannot be bound to the\n                network address.\n        \"\"\"\n        self.manager = multiprocessing.Manager()\n        self.policies = self.manager.dict()\n        policies = copy.deepcopy(operation_policy.policies)\n        for policy_name, policy_set in six.iteritems(policies):\n            self.policies[policy_name] = policy_set\n\n        self.policy_monitor = monitor.PolicyDirectoryMonitor(\n            self.config.settings.get('policy_path'),\n            self.policies,\n            self.live_policies\n        )\n\n        def interrupt_handler(trigger, frame):\n            self.policy_monitor.stop()\n        signal.signal(signal.SIGINT, interrupt_handler)\n        signal.signal(signal.SIGTERM, interrupt_handler)\n\n        self.policy_monitor.start()\n\n        self._engine = engine.KmipEngine(\n            policies=self.policies,\n            database_path=self.config.settings.get('database_path')\n        )\n\n        self._logger.info(\"Starting server socket handler.\")\n\n        # Create a TCP stream socket and configure it for immediate reuse.\n        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n        self._logger.debug(\n            \"Configured cipher suites: {0}\".format(\n                len(self.config.settings.get('tls_cipher_suites'))\n            )\n        )\n        for cipher in self.config.settings.get('tls_cipher_suites'):\n            self._logger.debug(cipher)\n        auth_suite_ciphers = self.auth_suite.ciphers.split(':')\n        self._logger.debug(\n            \"Authentication suite ciphers to use: {0}\".format(\n                len(auth_suite_ciphers)\n            )\n        )\n        for cipher in auth_suite_ciphers:\n            self._logger.debug(cipher)\n\n        self._socket = ssl.wrap_socket(\n            self._socket,\n            keyfile=self.config.settings.get('key_path'),\n            certfile=self.config.settings.get('certificate_path'),\n            server_side=True,\n            cert_reqs=ssl.CERT_REQUIRED,\n            ssl_version=self.auth_suite.protocol,\n            ca_certs=self.config.settings.get('ca_path'),\n            do_handshake_on_connect=True,\n            suppress_ragged_eofs=True,\n            ciphers=self.auth_suite.ciphers\n        )\n\n        try:\n            self._socket.bind(\n                (\n                    self.config.settings.get('hostname'),\n                    int(self.config.settings.get('port'))\n                )\n            )\n        except Exception as e:\n            self._logger.exception(e)\n            raise exceptions.NetworkingError(\n                \"Server failed to bind socket handler to {0}:{1}\".format(\n                    self.config.settings.get('hostname'),\n                    self.config.settings.get('port')\n                )\n            )\n        else:\n            self._logger.info(\n                \"Server successfully bound socket handler to {0}:{1}\".format(\n                    self.config.settings.get('hostname'),\n                    self.config.settings.get('port')\n                )\n            )\n            self._is_serving = True\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _recv_frame(self, message=None):\n        recv = self._get_bytes\n\n        # Unpacking the frame described in Section 5.2 of RFC6455\n        # (https://tools.ietf.org/html/rfc6455#section-5.2)\n        header = recv(2)\n        a, b = struct.unpack('!BB', header)\n        finished = a >> 7 == 1\n        rsv123 = a >> 4 & 7\n        rsv1 = rsv123 & 4\n        if rsv123:\n            if rsv1 and \"permessage-deflate\" not in self.extensions:\n                # must be zero - unless it's compressed then rsv1 is true\n                raise FailedConnectionError(\n                    1002,\n                    \"RSV1, RSV2, RSV3: MUST be 0 unless an extension is\"\n                    \" negotiated that defines meanings for non-zero values.\")\n        opcode = a & 15\n        if opcode not in (0, 1, 2, 8, 9, 0xA):\n            raise FailedConnectionError(1002, \"Unknown opcode received.\")\n        masked = b & 128 == 128\n        if not masked and not self.client:\n            raise FailedConnectionError(1002, \"A client MUST mask all frames\"\n                                        \" that it sends to the server\")\n        length = b & 127\n        if opcode & 8:\n            if not finished:\n                raise FailedConnectionError(1002, \"Control frames must not\"\n                                            \" be fragmented.\")\n            if length > 125:\n                raise FailedConnectionError(\n                    1002,\n                    \"All control frames MUST have a payload length of 125\"\n                    \" bytes or less\")\n        elif opcode and message:\n            raise FailedConnectionError(\n                1002,\n                \"Received a non-continuation opcode within\"\n                \" fragmented message.\")\n        elif not opcode and not message:\n            raise FailedConnectionError(\n                1002,\n                \"Received continuation opcode with no previous\"\n                \" fragments received.\")\n        if length == 126:\n            length = struct.unpack('!H', recv(2))[0]\n        elif length == 127:\n            length = struct.unpack('!Q', recv(8))[0]\n        if masked:\n            mask = struct.unpack('!BBBB', recv(4))\n        received = 0\n        if not message or opcode & 8:\n            decoder = self.UTF8Decoder() if opcode == 1 else None\n            decompressor = self._get_permessage_deflate_dec(rsv1)\n            message = self.Message(opcode, decoder=decoder, decompressor=decompressor)\n        if not length:\n            message.push(b'', final=finished)\n        else:\n            while received < length:\n                d = self.socket.recv(length - received)\n                if not d:\n                    raise ConnectionClosedError()\n                dlen = len(d)\n                if masked:\n                    d = self._apply_mask(d, mask, length=dlen, offset=received)\n                received = received + dlen\n                try:\n                    message.push(d, final=finished)\n                except (UnicodeDecodeError, ValueError):\n                    raise FailedConnectionError(\n                        1007, \"Text data must be valid utf-8\")\n        return message\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decode(\n        self,\n        types: Iterable[TypeStr],\n        data: Decodable,\n    ) -> Tuple[Any, ...]:\n        \"\"\"\n        Decodes the binary value ``data`` as a sequence of values of the ABI types\n        in ``types`` via the head-tail mechanism into a tuple of equivalent python\n        values.\n\n        :param types: A list or tuple of string representations of the ABI types that\n            will be used for decoding e.g. ``('uint256', 'bytes[]', '(int,int)')``\n        :param data: The binary value to be decoded.\n\n        :returns: A tuple of equivalent python values for the ABI values\n            represented in ``data``.\n        \"\"\"\n        validate_list_like_param(types, \"types\")\n        validate_bytes_param(data, \"data\")\n\n        decoders = [self._registry.get_decoder(type_str) for type_str in types]\n\n        decoder = TupleDecoder(decoders=decoders)\n        stream = self.stream_class(data)\n\n        return decoder(stream)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def _get_form(self) -> FormData:\n        if self._form is None:\n            assert (\n                parse_options_header is not None\n            ), \"The `python-multipart` library must be installed to use form parsing.\"\n            content_type_header = self.headers.get(\"Content-Type\")\n            content_type: bytes\n            content_type, _ = parse_options_header(content_type_header)\n            if content_type == b\"multipart/form-data\":\n                try:\n                    multipart_parser = MultiPartParser(self.headers, self.stream())\n                    self._form = await multipart_parser.parse()\n                except MultiPartException as exc:\n                    if \"app\" in self.scope:\n                        raise HTTPException(status_code=400, detail=exc.message)\n                    raise exc\n            elif content_type == b\"application/x-www-form-urlencoded\":\n                form_parser = FormParser(self.headers, self.stream())\n                self._form = await form_parser.parse()\n            else:\n                self._form = FormData()\n        return self._form\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self, headers: Headers, stream: typing.AsyncGenerator[bytes, None]\n    ) -> None:\n        assert (\n            multipart is not None\n        ), \"The `python-multipart` library must be installed to use form parsing.\"\n        self.headers = headers\n        self.stream = stream\n        self.messages: typing.List[typing.Tuple[MultiPartMessage, bytes]] = []\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask2(\n        self,\n        text,\n        mode=\"\",\n        direction=None,\n        features=None,\n        language=None,\n        stroke_width=0,\n        anchor=None,\n        ink=0,\n        start=None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. If the font has embedded color data, the bitmap\n        should have mode ``RGBA``. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n                          .. versionadded:: 4.2.0\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n                         .. versionadded:: 4.2.0\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n                         .. versionadded:: 6.0.0\n\n        :param stroke_width: The width of the text stroke.\n\n                         .. versionadded:: 6.2.0\n\n        :param anchor:  The text anchor alignment. Determines the relative location of\n                        the anchor to the text. The default alignment is top left.\n                        See :ref:`text-anchors` for valid values.\n\n                         .. versionadded:: 8.0.0\n\n        :param ink: Foreground ink for rendering in RGBA mode.\n\n                         .. versionadded:: 8.0.0\n\n        :param start: Tuple of horizontal and vertical offset, as text may render\n                      differently when starting at fractional coordinates.\n\n                         .. versionadded:: 9.4.0\n\n        :return: A tuple of an internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module, and the text offset, the\n                 gap between the starting coordinate and the first marking\n        \"\"\"\n        if start is None:\n            start = (0, 0)\n        im, size, offset = self.font.render(\n            text,\n            Image.core.fill,\n            mode,\n            direction,\n            features,\n            language,\n            stroke_width,\n            anchor,\n            ink,\n            start[0],\n            start[1],\n            Image.MAX_IMAGE_PIXELS,\n        )\n        Image._decompression_bomb_check(size)\n        return im, offset\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_url(url):\n    \"\"\"\n    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n    performed to parse incomplete urls. Fields not provided will be None.\n    This parser is RFC 3986 compliant.\n\n    The parser logic and helper functions are based heavily on\n    work done in the ``rfc3986`` module.\n\n    :param str url: URL to parse into a :class:`.Url` namedtuple.\n\n    Partly backwards-compatible with :mod:`urlparse`.\n\n    Example::\n\n        >>> parse_url('http://google.com/mail/')\n        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n        >>> parse_url('google.com:80')\n        Url(scheme=None, host='google.com', port=80, path=None, ...)\n        >>> parse_url('/foo?bar')\n        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n    \"\"\"\n    if not url:\n        # Empty\n        return Url()\n\n    source_url = url\n    if not SCHEME_RE.search(url):\n        url = \"//\" + url\n\n    try:\n        scheme, authority, path, query, fragment = URI_RE.match(url).groups()\n        normalize_uri = scheme is None or scheme.lower() in NORMALIZABLE_SCHEMES\n\n        if scheme:\n            scheme = scheme.lower()\n\n        if authority:\n            auth, host, port = SUBAUTHORITY_RE.match(authority).groups()\n            if auth and normalize_uri:\n                auth = _encode_invalid_chars(auth, USERINFO_CHARS)\n            if port == \"\":\n                port = None\n        else:\n            auth, host, port = None, None, None\n\n        if port is not None:\n            port = int(port)\n            if not (0 <= port <= 65535):\n                raise LocationParseError(url)\n\n        host = _normalize_host(host, scheme)\n\n        if normalize_uri and path:\n            path = _remove_path_dot_segments(path)\n            path = _encode_invalid_chars(path, PATH_CHARS)\n        if normalize_uri and query:\n            query = _encode_invalid_chars(query, QUERY_CHARS)\n        if normalize_uri and fragment:\n            fragment = _encode_invalid_chars(fragment, FRAGMENT_CHARS)\n\n    except (ValueError, AttributeError):\n        return six.raise_from(LocationParseError(source_url), None)\n\n    # For the sake of backwards compatibility we put empty\n    # string values for path if there are any defined values\n    # beyond the path in the URL.\n    # TODO: Remove this when we break backwards compatibility.\n    if not path:\n        if query is not None or fragment is not None:\n            path = \"\"\n        else:\n            path = None\n\n    # Ensure that each part of the URL is a `str` for\n    # backwards compatibility.\n    if isinstance(url, six.text_type):\n        ensure_func = six.ensure_text\n    else:\n        ensure_func = six.ensure_str\n\n    def ensure_type(x):\n        return x if x is None else ensure_func(x)\n\n    return Url(\n        scheme=ensure_type(scheme),\n        auth=ensure_type(auth),\n        host=ensure_type(host),\n        port=port,\n        path=ensure_type(path),\n        query=ensure_type(query),\n        fragment=ensure_type(fragment),\n    )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_command_line(argv: List[str]) -> argparse.Namespace:  # noqa: C901.\n    defaults: Dict[str, Any] = {\n        \"json_indent\": None,\n        \"ordered\": True,\n        \"stringify\": False,\n        \"yaml_options\": {},\n    }\n\n    me = Path(argv[0]).name\n    argv0_from, argv0_to = argv0_to_format(me)\n    format_from_argv0 = argv0_to != \"\"\n\n    parser = argparse.ArgumentParser(\n        description=\"Convert between CBOR, JSON, MessagePack, TOML, and YAML.\"\n    )\n    parser.add_argument(\"-v\", \"--version\", action=\"version\", version=__version__)\n\n    input_group = parser.add_mutually_exclusive_group()\n    input_group.add_argument(\"input\", nargs=\"?\", default=\"-\", help=\"input file\")\n    input_group.add_argument(\n        \"-i\",\n        \"--input\",\n        dest=\"input_flag\",\n        metavar=\"input\",\n        default=None,\n        help=\"input file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--if\",\n            \"-if\",\n            \"--input-format\",\n            dest=\"input_format\",\n            default=\"\",\n            help=\"input format\",\n            choices=FORMATS,\n        )\n\n    if not format_from_argv0 or argv0_to == \"json\":\n        parser.add_argument(\n            \"--json-indent\",\n            \"--indent-json\",\n            dest=\"json_indent\",\n            metavar=\"n\",\n            type=int,\n            default=defaults[\"json_indent\"],\n            help=\"JSON indentation\",\n        )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\"}:\n        parser.add_argument(\n            \"-k\",\n            \"--stringify\",\n            dest=\"stringify\",\n            action=\"store_true\",\n            help=(\n                \"Turn into strings boolean, date-time, and null keys for JSON \"\n                \"and TOML and null values for TOML\"\n            ),\n        )\n\n    output_group = parser.add_mutually_exclusive_group()\n    output_group.add_argument(\"output\", nargs=\"?\", default=\"-\", help=\"output file\")\n    output_group.add_argument(\n        \"-o\",\n        \"--output\",\n        dest=\"output_flag\",\n        metavar=\"output\",\n        default=None,\n        help=\"output file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--of\",\n            \"-of\",\n            \"--output-format\",\n            dest=\"output_format\",\n            default=\"\",\n            help=\"output format\",\n            choices=FORMATS,\n        )\n\n    parser.add_argument(\n        \"-p\",\n        \"--preserve-key-order\",\n        help=argparse.SUPPRESS,\n    )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\", \"yaml\"}:\n        parser.add_argument(\n            \"-s\",\n            \"--sort-keys\",\n            dest=\"ordered\",\n            action=\"store_false\",\n            help=\"sort JSON, TOML, YAML keys instead of preserving key order\",\n        )\n\n    parser.add_argument(\n        \"--unwrap\",\n        dest=\"unwrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"only output the data stored under the given key\",\n    )\n    parser.add_argument(\n        \"--wrap\",\n        dest=\"wrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"wrap the data in a map type with the given key\",\n    )\n\n    if not format_from_argv0 or argv0_to == \"yaml\":\n        parser.add_argument(\n            \"--yaml-indent\",\n            dest=\"yaml_indent\",\n            metavar=\"n\",\n            type=int,\n            default=2,\n            help=\"YAML indentation\",\n        )\n        parser.add_argument(\n            \"--yaml-style\",\n            dest=\"yaml_style\",\n            default=None,\n            help=\"YAML formatting style\",\n            choices=[\"\", \"'\", '\"', \"|\", \">\"],\n        )\n\n        def yaml_width(value: str) -> int:\n            # This is theoretically compatible with LibYAML.\n            return (1 << 32) - 1 if value.lower() == \"inf\" else int(value)\n\n        parser.add_argument(\n            \"--yaml-width\",\n            dest=\"yaml_width\",\n            metavar=\"n\",\n            type=yaml_width,  # Allow \"inf\".\n            default=80,\n            help=\"YAML line width for long strings\",\n        )\n\n    args = parser.parse_args(args=argv[1:])\n\n    # Use the positional input and output arguments.\n    if args.input_flag is not None:\n        args.input = args.input_flag\n\n    if args.output_flag is not None:\n        args.output = args.output_flag\n\n    # Determine the implicit input and output format if possible.\n    if format_from_argv0:\n        args.input_format = argv0_from\n        args.output_format = argv0_to\n    else:\n        if args.input_format == \"\":\n            args.input_format = extension_to_format(args.input)\n            if args.input_format == \"\":\n                parser.error(\"Need an explicit input format\")\n\n        if args.output_format == \"\":\n            args.output_format = extension_to_format(args.output)\n            if args.output_format == \"\":\n                parser.error(\"Need an explicit output format\")\n\n    for key, value in defaults.items():\n        vars(args).setdefault(key, value)\n\n    # Wrap the yaml_* option.\n    if \"yaml_indent\" in vars(args):\n        vars(args)[\"yaml_options\"] = {\n            \"default_style\": args.yaml_style,\n            \"indent\": args.yaml_indent,\n            \"width\": args.yaml_width,\n        }\n        for key in [\"yaml_indent\", \"yaml_style\", \"yaml_width\"]:\n            del vars(args)[key]\n\n    return args\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != \"POST\":\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n            return\n        if self._read_started and not hasattr(self, \"_body\"):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == \"multipart/form-data\":\n            if hasattr(self, \"_body\"):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except MultiPartParserError:\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == \"application/x-www-form-urlencoded\":\n            self._post, self._files = (\n                QueryDict(self.body, encoding=self._encoding),\n                MultiValueDict(),\n            )\n        else:\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getbbox(self, text, *args, **kwargs):\n        \"\"\"\n        Returns bounding box (in pixels) of given text.\n\n        .. versionadded:: 9.2.0\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n        :return: ``(left, top, right, bottom)`` bounding box\n        \"\"\"\n        width, height = self.font.getsize(text)\n        return 0, 0, width, height\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name):\n        \"\"\"\n        Returns a filename that's free on the target storage system, and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, add an underscore and a number (before\n        # the file extension, if one exists) to the filename until the generated\n        # filename doesn't exist.\n        count = itertools.count(1)\n        while self.exists(name):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, \"%s_%s%s\" % (file_root, count.next(), file_ext))\n\n        return name\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse(self):\n        \"\"\"\n        Parse the POST data and break it into a FILES MultiValueDict and a POST\n        MultiValueDict.\n\n        Return a tuple containing the POST and FILES dictionary, respectively.\n        \"\"\"\n        from django.http import QueryDict\n\n        encoding = self._encoding\n        handlers = self._upload_handlers\n\n        # HTTP spec says that Content-Length >= 0 is valid\n        # handling content-length == 0 before continuing\n        if self._content_length == 0:\n            return QueryDict(encoding=self._encoding), MultiValueDict()\n\n        # See if any of the handlers take care of the parsing.\n        # This allows overriding everything if need be.\n        for handler in handlers:\n            result = handler.handle_raw_input(\n                self._input_data,\n                self._meta,\n                self._content_length,\n                self._boundary,\n                encoding,\n            )\n            # Check to see if it was handled\n            if result is not None:\n                return result[0], result[1]\n\n        # Create the data structures to be used later.\n        self._post = QueryDict(mutable=True)\n        self._files = MultiValueDict()\n\n        # Instantiate the parser and stream:\n        stream = LazyStream(ChunkIter(self._input_data, self._chunk_size))\n\n        # Whether or not to signal a file-completion at the beginning of the loop.\n        old_field_name = None\n        counters = [0] * len(handlers)\n\n        # Number of bytes that have been read.\n        num_bytes_read = 0\n        # To count the number of keys in the request.\n        num_post_keys = 0\n        # To limit the amount of data read from the request.\n        read_size = None\n        # Whether a file upload is finished.\n        uploaded_file = True\n\n        try:\n            for item_type, meta_data, field_stream in Parser(stream, self._boundary):\n                if old_field_name:\n                    # We run this at the beginning of the next loop\n                    # since we cannot be sure a file is complete until\n                    # we hit the next boundary/part of the multipart content.\n                    self.handle_file_complete(old_field_name, counters)\n                    old_field_name = None\n                    uploaded_file = True\n\n                try:\n                    disposition = meta_data['content-disposition'][1]\n                    field_name = disposition['name'].strip()\n                except (KeyError, IndexError, AttributeError):\n                    continue\n\n                transfer_encoding = meta_data.get('content-transfer-encoding')\n                if transfer_encoding is not None:\n                    transfer_encoding = transfer_encoding[0].strip()\n                field_name = force_str(field_name, encoding, errors='replace')\n\n                if item_type == FIELD:\n                    # Avoid storing more than DATA_UPLOAD_MAX_NUMBER_FIELDS.\n                    num_post_keys += 1\n                    if (settings.DATA_UPLOAD_MAX_NUMBER_FIELDS is not None and\n                            settings.DATA_UPLOAD_MAX_NUMBER_FIELDS < num_post_keys):\n                        raise TooManyFieldsSent(\n                            'The number of GET/POST parameters exceeded '\n                            'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'\n                        )\n\n                    # Avoid reading more than DATA_UPLOAD_MAX_MEMORY_SIZE.\n                    if settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None:\n                        read_size = settings.DATA_UPLOAD_MAX_MEMORY_SIZE - num_bytes_read\n\n                    # This is a post field, we can just set it in the post\n                    if transfer_encoding == 'base64':\n                        raw_data = field_stream.read(size=read_size)\n                        num_bytes_read += len(raw_data)\n                        try:\n                            data = base64.b64decode(raw_data)\n                        except binascii.Error:\n                            data = raw_data\n                    else:\n                        data = field_stream.read(size=read_size)\n                        num_bytes_read += len(data)\n\n                    # Add two here to make the check consistent with the\n                    # x-www-form-urlencoded check that includes '&='.\n                    num_bytes_read += len(field_name) + 2\n                    if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n                            num_bytes_read > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n                        raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n\n                    self._post.appendlist(field_name, force_str(data, encoding, errors='replace'))\n                elif item_type == FILE:\n                    # This is a file, use the handler...\n                    file_name = disposition.get('filename')\n                    if file_name:\n                        file_name = force_str(file_name, encoding, errors='replace')\n                        file_name = self.sanitize_file_name(file_name)\n                    if not file_name:\n                        continue\n\n                    content_type, content_type_extra = meta_data.get('content-type', ('', {}))\n                    content_type = content_type.strip()\n                    charset = content_type_extra.get('charset')\n\n                    try:\n                        content_length = int(meta_data.get('content-length')[0])\n                    except (IndexError, TypeError, ValueError):\n                        content_length = None\n\n                    counters = [0] * len(handlers)\n                    uploaded_file = False\n                    try:\n                        for handler in handlers:\n                            try:\n                                handler.new_file(\n                                    field_name, file_name, content_type,\n                                    content_length, charset, content_type_extra,\n                                )\n                            except StopFutureHandlers:\n                                break\n\n                        for chunk in field_stream:\n                            if transfer_encoding == 'base64':\n                                # We only special-case base64 transfer encoding\n                                # We should always decode base64 chunks by multiple of 4,\n                                # ignoring whitespace.\n\n                                stripped_chunk = b\"\".join(chunk.split())\n\n                                remaining = len(stripped_chunk) % 4\n                                while remaining != 0:\n                                    over_chunk = field_stream.read(4 - remaining)\n                                    if not over_chunk:\n                                        break\n                                    stripped_chunk += b\"\".join(over_chunk.split())\n                                    remaining = len(stripped_chunk) % 4\n\n                                try:\n                                    chunk = base64.b64decode(stripped_chunk)\n                                except Exception as exc:\n                                    # Since this is only a chunk, any error is an unfixable error.\n                                    raise MultiPartParserError(\"Could not decode base64 data.\") from exc\n\n                            for i, handler in enumerate(handlers):\n                                chunk_length = len(chunk)\n                                chunk = handler.receive_data_chunk(chunk, counters[i])\n                                counters[i] += chunk_length\n                                if chunk is None:\n                                    # Don't continue if the chunk received by\n                                    # the handler is None.\n                                    break\n\n                    except SkipFile:\n                        self._close_files()\n                        # Just use up the rest of this file...\n                        exhaust(field_stream)\n                    else:\n                        # Handle file upload completions on next iteration.\n                        old_field_name = field_name\n                else:\n                    # If this is neither a FIELD or a FILE, just exhaust the stream.\n                    exhaust(stream)\n        except StopUpload as e:\n            self._close_files()\n            if not e.connection_reset:\n                exhaust(self._input_data)\n        else:\n            if not uploaded_file:\n                for handler in handlers:\n                    handler.upload_interrupted()\n            # Make sure that the request data is all fed\n            exhaust(self._input_data)\n\n        # Signal that the upload has completed.\n        # any() shortcircuits if a handler's upload_complete() returns a value.\n        any(handler.upload_complete() for handler in handlers)\n        self._post._mutable = False\n        return self._post, self._files\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def execute(self, image_id, file_path):\n\n        # NOTE(flaper87): A format must be explicitly\n        # specified. There's no \"sane\" default for this\n        # because the dest format may work differently depending\n        # on the environment OpenStack is running in.\n        conversion_format = CONF.taskflow_executor.conversion_format\n        if conversion_format is None:\n            if not _Convert.conversion_missing_warned:\n                msg = _LW('The conversion format is None, please add a value '\n                          'for it in the config file for this task to '\n                          'work: %s')\n                LOG.warn(msg, self.task_id)\n                _Convert.conversion_missing_warned = True\n            return\n\n        # TODO(flaper87): Check whether the image is in the desired\n        # format already. Probably using `qemu-img` just like the\n        # `Introspection` task.\n        dest_path = os.path.join(CONF.task.work_dir, \"%s.converted\" % image_id)\n        stdout, stderr = putils.trycmd('qemu-img', 'convert', '-O',\n                                       conversion_format, file_path, dest_path,\n                                       log_errors=putils.LOG_ALL_ERRORS)\n\n        if stderr:\n            raise RuntimeError(stderr)\n\n        os.rename(dest_path, file_path.split(\"file://\")[-1])\n        return file_path\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static PyObject *Py_FindObjects(PyObject *obj, PyObject *args)\n{\n    PyArrayObject *input = NULL;\n    PyObject *result = NULL, *tuple = NULL, *start = NULL, *end = NULL;\n    PyObject *slc = NULL;\n    int jj;\n    npy_intp max_label;\n    npy_intp ii, *regions = NULL;\n\n    if (!PyArg_ParseTuple(args, \"O&n\",\n                          NI_ObjectToInputArray, &input, &max_label))\n        goto exit;\n\n    if (max_label < 0)\n        max_label = 0;\n    if (max_label > 0) {\n        if (PyArray_NDIM(input) > 0) {\n            regions = (npy_intp*)malloc(2 * max_label * PyArray_NDIM(input) *\n                                        sizeof(npy_intp));\n        } else {\n            regions = (npy_intp*)malloc(max_label * sizeof(npy_intp));\n        }\n        if (!regions) {\n            PyErr_NoMemory();\n            goto exit;\n        }\n    }\n\n    if (!NI_FindObjects(input, max_label, regions))\n        goto exit;\n\n    result = PyList_New(max_label);\n    if (!result) {\n        PyErr_NoMemory();\n        goto exit;\n    }\n\n    for(ii = 0; ii < max_label; ii++) {\n        npy_intp idx =\n                PyArray_NDIM(input) > 0 ? 2 * PyArray_NDIM(input) * ii : ii;\n        if (regions[idx] >= 0) {\n            PyObject *tuple = PyTuple_New(PyArray_NDIM(input));\n            if (!tuple) {\n                PyErr_NoMemory();\n                goto exit;\n            }\n            for(jj = 0; jj < PyArray_NDIM(input); jj++) {\n                start = PyLong_FromSsize_t(regions[idx + jj]);\n                end = PyLong_FromSsize_t(regions[idx + jj +\n                                             PyArray_NDIM(input)]);\n                if (!start || !end) {\n                    PyErr_NoMemory();\n                    goto exit;\n                }\n                slc = PySlice_New(start, end, NULL);\n                if (!slc) {\n                    PyErr_NoMemory();\n                    goto exit;\n                }\n                Py_XDECREF(start);\n                Py_XDECREF(end);\n                start = end = NULL;\n                PyTuple_SetItem(tuple, jj, slc);\n                slc = NULL;\n            }\n            PyList_SetItem(result, ii, tuple);\n            tuple = NULL;\n        } else {\n            Py_INCREF(Py_None);\n            PyList_SetItem(result, ii, Py_None);\n        }\n    }\n\n    Py_INCREF(result);\n\n exit:\n    Py_XDECREF(input);\n    Py_XDECREF(result);\n    Py_XDECREF(tuple);\n    Py_XDECREF(start);\n    Py_XDECREF(end);\n    Py_XDECREF(slc);\n    free(regions);\n    if (PyErr_Occurred()) {\n        return NULL;\n    } else {\n        return result;\n    }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def start(self):\n        \"\"\"\n        Prepare the server to start serving connections.\n\n        Configure the server socket handler and establish a TLS wrapping\n        socket from which all client connections descend. Bind this TLS\n        socket to the specified network address for the server.\n\n        Raises:\n            NetworkingError: Raised if the TLS socket cannot be bound to the\n                network address.\n        \"\"\"\n        self.manager = multiprocessing.Manager()\n        self.policies = self.manager.dict()\n        policies = copy.deepcopy(operation_policy.policies)\n        for policy_name, policy_set in six.iteritems(policies):\n            self.policies[policy_name] = policy_set\n\n        self.policy_monitor = monitor.PolicyDirectoryMonitor(\n            self.config.settings.get('policy_path'),\n            self.policies,\n            self.live_policies\n        )\n\n        def interrupt_handler(trigger, frame):\n            self.policy_monitor.stop()\n        signal.signal(signal.SIGINT, interrupt_handler)\n        signal.signal(signal.SIGTERM, interrupt_handler)\n\n        self.policy_monitor.start()\n\n        self._engine = engine.KmipEngine(\n            policies=self.policies,\n            database_path=self.config.settings.get('database_path')\n        )\n\n        self._logger.info(\"Starting server socket handler.\")\n\n        # Create a TCP stream socket and configure it for immediate reuse.\n        socket.setdefaulttimeout(10)\n        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n        self._logger.debug(\n            \"Configured cipher suites: {0}\".format(\n                len(self.config.settings.get('tls_cipher_suites'))\n            )\n        )\n        for cipher in self.config.settings.get('tls_cipher_suites'):\n            self._logger.debug(cipher)\n        auth_suite_ciphers = self.auth_suite.ciphers.split(':')\n        self._logger.debug(\n            \"Authentication suite ciphers to use: {0}\".format(\n                len(auth_suite_ciphers)\n            )\n        )\n        for cipher in auth_suite_ciphers:\n            self._logger.debug(cipher)\n\n        self._socket = ssl.wrap_socket(\n            self._socket,\n            keyfile=self.config.settings.get('key_path'),\n            certfile=self.config.settings.get('certificate_path'),\n            server_side=True,\n            cert_reqs=ssl.CERT_REQUIRED,\n            ssl_version=self.auth_suite.protocol,\n            ca_certs=self.config.settings.get('ca_path'),\n            do_handshake_on_connect=True,\n            suppress_ragged_eofs=True,\n            ciphers=self.auth_suite.ciphers\n        )\n\n        try:\n            self._socket.bind(\n                (\n                    self.config.settings.get('hostname'),\n                    int(self.config.settings.get('port'))\n                )\n            )\n        except Exception as e:\n            self._logger.exception(e)\n            raise exceptions.NetworkingError(\n                \"Server failed to bind socket handler to {0}:{1}\".format(\n                    self.config.settings.get('hostname'),\n                    self.config.settings.get('port')\n                )\n            )\n        else:\n            self._logger.info(\n                \"Server successfully bound socket handler to {0}:{1}\".format(\n                    self.config.settings.get('hostname'),\n                    self.config.settings.get('port')\n                )\n            )\n            self._is_serving = True\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _recv_frame(self, message=None):\n        recv = self._get_bytes\n\n        # Unpacking the frame described in Section 5.2 of RFC6455\n        # (https://tools.ietf.org/html/rfc6455#section-5.2)\n        header = recv(2)\n        a, b = struct.unpack('!BB', header)\n        finished = a >> 7 == 1\n        rsv123 = a >> 4 & 7\n        rsv1 = rsv123 & 4\n        if rsv123:\n            if rsv1 and \"permessage-deflate\" not in self.extensions:\n                # must be zero - unless it's compressed then rsv1 is true\n                raise FailedConnectionError(\n                    1002,\n                    \"RSV1, RSV2, RSV3: MUST be 0 unless an extension is\"\n                    \" negotiated that defines meanings for non-zero values.\")\n        opcode = a & 15\n        if opcode not in (0, 1, 2, 8, 9, 0xA):\n            raise FailedConnectionError(1002, \"Unknown opcode received.\")\n        masked = b & 128 == 128\n        if not masked and not self.client:\n            raise FailedConnectionError(1002, \"A client MUST mask all frames\"\n                                        \" that it sends to the server\")\n        length = b & 127\n        if opcode & 8:\n            if not finished:\n                raise FailedConnectionError(1002, \"Control frames must not\"\n                                            \" be fragmented.\")\n            if length > 125:\n                raise FailedConnectionError(\n                    1002,\n                    \"All control frames MUST have a payload length of 125\"\n                    \" bytes or less\")\n        elif opcode and message:\n            raise FailedConnectionError(\n                1002,\n                \"Received a non-continuation opcode within\"\n                \" fragmented message.\")\n        elif not opcode and not message:\n            raise FailedConnectionError(\n                1002,\n                \"Received continuation opcode with no previous\"\n                \" fragments received.\")\n        if length == 126:\n            length = struct.unpack('!H', recv(2))[0]\n        elif length == 127:\n            length = struct.unpack('!Q', recv(8))[0]\n\n        if length > self.max_frame_length:\n            raise FailedConnectionError(1009, \"Incoming frame of {} bytes is above length limit of {} bytes.\".format(\n                length, self.max_frame_length))\n        if masked:\n            mask = struct.unpack('!BBBB', recv(4))\n        received = 0\n        if not message or opcode & 8:\n            decoder = self.UTF8Decoder() if opcode == 1 else None\n            decompressor = self._get_permessage_deflate_dec(rsv1)\n            message = self.Message(opcode, self.max_frame_length, decoder=decoder, decompressor=decompressor)\n        if not length:\n            message.push(b'', final=finished)\n        else:\n            while received < length:\n                d = self.socket.recv(length - received)\n                if not d:\n                    raise ConnectionClosedError()\n                dlen = len(d)\n                if masked:\n                    d = self._apply_mask(d, mask, length=dlen, offset=received)\n                received = received + dlen\n                try:\n                    message.push(d, final=finished)\n                except (UnicodeDecodeError, ValueError):\n                    raise FailedConnectionError(\n                        1007, \"Text data must be valid utf-8\")\n        return message\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def decode(\n        self,\n        types: Iterable[TypeStr],\n        data: Decodable,\n    ) -> Tuple[Any, ...]:\n        \"\"\"\n        Decodes the binary value ``data`` as a sequence of values of the ABI types\n        in ``types`` via the head-tail mechanism into a tuple of equivalent python\n        values.\n\n        :param types: A list or tuple of string representations of the ABI types that\n            will be used for decoding e.g. ``('uint256', 'bytes[]', '(int,int)')``\n        :param data: The binary value to be decoded.\n\n        :returns: A tuple of equivalent python values for the ABI values\n            represented in ``data``.\n        \"\"\"\n        # validate decode types\n        validate_codec_types(types)\n\n        # validate decode data\n        validate_bytes_param(data, \"data\")\n\n        decoders = [self._registry.get_decoder(type_str) for type_str in types]\n\n        decoder = TupleDecoder(decoders=decoders)\n        stream = self.stream_class(data)\n\n        return decoder(stream)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def _get_form(\n        self,\n        *,\n        max_files: typing.Union[int, float] = 1000,\n        max_fields: typing.Union[int, float] = 1000,\n    ) -> FormData:\n        if self._form is None:\n            assert (\n                parse_options_header is not None\n            ), \"The `python-multipart` library must be installed to use form parsing.\"\n            content_type_header = self.headers.get(\"Content-Type\")\n            content_type: bytes\n            content_type, _ = parse_options_header(content_type_header)\n            if content_type == b\"multipart/form-data\":\n                try:\n                    multipart_parser = MultiPartParser(\n                        self.headers,\n                        self.stream(),\n                        max_files=max_files,\n                        max_fields=max_fields,\n                    )\n                    self._form = await multipart_parser.parse()\n                except MultiPartException as exc:\n                    if \"app\" in self.scope:\n                        raise HTTPException(status_code=400, detail=exc.message)\n                    raise exc\n            elif content_type == b\"application/x-www-form-urlencoded\":\n                form_parser = FormParser(self.headers, self.stream())\n                self._form = await form_parser.parse()\n            else:\n                self._form = FormData()\n        return self._form\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(\n        self,\n        headers: Headers,\n        stream: typing.AsyncGenerator[bytes, None],\n        *,\n        max_files: typing.Union[int, float] = 1000,\n        max_fields: typing.Union[int, float] = 1000,\n    ) -> None:\n        assert (\n            multipart is not None\n        ), \"The `python-multipart` library must be installed to use form parsing.\"\n        self.headers = headers\n        self.stream = stream\n        self.max_files = max_files\n        self.max_fields = max_fields\n        self.items: typing.List[typing.Tuple[str, typing.Union[str, UploadFile]]] = []\n        self._current_files = 0\n        self._current_fields = 0\n        self._current_partial_header_name: bytes = b\"\"\n        self._current_partial_header_value: bytes = b\"\"\n        self._current_part = MultipartPart()\n        self._charset = \"\"\n        self._file_parts_to_write: typing.List[typing.Tuple[MultipartPart, bytes]] = []\n        self._file_parts_to_finish: typing.List[MultipartPart] = []\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getmask2(\n        self,\n        text,\n        mode=\"\",\n        direction=None,\n        features=None,\n        language=None,\n        stroke_width=0,\n        anchor=None,\n        ink=0,\n        start=None,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"\n        Create a bitmap for the text.\n\n        If the font uses antialiasing, the bitmap should have mode ``L`` and use a\n        maximum value of 255. If the font has embedded color data, the bitmap\n        should have mode ``RGBA``. Otherwise, it should have mode ``1``.\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n                     .. versionadded:: 1.1.5\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n                          .. versionadded:: 4.2.0\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n                         .. versionadded:: 4.2.0\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n                         .. versionadded:: 6.0.0\n\n        :param stroke_width: The width of the text stroke.\n\n                         .. versionadded:: 6.2.0\n\n        :param anchor:  The text anchor alignment. Determines the relative location of\n                        the anchor to the text. The default alignment is top left.\n                        See :ref:`text-anchors` for valid values.\n\n                         .. versionadded:: 8.0.0\n\n        :param ink: Foreground ink for rendering in RGBA mode.\n\n                         .. versionadded:: 8.0.0\n\n        :param start: Tuple of horizontal and vertical offset, as text may render\n                      differently when starting at fractional coordinates.\n\n                         .. versionadded:: 9.4.0\n\n        :return: A tuple of an internal PIL storage memory instance as defined by the\n                 :py:mod:`PIL.Image.core` interface module, and the text offset, the\n                 gap between the starting coordinate and the first marking\n        \"\"\"\n        _string_length_check(text)\n        if start is None:\n            start = (0, 0)\n        im, size, offset = self.font.render(\n            text,\n            Image.core.fill,\n            mode,\n            direction,\n            features,\n            language,\n            stroke_width,\n            anchor,\n            ink,\n            start[0],\n            start[1],\n            Image.MAX_IMAGE_PIXELS,\n        )\n        Image._decompression_bomb_check(size)\n        return im, offset\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_url(url):\n    \"\"\"\n    Given a url, return a parsed :class:`.Url` namedtuple. Best-effort is\n    performed to parse incomplete urls. Fields not provided will be None.\n    This parser is RFC 3986 compliant.\n\n    The parser logic and helper functions are based heavily on\n    work done in the ``rfc3986`` module.\n\n    :param str url: URL to parse into a :class:`.Url` namedtuple.\n\n    Partly backwards-compatible with :mod:`urlparse`.\n\n    Example::\n\n        >>> parse_url('http://google.com/mail/')\n        Url(scheme='http', host='google.com', port=None, path='/mail/', ...)\n        >>> parse_url('google.com:80')\n        Url(scheme=None, host='google.com', port=80, path=None, ...)\n        >>> parse_url('/foo?bar')\n        Url(scheme=None, host=None, port=None, path='/foo', query='bar', ...)\n    \"\"\"\n    if not url:\n        # Empty\n        return Url()\n\n    source_url = url\n    if not SCHEME_RE.search(url):\n        url = \"//\" + url\n\n    try:\n        scheme, authority, path, query, fragment = URI_RE.match(url).groups()\n        normalize_uri = scheme is None or scheme.lower() in NORMALIZABLE_SCHEMES\n\n        if scheme:\n            scheme = scheme.lower()\n\n        if authority:\n            auth, _, host_port = authority.rpartition(\"@\")\n            auth = auth or None\n            host, port = _HOST_PORT_RE.match(host_port).groups()\n            if auth and normalize_uri:\n                auth = _encode_invalid_chars(auth, USERINFO_CHARS)\n            if port == \"\":\n                port = None\n        else:\n            auth, host, port = None, None, None\n\n        if port is not None:\n            port = int(port)\n            if not (0 <= port <= 65535):\n                raise LocationParseError(url)\n\n        host = _normalize_host(host, scheme)\n\n        if normalize_uri and path:\n            path = _remove_path_dot_segments(path)\n            path = _encode_invalid_chars(path, PATH_CHARS)\n        if normalize_uri and query:\n            query = _encode_invalid_chars(query, QUERY_CHARS)\n        if normalize_uri and fragment:\n            fragment = _encode_invalid_chars(fragment, FRAGMENT_CHARS)\n\n    except (ValueError, AttributeError):\n        return six.raise_from(LocationParseError(source_url), None)\n\n    # For the sake of backwards compatibility we put empty\n    # string values for path if there are any defined values\n    # beyond the path in the URL.\n    # TODO: Remove this when we break backwards compatibility.\n    if not path:\n        if query is not None or fragment is not None:\n            path = \"\"\n        else:\n            path = None\n\n    # Ensure that each part of the URL is a `str` for\n    # backwards compatibility.\n    if isinstance(url, six.text_type):\n        ensure_func = six.ensure_text\n    else:\n        ensure_func = six.ensure_str\n\n    def ensure_type(x):\n        return x if x is None else ensure_func(x)\n\n    return Url(\n        scheme=ensure_type(scheme),\n        auth=ensure_type(auth),\n        host=ensure_type(host),\n        port=port,\n        path=ensure_type(path),\n        query=ensure_type(query),\n        fragment=ensure_type(fragment),\n    )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_command_line(argv: List[str]) -> argparse.Namespace:  # noqa: C901.\n    defaults: Dict[str, Any] = {\n        \"json_indent\": None,\n        \"ordered\": True,\n        \"stringify\": False,\n        \"yaml_options\": {},\n    }\n\n    me = Path(argv[0]).name\n    argv0_from, argv0_to = argv0_to_format(me)\n    format_from_argv0 = argv0_to != \"\"\n\n    parser = argparse.ArgumentParser(\n        description=\"Convert between CBOR, JSON, MessagePack, TOML, and YAML.\"\n    )\n    parser.add_argument(\"-v\", \"--version\", action=\"version\", version=__version__)\n\n    input_group = parser.add_mutually_exclusive_group()\n    input_group.add_argument(\"input\", nargs=\"?\", default=\"-\", help=\"input file\")\n    input_group.add_argument(\n        \"-i\",\n        \"--input\",\n        dest=\"input_flag\",\n        metavar=\"input\",\n        default=None,\n        help=\"input file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--if\",\n            \"-if\",\n            \"--input-format\",\n            dest=\"input_format\",\n            default=\"\",\n            help=\"input format\",\n            choices=FORMATS,\n        )\n\n    if not format_from_argv0 or argv0_to == \"json\":\n        parser.add_argument(\n            \"--json-indent\",\n            \"--indent-json\",\n            dest=\"json_indent\",\n            metavar=\"n\",\n            type=int,\n            default=defaults[\"json_indent\"],\n            help=\"JSON indentation\",\n        )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\"}:\n        parser.add_argument(\n            \"-k\",\n            \"--stringify\",\n            dest=\"stringify\",\n            action=\"store_true\",\n            help=(\n                \"Turn into strings boolean, date-time, and null keys for JSON \"\n                \"and TOML and null values for TOML\"\n            ),\n        )\n\n    parser.add_argument(\n        \"--max-nodes\",\n        dest=\"max_nodes\",\n        metavar=\"n\",\n        type=int,\n        default=DEFAULT_MAX_NODES,\n        help=\"maximum number of nodes in input data (default %(default)s)\",\n    )\n\n    output_group = parser.add_mutually_exclusive_group()\n    output_group.add_argument(\"output\", nargs=\"?\", default=\"-\", help=\"output file\")\n    output_group.add_argument(\n        \"-o\",\n        \"--output\",\n        dest=\"output_flag\",\n        metavar=\"output\",\n        default=None,\n        help=\"output file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--of\",\n            \"-of\",\n            \"--output-format\",\n            dest=\"output_format\",\n            default=\"\",\n            help=\"output format\",\n            choices=FORMATS,\n        )\n\n    parser.add_argument(\n        \"-p\",\n        \"--preserve-key-order\",\n        help=argparse.SUPPRESS,\n    )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\", \"yaml\"}:\n        parser.add_argument(\n            \"-s\",\n            \"--sort-keys\",\n            dest=\"ordered\",\n            action=\"store_false\",\n            help=\"sort JSON, TOML, YAML keys instead of preserving key order\",\n        )\n\n    parser.add_argument(\n        \"--unwrap\",\n        dest=\"unwrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"only output the data stored under the given key\",\n    )\n    parser.add_argument(\n        \"--wrap\",\n        dest=\"wrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"wrap the data in a map type with the given key\",\n    )\n\n    if not format_from_argv0 or argv0_to == \"yaml\":\n        parser.add_argument(\n            \"--yaml-indent\",\n            dest=\"yaml_indent\",\n            metavar=\"n\",\n            type=int,\n            default=2,\n            help=\"YAML indentation\",\n        )\n        parser.add_argument(\n            \"--yaml-style\",\n            dest=\"yaml_style\",\n            default=None,\n            help=\"YAML formatting style\",\n            choices=[\"\", \"'\", '\"', \"|\", \">\"],\n        )\n\n        def yaml_width(value: str) -> int:\n            # This is theoretically compatible with LibYAML.\n            return (1 << 32) - 1 if value.lower() == \"inf\" else int(value)\n\n        parser.add_argument(\n            \"--yaml-width\",\n            dest=\"yaml_width\",\n            metavar=\"n\",\n            type=yaml_width,  # Allow \"inf\".\n            default=80,\n            help=\"YAML line width for long strings\",\n        )\n\n    args = parser.parse_args(args=argv[1:])\n\n    # Use the positional input and output arguments.\n    if args.input_flag is not None:\n        args.input = args.input_flag\n\n    if args.output_flag is not None:\n        args.output = args.output_flag\n\n    # Determine the implicit input and output format if possible.\n    if format_from_argv0:\n        args.input_format = argv0_from\n        args.output_format = argv0_to\n    else:\n        if args.input_format == \"\":\n            args.input_format = extension_to_format(args.input)\n            if args.input_format == \"\":\n                parser.error(\"Need an explicit input format\")\n\n        if args.output_format == \"\":\n            args.output_format = extension_to_format(args.output)\n            if args.output_format == \"\":\n                parser.error(\"Need an explicit output format\")\n\n    for key, value in defaults.items():\n        vars(args).setdefault(key, value)\n\n    # Wrap the yaml_* option.\n    if \"yaml_indent\" in vars(args):\n        vars(args)[\"yaml_options\"] = {\n            \"default_style\": args.yaml_style,\n            \"indent\": args.yaml_indent,\n            \"width\": args.yaml_width,\n        }\n        for key in [\"yaml_indent\", \"yaml_style\", \"yaml_width\"]:\n            del vars(args)[key]\n\n    return args\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _load_post_and_files(self):\n        \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n        if self.method != \"POST\":\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n            return\n        if self._read_started and not hasattr(self, \"_body\"):\n            self._mark_post_parse_error()\n            return\n\n        if self.content_type == \"multipart/form-data\":\n            if hasattr(self, \"_body\"):\n                # Use already read data\n                data = BytesIO(self._body)\n            else:\n                data = self\n            try:\n                self._post, self._files = self.parse_file_upload(self.META, data)\n            except (MultiPartParserError, TooManyFilesSent):\n                # An error occurred while parsing POST data. Since when\n                # formatting the error the request handler might access\n                # self.POST, set self._post and self._file to prevent\n                # attempts to parse POST data again.\n                self._mark_post_parse_error()\n                raise\n        elif self.content_type == \"application/x-www-form-urlencoded\":\n            self._post, self._files = (\n                QueryDict(self.body, encoding=self._encoding),\n                MultiValueDict(),\n            )\n        else:\n            self._post, self._files = (\n                QueryDict(encoding=self._encoding),\n                MultiValueDict(),\n            )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    /* Don't do any checks at all with an excessively large modulus */\n    if (BN_num_bits(dh->params.p) > OPENSSL_DH_CHECK_MAX_MODULUS_BITS) {\n        ERR_raise(ERR_LIB_DH, DH_R_MODULUS_TOO_LARGE);\n        *ret = DH_MODULUS_TOO_LARGE | DH_CHECK_PUBKEY_INVALID;\n        return 0;\n    }\n\n    if (dh->params.q != NULL && BN_ucmp(dh->params.p, dh->params.q) < 0) {\n        *ret |= DH_CHECK_INVALID_Q_VALUE | DH_CHECK_PUBKEY_INVALID;\n        return 1;\n    }\n\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getbbox(self, text, *args, **kwargs):\n        \"\"\"\n        Returns bounding box (in pixels) of given text.\n\n        .. versionadded:: 9.2.0\n\n        :param text: Text to render.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n        :return: ``(left, top, right, bottom)`` bounding box\n        \"\"\"\n        _string_length_check(text)\n        width, height = self.font.getsize(text)\n        return 0, 0, width, height\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name):\n        \"\"\"\n        Returns a filename that's free on the target storage system, and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, add an underscore and a random 7\n        # character alphanumeric string (before the file extension, if one\n        # exists) to the filename until the generated filename doesn't exist.\n        while self.exists(name):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, \"%s_%s%s\" % (file_root, get_random_string(7), file_ext))\n\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "int DH_check_pub_key(const DH *dh, const BIGNUM *pub_key, int *ret)\n{\n    /* Don't do any checks at all with an excessively large modulus */\n    if (BN_num_bits(dh->params.p) > OPENSSL_DH_CHECK_MAX_MODULUS_BITS) {\n        ERR_raise(ERR_LIB_DH, DH_R_MODULUS_TOO_LARGE);\n        *ret = DH_MODULUS_TOO_LARGE | DH_CHECK_PUBKEY_INVALID;\n        return 0;\n    }\n\n    if (dh->params.q != NULL && BN_ucmp(dh->params.p, dh->params.q) < 0) {\n        *ret |= DH_CHECK_INVALID_Q_VALUE | DH_CHECK_PUBKEY_INVALID;\n        return 1;\n    }\n\n    return ossl_ffc_validate_public_key(&dh->params, pub_key, ret);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def parse(self):\n        # Call the actual parse routine and close all open files in case of\n        # errors. This is needed because if exceptions are thrown the\n        # MultiPartParser will not be garbage collected immediately and\n        # resources would be kept alive. This is only needed for errors because\n        # the Request object closes all uploaded files at the end of the\n        # request.\n        try:\n            return self._parse()\n        except Exception:\n            if hasattr(self, \"_files\"):\n                for _, files in self._files.lists():\n                    for fileobj in files:\n                        fileobj.close()\n            raise\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def execute(self, image_id, file_path):\n\n        # NOTE(flaper87): A format must be explicitly\n        # specified. There's no \"sane\" default for this\n        # because the dest format may work differently depending\n        # on the environment OpenStack is running in.\n        conversion_format = CONF.taskflow_executor.conversion_format\n        if conversion_format is None:\n            if not _Convert.conversion_missing_warned:\n                msg = _LW('The conversion format is None, please add a value '\n                          'for it in the config file for this task to '\n                          'work: %s')\n                LOG.warn(msg, self.task_id)\n                _Convert.conversion_missing_warned = True\n            return\n\n        image_obj = self.image_repo.get(image_id)\n        src_format = image_obj.disk_format\n\n        # TODO(flaper87): Check whether the image is in the desired\n        # format already. Probably using `qemu-img` just like the\n        # `Introspection` task.\n\n        # NOTE(hemanthm): We add '-f' parameter to the convert command here so\n        # that the image format need not be inferred by qemu utils. This\n        # shields us from being vulnerable to an attack vector described here\n        # https://bugs.launchpad.net/glance/+bug/1449062\n\n        dest_path = os.path.join(CONF.task.work_dir, \"%s.converted\" % image_id)\n        stdout, stderr = putils.trycmd('qemu-img', 'convert',\n                                       '-f', src_format,\n                                       '-O', conversion_format,\n                                       file_path, dest_path,\n                                       log_errors=putils.LOG_ALL_ERRORS)\n\n        if stderr:\n            raise RuntimeError(stderr)\n\n        os.rename(dest_path, file_path.split(\"file://\")[-1])\n        return file_path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static PyObject *Py_FindObjects(PyObject *obj, PyObject *args)\n{\n    PyArrayObject *input = NULL;\n    PyObject *result = NULL, *tuple = NULL, *start = NULL, *end = NULL;\n    PyObject *slc = NULL;\n    int jj;\n    npy_intp max_label;\n    npy_intp ii, *regions = NULL;\n\n    if (!PyArg_ParseTuple(args, \"O&n\",\n                          NI_ObjectToInputArray, &input, &max_label))\n        goto exit;\n\n    if (max_label < 0)\n        max_label = 0;\n    if (max_label > 0) {\n        if (PyArray_NDIM(input) > 0) {\n            regions = (npy_intp*)malloc(2 * max_label * PyArray_NDIM(input) *\n                                        sizeof(npy_intp));\n        } else {\n            regions = (npy_intp*)malloc(max_label * sizeof(npy_intp));\n        }\n        if (!regions) {\n            PyErr_NoMemory();\n            goto exit;\n        }\n    }\n\n    if (!NI_FindObjects(input, max_label, regions))\n        goto exit;\n\n    result = PyList_New(max_label);\n    if (!result) {\n        PyErr_NoMemory();\n        goto exit;\n    }\n\n    for(ii = 0; ii < max_label; ii++) {\n        npy_intp idx =\n                PyArray_NDIM(input) > 0 ? 2 * PyArray_NDIM(input) * ii : ii;\n        if (regions[idx] >= 0) {\n            tuple = PyTuple_New(PyArray_NDIM(input));\n            if (!tuple) {\n                PyErr_NoMemory();\n                goto exit;\n            }\n            for(jj = 0; jj < PyArray_NDIM(input); jj++) {\n                start = PyLong_FromSsize_t(regions[idx + jj]);\n                end = PyLong_FromSsize_t(regions[idx + jj +\n                                             PyArray_NDIM(input)]);\n                if (!start || !end) {\n                    PyErr_NoMemory();\n                    goto exit;\n                }\n                slc = PySlice_New(start, end, NULL);\n                if (!slc) {\n                    PyErr_NoMemory();\n                    goto exit;\n                }\n                Py_DECREF(start);\n                Py_DECREF(end);\n                start = end = NULL;\n                PyTuple_SetItem(tuple, jj, slc);\n                slc = NULL;\n            }\n            PyList_SetItem(result, ii, tuple);\n            tuple = NULL;\n        } else {\n            Py_INCREF(Py_None);\n            PyList_SetItem(result, ii, Py_None);\n        }\n    }\n\n    Py_INCREF(result);\n\n exit:\n    Py_XDECREF(input);\n    Py_XDECREF(result);\n    Py_XDECREF(tuple);\n    Py_XDECREF(start);\n    Py_XDECREF(end);\n    Py_XDECREF(slc);\n    free(regions);\n    if (PyErr_Occurred()) {\n        return NULL;\n    } else {\n        return result;\n    }\n}\n"}, {"role": "assistant", "content": "False"}]}
