{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    exc = MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def dump_content(destination, path, getter):\n    logging.debug(path)\n    content = getter(path)\n    if path.endswith(\"/\"):\n        path = path + \"index.html\"\n\n    path = Path(destination) / path.lstrip(\"/\")\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"wb\") as f:\n        f.write(content)\n    return content\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=request_dict[\"path\"],\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = request_dict[\"path\"]\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def boboAwareZopeTraverse(object, path_items, econtext):\n    \"\"\"Traverses a sequence of names, first trying attributes then items.\n\n    This uses zope.traversing path traversal where possible and interacts\n    correctly with objects providing OFS.interface.ITraversable when\n    necessary (bobo-awareness).\n    \"\"\"\n    request = getattr(econtext, 'request', None)\n    path_items = list(path_items)\n    path_items.reverse()\n\n    while path_items:\n        name = path_items.pop()\n        if OFS.interfaces.ITraversable.providedBy(object):\n            object = object.restrictedTraverse(name)\n        else:\n            object = traversePathElement(object, name, path_items,\n                                         request=request)\n    return object\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_obj_absolute_path(obj_path):\n    return os.path.join(DATAROOT, obj_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def handle_html_static(self, request):\n        \"\"\"Handle static html.\"\"\"\n        if not (page := request.path[1:]):\n            page = \"index.html\"\n        file = os.path.join(self.web_path, page)\n        try:\n            with open(file, encoding=\"utf-8\"):\n                return web.FileResponse(file)\n        except (FileNotFoundError, IsADirectoryError) as exc:\n            raise web.HTTPNotFound(reason=\"File not found\") from exc\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def side_effect(old_cmd, command):\n    with zipfile.ZipFile(_zip_file(old_cmd), 'r') as archive:\n        for file in archive.namelist():\n            try:\n                os.remove(file)\n            except OSError:\n                # does not try to remove directories as we cannot know if they\n                # already existed before\n                pass\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _secure_path(path_tuple):\n    if _has_insecure_pathelement(path_tuple):\n        # belt-and-suspenders security; this should never be true\n        # unless someone screws up the traversal_path code\n        # (request.subpath is computed via traversal_path too)\n        return None\n    if any([_contains_slash(item) for item in path_tuple]):\n        return None\n    encoded = '/'.join(path_tuple)  # will be unicode\n    return encoded\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def make_after_request_function(resources):\n    def cors_after_request(resp):\n        # If CORS headers are set in a view decorator, pass\n        if resp.headers is not None and resp.headers.get(ACL_ORIGIN):\n            LOG.debug('CORS have been already evaluated, skipping')\n            return resp\n\n        for res_regex, res_options in resources:\n            if try_match(request.path, res_regex):\n                LOG.debug(\"Request to '%s' matches CORS resource '%s'. Using options: %s\",\n                      request.path, get_regexp_pattern(res_regex), res_options)\n                set_cors_headers(resp, res_options)\n                break\n        else:\n            LOG.debug('No CORS rule matches')\n        return resp\n    return cors_after_request\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def put(self, name: str):\n        ''' add new file\n            params in FormData:\n                - file\n                - original_file_name [optional]\n        '''\n\n        data = {}\n        mindsdb_file_name = name\n\n        existing_file_names = ca.file_controller.get_files_names()\n\n        def on_field(field):\n            name = field.field_name.decode()\n            value = field.value.decode()\n            data[name] = value\n\n        file_object = None\n\n        def on_file(file):\n            nonlocal file_object\n            data['file'] = file.file_name.decode()\n            file_object = file.file_object\n\n        temp_dir_path = tempfile.mkdtemp(prefix='mindsdb_file_')\n\n        if request.headers['Content-Type'].startswith('multipart/form-data'):\n            parser = multipart.create_form_parser(\n                headers=request.headers,\n                on_field=on_field,\n                on_file=on_file,\n                config={\n                    'UPLOAD_DIR': temp_dir_path.encode(),    # bytes required\n                    'UPLOAD_KEEP_FILENAME': True,\n                    'UPLOAD_KEEP_EXTENSIONS': True,\n                    'MAX_MEMORY_FILE_SIZE': 0\n                }\n            )\n\n            while True:\n                chunk = request.stream.read(8192)\n                if not chunk:\n                    break\n                parser.write(chunk)\n            parser.finalize()\n            parser.close()\n\n            if file_object is not None and not file_object.closed:\n                file_object.close()\n        else:\n            data = request.json\n\n        if mindsdb_file_name in existing_file_names:\n            return http_error(\n                400,\n                \"File already exists\",\n                f\"File with name '{data['file']}' already exists\"\n            )\n\n        if data.get('source_type') == 'url':\n            url = data['source']\n            data['file'] = data['name']\n\n            config = Config()\n            is_cloud = config.get('cloud', False)\n            if is_cloud is True and ctx.user_class != 1:\n                info = requests.head(url)\n                file_size = info.headers.get('Content-Length')\n                try:\n                    file_size = int(file_size)\n                except Exception:\n                    pass\n\n                if file_size is None:\n                    return http_error(\n                        400,\n                        \"Error getting file info\",\n                        \"\u0421an't determine remote file size\"\n                    )\n                if file_size > 1024 * 1024 * 100:\n                    return http_error(\n                        400,\n                        \"File is too big\",\n                        \"Upload limit for file is 100Mb\"\n                    )\n            with requests.get(url, stream=True) as r:\n                if r.status_code != 200:\n                    return http_error(\n                        400,\n                        \"Error getting file\",\n                        f\"Got status code: {r.status_code}\"\n                    )\n                file_path = os.path.join(temp_dir_path, data['file'])\n                with open(file_path, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        f.write(chunk)\n\n        original_file_name = data.get('original_file_name')\n\n        file_path = os.path.join(temp_dir_path, data['file'])\n        lp = file_path.lower()\n        if lp.endswith(('.zip', '.tar.gz')):\n            if lp.endswith('.zip'):\n                with zipfile.ZipFile(file_path) as f:\n                    f.extractall(temp_dir_path)\n            elif lp.endswith('.tar.gz'):\n                with tarfile.open(file_path) as f:\n                    f.extractall(temp_dir_path)\n            os.remove(file_path)\n            files = os.listdir(temp_dir_path)\n            if len(files) != 1:\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain only one data file.')\n            file_path = os.path.join(temp_dir_path, files[0])\n            mindsdb_file_name = files[0]\n            if not os.path.isfile(file_path):\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain data file in root.')\n\n        ca.file_controller.save_file(mindsdb_file_name, file_path, file_name=original_file_name)\n\n        os.rmdir(temp_dir_path)\n\n        return '', 200\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        # follow symlinks to get an accurate normalized path\n        component_root = os.path.realpath(component_root)\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.realpath(os.path.join(component_root, filename))\n\n        # Do NOT expose anything outside of the component root.\n        if os.path.commonprefix([component_root, abspath]) != component_root or (\n            not os.path.normpath(abspath).startswith(\n                component_root\n            )  # this is a recommendation from CodeQL, probably a bit redundant\n        ):\n            self.write(\"forbidden\")\n            self.set_status(403)\n            return\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except (OSError) as e:\n            _LOGGER.error(\n                \"ComponentRequestHandler: GET %s read error\", abspath, exc_info=e\n            )\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _unzip_iter(filename, root, verbose=True):\n    if verbose:\n        sys.stdout.write('Unzipping %s' % os.path.split(filename)[1])\n        sys.stdout.flush()\n\n    try:\n        zf = zipfile.ZipFile(filename)\n    except zipfile.error as e:\n        yield ErrorMessage(filename, 'Error with downloaded zip file')\n        return\n    except Exception as e:\n        yield ErrorMessage(filename, e)\n        return\n\n    # Get lists of directories & files\n    namelist = zf.namelist()\n    dirlist = set()\n    for x in namelist:\n        if x.endswith('/'):\n            dirlist.add(x)\n        else:\n            dirlist.add(x.rsplit('/', 1)[0] + '/')\n    filelist = [x for x in namelist if not x.endswith('/')]\n\n    # Create the target directory if it doesn't exist\n    if not os.path.exists(root):\n        os.mkdir(root)\n\n    # Create the directory structure\n    for dirname in sorted(dirlist):\n        pieces = dirname[:-1].split('/')\n        for i in range(len(pieces)):\n            dirpath = os.path.join(root, *pieces[: i + 1])\n            if not os.path.exists(dirpath):\n                os.mkdir(dirpath)\n\n    # Extract files.\n    for i, filename in enumerate(filelist):\n        filepath = os.path.join(root, *filename.split('/'))\n\n        try:\n            with open(filepath, 'wb') as dstfile, zf.open(filename) as srcfile:\n                shutil.copyfileobj(srcfile, dstfile)\n        except Exception as e:\n            yield ErrorMessage(filename, e)\n            return\n\n        if verbose and (i * 10 / len(filelist) > (i - 1) * 10 / len(filelist)):\n            sys.stdout.write('.')\n            sys.stdout.flush()\n    if verbose:\n        print()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _build_api(self) -> None:\n        # Generate Client\n        client_path = self.package_dir / \"client.py\"\n        client_template = self.env.get_template(\"client.pyi\")\n        client_path.write_text(client_template.render())\n\n        # Generate endpoints\n        api_dir = self.package_dir / \"api\"\n        api_dir.mkdir()\n        api_init = api_dir / \"__init__.py\"\n        api_init.write_text('\"\"\" Contains synchronous methods for accessing the API \"\"\"')\n\n        async_api_dir = self.package_dir / \"async_api\"\n        async_api_dir.mkdir()\n        async_api_init = async_api_dir / \"__init__.py\"\n        async_api_init.write_text('\"\"\" Contains async methods for accessing the API \"\"\"')\n\n        api_errors = self.package_dir / \"errors.py\"\n        errors_template = self.env.get_template(\"errors.pyi\")\n        api_errors.write_text(errors_template.render())\n\n        endpoint_template = self.env.get_template(\"endpoint_module.pyi\")\n        async_endpoint_template = self.env.get_template(\"async_endpoint_module.pyi\")\n        for tag, collection in self.openapi.endpoint_collections_by_tag.items():\n            module_path = api_dir / f\"{tag}.py\"\n            module_path.write_text(endpoint_template.render(collection=collection))\n            async_module_path = async_api_dir / f\"{tag}.py\"\n            async_module_path.write_text(async_endpoint_template.render(collection=collection))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def validate_absolute_path(self, root: str, absolute_path: str) -> Optional[str]:\n        full_path = os.path.realpath(absolute_path)\n\n        if os.path.isdir(full_path):\n            # we don't want to serve directories, and serve only files\n            raise tornado.web.HTTPError(404)\n\n        if os.path.commonprefix([full_path, root]) != root:\n            # Don't allow misbehaving clients to break out of the static files directory\n            _LOGGER.warning(\n                \"Serving files outside of the static directory is not supported\"\n            )\n            raise tornado.web.HTTPError(404)\n\n        if (\n            os.path.exists(full_path)\n            and os.path.getsize(full_path) > MAX_APP_STATIC_FILE_SIZE\n        ):\n            raise tornado.web.HTTPError(\n                404,\n                \"File is too large, its size should not exceed \"\n                f\"{MAX_APP_STATIC_FILE_SIZE} bytes\",\n                reason=\"File is too large\",\n            )\n\n        return super().validate_absolute_path(root, absolute_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _extract_tar_file(tar, filename, b_dest, b_temp_path, expected_hash=None):\n    n_filename = to_native(filename, errors='surrogate_or_strict')\n    try:\n        member = tar.getmember(n_filename)\n    except KeyError:\n        raise AnsibleError(\"Collection tar at '%s' does not contain the expected file '%s'.\" % (to_native(tar.name),\n                                                                                                n_filename))\n\n    with tempfile.NamedTemporaryFile(dir=b_temp_path, delete=False) as tmpfile_obj:\n        bufsize = 65536\n        sha256_digest = sha256()\n        with _tarfile_extract(tar, member) as tar_obj:\n            data = tar_obj.read(bufsize)\n            while data:\n                tmpfile_obj.write(data)\n                tmpfile_obj.flush()\n                sha256_digest.update(data)\n                data = tar_obj.read(bufsize)\n\n        actual_hash = sha256_digest.hexdigest()\n\n        if expected_hash and actual_hash != expected_hash:\n            raise AnsibleError(\"Checksum mismatch for '%s' inside collection at '%s'\"\n                               % (n_filename, to_native(tar.name)))\n\n        b_dest_filepath = os.path.join(b_dest, to_bytes(filename, errors='surrogate_or_strict'))\n        b_parent_dir = os.path.split(b_dest_filepath)[0]\n        if not os.path.exists(b_parent_dir):\n            # Seems like Galaxy does not validate if all file entries have a corresponding dir ftype entry. This check\n            # makes sure we create the parent directory even if it wasn't set in the metadata.\n            os.makedirs(b_parent_dir, mode=0o0755)\n\n        shutil.move(to_bytes(tmpfile_obj.name, errors='surrogate_or_strict'), b_dest_filepath)\n\n        # Default to rw-r--r-- and only add execute if the tar file has execute.\n        new_mode = 0o644\n        if stat.S_IMODE(member.mode) & stat.S_IXUSR:\n            new_mode |= 0o0111\n\n        os.chmod(b_dest_filepath, new_mode)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return os.path.join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        return self._save(name, content)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def config():\n    config_disabled = (\n            app.config['CONFIG_DISABLE'] or\n            not valid_user_session(session))\n    if request.method == 'GET':\n        return json.dumps(g.user_config.__dict__)\n    elif request.method == 'PUT' and not config_disabled:\n        if 'name' in request.args:\n            config_pkl = os.path.join(\n                app.config['CONFIG_PATH'],\n                request.args.get('name'))\n            session['config'] = (pickle.load(open(config_pkl, 'rb'))\n                                 if os.path.exists(config_pkl)\n                                 else session['config'])\n            return json.dumps(session['config'])\n        else:\n            return json.dumps({})\n    elif not config_disabled:\n        config_data = request.form.to_dict()\n        if 'url' not in config_data or not config_data['url']:\n            config_data['url'] = g.user_config.url\n\n        # Save config by name to allow a user to easily load later\n        if 'name' in request.args:\n            pickle.dump(\n                config_data,\n                open(os.path.join(\n                    app.config['CONFIG_PATH'],\n                    request.args.get('name')), 'wb'))\n\n        session['config'] = config_data\n        return redirect(config_data['url'])\n    else:\n        return redirect(url_for('.index'), code=403)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_snippet_path(self, path):\r\n        \"\"\"Get snippet path.\"\"\"\r\n\r\n        snippet = None\r\n        for base in self.base_path:\r\n            if os.path.exists(base):\r\n                if os.path.isdir(base):\r\n                    filename = os.path.join(base, path)\r\n                    if os.path.exists(filename):\r\n                        snippet = filename\r\n                        break\r\n                else:\r\n                    basename = os.path.basename(base)\r\n                    dirname = os.path.dirname(base)\r\n                    if basename.lower() == path.lower():\r\n                        filename = os.path.join(dirname, path)\r\n                        if os.path.exists(filename):\r\n                            snippet = filename\r\n                            break\r\n        return snippet\r\n\r"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return os.path.join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def install(self):\n\n        if self.scm:\n            # create tar file from scm url\n            tmp_file = RoleRequirement.scm_archive_role(keep_scm_meta=context.CLIARGS['keep_scm_meta'], **self.spec)\n        elif self.src:\n            if os.path.isfile(self.src):\n                tmp_file = self.src\n            elif '://' in self.src:\n                role_data = self.src\n                tmp_file = self.fetch(role_data)\n            else:\n                role_data = self.api.lookup_role_by_name(self.src)\n                if not role_data:\n                    raise AnsibleError(\"- sorry, %s was not found on %s.\" % (self.src, self.api.api_server))\n\n                if role_data.get('role_type') == 'APP':\n                    # Container Role\n                    display.warning(\"%s is a Container App role, and should only be installed using Ansible \"\n                                    \"Container\" % self.name)\n\n                role_versions = self.api.fetch_role_related('versions', role_data['id'])\n                if not self.version:\n                    # convert the version names to LooseVersion objects\n                    # and sort them to get the latest version. If there\n                    # are no versions in the list, we'll grab the head\n                    # of the master branch\n                    if len(role_versions) > 0:\n                        loose_versions = [LooseVersion(a.get('name', None)) for a in role_versions]\n                        try:\n                            loose_versions.sort()\n                        except TypeError:\n                            raise AnsibleError(\n                                'Unable to compare role versions (%s) to determine the most recent version due to incompatible version formats. '\n                                'Please contact the role author to resolve versioning conflicts, or specify an explicit role version to '\n                                'install.' % ', '.join([v.vstring for v in loose_versions])\n                            )\n                        self.version = to_text(loose_versions[-1])\n                    elif role_data.get('github_branch', None):\n                        self.version = role_data['github_branch']\n                    else:\n                        self.version = 'master'\n                elif self.version != 'master':\n                    if role_versions and to_text(self.version) not in [a.get('name', None) for a in role_versions]:\n                        raise AnsibleError(\"- the specified version (%s) of %s was not found in the list of available versions (%s).\" % (self.version,\n                                                                                                                                         self.name,\n                                                                                                                                         role_versions))\n\n                # check if there's a source link/url for our role_version\n                for role_version in role_versions:\n                    if role_version['name'] == self.version and 'source' in role_version:\n                        self.src = role_version['source']\n                    if role_version['name'] == self.version and 'download_url' in role_version:\n                        self.download_url = role_version['download_url']\n\n                tmp_file = self.fetch(role_data)\n\n        else:\n            raise AnsibleError(\"No valid role data found\")\n\n        if tmp_file:\n\n            display.debug(\"installing from %s\" % tmp_file)\n\n            if not tarfile.is_tarfile(tmp_file):\n                raise AnsibleError(\"the downloaded file does not appear to be a valid tar archive.\")\n            else:\n                role_tar_file = tarfile.open(tmp_file, \"r\")\n                # verify the role's meta file\n                meta_file = None\n                members = role_tar_file.getmembers()\n                # next find the metadata file\n                for member in members:\n                    for meta_main in self.META_MAIN:\n                        if meta_main in member.name:\n                            # Look for parent of meta/main.yml\n                            # Due to possibility of sub roles each containing meta/main.yml\n                            # look for shortest length parent\n                            meta_parent_dir = os.path.dirname(os.path.dirname(member.name))\n                            if not meta_file:\n                                archive_parent_dir = meta_parent_dir\n                                meta_file = member\n                            else:\n                                if len(meta_parent_dir) < len(archive_parent_dir):\n                                    archive_parent_dir = meta_parent_dir\n                                    meta_file = member\n                if not meta_file:\n                    raise AnsibleError(\"this role does not appear to have a meta/main.yml file.\")\n                else:\n                    try:\n                        self._metadata = yaml_load(role_tar_file.extractfile(meta_file))\n                    except Exception:\n                        raise AnsibleError(\"this role does not appear to have a valid meta/main.yml file.\")\n\n                paths = self.paths\n                if self.path != paths[0]:\n                    # path can be passed though __init__\n                    # FIXME should this be done in __init__?\n                    paths[:0] = self.path\n                paths_len = len(paths)\n                for idx, path in enumerate(paths):\n                    self.path = path\n                    display.display(\"- extracting %s to %s\" % (self.name, self.path))\n                    try:\n                        if os.path.exists(self.path):\n                            if not os.path.isdir(self.path):\n                                raise AnsibleError(\"the specified roles path exists and is not a directory.\")\n                            elif not context.CLIARGS.get(\"force\", False):\n                                raise AnsibleError(\"the specified role %s appears to already exist. Use --force to replace it.\" % self.name)\n                            else:\n                                # using --force, remove the old path\n                                if not self.remove():\n                                    raise AnsibleError(\"%s doesn't appear to contain a role.\\n  please remove this directory manually if you really \"\n                                                       \"want to put the role here.\" % self.path)\n                        else:\n                            os.makedirs(self.path)\n\n                        # We strip off any higher-level directories for all of the files\n                        # contained within the tar file here. The default is 'github_repo-target'.\n                        # Gerrit instances, on the other hand, does not have a parent directory at all.\n                        for member in members:\n                            # we only extract files, and remove any relative path\n                            # bits that might be in the file for security purposes\n                            # and drop any containing directory, as mentioned above\n                            if member.isreg() or member.issym():\n                                n_member_name = to_native(member.name)\n                                n_archive_parent_dir = to_native(archive_parent_dir)\n                                n_parts = n_member_name.replace(n_archive_parent_dir, \"\", 1).split(os.sep)\n                                n_final_parts = []\n                                for n_part in n_parts:\n                                    # TODO if the condition triggers it produces a broken installation.\n                                    # It will create the parent directory as an empty file and will\n                                    # explode if the directory contains valid files.\n                                    # Leaving this as is since the whole module needs a rewrite.\n                                    if n_part != '..' and not n_part.startswith('~') and '$' not in n_part:\n                                        n_final_parts.append(n_part)\n                                member.name = os.path.join(*n_final_parts)\n\n                                if _check_working_data_filter():\n                                    # deprecated: description='extract fallback without filter' python_version='3.11'\n                                    role_tar_file.extract(member, to_native(self.path), filter='data')  # type: ignore[call-arg]\n                                else:\n                                    role_tar_file.extract(member, to_native(self.path))\n\n                        # write out the install info file for later use\n                        self._write_galaxy_install_info()\n                        break\n                    except OSError as e:\n                        if e.errno == errno.EACCES and idx < paths_len - 1:\n                            continue\n                        raise AnsibleError(\"Could not update files in %s: %s\" % (self.path, to_native(e)))\n\n                # return the parsed yaml metadata\n                display.display(\"- %s was installed successfully\" % str(self))\n                if not (self.src and os.path.isfile(self.src)):\n                    try:\n                        os.unlink(tmp_file)\n                    except (OSError, IOError) as e:\n                        display.warning(u\"Unable to remove tmp file (%s): %s\" % (tmp_file, to_text(e)))\n                return True\n\n        return False\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendfile(request, filename, **kwargs):\n    # Respect the If-Modified-Since header.\n    statobj = os.stat(filename)\n\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj[stat.ST_MTIME], statobj[stat.ST_SIZE]):\n        return HttpResponseNotModified()\n\n    with File(open(filename, 'rb')) as f:\n        response = HttpResponse(f.chunks())\n\n    response[\"Last-Modified\"] = http_date(statobj[stat.ST_MTIME])\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def url_for(  # type: ignore[override]\n        self,\n        *,\n        filename: PathLike,\n        append_version: Optional[bool] = None,\n    ) -> URL:\n        if append_version is None:\n            append_version = self._append_version\n        filename = str(filename).lstrip(\"/\")\n\n        url = URL.build(path=self._prefix, encoded=True)\n        # filename is not encoded\n        if YARL_VERSION < (1, 6):\n            url = url / filename.replace(\"%\", \"%25\")\n        else:\n            url = url / filename\n\n        if append_version:\n            try:\n                filepath = self._directory.joinpath(filename).resolve()\n                if not self._follow_symlinks:\n                    filepath.relative_to(self._directory)\n            except (ValueError, FileNotFoundError):\n                # ValueError for case when path point to symlink\n                # with follow_symlinks is False\n                return url  # relatively safe\n            if filepath.is_file():\n                # TODO cache file content\n                # with file watcher for cache invalidation\n                with filepath.open(\"rb\") as f:\n                    file_bytes = f.read()\n                h = self._get_file_hash(file_bytes)\n                url = url.with_query({self.VERSION_KEY: h})\n                return url\n        return url\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_paths(base_path: pathlib.Path):\n    data_file = pathlib.Path(str(base_path) + \".data\")\n    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n\n    return data_file, metadata_file\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        path = urlparse(self.url).path\n        content_disposition = resp.headers.get(\"Content-Disposition\")\n        if content_disposition is not None and (\n            file_name := next(re.finditer(r\"filename=(.+)\", content_disposition), None)\n        ):\n            # NB: If the filename is quoted, unquote it\n            basename = file_name[1].strip(\"'\\\"\")\n            if _is_path(basename):\n                raise MlflowException.invalid_parameter_value(\n                    f\"Invalid filename in Content-Disposition header: {basename}. \"\n                    \"It must be a file name, not a path.\"\n                )\n        elif path is not None and len(posixpath.basename(path)) > 0:\n            basename = posixpath.basename(path)\n        else:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def edit_package():\n    api = flask.current_app.config[\"PYLOAD_API\"]\n    try:\n        id = int(flask.request.form[\"pack_id\"])\n        data = {\n            \"name\": flask.request.form[\"pack_name\"],\n            \"_folder\": flask.request.form[\"pack_folder\"],\n            \"password\": flask.request.form[\"pack_pws\"],\n        }\n\n        api.set_package_data(id, data)\n        return jsonify(response=\"success\")\n\n    except Exception:\n        return jsonify(False), 500\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def include_is_allowed(filepath):\n    for root in settings.ALLOWED_INCLUDE_ROOTS:\n        if filepath.startswith(root):\n            return True\n    return False\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def element():\n    element_url = src_url = request.args.get('url')\n    if element_url.startswith('gAAAAA'):\n        try:\n            cipher_suite = Fernet(g.session_key)\n            src_url = cipher_suite.decrypt(element_url.encode()).decode()\n        except (InvalidSignature, InvalidToken) as e:\n            return render_template(\n                'error.html',\n                error_message=str(e)), 401\n\n    src_type = request.args.get('type')\n\n    try:\n        file_data = g.user_request.send(base_url=src_url).content\n        tmp_mem = io.BytesIO()\n        tmp_mem.write(file_data)\n        tmp_mem.seek(0)\n\n        return send_file(tmp_mem, mimetype=src_type)\n    except exceptions.RequestException:\n        pass\n\n    empty_gif = base64.b64decode(\n        'R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==')\n    return send_file(io.BytesIO(empty_gif), mimetype='image/gif')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def download_compressed(self, url, zippath, unzippedpath):\n        \"\"\"Downloads a compressed file and extracts it\n\n        Args:\n            url (str): download link\n            zippath (str): path to download compressed file\n            unzippedpath (str): path to unzip compressed file\n        \"\"\"\n\n        response = requests.get(url, stream=True)\n\n        with open(zippath, \"wb\") as f:\n            f.write(response.raw.read())\n\n        shutil.unpack_archive(zippath, unzippedpath)\n        os.remove(zippath)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def snake_case(value: str) -> str:\n    value = re.sub(r\"([A-Z]{2,})([A-Z][a-z]|[ -_]|$)\", lambda m: m.group(1).title() + m.group(2), value.strip())\n    value = re.sub(r\"(^|[ _-])([A-Z])\", lambda m: m.group(1) + m.group(2).lower(), value)\n    return stringcase.snakecase(value)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n    head, tail = posixpath.split(artifact_path)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        tmp_path = os.path.join(tmp_dir, tail)\n        with open(tmp_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            while True:\n                chunk = request.stream.read(chunk_size)\n                if len(chunk) == 0:\n                    break\n                f.write(chunk)\n\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)\n\n    return _wrap_response(UploadArtifact.Response())\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _extract(\n        self,\n        path: Optional[Any] = None,\n        targets: Optional[List[str]] = None,\n        return_dict: bool = False,\n        callback: Optional[ExtractCallback] = None,\n    ) -> Optional[Dict[str, IO[Any]]]:\n        if callback is None:\n            pass\n        elif isinstance(callback, ExtractCallback):\n            self.reporterd = Thread(target=self.reporter, args=(callback,), daemon=True)\n            self.reporterd.start()\n        else:\n            raise ValueError(\"Callback specified is not an instance of subclass of py7zr.callbacks.ExtractCallback class\")\n        target_files: List[Tuple[pathlib.Path, Dict[str, Any]]] = []\n        target_dirs: List[pathlib.Path] = []\n        if path is not None:\n            if isinstance(path, str):\n                path = pathlib.Path(path)\n            try:\n                if not path.exists():\n                    path.mkdir(parents=True)\n                else:\n                    pass\n            except OSError as e:\n                if e.errno == errno.EEXIST and path.is_dir():\n                    pass\n                else:\n                    raise e\n        fnames: List[str] = []  # check duplicated filename in one archive?\n        self.q.put((\"pre\", None, None))\n        for f in self.files:\n            # When archive has a multiple files which have same name\n            # To guarantee order of archive, multi-thread decompression becomes off.\n            # Currently always overwrite by latter archives.\n            # TODO: provide option to select overwrite or skip.\n            if f.filename not in fnames:\n                outname = f.filename\n            else:\n                i = 0\n                while True:\n                    outname = f.filename + \"_%d\" % i\n                    if outname not in fnames:\n                        break\n                    i += 1\n            fnames.append(outname)\n            # check f.filename has invalid directory traversals\n            if path is None:\n                # do following but is_relative_to introduced in py 3.9\n                # so I replaced it with relative_to. when condition is not satisfied, raise ValueError\n                # if not pathlib.Path(...).joinpath(remove_relative_path_marker(outname)).is_relative_to(...):\n                #    raise Bad7zFile\n                try:\n                    pathlib.Path(os.getcwd()).joinpath(remove_relative_path_marker(outname)).relative_to(os.getcwd())\n                except ValueError:\n                    raise Bad7zFile\n                outfilename = pathlib.Path(remove_relative_path_marker(outname))\n            else:\n                outfilename = path.joinpath(remove_relative_path_marker(outname))\n                try:\n                    outfilename.relative_to(path)\n                except ValueError:\n                    raise Bad7zFile\n            # When python on Windows and not python on Cygwin,\n            # Add win32 file namespace to exceed microsoft windows\n            # path length limitation to 260 bytes\n            # ref.\n            # https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n            # In editions of Windows before Windows 10 version 1607,\n            # the maximum length for a path is MAX_PATH, which is defined as\n            # 260 characters. In later versions of Windows, changing a registry key\n            # or select option when python installation is required to remove the limit.\n            if is_windows_native_python() and outfilename.is_absolute() and not is_windows_unc_path(outfilename):\n                outfilename = pathlib.WindowsPath(\"\\\\\\\\?\\\\\" + str(outfilename))\n            if targets is not None and f.filename not in targets:\n                self.worker.register_filelike(f.id, None)\n                continue\n            if return_dict:\n                if f.is_directory or f.is_socket:\n                    # ignore special files and directories\n                    pass\n                else:\n                    fname = outfilename.as_posix()\n                    _buf = io.BytesIO()\n                    self._dict[fname] = _buf\n                    self.worker.register_filelike(f.id, MemIO(_buf))\n            elif f.is_directory:\n                if not outfilename.exists():\n                    target_dirs.append(outfilename)\n                    target_files.append((outfilename, f.file_properties()))\n                else:\n                    pass\n            elif f.is_socket:\n                pass  # TODO: implement me.\n            elif f.is_symlink or f.is_junction:\n                self.worker.register_filelike(f.id, outfilename)\n            else:\n                self.worker.register_filelike(f.id, outfilename)\n                target_files.append((outfilename, f.file_properties()))\n        for target_dir in sorted(target_dirs):\n            try:\n                target_dir.mkdir(parents=True)\n            except FileExistsError:\n                if target_dir.is_dir():\n                    pass\n                elif target_dir.is_file():\n                    raise DecompressionError(\"Directory {} is existed as a normal file.\".format(str(target_dir)))\n                else:\n                    raise DecompressionError(\"Directory {} making fails on unknown condition.\".format(str(target_dir)))\n\n        if callback is not None:\n            self.worker.extract(\n                self.fp,\n                parallel=(not self.password_protected and not self._filePassed),\n                q=self.q,\n            )\n        else:\n            self.worker.extract(\n                self.fp,\n                parallel=(not self.password_protected and not self._filePassed),\n            )\n\n        self.q.put((\"post\", None, None))\n        # early return when dict specified\n        if return_dict:\n            return self._dict\n        # set file properties\n        for outfilename, properties in target_files:\n            # mtime\n            lastmodified = None\n            try:\n                lastmodified = ArchiveTimestamp(properties[\"lastwritetime\"]).totimestamp()\n            except KeyError:\n                pass\n            if lastmodified is not None:\n                os.utime(str(outfilename), times=(lastmodified, lastmodified))\n            if os.name == \"posix\":\n                st_mode = properties[\"posix_mode\"]\n                if st_mode is not None:\n                    outfilename.chmod(st_mode)\n                    continue\n            # fallback: only set readonly if specified\n            if properties[\"readonly\"] and not properties[\"is_directory\"]:\n                ro_mask = 0o777 ^ (stat.S_IWRITE | stat.S_IWGRP | stat.S_IWOTH)\n                outfilename.chmod(outfilename.stat().st_mode & ro_mask)\n        return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def writestr(self, data: Union[str, bytes, bytearray, memoryview], arcname: str):\n        if not isinstance(arcname, str):\n            raise ValueError(\"Unsupported arcname\")\n        if isinstance(data, str):\n            self.writef(io.BytesIO(data.encode(\"UTF-8\")), arcname)\n        elif isinstance(data, bytes) or isinstance(data, bytearray) or isinstance(data, memoryview):\n            self.writef(io.BytesIO(data), arcname)\n        else:\n            raise ValueError(\"Unsupported data type.\")\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _abort_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/abort` to abort a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        AbortMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"upload_id\": [_assert_string],\n        },\n    )\n    path = request_message.path\n    upload_id = request_message.upload_id\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    artifact_repo.abort_multipart_upload(\n        path,\n        upload_id,\n        artifact_path,\n    )\n    return _wrap_response(AbortMultipartUpload.Response())\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        if not os.path.exists(directory):\n            try:\n                if self.directory_permissions_mode is not None:\n                    # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                    # argument to intermediate-level directories.\n                    old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                    try:\n                        os.makedirs(directory, self.directory_permissions_mode)\n                    finally:\n                        os.umask(old_umask)\n                else:\n                    os.makedirs(directory)\n            except FileExistsError:\n                # There's a race between os.path.exists() and os.makedirs().\n                # If os.makedirs() fails with FileExistsError, the directory\n                # was created concurrently.\n                pass\n        if not os.path.isdir(directory):\n            raise IOError(\"%s exists and is not a directory.\" % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return name.replace('\\\\', '/')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def list_artifacts(self, path=None):\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, tail = self.artifact_uri.split(endpoint, maxsplit=1)\n        root = tail.lstrip(\"/\")\n        params = {\"path\": posixpath.join(root, path) if path else root}\n        host_creds = _get_default_host_creds(url)\n        resp = http_request(host_creds, endpoint, \"GET\", params=params)\n        augmented_raise_for_status(resp)\n        file_infos = []\n        for f in resp.json().get(\"files\", []):\n            validate_path_is_safe(f[\"path\"])\n            file_info = FileInfo(\n                posixpath.join(path, f[\"path\"]) if path else f[\"path\"],\n                f[\"is_dir\"],\n                int(f[\"file_size\"]) if (\"file_size\" in f) else None,\n            )\n            file_infos.append(file_info)\n\n        return sorted(file_infos, key=lambda f: f.path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=request_dict[\"path\"],\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = request_dict[\"path\"]\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.join(component_root, filename)\n\n        LOGGER.debug(\"ComponentRequestHandler: GET: %s -> %s\", path, abspath)\n\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except (OSError) as e:\n            LOGGER.error(f\"ComponentRequestHandler: GET {path} read error\", exc_info=e)\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename and not os.path.exists(filename):\n                    os.makedirs(filename)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname and not os.path.exists(dirname):\n                        os.makedirs(dirname)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n        validate_path_is_safe(path)\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            static_path = os.path.join(self.E.mod, \"web/\", self.vpath[5:])\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _create_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/create` to create a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        CreateMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"num_parts\": [_assert_intlike],\n        },\n    )\n    path = request_message.path\n    num_parts = request_message.num_parts\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    create_response = artifact_repo.create_multipart_upload(\n        path,\n        num_parts,\n        artifact_path,\n    )\n    response_message = create_response.to_proto()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def read_other_paths(request: Request) -> Response:\n    \"\"\"\n    Return related frontend files. Adapted from https://github.com/tiangolo/fastapi/issues/130\n    \"\"\"\n    # check first if requested file exists (for frontend assets)\n    path = request.path_params[\"catchall\"]\n\n    # search for matching route in package (i.e. /dataset)\n    ui_file = match_route(get_ui_file_map(), path)\n\n    # if not, check if the requested file is an asset (i.e. /_next/static/...)\n    if not ui_file:\n        ui_file = get_path_to_admin_ui_file(path)\n\n    # Serve up the file as long as it is within the UI directory\n    if ui_file and ui_file.is_file():\n        if not path_is_in_ui_directory(ui_file):\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND, detail=\"Item not found\"\n            )\n        logger.debug(\n            \"catchall request path '{}' matched static admin UI file: {}\",\n            path,\n            ui_file,\n        )\n        return FileResponse(ui_file)\n\n    # raise 404 for anything that should be backend endpoint but we can't find it\n    if path.startswith(API_PREFIX[1:]):\n        logger.debug(\n            \"catchall request path '{}' matched an invalid API route, return 404\",\n            path,\n        )\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND, detail=\"Item not found\"\n        )\n\n    # otherwise return the index\n    logger.debug(\n        \"catchall request path '{}' did not match any admin UI routes, return generic admin UI index\",\n        path,\n    )\n    return get_admin_index_as_response()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = os.path.join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return os.path.join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_context_data(self, **kwargs):\n        template = self.kwargs['template']\n        templates = []\n        try:\n            default_engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            # This doesn't account for template loaders (#24128).\n            for index, directory in enumerate(default_engine.dirs):\n                template_file = Path(directory) / template\n                if template_file.exists():\n                    with template_file.open() as f:\n                        template_contents = f.read()\n                else:\n                    template_contents = ''\n                templates.append({\n                    'file': template_file,\n                    'exists': template_file.exists(),\n                    'contents': template_contents,\n                    'order': index,\n                })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': template,\n            'templates': templates,\n        })\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_package(self, name, links, dest=Destination.QUEUE):\n        \"\"\"\n        Adds a package, with links to desired destination.\n\n        :param name: name of the new package\n        :param links: list of urls\n        :param dest: `Destination`\n        :return: package id of the new package\n        \"\"\"\n        if self.pyload.config.get(\"general\", \"folder_per_package\"):\n            folder = name\n        else:\n            folder = \"\"\n\n        folder = (\n            folder.replace(\"http://\", \"\")\n            .replace(\"https://\", \"\")\n            .replace(\":\", \"\")\n            .replace(\"/\", \"_\")\n            .replace(\"\\\\\", \"_\")\n        )\n\n        package_id = self.pyload.files.add_package(name, folder, Destination(dest))\n\n        self.pyload.files.add_links(links, package_id)\n\n        self.pyload.log.info(\n            self._(\"Added package {name} containing {count:d} links\").format(\n                name=name, count=len(links)\n            )\n        )\n\n        self.pyload.files.save()\n\n        return package_id\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendfile(request, filename, **kwargs):\n    response = HttpResponse()\n    url = _convert_file_to_url(filename)\n    response['X-Accel-Redirect'] = url.encode('utf-8')\n\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def window():\n    target_url = request.args.get('location')\n    if target_url.startswith('gAAAAA'):\n        cipher_suite = Fernet(g.session_key)\n        target_url = cipher_suite.decrypt(target_url.encode()).decode()\n\n    content_filter = Filter(\n        g.session_key,\n        root_url=request.url_root,\n        config=g.user_config)\n    target = urlparse.urlparse(target_url)\n    host_url = f'{target.scheme}://{target.netloc}'\n\n    get_body = g.user_request.send(base_url=target_url).text\n\n    results = bsoup(get_body, 'html.parser')\n    src_attrs = ['src', 'href', 'srcset', 'data-srcset', 'data-src']\n\n    # Parse HTML response and replace relative links w/ absolute\n    for element in results.find_all():\n        for attr in src_attrs:\n            if not element.has_attr(attr) or not element[attr].startswith('/'):\n                continue\n\n            element[attr] = host_url + element[attr]\n\n    # Replace or remove javascript sources\n    for script in results.find_all('script', {'src': True}):\n        if 'nojs' in request.args:\n            script.decompose()\n        else:\n            content_filter.update_element_src(script, 'application/javascript')\n\n    # Replace all possible image attributes\n    img_sources = ['src', 'data-src', 'data-srcset', 'srcset']\n    for img in results.find_all('img'):\n        _ = [\n            content_filter.update_element_src(img, 'image/png', attr=_)\n            for _ in img_sources if img.has_attr(_)\n        ]\n\n    # Replace all stylesheet sources\n    for link in results.find_all('link', {'href': True}):\n        content_filter.update_element_src(link, 'text/css', attr='href')\n\n    # Use anonymous view for all links on page\n    for a in results.find_all('a', {'href': True}):\n        a['href'] = f'{Endpoint.window}?location=' + a['href'] + (\n            '&nojs=1' if 'nojs' in request.args else '')\n\n    # Remove all iframes -- these are commonly used inside of <noscript> tags\n    # to enforce loading Google Analytics\n    for iframe in results.find_all('iframe'):\n        iframe.decompose()\n\n    return render_template(\n        'display.html',\n        response=results,\n        translation=app.config['TRANSLATIONS'][\n            g.user_config.get_localization_lang()\n        ]\n    )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    # We must decode URL before validating it\n    path = urllib.parse.unquote(path)\n\n    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def dump_content(destination, path, getter):\n    logging.debug(path)\n    content = getter(path)\n    if path.endswith(\"/\"):\n        path = path + \"index.html\"\n\n    path = (Path(destination) / path.lstrip(\"/\")).resolve()\n    if not Path(destination) in path.parents:\n        raise CommandError(\"Path traversal detected, aborting.\")\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    with open(path, \"wb\") as f:\n        f.write(content)\n    return content\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def boboAwareZopeTraverse(object, path_items, econtext):\n    \"\"\"Traverses a sequence of names, first trying attributes then items.\n\n    This uses zope.traversing path traversal where possible and interacts\n    correctly with objects providing OFS.interface.ITraversable when\n    necessary (bobo-awareness).\n    \"\"\"\n    request = getattr(econtext, 'request', None)\n    path_items = list(path_items)\n    path_items.reverse()\n\n    while path_items:\n        name = path_items.pop()\n\n        if name == '_':\n            warnings.warn('Traversing to the name `_` is deprecated '\n                          'and will be removed in Zope 6.',\n                          DeprecationWarning)\n        elif name.startswith('_'):\n            raise NotFound(name)\n\n        if OFS.interfaces.ITraversable.providedBy(object):\n            object = object.restrictedTraverse(name)\n        else:\n            object = traversePathElement(object, name, path_items,\n                                         request=request)\n    return object\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_obj_absolute_path(obj_path):\n    return safe_join(DATAROOT, obj_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def handle_html_static(self, request):\n        \"\"\"Handle static html.\"\"\"\n        if not (page := request.path[1:]):\n            page = \"index.html\"\n        file = os.path.normpath(os.path.join(self.web_path, page))\n        if not file.startswith(self.web_path):\n            raise ValueError(f\"File access outside {self.web_path} not permitted.\")\n        try:\n            with open(file, encoding=\"utf-8\"):\n                return web.FileResponse(file)\n        except (FileNotFoundError, IsADirectoryError) as exc:\n            raise web.HTTPNotFound(reason=\"File not found\") from exc\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def side_effect(old_cmd, command):\n    with zipfile.ZipFile(_zip_file(old_cmd), 'r') as archive:\n        for file in archive.namelist():\n            if not os.path.abspath(file).startswith(os.getcwd()):\n                # it's unsafe to overwrite files outside of the current directory\n                continue\n\n            try:\n                os.remove(file)\n            except OSError:\n                # does not try to remove directories as we cannot know if they\n                # already existed before\n                pass\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _secure_path(path_tuple):\n    if _has_insecure_pathelement(path_tuple):\n        # belt-and-suspenders security; this should never be true\n        # unless someone screws up the traversal_path code\n        # (request.subpath is computed via traversal_path too)\n        return None\n    if any([_contains_invalid_element_char(item) for item in path_tuple]):\n        return None\n    encoded = '/'.join(path_tuple)  # will be unicode\n    return encoded\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def make_after_request_function(resources):\n    def cors_after_request(resp):\n        # If CORS headers are set in a view decorator, pass\n        if resp.headers is not None and resp.headers.get(ACL_ORIGIN):\n            LOG.debug('CORS have been already evaluated, skipping')\n            return resp\n        normalized_path = unquote_plus(request.path)\n        for res_regex, res_options in resources:\n            if try_match(normalized_path, res_regex):\n                LOG.debug(\"Request to '%s' matches CORS resource '%s'. Using options: %s\",\n                      request.path, get_regexp_pattern(res_regex), res_options)\n                set_cors_headers(resp, res_options)\n                break\n        else:\n            LOG.debug('No CORS rule matches')\n        return resp\n    return cors_after_request\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def put(self, name: str):\n        ''' add new file\n            params in FormData:\n                - file\n                - original_file_name [optional]\n        '''\n\n        data = {}\n        mindsdb_file_name = name\n\n        existing_file_names = ca.file_controller.get_files_names()\n\n        def on_field(field):\n            name = field.field_name.decode()\n            value = field.value.decode()\n            data[name] = value\n\n        file_object = None\n\n        def on_file(file):\n            nonlocal file_object\n            data['file'] = file.file_name.decode()\n            file_object = file.file_object\n\n        temp_dir_path = tempfile.mkdtemp(prefix='mindsdb_file_')\n\n        if request.headers['Content-Type'].startswith('multipart/form-data'):\n            parser = multipart.create_form_parser(\n                headers=request.headers,\n                on_field=on_field,\n                on_file=on_file,\n                config={\n                    'UPLOAD_DIR': temp_dir_path.encode(),    # bytes required\n                    'UPLOAD_KEEP_FILENAME': True,\n                    'UPLOAD_KEEP_EXTENSIONS': True,\n                    'MAX_MEMORY_FILE_SIZE': 0\n                }\n            )\n\n            while True:\n                chunk = request.stream.read(8192)\n                if not chunk:\n                    break\n                parser.write(chunk)\n            parser.finalize()\n            parser.close()\n\n            if file_object is not None and not file_object.closed:\n                file_object.close()\n        else:\n            data = request.json\n\n        if mindsdb_file_name in existing_file_names:\n            return http_error(\n                400,\n                \"File already exists\",\n                f\"File with name '{data['file']}' already exists\"\n            )\n\n        if data.get('source_type') == 'url':\n            url = data['source']\n            data['file'] = data['name']\n\n            config = Config()\n            is_cloud = config.get('cloud', False)\n            if is_cloud is True and ctx.user_class != 1:\n                info = requests.head(url)\n                file_size = info.headers.get('Content-Length')\n                try:\n                    file_size = int(file_size)\n                except Exception:\n                    pass\n\n                if file_size is None:\n                    return http_error(\n                        400,\n                        \"Error getting file info\",\n                        \"\u0421an't determine remote file size\"\n                    )\n                if file_size > 1024 * 1024 * 100:\n                    return http_error(\n                        400,\n                        \"File is too big\",\n                        \"Upload limit for file is 100Mb\"\n                    )\n            with requests.get(url, stream=True) as r:\n                if r.status_code != 200:\n                    return http_error(\n                        400,\n                        \"Error getting file\",\n                        f\"Got status code: {r.status_code}\"\n                    )\n                file_path = os.path.join(temp_dir_path, data['file'])\n                with open(file_path, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        f.write(chunk)\n\n        original_file_name = data.get('original_file_name')\n\n        file_path = os.path.join(temp_dir_path, data['file'])\n        lp = file_path.lower()\n        if lp.endswith(('.zip', '.tar.gz')):\n            if lp.endswith('.zip'):\n                with zipfile.ZipFile(file_path) as f:\n                    f.extractall(temp_dir_path)\n            elif lp.endswith('.tar.gz'):\n                with tarfile.open(file_path) as f:\n                    safe_extract(f, temp_dir_path)\n            os.remove(file_path)\n            files = os.listdir(temp_dir_path)\n            if len(files) != 1:\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain only one data file.')\n            file_path = os.path.join(temp_dir_path, files[0])\n            mindsdb_file_name = files[0]\n            if not os.path.isfile(file_path):\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain data file in root.')\n\n        ca.file_controller.save_file(mindsdb_file_name, file_path, file_name=original_file_name)\n\n        os.rmdir(temp_dir_path)\n\n        return '', 200\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        # follow symlinks to get an accurate normalized path\n        component_root = os.path.realpath(component_root)\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.realpath(os.path.join(component_root, filename))\n\n        # Do NOT expose anything outside of the component root.\n        if os.path.commonpath([component_root, abspath]) != component_root:\n            self.write(\"forbidden\")\n            self.set_status(403)\n            return\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except OSError as e:\n            _LOGGER.error(\n                \"ComponentRequestHandler: GET %s read error\", abspath, exc_info=e\n            )\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _unzip_iter(filename, root, verbose=True):\n    if verbose:\n        sys.stdout.write('Unzipping %s' % os.path.split(filename)[1])\n        sys.stdout.flush()\n\n    try:\n        zf = zipfile.ZipFile(filename)\n    except zipfile.error as e:\n        yield ErrorMessage(filename, 'Error with downloaded zip file')\n        return\n    except Exception as e:\n        yield ErrorMessage(filename, e)\n        return\n\n    zf.extractall(root)\n\n    if verbose:\n        print()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        filename = str(filename).replace('\\\\', '/')\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _build_api(self) -> None:\n        # Generate Client\n        client_path = self.package_dir / \"client.py\"\n        client_template = self.env.get_template(\"client.pyi\")\n        client_path.write_text(client_template.render())\n\n        # Generate endpoints\n        api_dir = self.package_dir / \"api\"\n        api_dir.mkdir()\n        api_init = api_dir / \"__init__.py\"\n        api_init.write_text('\"\"\" Contains synchronous methods for accessing the API \"\"\"')\n\n        async_api_dir = self.package_dir / \"async_api\"\n        async_api_dir.mkdir()\n        async_api_init = async_api_dir / \"__init__.py\"\n        async_api_init.write_text('\"\"\" Contains async methods for accessing the API \"\"\"')\n\n        api_errors = self.package_dir / \"errors.py\"\n        errors_template = self.env.get_template(\"errors.pyi\")\n        api_errors.write_text(errors_template.render())\n\n        endpoint_template = self.env.get_template(\"endpoint_module.pyi\")\n        async_endpoint_template = self.env.get_template(\"async_endpoint_module.pyi\")\n        for tag, collection in self.openapi.endpoint_collections_by_tag.items():\n            tag = utils.snake_case(tag)\n            module_path = api_dir / f\"{tag}.py\"\n            module_path.write_text(endpoint_template.render(collection=collection))\n            async_module_path = async_api_dir / f\"{tag}.py\"\n            async_module_path.write_text(async_endpoint_template.render(collection=collection))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def validate_absolute_path(self, root: str, absolute_path: str) -> Optional[str]:\n        full_path = os.path.realpath(absolute_path)\n\n        if os.path.isdir(full_path):\n            # we don't want to serve directories, and serve only files\n            raise tornado.web.HTTPError(404)\n\n        if os.path.commonpath([full_path, root]) != root:\n            # Don't allow misbehaving clients to break out of the static files directory\n            _LOGGER.warning(\n                \"Serving files outside of the static directory is not supported\"\n            )\n            raise tornado.web.HTTPError(404)\n\n        if (\n            os.path.exists(full_path)\n            and os.path.getsize(full_path) > MAX_APP_STATIC_FILE_SIZE\n        ):\n            raise tornado.web.HTTPError(\n                404,\n                \"File is too large, its size should not exceed \"\n                f\"{MAX_APP_STATIC_FILE_SIZE} bytes\",\n                reason=\"File is too large\",\n            )\n\n        return super().validate_absolute_path(root, absolute_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _extract_tar_file(tar, filename, b_dest, b_temp_path, expected_hash=None):\n    n_filename = to_native(filename, errors='surrogate_or_strict')\n    try:\n        member = tar.getmember(n_filename)\n    except KeyError:\n        raise AnsibleError(\"Collection tar at '%s' does not contain the expected file '%s'.\" % (to_native(tar.name),\n                                                                                                n_filename))\n\n    with tempfile.NamedTemporaryFile(dir=b_temp_path, delete=False) as tmpfile_obj:\n        bufsize = 65536\n        sha256_digest = sha256()\n        with _tarfile_extract(tar, member) as tar_obj:\n            data = tar_obj.read(bufsize)\n            while data:\n                tmpfile_obj.write(data)\n                tmpfile_obj.flush()\n                sha256_digest.update(data)\n                data = tar_obj.read(bufsize)\n\n        actual_hash = sha256_digest.hexdigest()\n\n        if expected_hash and actual_hash != expected_hash:\n            raise AnsibleError(\"Checksum mismatch for '%s' inside collection at '%s'\"\n                               % (n_filename, to_native(tar.name)))\n\n        b_dest_filepath = os.path.abspath(os.path.join(b_dest, to_bytes(filename, errors='surrogate_or_strict')))\n        b_parent_dir = os.path.dirname(b_dest_filepath)\n        if b_parent_dir != b_dest and not b_parent_dir.startswith(b_dest + to_bytes(os.path.sep)):\n            raise AnsibleError(\"Cannot extract tar entry '%s' as it will be placed outside the collection directory\"\n                               % to_native(filename, errors='surrogate_or_strict'))\n\n        if not os.path.exists(b_parent_dir):\n            # Seems like Galaxy does not validate if all file entries have a corresponding dir ftype entry. This check\n            # makes sure we create the parent directory even if it wasn't set in the metadata.\n            os.makedirs(b_parent_dir, mode=0o0755)\n\n        shutil.move(to_bytes(tmpfile_obj.name, errors='surrogate_or_strict'), b_dest_filepath)\n\n        # Default to rw-r--r-- and only add execute if the tar file has execute.\n        new_mode = 0o644\n        if stat.S_IMODE(member.mode) & stat.S_IXUSR:\n            new_mode |= 0o0111\n\n        os.chmod(b_dest_filepath, new_mode)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return safe_join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def save(self, name, content, max_length=None):\n        \"\"\"\n        Save new content to the file specified by name. The content should be\n        a proper File object or any Python file-like object, ready to be read\n        from the beginning.\n        \"\"\"\n        # Get the proper name for the file, as it will actually be saved.\n        if name is None:\n            name = content.name\n\n        if not hasattr(content, 'chunks'):\n            content = File(content, name)\n\n        name = self.get_available_name(name, max_length=max_length)\n        name = self._save(name, content)\n        # Ensure that the name returned from the storage system is still valid.\n        validate_file_name(name, allow_relative_path=True)\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def config():\n    config_disabled = (\n            app.config['CONFIG_DISABLE'] or\n            not valid_user_session(session))\n\n    name = ''\n    if 'name' in request.args:\n        name = os.path.normpath(request.args.get('name'))\n        if not re.match(r'^[A-Za-z0-9_.+-]+$', name):\n            return make_response('Invalid config name', 400)\n\n    if request.method == 'GET':\n        return json.dumps(g.user_config.__dict__)\n    elif request.method == 'PUT' and not config_disabled:\n        if name:\n            config_pkl = os.path.join(app.config['CONFIG_PATH'], name)\n            session['config'] = (pickle.load(open(config_pkl, 'rb'))\n                                 if os.path.exists(config_pkl)\n                                 else session['config'])\n            return json.dumps(session['config'])\n        else:\n            return json.dumps({})\n    elif not config_disabled:\n        config_data = request.form.to_dict()\n        if 'url' not in config_data or not config_data['url']:\n            config_data['url'] = g.user_config.url\n\n        # Save config by name to allow a user to easily load later\n        if 'name' in request.args:\n            pickle.dump(\n                config_data,\n                open(os.path.join(\n                    app.config['CONFIG_PATH'],\n                    name), 'wb'))\n\n        session['config'] = config_data\n        return redirect(config_data['url'])\n    else:\n        return redirect(url_for('.index'), code=403)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_snippet_path(self, path):\r\n        \"\"\"Get snippet path.\"\"\"\r\n\r\n        snippet = None\r\n        for base in self.base_path:\r\n            if os.path.exists(base):\r\n                if os.path.isdir(base):\r\n                    if self.restrict_base_path:\r\n                        filename = os.path.abspath(os.path.join(base, path))\r\n                        # If the absolute path is no longer under the specified base path, reject the file\r\n                        if not os.path.samefile(base, os.path.dirname(filename)):\r\n                            continue\r\n                    else:\r\n                        filename = os.path.join(base, path)\r\n                    if os.path.exists(filename):\r\n                        snippet = filename\r\n                        break\r\n                else:\r\n                    dirname = os.path.dirname(base)\r\n                    filename = os.path.join(dirname, path)\r\n                    if os.path.exists(filename) and os.path.samefile(filename, base):\r\n                        snippet = filename\r\n                        break\r\n        return snippet\r\n\r"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Ensure the saved path is always relative to the storage root.\n        name = os.path.relpath(full_path, self.location)\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return safe_join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def install(self):\n\n        if self.scm:\n            # create tar file from scm url\n            tmp_file = RoleRequirement.scm_archive_role(keep_scm_meta=context.CLIARGS['keep_scm_meta'], **self.spec)\n        elif self.src:\n            if os.path.isfile(self.src):\n                tmp_file = self.src\n            elif '://' in self.src:\n                role_data = self.src\n                tmp_file = self.fetch(role_data)\n            else:\n                role_data = self.api.lookup_role_by_name(self.src)\n                if not role_data:\n                    raise AnsibleError(\"- sorry, %s was not found on %s.\" % (self.src, self.api.api_server))\n\n                if role_data.get('role_type') == 'APP':\n                    # Container Role\n                    display.warning(\"%s is a Container App role, and should only be installed using Ansible \"\n                                    \"Container\" % self.name)\n\n                role_versions = self.api.fetch_role_related('versions', role_data['id'])\n                if not self.version:\n                    # convert the version names to LooseVersion objects\n                    # and sort them to get the latest version. If there\n                    # are no versions in the list, we'll grab the head\n                    # of the master branch\n                    if len(role_versions) > 0:\n                        loose_versions = [LooseVersion(a.get('name', None)) for a in role_versions]\n                        try:\n                            loose_versions.sort()\n                        except TypeError:\n                            raise AnsibleError(\n                                'Unable to compare role versions (%s) to determine the most recent version due to incompatible version formats. '\n                                'Please contact the role author to resolve versioning conflicts, or specify an explicit role version to '\n                                'install.' % ', '.join([v.vstring for v in loose_versions])\n                            )\n                        self.version = to_text(loose_versions[-1])\n                    elif role_data.get('github_branch', None):\n                        self.version = role_data['github_branch']\n                    else:\n                        self.version = 'master'\n                elif self.version != 'master':\n                    if role_versions and to_text(self.version) not in [a.get('name', None) for a in role_versions]:\n                        raise AnsibleError(\"- the specified version (%s) of %s was not found in the list of available versions (%s).\" % (self.version,\n                                                                                                                                         self.name,\n                                                                                                                                         role_versions))\n\n                # check if there's a source link/url for our role_version\n                for role_version in role_versions:\n                    if role_version['name'] == self.version and 'source' in role_version:\n                        self.src = role_version['source']\n                    if role_version['name'] == self.version and 'download_url' in role_version:\n                        self.download_url = role_version['download_url']\n\n                tmp_file = self.fetch(role_data)\n\n        else:\n            raise AnsibleError(\"No valid role data found\")\n\n        if tmp_file:\n\n            display.debug(\"installing from %s\" % tmp_file)\n\n            if not tarfile.is_tarfile(tmp_file):\n                raise AnsibleError(\"the downloaded file does not appear to be a valid tar archive.\")\n            else:\n                role_tar_file = tarfile.open(tmp_file, \"r\")\n                # verify the role's meta file\n                meta_file = None\n                members = role_tar_file.getmembers()\n                # next find the metadata file\n                for member in members:\n                    for meta_main in self.META_MAIN:\n                        if meta_main in member.name:\n                            # Look for parent of meta/main.yml\n                            # Due to possibility of sub roles each containing meta/main.yml\n                            # look for shortest length parent\n                            meta_parent_dir = os.path.dirname(os.path.dirname(member.name))\n                            if not meta_file:\n                                archive_parent_dir = meta_parent_dir\n                                meta_file = member\n                            else:\n                                if len(meta_parent_dir) < len(archive_parent_dir):\n                                    archive_parent_dir = meta_parent_dir\n                                    meta_file = member\n                if not meta_file:\n                    raise AnsibleError(\"this role does not appear to have a meta/main.yml file.\")\n                else:\n                    try:\n                        self._metadata = yaml_load(role_tar_file.extractfile(meta_file))\n                    except Exception:\n                        raise AnsibleError(\"this role does not appear to have a valid meta/main.yml file.\")\n\n                paths = self.paths\n                if self.path != paths[0]:\n                    # path can be passed though __init__\n                    # FIXME should this be done in __init__?\n                    paths[:0] = self.path\n                paths_len = len(paths)\n                for idx, path in enumerate(paths):\n                    self.path = path\n                    display.display(\"- extracting %s to %s\" % (self.name, self.path))\n                    try:\n                        if os.path.exists(self.path):\n                            if not os.path.isdir(self.path):\n                                raise AnsibleError(\"the specified roles path exists and is not a directory.\")\n                            elif not context.CLIARGS.get(\"force\", False):\n                                raise AnsibleError(\"the specified role %s appears to already exist. Use --force to replace it.\" % self.name)\n                            else:\n                                # using --force, remove the old path\n                                if not self.remove():\n                                    raise AnsibleError(\"%s doesn't appear to contain a role.\\n  please remove this directory manually if you really \"\n                                                       \"want to put the role here.\" % self.path)\n                        else:\n                            os.makedirs(self.path)\n\n                        # We strip off any higher-level directories for all of the files\n                        # contained within the tar file here. The default is 'github_repo-target'.\n                        # Gerrit instances, on the other hand, does not have a parent directory at all.\n                        for member in members:\n                            # we only extract files, and remove any relative path\n                            # bits that might be in the file for security purposes\n                            # and drop any containing directory, as mentioned above\n                            if member.isreg() or member.issym():\n                                for attr in ('name', 'linkname'):\n                                    attr_value = getattr(member, attr, None)\n                                    if not attr_value:\n                                        continue\n                                    n_attr_value = to_native(attr_value)\n                                    n_archive_parent_dir = to_native(archive_parent_dir)\n                                    n_parts = n_attr_value.replace(n_archive_parent_dir, \"\", 1).split(os.sep)\n                                    n_final_parts = []\n                                    for n_part in n_parts:\n                                        # TODO if the condition triggers it produces a broken installation.\n                                        # It will create the parent directory as an empty file and will\n                                        # explode if the directory contains valid files.\n                                        # Leaving this as is since the whole module needs a rewrite.\n                                        #\n                                        # Check if we have any files with illegal names,\n                                        # and display a warning if so. This could help users\n                                        # to debug a broken installation.\n                                        if not n_part:\n                                            continue\n                                        if n_part == '..':\n                                            display.warning(f\"Illegal filename '{n_part}': '..' is not allowed\")\n                                            continue\n                                        if n_part.startswith('~'):\n                                            display.warning(f\"Illegal filename '{n_part}': names cannot start with '~'\")\n                                            continue\n                                        if '$' in n_part:\n                                            display.warning(f\"Illegal filename '{n_part}': names cannot contain '$'\")\n                                            continue\n                                        n_final_parts.append(n_part)\n                                    setattr(member, attr, os.path.join(*n_final_parts))\n\n                                if _check_working_data_filter():\n                                    # deprecated: description='extract fallback without filter' python_version='3.11'\n                                    role_tar_file.extract(member, to_native(self.path), filter='data')  # type: ignore[call-arg]\n                                else:\n                                    role_tar_file.extract(member, to_native(self.path))\n\n                        # write out the install info file for later use\n                        self._write_galaxy_install_info()\n                        break\n                    except OSError as e:\n                        if e.errno == errno.EACCES and idx < paths_len - 1:\n                            continue\n                        raise AnsibleError(\"Could not update files in %s: %s\" % (self.path, to_native(e)))\n\n                # return the parsed yaml metadata\n                display.display(\"- %s was installed successfully\" % str(self))\n                if not (self.src and os.path.isfile(self.src)):\n                    try:\n                        os.unlink(tmp_file)\n                    except (OSError, IOError) as e:\n                        display.warning(u\"Unable to remove tmp file (%s): %s\" % (tmp_file, to_text(e)))\n                return True\n\n        return False\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendfile(request, filepath, **kwargs):\n    '''Use the SENDFILE_ROOT value composed with the path arrived as argument\n    to build an absolute path with which resolve and return the file contents.\n\n    If the path points to a file out of the root directory (should cover both\n    situations with '..' and symlinks) then a 404 is raised.\n    '''\n    statobj = filepath.stat()\n\n    # Respect the If-Modified-Since header.\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj.st_mtime, statobj.st_size):\n        return HttpResponseNotModified()\n\n    with File(filepath.open('rb')) as f:\n        response = HttpResponse(f.chunks())\n\n    response[\"Last-Modified\"] = http_date(statobj.st_mtime)\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def url_for(  # type: ignore[override]\n        self,\n        *,\n        filename: PathLike,\n        append_version: Optional[bool] = None,\n    ) -> URL:\n        if append_version is None:\n            append_version = self._append_version\n        filename = str(filename).lstrip(\"/\")\n\n        url = URL.build(path=self._prefix, encoded=True)\n        # filename is not encoded\n        if YARL_VERSION < (1, 6):\n            url = url / filename.replace(\"%\", \"%25\")\n        else:\n            url = url / filename\n\n        if append_version:\n            unresolved_path = self._directory.joinpath(filename)\n            try:\n                if self._follow_symlinks:\n                    normalized_path = Path(os.path.normpath(unresolved_path))\n                    normalized_path.relative_to(self._directory)\n                    filepath = normalized_path.resolve()\n                else:\n                    filepath = unresolved_path.resolve()\n                    filepath.relative_to(self._directory)\n            except (ValueError, FileNotFoundError):\n                # ValueError for case when path point to symlink\n                # with follow_symlinks is False\n                return url  # relatively safe\n            if filepath.is_file():\n                # TODO cache file content\n                # with file watcher for cache invalidation\n                with filepath.open(\"rb\") as f:\n                    file_bytes = f.read()\n                h = self._get_file_hash(file_bytes)\n                url = url.with_query({self.VERSION_KEY: h})\n                return url\n        return url\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_paths(root: str, sub_path: str) \\\n        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n    base_path = flask.safe_join(root, sub_path)\n    data_file = pathlib.Path(base_path + \".data\")\n    metadata_file = pathlib.Path(base_path + \".meta\")\n\n    return data_file, metadata_file\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    path = request_dict[\"path\"]\n    path = validate_path_is_safe(path)\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        basename = self._extract_filename(resp)\n\n        if not basename:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def edit_package():\n    api = flask.current_app.config[\"PYLOAD_API\"]\n    try:\n        pack_id = int(flask.request.form[\"pack_id\"])\n        pack_folder = flask.request.form[\"pack_folder\"].lstrip(f\"{os.path.sep}\").replace(f\"..{os.path.sep}\", f\"\")\n        data = {\n            \"name\": flask.request.form[\"pack_name\"],\n            \"_folder\": pack_folder,\n            \"password\": flask.request.form[\"pack_pws\"],\n        }\n\n        api.set_package_data(pack_id, data)\n        return jsonify(response=\"success\")\n\n    except Exception:\n        return jsonify(False), 500\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def include_is_allowed(filepath):\n    filepath = os.path.abspath(filepath)\n    for root in settings.ALLOWED_INCLUDE_ROOTS:\n        if filepath.startswith(root):\n            return True\n    return False\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def element():\n    empty_gif = base64.b64decode(\n        'R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==')\n    element_url = src_url = request.args.get('url')\n    if element_url.startswith('gAAAAA'):\n        try:\n            cipher_suite = Fernet(g.session_key)\n            src_url = cipher_suite.decrypt(element_url.encode()).decode()\n        except (InvalidSignature, InvalidToken) as e:\n            return render_template(\n                'error.html',\n                error_message=str(e)), 401\n\n    src_type = request.args.get('type')\n\n    # Ensure requested element is from a valid domain\n    domain = urlparse.urlparse(src_url).netloc\n    if not validators.domain(domain):\n        return send_file(io.BytesIO(empty_gif), mimetype='image/gif')\n\n    try:\n        file_data = g.user_request.send(base_url=src_url).content\n        tmp_mem = io.BytesIO()\n        tmp_mem.write(file_data)\n        tmp_mem.seek(0)\n\n        return send_file(tmp_mem, mimetype=src_type)\n    except exceptions.RequestException:\n        pass\n\n    return send_file(io.BytesIO(empty_gif), mimetype='image/gif')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def download_compressed(self, url, zippath, unzippedpath):\n        \"\"\"Downloads a compressed file and extracts it\n\n        Args:\n            url (str): download link\n            zippath (str): path to download compressed file\n            unzippedpath (str): path to unzip compressed file\n        \"\"\"\n\n        response = requests.get(url, stream=True)\n\n        with open(zippath, \"wb\") as f:\n            f.write(response.raw.read())\n\n        if zippath.endswith('.tar.gz'):\n            tarsafe.open(zippath).extractall(unzippedpath)\n            os.remove(zippath)\n        else:\n            raise ValueError(\"unsupported archive extension: \" + zippath)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def snake_case(value: str) -> str:\n    return stringcase.snakecase(group_title(_sanitize(value)))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    artifact_path = validate_path_is_safe(artifact_path)\n    head, tail = posixpath.split(artifact_path)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        tmp_path = os.path.join(tmp_dir, tail)\n        with open(tmp_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            while True:\n                chunk = request.stream.read(chunk_size)\n                if len(chunk) == 0:\n                    break\n                f.write(chunk)\n\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)\n\n    return _wrap_response(UploadArtifact.Response())\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _extract(\n        self,\n        path: Optional[Any] = None,\n        targets: Optional[List[str]] = None,\n        return_dict: bool = False,\n        callback: Optional[ExtractCallback] = None,\n    ) -> Optional[Dict[str, IO[Any]]]:\n        if callback is None:\n            pass\n        elif isinstance(callback, ExtractCallback):\n            self.reporterd = Thread(target=self.reporter, args=(callback,), daemon=True)\n            self.reporterd.start()\n        else:\n            raise ValueError(\"Callback specified is not an instance of subclass of py7zr.callbacks.ExtractCallback class\")\n        target_files: List[Tuple[pathlib.Path, Dict[str, Any]]] = []\n        target_dirs: List[pathlib.Path] = []\n        if path is not None:\n            if isinstance(path, str):\n                path = pathlib.Path(path)\n            try:\n                if not path.exists():\n                    path.mkdir(parents=True)\n                else:\n                    pass\n            except OSError as e:\n                if e.errno == errno.EEXIST and path.is_dir():\n                    pass\n                else:\n                    raise e\n        fnames: List[str] = []  # check duplicated filename in one archive?\n        self.q.put((\"pre\", None, None))\n        for f in self.files:\n            # When archive has a multiple files which have same name\n            # To guarantee order of archive, multi-thread decompression becomes off.\n            # Currently always overwrite by latter archives.\n            # TODO: provide option to select overwrite or skip.\n            if f.filename not in fnames:\n                outname = f.filename\n            else:\n                i = 0\n                while True:\n                    outname = f.filename + \"_%d\" % i\n                    if outname not in fnames:\n                        break\n                    i += 1\n            fnames.append(outname)\n            if path is None or path.is_absolute():\n                outfilename = get_sanitized_output_path(outname, path)\n            else:\n                outfilename = get_sanitized_output_path(outname, pathlib.Path(os.getcwd()).joinpath(path))\n            if targets is not None and f.filename not in targets:\n                self.worker.register_filelike(f.id, None)\n                continue\n            if return_dict:\n                if f.is_directory or f.is_socket:\n                    # ignore special files and directories\n                    pass\n                else:\n                    fname = outfilename.as_posix()\n                    _buf = io.BytesIO()\n                    self._dict[fname] = _buf\n                    self.worker.register_filelike(f.id, MemIO(_buf))\n            elif f.is_directory:\n                if not outfilename.exists():\n                    target_dirs.append(outfilename)\n                    target_files.append((outfilename, f.file_properties()))\n                else:\n                    pass\n            elif f.is_socket:\n                pass  # TODO: implement me.\n            elif f.is_symlink or f.is_junction:\n                self.worker.register_filelike(f.id, outfilename)\n            else:\n                self.worker.register_filelike(f.id, outfilename)\n                target_files.append((outfilename, f.file_properties()))\n        for target_dir in sorted(target_dirs):\n            try:\n                target_dir.mkdir(parents=True)\n            except FileExistsError:\n                if target_dir.is_dir():\n                    pass\n                elif target_dir.is_file():\n                    raise DecompressionError(\"Directory {} is existed as a normal file.\".format(str(target_dir)))\n                else:\n                    raise DecompressionError(\"Directory {} making fails on unknown condition.\".format(str(target_dir)))\n\n        if callback is not None:\n            self.worker.extract(\n                self.fp,\n                path,\n                parallel=(not self.password_protected and not self._filePassed),\n                q=self.q,\n            )\n        else:\n            self.worker.extract(\n                self.fp,\n                path,\n                parallel=(not self.password_protected and not self._filePassed),\n            )\n\n        self.q.put((\"post\", None, None))\n        # early return when dict specified\n        if return_dict:\n            return self._dict\n        # set file properties\n        for outfilename, properties in target_files:\n            # mtime\n            lastmodified = None\n            try:\n                lastmodified = ArchiveTimestamp(properties[\"lastwritetime\"]).totimestamp()\n            except KeyError:\n                pass\n            if lastmodified is not None:\n                os.utime(str(outfilename), times=(lastmodified, lastmodified))\n            if os.name == \"posix\":\n                st_mode = properties[\"posix_mode\"]\n                if st_mode is not None:\n                    outfilename.chmod(st_mode)\n                    continue\n            # fallback: only set readonly if specified\n            if properties[\"readonly\"] and not properties[\"is_directory\"]:\n                ro_mask = 0o777 ^ (stat.S_IWRITE | stat.S_IWGRP | stat.S_IWOTH)\n                outfilename.chmod(outfilename.stat().st_mode & ro_mask)\n        return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def writestr(self, data: Union[str, bytes, bytearray, memoryview], arcname: str):\n        if not check_archive_path(arcname):\n            raise ValueError(f\"Specified path is bad: {arcname}\")\n        return self._writestr(data, arcname)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_available_name(self, name, max_length=None):\n        \"\"\"\n        Return a filename that's free on the target storage system and\n        available for new content to be written to.\n        \"\"\"\n        name = str(name).replace('\\\\', '/')\n        dir_name, file_name = os.path.split(name)\n        if '..' in pathlib.PurePath(dir_name).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dir_name)\n        validate_file_name(file_name)\n        file_root, file_ext = os.path.splitext(file_name)\n        # If the filename already exists, generate an alternative filename\n        # until it doesn't exist.\n        # Truncate original name if required, so the new filename does not\n        # exceed the max_length.\n        while self.exists(name) or (max_length and len(name) > max_length):\n            # file_ext includes the dot.\n            name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n            if max_length is None:\n                continue\n            # Truncate file_root if max_length exceeded.\n            truncation = len(name) - max_length\n            if truncation > 0:\n                file_root = file_root[:-truncation]\n                # Entire file_root was truncated in attempt to find an available filename.\n                if not file_root:\n                    raise SuspiciousFileOperation(\n                        'Storage can not find an available filename for \"%s\". '\n                        'Please make sure that the corresponding file field '\n                        'allows sufficient \"max_length\".' % name\n                    )\n                name = os.path.join(dir_name, self.get_alternative_name(file_root, file_ext))\n        return name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _abort_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/abort` to abort a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    artifact_path = validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        AbortMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"upload_id\": [_assert_string],\n        },\n    )\n    path = request_message.path\n    upload_id = request_message.upload_id\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    artifact_repo.abort_multipart_upload(\n        path,\n        upload_id,\n        artifact_path,\n    )\n    return _wrap_response(AbortMultipartUpload.Response())\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        if not os.path.exists(directory):\n            try:\n                if self.directory_permissions_mode is not None:\n                    # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                    # argument to intermediate-level directories.\n                    old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                    try:\n                        os.makedirs(directory, self.directory_permissions_mode)\n                    finally:\n                        os.umask(old_umask)\n                else:\n                    os.makedirs(directory)\n            except FileExistsError:\n                # There's a race between os.path.exists() and os.makedirs().\n                # If os.makedirs() fails with FileExistsError, the directory\n                # was created concurrently.\n                pass\n        if not os.path.isdir(directory):\n            raise IOError(\"%s exists and is not a directory.\" % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Ensure the saved path is always relative to the storage root.\n        name = os.path.relpath(full_path, self.location)\n        # Store filenames with forward slashes, even on Windows.\n        return name.replace('\\\\', '/')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def list_artifacts(self, path=None):\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, tail = self.artifact_uri.split(endpoint, maxsplit=1)\n        root = tail.lstrip(\"/\")\n        params = {\"path\": posixpath.join(root, path) if path else root}\n        host_creds = _get_default_host_creds(url)\n        resp = http_request(host_creds, endpoint, \"GET\", params=params)\n        augmented_raise_for_status(resp)\n        file_infos = []\n        for f in resp.json().get(\"files\", []):\n            validated_path = validate_path_is_safe(f[\"path\"])\n            file_info = FileInfo(\n                posixpath.join(path, validated_path) if path else validated_path,\n                f[\"is_dir\"],\n                int(f[\"file_size\"]) if (\"file_size\" in f) else None,\n            )\n            file_infos.append(file_info)\n\n        return sorted(file_infos, key=lambda f: f.path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get(self, path: str) -> None:\n        parts = path.split(\"/\")\n        component_name = parts[0]\n        component_root = self._registry.get_component_path(component_name)\n        if component_root is None:\n            self.write(\"not found\")\n            self.set_status(404)\n            return\n\n        # follow symlinks to get an accurate normalized path\n        component_root = os.path.realpath(component_root)\n        filename = \"/\".join(parts[1:])\n        abspath = os.path.realpath(os.path.join(component_root, filename))\n\n        # Do NOT expose anything outside of the component root.\n        if os.path.commonprefix([component_root, abspath]) != component_root:\n            self.write(\"forbidden\")\n            self.set_status(403)\n            return\n\n        LOGGER.debug(\"ComponentRequestHandler: GET: %s -> %s\", path, abspath)\n\n        try:\n            with open(abspath, \"rb\") as file:\n                contents = file.read()\n        except (OSError) as e:\n            LOGGER.error(f\"ComponentRequestHandler: GET {path} read error\", exc_info=e)\n            self.write(\"read error\")\n            self.set_status(404)\n            return\n\n        self.write(contents)\n        self.set_header(\"Content-Type\", self.get_content_type(abspath))\n\n        self.set_extra_headers(path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename and not os.path.exists(filename):\n                    os.makedirs(filename)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname and not os.path.exists(dirname):\n                        os.makedirs(dirname)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n        path = validate_path_is_safe(path)\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    path = request_dict[\"path\"]\n    path = validate_path_is_safe(path)\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            path_base = os.path.join(self.E.mod, \"web\")\n            static_path = absreal(os.path.join(path_base, self.vpath[5:]))\n            if not static_path.startswith(path_base):\n                t = \"attempted path traversal [{}] => [{}]\"\n                self.log(t.format(self.vpath, static_path), 1)\n                self.tx_404()\n                return False\n\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Ensure the saved path is always relative to the storage root.\n        name = os.path.relpath(full_path, self.location)\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _create_multipart_upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `POST /mlflow-artifacts/mpu/create` to create a multipart upload\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    artifact_path = validate_path_is_safe(artifact_path)\n\n    request_message = _get_request_message(\n        CreateMultipartUpload(),\n        schema={\n            \"path\": [_assert_required, _assert_string],\n            \"num_parts\": [_assert_intlike],\n        },\n    )\n    path = request_message.path\n    num_parts = request_message.num_parts\n\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    _validate_support_multipart_upload(artifact_repo)\n\n    create_response = artifact_repo.create_multipart_upload(\n        path,\n        num_parts,\n        artifact_path,\n    )\n    response_message = create_response.to_proto()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def read_other_paths(request: Request) -> Response:\n    \"\"\"\n    Return related frontend files. Adapted from https://github.com/tiangolo/fastapi/issues/130\n    \"\"\"\n    # check first if requested file exists (for frontend assets)\n    path = request.path_params[\"catchall\"]\n    logger.debug(f\"Catch all path detected: {path}\")\n    try:\n        path = sanitise_url_path(path)\n    except MalisciousUrlException:\n        # if a maliscious URL is detected, route the user to the index\n        return get_admin_index_as_response()\n\n    # search for matching route in package (i.e. /dataset)\n    ui_file = match_route(get_ui_file_map(), path)\n\n    # if not, check if the requested file is an asset (i.e. /_next/static/...)\n    if not ui_file:\n        ui_file = get_path_to_admin_ui_file(path)\n\n    # Serve up the file as long as it is within the UI directory\n    if ui_file and ui_file.is_file():\n        if not path_is_in_ui_directory(ui_file):\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND, detail=\"Item not found\"\n            )\n        logger.debug(\n            \"catchall request path '{}' matched static admin UI file: {}\",\n            path,\n            ui_file,\n        )\n        return FileResponse(ui_file)\n\n    # raise 404 for anything that should be backend endpoint but we can't find it\n    if path.startswith(API_PREFIX[1:]):\n        logger.debug(\n            \"catchall request path '{}' matched an invalid API route, return 404\",\n            path,\n        )\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND, detail=\"Item not found\"\n        )\n\n    # otherwise return the index\n    logger.debug(\n        \"catchall request path '{}' did not match any admin UI routes, return generic admin UI index\",\n        path,\n    )\n    return get_admin_index_as_response()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def job_browse(job_id: int, path):\n    \"\"\"\n    Browse directory of the job.\n    :param job_id: int\n    :param path: str\n    \"\"\"\n\n    try:\n        # Query job information\n        job_info = query_internal_api(f\"/internal/jobs/{job_id}\", \"get\")\n\n        # Base directory of the job\n        job_base_dir = os.path.dirname(os.path.dirname(job_info[\"outputdir\"]))\n\n    except Exception as err:\n        # Display error on the GUI\n        flash(str(err), \"danger\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Join the base and the requested path\n    abs_path = safe_join(job_base_dir, path)\n\n    # URL path variable for going back\n    back_path = os.path.dirname(abs_path).replace(job_base_dir, \"\")\n\n    # If path doesn't exist\n    if not os.path.exists(abs_path):\n        flash(\"Directory for this job does not exist.\", \"warning\")\n        return redirect(url_for(\"job_page\", job_id=job_id))\n\n    # Check if path is a file and send\n    if os.path.isfile(abs_path):\n        return send_file(abs_path)\n\n    files_info = []\n\n    # Show directory contents\n    files = os.listdir(abs_path)\n\n    # Store directory information\n    for file in files:\n        files_info.append({\n            \"file\": file,\n            \"directory\": os.path.isdir(os.path.join(abs_path, file))\n        })\n\n    return render_template('job_dir.html', title=f\"Job {job_id} Directory\",\n                           job_id=job_id,\n                           abs_path=abs_path,\n                           files_info=files_info,\n                           back_path=back_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_index_absolute_path(index):\n    return safe_join(INDEXDIR, index)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n        validate_path_is_safe(path)\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_context_data(self, **kwargs):\n        template = self.kwargs['template']\n        templates = []\n        try:\n            default_engine = Engine.get_default()\n        except ImproperlyConfigured:\n            # Non-trivial TEMPLATES settings aren't supported (#24125).\n            pass\n        else:\n            # This doesn't account for template loaders (#24128).\n            for index, directory in enumerate(default_engine.dirs):\n                template_file = Path(safe_join(directory, template))\n                if template_file.exists():\n                    with template_file.open() as f:\n                        template_contents = f.read()\n                else:\n                    template_contents = ''\n                templates.append({\n                    'file': template_file,\n                    'exists': template_file.exists(),\n                    'contents': template_contents,\n                    'order': index,\n                })\n        return super().get_context_data(**{\n            **kwargs,\n            'name': template,\n            'templates': templates,\n        })\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_package(self, name, links, dest=Destination.QUEUE):\n        \"\"\"\n        Adds a package, with links to desired destination.\n\n        :param name: name of the new package\n        :param links: list of urls\n        :param dest: `Destination`\n        :return: package id of the new package\n        \"\"\"\n        if self.pyload.config.get(\"general\", \"folder_per_package\"):\n            folder = name\n        else:\n            folder = \"\"\n\n        folder = (\n            folder.replace(\"http://\", \"\")\n            .replace(\"https://\", \"\")\n            .replace(\"../\", \"_\")\n            .replace(\"..\\\\\", \"_\")\n            .replace(\":\", \"\")\n            .replace(\"/\", \"_\")\n            .replace(\"\\\\\", \"_\")\n        )\n\n        package_id = self.pyload.files.add_package(name, folder, Destination(dest))\n\n        self.pyload.files.add_links(links, package_id)\n\n        self.pyload.log.info(\n            self._(\"Added package {name} containing {count:d} links\").format(\n                name=name, count=len(links)\n            )\n        )\n\n        self.pyload.files.save()\n\n        return package_id\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendfile(request, filename, **kwargs):\n    response = HttpResponse()\n    response['X-Accel-Redirect'] = _convert_file_to_url(filename)\n\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def window():\n    target_url = request.args.get('location')\n    if target_url.startswith('gAAAAA'):\n        cipher_suite = Fernet(g.session_key)\n        target_url = cipher_suite.decrypt(target_url.encode()).decode()\n\n    content_filter = Filter(\n        g.session_key,\n        root_url=request.url_root,\n        config=g.user_config)\n    target = urlparse.urlparse(target_url)\n\n    # Ensure requested URL has a valid domain\n    if not validators.domain(target.netloc):\n        return render_template(\n            'error.html',\n            error_message='Invalid location'), 400\n\n    host_url = f'{target.scheme}://{target.netloc}'\n\n    get_body = g.user_request.send(base_url=target_url).text\n\n    results = bsoup(get_body, 'html.parser')\n    src_attrs = ['src', 'href', 'srcset', 'data-srcset', 'data-src']\n\n    # Parse HTML response and replace relative links w/ absolute\n    for element in results.find_all():\n        for attr in src_attrs:\n            if not element.has_attr(attr) or not element[attr].startswith('/'):\n                continue\n\n            element[attr] = host_url + element[attr]\n\n    # Replace or remove javascript sources\n    for script in results.find_all('script', {'src': True}):\n        if 'nojs' in request.args:\n            script.decompose()\n        else:\n            content_filter.update_element_src(script, 'application/javascript')\n\n    # Replace all possible image attributes\n    img_sources = ['src', 'data-src', 'data-srcset', 'srcset']\n    for img in results.find_all('img'):\n        _ = [\n            content_filter.update_element_src(img, 'image/png', attr=_)\n            for _ in img_sources if img.has_attr(_)\n        ]\n\n    # Replace all stylesheet sources\n    for link in results.find_all('link', {'href': True}):\n        content_filter.update_element_src(link, 'text/css', attr='href')\n\n    # Use anonymous view for all links on page\n    for a in results.find_all('a', {'href': True}):\n        a['href'] = f'{Endpoint.window}?location=' + a['href'] + (\n            '&nojs=1' if 'nojs' in request.args else '')\n\n    # Remove all iframes -- these are commonly used inside of <noscript> tags\n    # to enforce loading Google Analytics\n    for iframe in results.find_all('iframe'):\n        iframe.decompose()\n\n    return render_template(\n        'display.html',\n        response=results,\n        translation=app.config['TRANSLATIONS'][\n            g.user_config.get_localization_lang()\n        ]\n    )\n"}, {"role": "assistant", "content": "False"}]}
