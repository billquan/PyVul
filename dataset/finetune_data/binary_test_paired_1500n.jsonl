{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def extract_js(response):\n    \"\"\"\n    extracts javascript from a given string\n    \"\"\"\n    return re_extract_js.findall(response)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def rpn(self, irc, msg, args):\n        \"\"\"<rpn math expression>\n\n        Returns the value of an RPN expression.\n        \"\"\"\n        stack = []\n        for arg in args:\n            try:\n                x = complex(arg)\n                if x == abs(x):\n                    x = abs(x)\n                stack.append(x)\n            except ValueError: # Not a float.\n                if arg in self._mathSafeEnv:\n                    f = self._mathSafeEnv[arg]\n                    if callable(f):\n                        called = False\n                        arguments = []\n                        while not called and stack:\n                            arguments.append(stack.pop())\n                            try:\n                                stack.append(f(*arguments))\n                                called = True\n                            except TypeError:\n                                pass\n                        if not called:\n                            irc.error(_('Not enough arguments for %s') % arg)\n                            return\n                    else:\n                        stack.append(f)\n                elif arg in self._rpnEnv:\n                    self._rpnEnv[arg](stack)\n                else:\n                    arg2 = stack.pop()\n                    arg1 = stack.pop()\n                    s = '%s%s%s' % (arg1, arg, arg2)\n                    try:\n                        stack.append(eval(s, self._mathSafeEnv, self._mathSafeEnv))\n                    except SyntaxError:\n                        irc.error(format(_('%q is not a defined function.'),\n                                         arg))\n                        return\n        if len(stack) == 1:\n            irc.reply(str(self._complexToString(complex(stack[0]))))\n        else:\n            s = ', '.join(map(self._complexToString, list(map(complex, stack))))\n            irc.reply(_('Stack: [%s]') % s)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def append(self, key, value):\n        self.dict.setdefault(_hkey(key), []).append(\n            value if isinstance(value, unicode) else str(value))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) final {\n    // Extract inputs and validate shapes and types.\n    const CSRSparseMatrix* input_matrix;\n    OP_REQUIRES_OK(ctx, ExtractVariantFromInput(ctx, 0, &input_matrix));\n    const Tensor& input_permutation_indices = ctx->input(1);\n\n    int64 num_rows;\n    int batch_size;\n    ValidateInputs(ctx, *input_matrix, input_permutation_indices, &batch_size,\n                   &num_rows);\n\n    // Allocate batch pointers.\n    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n    auto batch_ptr_vec = batch_ptr.vec<int32>();\n    batch_ptr_vec(0) = 0;\n\n    // Temporary vector of Eigen SparseMatrices to store the Sparse Cholesky\n    // factors.\n    // Note: we use column-compressed (CSC) SparseMatrix because SimplicialLLT\n    // returns the factors in column major format. Since our input should be\n    // symmetric, column major and row major is identical in storage. We just\n    // have to switch to reading the upper triangular part of the input, which\n    // corresponds to the lower triangular part in row major format.\n    std::vector<SparseMatrix> sparse_cholesky_factors(batch_size);\n\n    // TODO(anudhyan): Tune the cost per unit based on benchmarks.\n    const double nnz_per_row =\n        (input_matrix->total_nnz() / batch_size) / num_rows;\n    const int64 sparse_cholesky_cost_per_batch =\n        nnz_per_row * nnz_per_row * num_rows;\n    // Perform sparse Cholesky factorization of each batch in parallel.\n    auto worker_threads = *(ctx->device()->tensorflow_cpu_worker_threads());\n    std::atomic<int64> invalid_input_index(-1);\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          sparse_cholesky_cost_per_batch,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              // Define an Eigen SparseMatrix Map to operate on the\n              // CSRSparseMatrix component without copying the data.\n              Eigen::Map<const SparseMatrix> sparse_matrix(\n                  num_rows, num_rows, input_matrix->nnz(batch_index),\n                  input_matrix->row_pointers_vec(batch_index).data(),\n                  input_matrix->col_indices_vec(batch_index).data(),\n                  input_matrix->values_vec<T>(batch_index).data());\n\n              Eigen::SimplicialLLT<SparseMatrix, Eigen::Upper,\n                                   Eigen::NaturalOrdering<int>>\n                  solver;\n              auto permutation_indices_flat =\n                  input_permutation_indices.flat<int32>().data();\n\n              // Invert the fill-in reducing ordering and apply it to the input\n              // sparse matrix.\n              Eigen::Map<\n                  Eigen::PermutationMatrix<Eigen::Dynamic, Eigen::Dynamic, int>>\n                  permutation(permutation_indices_flat + batch_index * num_rows,\n                              num_rows);\n              auto permutation_inverse = permutation.inverse();\n\n              SparseMatrix permuted_sparse_matrix;\n              permuted_sparse_matrix.template selfadjointView<Eigen::Upper>() =\n                  sparse_matrix.template selfadjointView<Eigen::Upper>()\n                      .twistedBy(permutation_inverse);\n\n              // Compute the Cholesky decomposition.\n              solver.compute(permuted_sparse_matrix);\n              if (solver.info() != Eigen::Success) {\n                invalid_input_index = batch_index;\n                return;\n              }\n\n              // Get the upper triangular factor, which would end up in the\n              // lower triangular part of the output CSRSparseMatrix when\n              // interpreted in row major format.\n              sparse_cholesky_factors[batch_index] =\n                  std::move(solver.matrixU());\n              // For now, batch_ptr contains the number of nonzeros in each\n              // batch.\n              batch_ptr_vec(batch_index + 1) =\n                  sparse_cholesky_factors[batch_index].nonZeros();\n            }\n          });\n\n    // Check for invalid input.\n    OP_REQUIRES(\n        ctx, invalid_input_index == -1,\n        errors::InvalidArgument(\n            \"Sparse Cholesky factorization failed for batch index \",\n            invalid_input_index.load(), \". The input might not be valid.\"));\n\n    // Compute a cumulative sum to obtain the batch pointers.\n    std::partial_sum(batch_ptr_vec.data(),\n                     batch_ptr_vec.data() + batch_size + 1,\n                     batch_ptr_vec.data());\n\n    // Allocate output Tensors.\n    const int64 total_nnz = batch_ptr_vec(batch_size);\n    Tensor output_row_ptr(cpu_allocator(), DT_INT32,\n                          TensorShape({(num_rows + 1) * batch_size}));\n    Tensor output_col_ind(cpu_allocator(), DT_INT32, TensorShape({total_nnz}));\n    Tensor output_values(cpu_allocator(), DataTypeToEnum<T>::value,\n                         TensorShape({total_nnz}));\n    auto output_row_ptr_ptr = output_row_ptr.flat<int32>().data();\n    auto output_col_ind_ptr = output_col_ind.flat<int32>().data();\n    auto output_values_ptr = output_values.flat<T>().data();\n\n    // Copy the output matrices from each batch into the CSRSparseMatrix\n    // Tensors.\n    // TODO(b/129906419): Factor out the copy from Eigen SparseMatrix to\n    // CSRSparseMatrix into common utils. This is also used in\n    // SparseMatrixSparseMatMul.\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          (3 * total_nnz) / batch_size /* cost per unit */,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              const SparseMatrix& cholesky_factor =\n                  sparse_cholesky_factors[batch_index];\n              const int64 nnz = cholesky_factor.nonZeros();\n\n              std::copy(cholesky_factor.outerIndexPtr(),\n                        cholesky_factor.outerIndexPtr() + num_rows + 1,\n                        output_row_ptr_ptr + batch_index * (num_rows + 1));\n              std::copy(cholesky_factor.innerIndexPtr(),\n                        cholesky_factor.innerIndexPtr() + nnz,\n                        output_col_ind_ptr + batch_ptr_vec(batch_index));\n              std::copy(cholesky_factor.valuePtr(),\n                        cholesky_factor.valuePtr() + nnz,\n                        output_values_ptr + batch_ptr_vec(batch_index));\n            }\n          });\n\n    // Create the CSRSparseMatrix instance from its component Tensors and\n    // prepare the Variant output Tensor.\n    CSRSparseMatrix output_csr_matrix;\n    OP_REQUIRES_OK(\n        ctx,\n        CSRSparseMatrix::CreateCSRSparseMatrix(\n            DataTypeToEnum<T>::value, input_matrix->dense_shape(), batch_ptr,\n            output_row_ptr, output_col_ind, output_values, &output_csr_matrix));\n    Tensor* output_csr_matrix_tensor;\n    AllocatorAttributes cpu_alloc;\n    cpu_alloc.set_on_host(true);\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({}), &output_csr_matrix_tensor,\n                                  cpu_alloc));\n    output_csr_matrix_tensor->scalar<Variant>()() =\n        std::move(output_csr_matrix);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ALGnew(PyObject *self, PyObject *args, PyObject *kwdict)\n{\n\tunsigned char *key, *IV;\n\tALGobject * new=NULL;\n\tint keylen, IVlen=0, mode=MODE_ECB, segment_size=0;\n\tPyObject *counter = NULL;\n\tint counter_shortcut = 0;\n#ifdef PCT_ARC2_MODULE\n        int effective_keylen = 1024;    /* this is a weird default, but it's compatible with old versions of PyCrypto */\n#endif\n\t/* Set default values */\n\tif (!PyArg_ParseTupleAndKeywords(args, kwdict, \"s#|is#Oi\"\n#ifdef PCT_ARC2_MODULE\n\t\t\t\t\t \"i\"\n#endif\n\t\t\t\t\t , kwlist,\n\t\t\t\t\t &key, &keylen, &mode, &IV, &IVlen,\n\t\t\t\t\t &counter, &segment_size\n#ifdef PCT_ARC2_MODULE\n\t\t\t\t\t , &effective_keylen\n#endif\n\t\t)) \n\t{\n\t\treturn NULL;\n\t}\n\n\tif (mode<MODE_ECB || mode>MODE_CTR) \n\t{\n\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t     \"Unknown cipher feedback mode %i\",\n\t\t\t     mode);\n\t\treturn NULL;\n\t}\n\tif (mode == MODE_PGP) {\n\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t     \"MODE_PGP is not supported anymore\");\n\t\treturn NULL;\n\t}\n\tif (KEY_SIZE!=0 && keylen!=KEY_SIZE)\n\t{\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"Key must be %i bytes long, not %i\",\n\t\t\t     KEY_SIZE, keylen);\n\t\treturn NULL;\n\t}\n\tif (KEY_SIZE==0 && keylen==0)\n\t{\n\t\tPyErr_SetString(PyExc_ValueError,\n\t\t\t\t\"Key cannot be the null string\");\n\t\treturn NULL;\n\t}\n\tif (IVlen != BLOCK_SIZE && mode != MODE_ECB && mode != MODE_CTR)\n\t{\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"IV must be %i bytes long\", BLOCK_SIZE);\n\t\treturn NULL;\n\t}\n\n\t/* Mode-specific checks */\n\tif (mode == MODE_CFB) {\n\t\tif (segment_size == 0) segment_size = 8;\n\t\tif (segment_size < 1 || segment_size > BLOCK_SIZE*8 || ((segment_size & 7) != 0)) {\n\t\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t\t     \"segment_size must be multiple of 8 (bits) \"\n\t\t\t\t     \"between 1 and %i\", BLOCK_SIZE*8);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\tif (mode == MODE_CTR) {\n\t\tif (counter == NULL) {\n\t\t\tPyErr_SetString(PyExc_TypeError,\n\t\t\t\t\t\"'counter' keyword parameter is required with CTR mode\");\n\t\t\treturn NULL;\n\t\t} else if (Py_TYPE(counter) == PCT_CounterBEType || Py_TYPE(counter) == PCT_CounterLEType) {\n\t\t\tcounter_shortcut = 1;\n\t\t} else if (!PyCallable_Check(counter)) {\n\t\t\tPyErr_SetString(PyExc_ValueError, \n\t\t\t\t\t\"'counter' parameter must be a callable object\");\n\t\t\treturn NULL;\n\t\t}\n\t} else {\n\t\tif (counter != NULL) {\n\t\t\tPyErr_SetString(PyExc_ValueError, \n\t\t\t\t\t\"'counter' parameter only useful with CTR mode\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Cipher-specific checks */\n#ifdef PCT_ARC2_MODULE\n        if (effective_keylen<0 || effective_keylen>1024) {\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"RC2: effective_keylen must be between 0 and 1024, not %i\",\n\t\t\t     effective_keylen);\n\t\treturn NULL;\n        }\n#endif\n\n\t/* Copy parameters into object */\n\tnew = newALGobject();\n\tnew->segment_size = segment_size;\n\tnew->counter = counter;\n\tPy_XINCREF(counter);\n\tnew->counter_shortcut = counter_shortcut;\n#ifdef PCT_ARC2_MODULE\n        new->st.effective_keylen = effective_keylen;\n#endif\n\n\tblock_init(&(new->st), key, keylen);\n\tif (PyErr_Occurred())\n\t{\n\t\tPy_DECREF(new);\n\t\treturn NULL;\n\t}\n\tmemset(new->IV, 0, BLOCK_SIZE);\n\tmemset(new->oldCipher, 0, BLOCK_SIZE);\n\tmemcpy(new->IV, IV, IVlen);\n\tnew->mode = mode;\n\tnew->count=BLOCK_SIZE;   /* stores how many bytes in new->oldCipher have been used */\n\treturn new;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext *ctx) override {\n    // (0) validations\n    const Tensor *a_indices, *b_indices, *a_values_t, *b_values_t, *a_shape,\n        *b_shape, *thresh_t;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_indices\", &a_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_indices\", &b_indices));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsMatrix(a_indices->shape()) &&\n                    TensorShapeUtils::IsMatrix(b_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be matrices but received shapes: \",\n                    a_indices->shape().DebugString(), \" and \",\n                    b_indices->shape().DebugString()));\n    const int64 a_nnz = a_indices->dim_size(0);\n    const int64 b_nnz = b_indices->dim_size(0);\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_values\", &a_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_values\", &b_values_t));\n\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_values_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_values_t->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be vectors but received shapes: \",\n                    a_values_t->shape().DebugString(), \" and \",\n                    b_values_t->shape().DebugString()));\n    auto a_values = ctx->input(1).vec<T>();\n    auto b_values = ctx->input(4).vec<T>();\n    OP_REQUIRES(\n        ctx, a_values.size() == a_nnz && b_values.size() == b_nnz,\n        errors::InvalidArgument(\"Expected \", a_nnz, \" and \", b_nnz,\n                                \" non-empty input values, got \",\n                                a_values.size(), \" and \", b_values.size()));\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_shape\", &a_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_shape\", &b_shape));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_shape->shape()) &&\n                    TensorShapeUtils::IsVector(b_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shapes should be a vector but received shapes \",\n                    a_shape->shape().DebugString(), \" and \",\n                    b_shape->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, a_shape->IsSameSize(*b_shape),\n        errors::InvalidArgument(\n            \"Operands do not have the same ranks; got shapes: \",\n            a_shape->SummarizeValue(10), \" and \", b_shape->SummarizeValue(10)));\n    const auto a_shape_flat = a_shape->flat<int64>();\n    const auto b_shape_flat = b_shape->flat<int64>();\n    for (int i = 0; i < a_shape->NumElements(); ++i) {\n      OP_REQUIRES(ctx, a_shape_flat(i) == b_shape_flat(i),\n                  errors::InvalidArgument(\n                      \"Operands' shapes do not match: got \", a_shape_flat(i),\n                      \" and \", b_shape_flat(i), \" for dimension \", i));\n    }\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"thresh\", &thresh_t));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(thresh_t->shape()),\n                errors::InvalidArgument(\n                    \"The magnitude threshold must be a scalar: got shape \",\n                    thresh_t->shape().DebugString()));\n    // std::abs() so that it works for complex{64,128} values as well\n    const Treal thresh = thresh_t->scalar<Treal>()();\n\n    // (1) do a pass over inputs, and append values and indices to vectors\n    auto a_indices_mat = a_indices->matrix<int64>();\n    auto b_indices_mat = b_indices->matrix<int64>();\n    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx\n    entries_to_copy.reserve(a_nnz + b_nnz);\n    std::vector<T> out_values;\n    const int num_dims = a_shape->dim_size(0);\n\n    OP_REQUIRES(ctx, num_dims > 0,\n                errors::InvalidArgument(\"Invalid input_a shape. Received: \",\n                                        a_shape->DebugString()));\n\n    // The input and output sparse tensors are assumed to be ordered along\n    // increasing dimension number.\n    int64 i = 0, j = 0;\n    T s;\n    while (i < a_nnz && j < b_nnz) {\n      switch (sparse::DimComparator::cmp(a_indices_mat, b_indices_mat, i, j,\n                                         num_dims)) {\n        case -1:\n          entries_to_copy.emplace_back(true, i);\n          out_values.push_back(a_values(i));\n          ++i;\n          break;\n        case 0:\n          s = a_values(i) + b_values(j);\n          if (thresh <= std::abs(s)) {\n            entries_to_copy.emplace_back(true, i);\n            out_values.push_back(s);\n          }\n          ++i;\n          ++j;\n          break;\n        case 1:\n          entries_to_copy.emplace_back(false, j);\n          out_values.push_back(b_values(j));\n          ++j;\n          break;\n      }\n    }\n\n#define HANDLE_LEFTOVERS(A_OR_B, IDX, IS_A)     \\\n  while (IDX < A_OR_B##_nnz) {                  \\\n    entries_to_copy.emplace_back(IS_A, IDX);    \\\n    out_values.push_back(A_OR_B##_values(IDX)); \\\n    ++IDX;                                      \\\n  }\n\n    // at most one of these calls appends new values\n    HANDLE_LEFTOVERS(a, i, true);\n    HANDLE_LEFTOVERS(b, j, false);\n#undef HANDLE_LEFTOVERS\n\n    // (2) allocate and fill output tensors\n    const int64 sum_nnz = out_values.size();\n    Tensor *out_indices_t, *out_values_t;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({sum_nnz, num_dims}),\n                                        &out_indices_t));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(1, TensorShape({sum_nnz}), &out_values_t));\n    auto out_indices_mat = out_indices_t->matrix<int64>();\n    auto out_values_flat = out_values_t->vec<T>();\n\n    for (i = 0; i < sum_nnz; ++i) {\n      const bool from_a = entries_to_copy[i].first;\n      const int64 idx = entries_to_copy[i].second;\n      out_indices_mat.chip<0>(i) =\n          from_a ? a_indices_mat.chip<0>(idx) : b_indices_mat.chip<0>(idx);\n    }\n    if (sum_nnz > 0) {\n      std::copy_n(out_values.begin(), sum_nnz, &out_values_flat(0));\n    }\n    ctx->set_output(2, *a_shape);\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def received_client_receipt(\n        self,\n        room_id: str,\n        receipt_type: str,\n        user_id: str,\n        event_id: str,\n        thread_id: Optional[str],\n    ) -> None:\n        \"\"\"Called when a client tells us a local user has read up to the given\n        event_id in the room.\n        \"\"\"\n        receipt = ReadReceipt(\n            room_id=room_id,\n            receipt_type=receipt_type,\n            user_id=user_id,\n            event_ids=[event_id],\n            thread_id=thread_id,\n            data={\"ts\": int(self.clock.time_msec())},\n        )\n\n        is_new = await self._handle_new_receipts([receipt])\n        if not is_new:\n            return\n\n        if self.federation_sender and receipt_type != ReceiptTypes.READ_PRIVATE:\n            await self.federation_sender.send_read_receipt(receipt)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendEmail(\n    sydent: \"Sydent\",\n    templateFile: str,\n    mailTo: str,\n    substitutions: Dict[str, str],\n    log_send_errors: bool = True,\n) -> None:\n    \"\"\"\n    Sends an email with the given parameters.\n\n    :param sydent: The Sydent instance to use when building the configuration to send the\n        email with.\n    :param templateFile: The filename of the template to use when building the body of the\n        email.\n    :param mailTo: The email address to send the email to.\n    :param substitutions: The substitutions to use with the template.\n    :param log_send_errors: Whether to log errors happening when sending an email.\n    \"\"\"\n    mailFrom = sydent.config.email.sender\n    myHostname = sydent.config.email.host_name\n\n    midRandom = \"\".join([random.choice(string.ascii_letters) for _ in range(16)])\n    messageid = \"<%d%s@%s>\" % (time_msec(), midRandom, myHostname)\n\n    substitutions.update(\n        {\n            \"messageid\": messageid,\n            \"date\": email.utils.formatdate(localtime=False),\n            \"to\": mailTo,\n            \"from\": mailFrom,\n        }\n    )\n\n    # use jinja for rendering if jinja templates are present\n    if templateFile.endswith(\".j2\"):\n        # We add randomize the multipart boundary to stop user input from\n        # conflicting with it.\n        substitutions[\"multipart_boundary\"] = generateAlphanumericTokenOfLength(32)\n        template = sydent.config.general.template_environment.get_template(templateFile)\n        mailString = template.render(substitutions)\n    else:\n        allSubstitutions = {}\n        for k, v in substitutions.items():\n            allSubstitutions[k] = v\n            allSubstitutions[k + \"_forhtml\"] = escape(v)\n            allSubstitutions[k + \"_forurl\"] = urllib.parse.quote(v)\n        allSubstitutions[\"multipart_boundary\"] = generateAlphanumericTokenOfLength(32)\n        with open(templateFile) as template_file:\n            mailString = template_file.read() % allSubstitutions\n\n    try:\n        check_valid_email_address(mailTo, allow_description=False)\n    except EmailAddressException:\n        logger.warning(\"Invalid email address %s\", mailTo)\n        raise\n\n    mailServer = sydent.config.email.smtp_server\n    mailPort = int(sydent.config.email.smtp_port)\n    mailUsername = sydent.config.email.smtp_username\n    mailPassword = sydent.config.email.smtp_password\n    mailTLSMode = sydent.config.email.tls_mode\n\n    logger.info(\n        \"Sending mail to %s with mail server: %s\"\n        % (\n            mailTo,\n            mailServer,\n        )\n    )\n    try:\n        smtp: smtplib.SMTP\n        if mailTLSMode == \"SSL\" or mailTLSMode == \"TLS\":\n            smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname)\n        elif mailTLSMode == \"STARTTLS\":\n            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n            smtp.starttls()\n        else:\n            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n        if mailUsername != \"\":\n            smtp.login(mailUsername, mailPassword)\n\n        email_counter.inc()\n\n        # We're using the parsing above to do basic validation, but instead of\n        # failing it may munge the address it returns. So we should *not* use\n        # that parsed address, as it may not match any validation done\n        # elsewhere.\n        smtp.sendmail(mailFrom, mailTo, mailString.encode(\"utf-8\"))\n        smtp.quit()\n    except Exception as origException:\n        if log_send_errors:\n            twisted.python.log.err()\n        raise EmailSendException() from origException\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def write_data_table(self, report, report_data, has_totals=True):\n        self.data.append([c[\"title\"] for c in report.schema])\n        for datum in report_data:\n            datum = report.read_datum(datum)\n            self.data.append([format_data(data, format_iso_dates=True) for data in datum])\n\n        if has_totals:\n            for datum in report.get_totals(report_data):\n                datum = report.read_datum(datum)\n                self.data.append([format_data(data) for data in datum])\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static Status ValidateSavedTensors(const GraphDef& graph_def) {\n  for (const auto& node : graph_def.node()) {\n    const auto node_iterator = node.attr().find(\"value\");\n    if (node_iterator != node.attr().end()) {\n      AttrValue node_value = node_iterator->second;\n      if (node_value.has_tensor()) {\n        const PartialTensorShape node_shape(node_value.tensor().tensor_shape());\n        if (node_shape.num_elements() < 0) {\n          return errors::FailedPrecondition(\n              \"Saved model contains node \\\"\", node.name(), \"\\\" (op \\\"\",\n              node.op(), \"\\\") which initializes from a tensor with \",\n              node_shape.num_elements(), \" elements\");\n        }\n      }\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def users(self, criteria=u\"\", search=u\"\", action=u\"\", **kwargs):\n\n        # If we're just showing the initial page, just do that\n        form = UserForm()\n        if action in [\"add\", \"edit\"] and not form.validate():\n            # Display the form error to user using flash\n            flash(form.error_message, level='error')\n\n        elif action in [\"add\", \"edit\"] and form.validate():\n            if action == 'add':\n                user = self.app.store.add_user(form.username.data, form.password.data)\n            else:\n                user = self.app.store.get_user(form.username.data)\n                if form.password.data:\n                    user.set_password(form.password.data, old_password=None)\n            # Don't allow the user to changes it's \"role\" state.\n            if form.username.data != self.app.currentuser.username:\n                user.role = form.role.data\n            user.email = form.email.data or ''\n            if form.user_root.data:\n                user.user_root = form.user_root.data\n                if not user.valid_user_root():\n                    flash(_(\"User's root directory %s is not accessible!\") % user.user_root, level='error')\n                    logger.warning(\"user's root directory %s is not accessible\" % user.user_root)\n            # Try to update disk quota if the human readable value changed.\n            # Report error using flash.\n            if form.disk_quota and form.disk_quota.data:\n                try:\n                    new_quota = form.disk_quota.data\n                    old_quota = humanfriendly.parse_size(humanfriendly.format_size(user.disk_quota, binary=True))\n                    if old_quota != new_quota:\n                        user.disk_quota = new_quota\n                        flash(_(\"User's quota updated\"), level='success')\n                except QuotaUnsupported as e:\n                    flash(_(\"Setting user's quota is not supported\"), level='warning')\n                except Exception as e:\n                    flash(_(\"Failed to update user's quota: %s\") % e, level='error')\n                    logger.warning(\"failed to update user's quota\", exc_info=1)\n            if action == 'add':\n                flash(_(\"User added successfully.\"))\n            else:\n                flash(_(\"User information modified successfully.\"))\n        elif action == 'delete':\n            if form.username.data == self.app.currentuser.username:\n                flash(_(\"You cannot remove your own account!\"), level='error')\n            else:\n                try:\n                    user = self.app.store.get_user(form.username.data)\n                    if user:\n                        user.delete()\n                        flash(_(\"User account removed.\"))\n                    else:\n                        flash(_(\"User doesn't exists!\"), level='warning')\n                except ValueError as e:\n                    flash(e, level='error')\n\n        params = {\n            \"form\": UserForm(formdata=None),\n            \"criteria\": criteria,\n            \"search\": search,\n            \"users\": list(self.app.store.users(search=search, criteria=criteria))}\n\n        # Build users page\n        return self._compile_template(\"admin_users.html\", **params)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_lm_corpus(datadir, dataset):\n    fn = os.path.join(datadir, \"cache.pt\")\n    fn_pickle = os.path.join(datadir, \"cache.pkl\")\n    if os.path.exists(fn):\n        logger.info(\"Loading cached dataset...\")\n        corpus = torch.load(fn_pickle)\n    elif os.path.exists(fn):\n        logger.info(\"Loading cached dataset from pickle...\")\n        with open(fn, \"rb\") as fp:\n            corpus = pickle.load(fp)\n    else:\n        logger.info(f\"Producing dataset {dataset}...\")\n        kwargs = {}\n        if dataset in [\"wt103\", \"wt2\"]:\n            kwargs[\"special\"] = [\"<eos>\"]\n            kwargs[\"lower_case\"] = False\n        elif dataset == \"ptb\":\n            kwargs[\"special\"] = [\"<eos>\"]\n            kwargs[\"lower_case\"] = True\n        elif dataset == \"lm1b\":\n            kwargs[\"special\"] = []\n            kwargs[\"lower_case\"] = False\n            kwargs[\"vocab_file\"] = os.path.join(datadir, \"1b_word_vocab.txt\")\n        elif dataset in [\"enwik8\", \"text8\"]:\n            pass\n\n        corpus = TransfoXLCorpus(datadir, dataset, **kwargs)\n        torch.save(corpus, fn)\n\n    return corpus\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def list_artifacts(self, path=None):\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, tail = self.artifact_uri.split(endpoint, maxsplit=1)\n        root = tail.lstrip(\"/\")\n        params = {\"path\": posixpath.join(root, path) if path else root}\n        host_creds = _get_default_host_creds(url)\n        resp = http_request(host_creds, endpoint, \"GET\", params=params)\n        augmented_raise_for_status(resp)\n        file_infos = []\n        for f in resp.json().get(\"files\", []):\n            validate_path_is_safe(f[\"path\"])\n            file_info = FileInfo(\n                posixpath.join(path, f[\"path\"]) if path else f[\"path\"],\n                f[\"is_dir\"],\n                int(f[\"file_size\"]) if (\"file_size\" in f) else None,\n            )\n            file_infos.append(file_info)\n\n        return sorted(file_infos, key=lambda f: f.path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def window():\n    target_url = request.args.get('location')\n    if target_url.startswith('gAAAAA'):\n        cipher_suite = Fernet(g.session_key)\n        target_url = cipher_suite.decrypt(target_url.encode()).decode()\n\n    content_filter = Filter(\n        g.session_key,\n        root_url=request.url_root,\n        config=g.user_config)\n    target = urlparse.urlparse(target_url)\n    host_url = f'{target.scheme}://{target.netloc}'\n\n    get_body = g.user_request.send(base_url=target_url).text\n\n    results = bsoup(get_body, 'html.parser')\n    src_attrs = ['src', 'href', 'srcset', 'data-srcset', 'data-src']\n\n    # Parse HTML response and replace relative links w/ absolute\n    for element in results.find_all():\n        for attr in src_attrs:\n            if not element.has_attr(attr) or not element[attr].startswith('/'):\n                continue\n\n            element[attr] = host_url + element[attr]\n\n    # Replace or remove javascript sources\n    for script in results.find_all('script', {'src': True}):\n        if 'nojs' in request.args:\n            script.decompose()\n        else:\n            content_filter.update_element_src(script, 'application/javascript')\n\n    # Replace all possible image attributes\n    img_sources = ['src', 'data-src', 'data-srcset', 'srcset']\n    for img in results.find_all('img'):\n        _ = [\n            content_filter.update_element_src(img, 'image/png', attr=_)\n            for _ in img_sources if img.has_attr(_)\n        ]\n\n    # Replace all stylesheet sources\n    for link in results.find_all('link', {'href': True}):\n        content_filter.update_element_src(link, 'text/css', attr='href')\n\n    # Use anonymous view for all links on page\n    for a in results.find_all('a', {'href': True}):\n        a['href'] = f'{Endpoint.window}?location=' + a['href'] + (\n            '&nojs=1' if 'nojs' in request.args else '')\n\n    # Remove all iframes -- these are commonly used inside of <noscript> tags\n    # to enforce loading Google Analytics\n    for iframe in results.find_all('iframe'):\n        iframe.decompose()\n\n    return render_template(\n        'display.html',\n        response=results,\n        translation=app.config['TRANSLATIONS'][\n            g.user_config.get_localization_lang()\n        ]\n    )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def delete(request, name):\n  if 'delete' not in getPermissions(request.user):\n    return json_response( dict(error=\"Must be logged in with appropriate permissions to delete\") )\n\n  try:\n    dashboard = Dashboard.objects.get(name=name)\n  except Dashboard.DoesNotExist:\n    return json_response( dict(error=\"Dashboard '%s' does not exist. \" % name) )\n  else:\n    dashboard.delete()\n    return json_response( dict(success=True) )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, **kwargs):\n        \"\"\"Initialize HTMLSerializer.\n\n        Keyword options (default given first unless specified) include:\n\n        inject_meta_charset=True|False\n          Whether it insert a meta element to define the character set of the\n          document.\n        quote_attr_values=True|False\n          Whether to quote attribute values that don't require quoting\n          per HTML5 parsing rules.\n        quote_char=u'\"'|u\"'\"\n          Use given quote character for attribute quoting. Default is to\n          use double quote unless attribute value contains a double quote,\n          in which case single quotes are used instead.\n        escape_lt_in_attrs=False|True\n          Whether to escape < in attribute values.\n        escape_rcdata=False|True\n          Whether to escape characters that need to be escaped within normal\n          elements within rcdata elements such as style.\n        resolve_entities=True|False\n          Whether to resolve named character entities that appear in the\n          source tree. The XML predefined entities &lt; &gt; &amp; &quot; &apos;\n          are unaffected by this setting.\n        strip_whitespace=False|True\n          Whether to remove semantically meaningless whitespace. (This\n          compresses all whitespace to a single space except within pre.)\n        minimize_boolean_attributes=True|False\n          Shortens boolean attributes to give just the attribute value,\n          for example <input disabled=\"disabled\"> becomes <input disabled>.\n        use_trailing_solidus=False|True\n          Includes a close-tag slash at the end of the start tag of void\n          elements (empty elements whose end tag is forbidden). E.g. <hr/>.\n        space_before_trailing_solidus=True|False\n          Places a space immediately before the closing slash in a tag\n          using a trailing solidus. E.g. <hr />. Requires use_trailing_solidus.\n        sanitize=False|True\n          Strip all unsafe or unknown constructs from output.\n          See `html5lib user documentation`_\n        omit_optional_tags=True|False\n          Omit start/end tags that are optional.\n        alphabetical_attributes=False|True\n          Reorder attributes to be in alphabetical order.\n\n        .. _html5lib user documentation: http://code.google.com/p/html5lib/wiki/UserDocumentation\n        \"\"\"\n        if 'quote_char' in kwargs:\n            self.use_best_quote_char = False\n        for attr in self.options:\n            setattr(self, attr, kwargs.get(attr, getattr(self, attr)))\n        self.errors = []\n        self.strict = False\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def reset_password(self, userid, password):\n        \"\"\"\n        Change/Reset a user's password for authdb.\n\n        Password will be hashed and saved.\n        :param userid: the user id to reset the password\n        :param password: the clear text password to reset and save hashed on the db\n        \"\"\"\n        user = self.get_user_by_id(userid)\n        user.password = generate_password_hash(password)\n        self.update_user(user)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def archive(request, bookmark_id: int):\n    bookmark = Bookmark.objects.get(pk=bookmark_id)\n    archive_bookmark(bookmark)\n    return_url = request.GET.get('return_url')\n    return_url = return_url if return_url else reverse('bookmarks:index')\n    return HttpResponseRedirect(return_url)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const auto splits = ctx->input(0).flat<int64_t>();\n    const auto values = ctx->input(1).flat<Tidx>();\n    const Tensor& size_t = ctx->input(2);\n    const auto weights = ctx->input(3).flat<T>();\n    const int64_t weights_size = weights.size();\n\n    Tidx size = size_t.scalar<Tidx>()();\n    OP_REQUIRES(\n        ctx, size >= 0,\n        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n\n    int num_rows = splits.size() - 1;\n    int num_values = values.size();\n    int batch_idx = 0;\n\n    OP_REQUIRES(ctx, splits(0) == 0,\n                errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                        splits(0)));\n\n    OP_REQUIRES(ctx, splits(num_rows) == num_values,\n                errors::InvalidArgument(\n                    \"Splits must end with the number of values, got \",\n                    splits(num_rows), \" instead of \", num_values));\n\n    Tensor* out_t;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n    functor::SetZeroFunctor<Device, T> fill;\n    fill(ctx->eigen_device<Device>(), out_t->flat<T>());\n    const auto out = out_t->matrix<T>();\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits(batch_idx)) {\n        batch_idx++;\n      }\n      Tidx bin = values(idx);\n      OP_REQUIRES(ctx, bin >= 0,\n                  errors::InvalidArgument(\"Input must be non-negative\"));\n      if (bin < size) {\n        if (binary_output_) {\n          out(batch_idx - 1, bin) = T(1);\n        } else {\n          T value = (weights_size > 0) ? weights(idx) : T(1);\n          out(batch_idx - 1, bin) += value;\n        }\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __call__(self, value):\n        if not isinstance(value, str):\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        if self.unsafe_chars.intersection(value):\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        # Check if the scheme is valid.\n        scheme = value.split(\"://\")[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n\n        # Then check full URL\n        try:\n            splitted_url = urlsplit(value)\n        except ValueError:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                scheme, netloc, path, query, fragment = splitted_url\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r\"^\\[(.+)\\](?::[0-9]{1,5})?$\", splitted_url.netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(\n                        self.message, code=self.code, params={\"value\": value}\n                    )\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if splitted_url.hostname is None or len(splitted_url.hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_command_line(argv: List[str]) -> argparse.Namespace:  # noqa: C901.\n    defaults: Dict[str, Any] = {\n        \"json_indent\": None,\n        \"ordered\": True,\n        \"stringify\": False,\n        \"yaml_options\": {},\n    }\n\n    me = Path(argv[0]).name\n    argv0_from, argv0_to = argv0_to_format(me)\n    format_from_argv0 = argv0_to != \"\"\n\n    parser = argparse.ArgumentParser(\n        description=\"Convert between CBOR, JSON, MessagePack, TOML, and YAML.\"\n    )\n    parser.add_argument(\"-v\", \"--version\", action=\"version\", version=__version__)\n\n    input_group = parser.add_mutually_exclusive_group()\n    input_group.add_argument(\"input\", nargs=\"?\", default=\"-\", help=\"input file\")\n    input_group.add_argument(\n        \"-i\",\n        \"--input\",\n        dest=\"input_flag\",\n        metavar=\"input\",\n        default=None,\n        help=\"input file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--if\",\n            \"-if\",\n            \"--input-format\",\n            dest=\"input_format\",\n            default=\"\",\n            help=\"input format\",\n            choices=FORMATS,\n        )\n\n    if not format_from_argv0 or argv0_to == \"json\":\n        parser.add_argument(\n            \"--json-indent\",\n            \"--indent-json\",\n            dest=\"json_indent\",\n            metavar=\"n\",\n            type=int,\n            default=defaults[\"json_indent\"],\n            help=\"JSON indentation\",\n        )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\"}:\n        parser.add_argument(\n            \"-k\",\n            \"--stringify\",\n            dest=\"stringify\",\n            action=\"store_true\",\n            help=(\n                \"Turn into strings boolean, date-time, and null keys for JSON \"\n                \"and TOML and null values for TOML\"\n            ),\n        )\n\n    output_group = parser.add_mutually_exclusive_group()\n    output_group.add_argument(\"output\", nargs=\"?\", default=\"-\", help=\"output file\")\n    output_group.add_argument(\n        \"-o\",\n        \"--output\",\n        dest=\"output_flag\",\n        metavar=\"output\",\n        default=None,\n        help=\"output file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--of\",\n            \"-of\",\n            \"--output-format\",\n            dest=\"output_format\",\n            default=\"\",\n            help=\"output format\",\n            choices=FORMATS,\n        )\n\n    parser.add_argument(\n        \"-p\",\n        \"--preserve-key-order\",\n        help=argparse.SUPPRESS,\n    )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\", \"yaml\"}:\n        parser.add_argument(\n            \"-s\",\n            \"--sort-keys\",\n            dest=\"ordered\",\n            action=\"store_false\",\n            help=\"sort JSON, TOML, YAML keys instead of preserving key order\",\n        )\n\n    parser.add_argument(\n        \"--unwrap\",\n        dest=\"unwrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"only output the data stored under the given key\",\n    )\n    parser.add_argument(\n        \"--wrap\",\n        dest=\"wrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"wrap the data in a map type with the given key\",\n    )\n\n    if not format_from_argv0 or argv0_to == \"yaml\":\n        parser.add_argument(\n            \"--yaml-indent\",\n            dest=\"yaml_indent\",\n            metavar=\"n\",\n            type=int,\n            default=2,\n            help=\"YAML indentation\",\n        )\n        parser.add_argument(\n            \"--yaml-style\",\n            dest=\"yaml_style\",\n            default=None,\n            help=\"YAML formatting style\",\n            choices=[\"\", \"'\", '\"', \"|\", \">\"],\n        )\n\n        def yaml_width(value: str) -> int:\n            # This is theoretically compatible with LibYAML.\n            return (1 << 32) - 1 if value.lower() == \"inf\" else int(value)\n\n        parser.add_argument(\n            \"--yaml-width\",\n            dest=\"yaml_width\",\n            metavar=\"n\",\n            type=yaml_width,  # Allow \"inf\".\n            default=80,\n            help=\"YAML line width for long strings\",\n        )\n\n    args = parser.parse_args(args=argv[1:])\n\n    # Use the positional input and output arguments.\n    if args.input_flag is not None:\n        args.input = args.input_flag\n\n    if args.output_flag is not None:\n        args.output = args.output_flag\n\n    # Determine the implicit input and output format if possible.\n    if format_from_argv0:\n        args.input_format = argv0_from\n        args.output_format = argv0_to\n    else:\n        if args.input_format == \"\":\n            args.input_format = extension_to_format(args.input)\n            if args.input_format == \"\":\n                parser.error(\"Need an explicit input format\")\n\n        if args.output_format == \"\":\n            args.output_format = extension_to_format(args.output)\n            if args.output_format == \"\":\n                parser.error(\"Need an explicit output format\")\n\n    for key, value in defaults.items():\n        vars(args).setdefault(key, value)\n\n    # Wrap the yaml_* option.\n    if \"yaml_indent\" in vars(args):\n        vars(args)[\"yaml_options\"] = {\n            \"default_style\": args.yaml_style,\n            \"indent\": args.yaml_indent,\n            \"width\": args.yaml_width,\n        }\n        for key in [\"yaml_indent\", \"yaml_style\", \"yaml_width\"]:\n            del vars(args)[key]\n\n    return args\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def serve(request, path, document_root=None, show_indexes=False):\n    \"\"\"\n    Serve static files below a given point in the directory structure.\n\n    To use, put a URL pattern such as::\n\n        (r'^(?P<path>.*)$', 'django.views.static.serve', {'document_root': '/path/to/my/files/'})\n\n    in your URLconf. You must provide the ``document_root`` param. You may\n    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index\n    of the directory.  This index view will use the template hardcoded below,\n    but if you'd like to override it, you can create a template called\n    ``static/directory_index.html``.\n    \"\"\"\n    path = posixpath.normpath(unquote(path))\n    path = path.lstrip('/')\n    newpath = ''\n    for part in path.split('/'):\n        if not part:\n            # Strip empty path components.\n            continue\n        drive, part = os.path.splitdrive(part)\n        head, part = os.path.split(part)\n        if part in (os.curdir, os.pardir):\n            # Strip '.' and '..' in path.\n            continue\n        newpath = os.path.join(newpath, part).replace('\\\\', '/')\n    if newpath and path != newpath:\n        return HttpResponseRedirect(newpath)\n    fullpath = os.path.join(document_root, newpath)\n    if os.path.isdir(fullpath):\n        if show_indexes:\n            return directory_index(newpath, fullpath)\n        raise Http404(_(\"Directory indexes are not allowed here.\"))\n    if not os.path.exists(fullpath):\n        raise Http404(_('\"%(path)s\" does not exist') % {'path': fullpath})\n    # Respect the If-Modified-Since header.\n    statobj = os.stat(fullpath)\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj.st_mtime, statobj.st_size):\n        return HttpResponseNotModified()\n    content_type, encoding = mimetypes.guess_type(fullpath)\n    content_type = content_type or 'application/octet-stream'\n    response = StreamingHttpResponse(open(fullpath, 'rb'),\n                                     content_type=content_type)\n    response[\"Last-Modified\"] = http_date(statobj.st_mtime)\n    if stat.S_ISREG(statobj.st_mode):\n        response[\"Content-Length\"] = statobj.st_size\n    if encoding:\n        response[\"Content-Encoding\"] = encoding\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def create_table(\n        self,\n        name: str,\n        obj: pd.DataFrame | pa.Table | ir.Table | None = None,\n        *,\n        schema: sch.Schema | None = None,\n        database: str | None = None,\n        temp: bool = False,\n        overwrite: bool = False,\n    ) -> ir.Table:\n        \"\"\"Create a table.\n\n        Parameters\n        ----------\n        name\n            Name of the new table.\n        obj\n            An Ibis table expression or pandas table that will be used to\n            extract the schema and the data of the new table. If not provided,\n            `schema` must be given.\n        schema\n            The schema for the new table. Only one of `schema` or `obj` can be\n            provided.\n        database\n            Name of the database where the table will be created, if not the\n            default.\n        temp\n            Should the table be temporary for the session.\n        overwrite\n            Clobber existing data\n\n        Returns\n        -------\n        Table\n            The table that was created.\n        \"\"\"\n        if obj is None and schema is None:\n            raise com.IbisError(\"The schema or obj parameter is required\")\n\n        import pandas as pd\n        import pyarrow as pa\n\n        if isinstance(obj, (pd.DataFrame, pa.Table)):\n            obj = ibis.memtable(obj)\n\n        if database == self.current_database:\n            # avoid fully qualified name\n            database = None\n\n        if database is not None:\n            raise NotImplementedError(\n                \"Creating tables from a different database is not yet implemented\"\n            )\n\n        if obj is not None and schema is not None:\n            if not obj.schema().equals(ibis.schema(schema)):\n                raise com.IbisTypeError(\n                    \"Expression schema is not equal to passed schema. \"\n                    \"Try passing the expression without the schema\"\n                )\n        if schema is None:\n            schema = obj.schema()\n\n        self._schemas[self._fully_qualified_name(name, database)] = schema\n\n        if has_expr := obj is not None:\n            # this has to happen outside the `begin` block, so that in-memory\n            # tables are visible inside the transaction created by it\n            self._run_pre_execute_hooks(obj)\n\n        table = self._table_from_schema(\n            name,\n            schema,\n            # most databases don't allow temporary tables in a specific\n            # database so let the backend decide\n            #\n            # the ones that do (e.g., snowflake) should implement their own\n            # `create_table`\n            database=None if temp else (database or self.current_database),\n            temp=temp,\n        )\n\n        if has_expr:\n            if self.supports_create_or_replace:\n                ctas = CreateTableAs(\n                    name,\n                    self.compile(obj),\n                    temp=temp,\n                    overwrite=overwrite,\n                    quote=self.compiler.translator_class._quote_table_names,\n                )\n                with self.begin() as bind:\n                    bind.execute(ctas)\n            else:\n                tmptable = self._table_from_schema(\n                    util.gen_name(\"tmp_table_insert\"),\n                    schema,\n                    # some backends don't support temporary tables\n                    temp=self.supports_temporary_tables,\n                )\n                method = self._get_insert_method(obj)\n                insert = table.insert().from_select(tmptable.columns, tmptable.select())\n\n                with self.begin() as bind:\n                    # 1. write `obj` to a unique temp table\n                    tmptable.create(bind=bind)\n\n                # try/finally here so that a successfully created tmptable gets\n                # cleaned up no matter what\n                try:\n                    with self.begin() as bind:\n                        bind.execute(method(tmptable.insert()))\n\n                        # 2. recreate the existing table\n                        if overwrite:\n                            table.drop(bind=bind, checkfirst=True)\n                        table.create(bind=bind)\n\n                        # 3. insert the temp table's data into the (re)created table\n                        bind.execute(insert)\n                finally:\n                    self._clean_up_tmp_table(tmptable)\n        else:\n            with self.begin() as bind:\n                if overwrite:\n                    table.drop(bind=bind, checkfirst=True)\n                table.create(bind=bind)\n        return self.table(name, database=database)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def message_to_binary(self, message, message_type=ua.MessageType.SecureMessage, request_id=0):\n        \"\"\"\n        Convert OPC UA secure message to binary.\n        The only supported types are SecureOpen, SecureMessage, SecureClose.\n        If message_type is SecureMessage, the AlgorithmHeader should be passed as arg.\n        \"\"\"\n        chunks = MessageChunk.message_to_chunks(\n            self.security_policy,\n            message,\n            self._max_chunk_size,\n            message_type=message_type,\n            channel_id=self.security_token.ChannelId,\n            request_id=request_id,\n            token_id=self.security_token.TokenId,\n        )\n        for chunk in chunks:\n            self._sequence_number += 1\n            if self._sequence_number >= (1 << 32):\n                logger.debug(\"Wrapping sequence number: %d -> 1\", self._sequence_number)\n                self._sequence_number = 1\n            chunk.SequenceHeader.SequenceNumber = self._sequence_number\n        return b\"\".join([chunk.to_binary() for chunk in chunks])\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def from_unix_seconds(seconds: Union[int, float]) -> datetime:\n    while abs(seconds) > MS_WATERSHED:\n        seconds /= 1000\n    dt = EPOCH + timedelta(seconds=seconds)\n    return dt.replace(tzinfo=timezone.utc)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "inline void ComputeInterpolationWeights(\n    const int64 out_size, const int64 in_size, const float scale,\n    const int resolution, InterpolationCache<T_SCALE>* interpolation) {\n  const Scaler scaler;\n  interpolation->lower.resize(out_size + 1);\n  interpolation->upper.resize(out_size + 1);\n  interpolation->lerp.resize(out_size + 1);\n  interpolation->ilerp.resize(out_size + 1);\n\n  interpolation->lower[out_size] = 0;\n  interpolation->upper[out_size] = 0;\n  for (int64 i = out_size - 1; i >= 0; --i) {\n    const float in = scaler(i, scale);\n    const float in_f = std::floor(in);\n    interpolation->lower[i] =\n        std::max(static_cast<int64>(in_f), static_cast<int64>(0));\n    interpolation->upper[i] =\n        std::min(static_cast<int64>(std::ceil(in)), in_size - 1);\n    interpolation->lerp[i] = in - in_f;\n    interpolation->ilerp[i] =\n        static_cast<T_SCALE>((in - in_f) * (1 << resolution));\n  }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_attributes(self):\n        \"\"\"\n        Gets the Attributes from the AttributeStatement element.\n        EncryptedAttributes are not supported\n        \"\"\"\n        attributes = {}\n        attribute_nodes = self.__query_assertion('/saml:AttributeStatement/saml:Attribute')\n        for attribute_node in attribute_nodes:\n            attr_name = attribute_node.get('Name')\n            if attr_name in attributes.keys():\n                raise OneLogin_Saml2_ValidationError(\n                    'Found an Attribute element with duplicated Name',\n                    OneLogin_Saml2_ValidationError.DUPLICATED_ATTRIBUTE_NAME_FOUND\n                )\n\n            values = []\n            for attr in attribute_node.iterchildren('{%s}AttributeValue' % OneLogin_Saml2_Constants.NSMAP[OneLogin_Saml2_Constants.NS_PREFIX_SAML]):\n                # Remove any whitespace (which may be present where attributes are\n                # nested inside NameID children).\n                if attr.text:\n                    text = attr.text.strip()\n                    if text:\n                        values.append(text)\n\n                # Parse any nested NameID children\n                for nameid in attr.iterchildren('{%s}NameID' % OneLogin_Saml2_Constants.NSMAP[OneLogin_Saml2_Constants.NS_PREFIX_SAML]):\n                    values.append({\n                        'NameID': {\n                            'Format': nameid.get('Format'),\n                            'NameQualifier': nameid.get('NameQualifier'),\n                            'value': nameid.text\n                        }\n                    })\n\n            attributes[attr_name] = values\n        return attributes\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void TensorSliceReader::LoadShard(int shard) const {\n  CHECK_LT(shard, sss_.size());\n  if (sss_[shard] || !status_.ok()) {\n    return;  // Already loaded, or invalid.\n  }\n  string value;\n  SavedTensorSlices sts;\n  const string fname = fnames_[shard];\n  VLOG(1) << \"Reading meta data from file \" << fname << \"...\";\n  Table* table;\n  Status s = open_function_(fname, &table);\n  if (!s.ok()) {\n    status_ = errors::DataLoss(\"Unable to open table file \", fname, \": \",\n                               s.ToString());\n    return;\n  }\n  sss_[shard].reset(table);\n  if (!(table->Get(kSavedTensorSlicesKey, &value) &&\n        ParseProtoUnlimited(&sts, value))) {\n    status_ = errors::Internal(\n        \"Failed to find the saved tensor slices at the beginning of the \"\n        \"checkpoint file: \",\n        fname);\n    return;\n  }\n  status_ = CheckVersions(sts.meta().versions(), TF_CHECKPOINT_VERSION,\n                          TF_CHECKPOINT_VERSION_MIN_PRODUCER, \"Checkpoint\",\n                          \"checkpoint\");\n  if (!status_.ok()) return;\n  for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n    TensorShape ssm_shape;\n    status_ = TensorShape::BuildTensorShapeBase(ssm.shape(), &ssm_shape);\n    if (!status_.ok()) return;\n    for (const TensorSliceProto& tsp : ssm.slice()) {\n      TensorSlice ss_slice(tsp);\n      status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\n                                    ss_slice, &tensors_);\n      if (!status_.ok()) return;\n    }\n  }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  public ProxyResponseRenderer(\n      ProxySettings proxySettings,\n      KeyStoreSettings trustStoreSettings,\n      boolean preserveHostHeader,\n      String hostHeaderValue,\n      SettingsStore settingsStore,\n      boolean trustAllProxyTargets,\n      List<String> trustedProxyTargets,\n      boolean stubCorsEnabled,\n      NetworkAddressRules targetAddressRules,\n      int proxyTimeout) {\n    this.settingsStore = settingsStore;\n    reverseProxyClient =\n        HttpClientFactory.createClient(\n            1000,\n            proxyTimeout,\n            proxySettings,\n            trustStoreSettings,\n            true,\n            Collections.emptyList(),\n            true);\n    forwardProxyClient =\n        HttpClientFactory.createClient(\n            1000,\n            proxyTimeout,\n            proxySettings,\n            trustStoreSettings,\n            trustAllProxyTargets,\n            trustAllProxyTargets ? Collections.emptyList() : trustedProxyTargets,\n            false);\n\n    this.preserveHostHeader = preserveHostHeader;\n    this.hostHeaderValue = hostHeaderValue;\n    this.stubCorsEnabled = stubCorsEnabled;\n    this.targetAddressRules = targetAddressRules;\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def evaluate_link(self, link: Link) -> Package | None:\n        \"\"\"\n        Evaluate the link and return the package if it matches or None if it doesn't.\n        \"\"\"\n        try:\n            self.format_control.check_format(link, self.package_name)\n            self.check_yanked(link)\n            self.check_requires_python(link)\n            version: str | None = None\n            if link.is_wheel:\n                try:\n                    wheel_info = parse_wheel_filename(link.filename)\n                except (InvalidWheelFilename, InvalidVersion) as e:\n                    raise LinkMismatchError(str(e))\n                if self._canonical_name != wheel_info[0]:\n                    raise LinkMismatchError(\n                        f\"The package name doesn't match {wheel_info[0]}\"\n                    )\n                if not self.ignore_compatibility and wheel_info[3].isdisjoint(\n                    self.target_python.supported_tags()\n                ):\n                    raise LinkMismatchError(\n                        \"none of the wheel tags({}) are compatible\".format(\n                            \", \".join(sorted(str(tag) for tag in wheel_info[3]))\n                        ),\n                    )\n                version = str(wheel_info[1])\n            else:\n                if link._fragment_dict.get(\"egg\"):\n                    egg_info = strip_extras(link._fragment_dict[\"egg\"])\n                else:\n                    egg_info, ext = splitext(link.filename)\n                    if not ext:\n                        raise LinkMismatchError(f\"Not a file: {link.filename}\")\n                    if ext not in ARCHIVE_EXTENSIONS:\n                        raise LinkMismatchError(\n                            f\"Unsupported archive format: {link.filename}\"\n                        )\n                version = parse_version_from_egg_info(egg_info, self._canonical_name)\n                if version is None:\n                    raise LinkMismatchError(\n                        f\"Missing version in the filename {egg_info}\"\n                    )\n                try:\n                    Version(version)\n                except InvalidVersion:\n                    raise LinkMismatchError(\n                        f\"Invalid version in the filename {egg_info}: {version}\"\n                    )\n        except LinkMismatchError as e:\n            logger.debug(\"Skipping link %s: %s\", link, e)\n            return None\n        return Package(name=self.package_name, version=version, link=link)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def post(self, kernel_id, action):\n        \"\"\"Interrupt or restart a kernel.\"\"\"\n        km = self.kernel_manager\n        if action == \"interrupt\":\n            await ensure_async(km.interrupt_kernel(kernel_id))  # type:ignore[func-returns-value]\n            self.set_status(204)\n        if action == \"restart\":\n            try:\n                await km.restart_kernel(kernel_id)\n            except Exception as e:\n                message = \"Exception restarting kernel\"\n                self.log.error(message, exc_info=True)\n                traceback = format_tb(e.__traceback__)\n                self.write(json.dumps({\"message\": message, \"traceback\": traceback}))\n                self.set_status(500)\n            else:\n                model = await ensure_async(km.kernel_model(kernel_id))\n                self.write(json.dumps(model, default=json_default))\n        self.finish()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def compat_shlex_quote(s):\n        import re\n        return s if re.match(r'^[-_\\w./]+$', s) else '\"%s\"' % s.replace('\"', '\\\\\"')\nelse:"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "      void context.ready.then(async () => {\n        const file = context.model;\n        const workspace = (file.toJSON() as unknown) as Workspace.IWorkspace;\n        const path = context.path;\n        const id = workspace.metadata.id;\n\n        // Save the file contents as a workspace.\n        await this._workspaces.save(id, workspace);\n\n        // Save last save location for the save command.\n        await this._state.save(LAST_SAVE_ID, path);\n\n        // Navigate to new workspace.\n        const url = URLExt.join(this._application, 'workspaces', id);\n        if (this._router) {\n          this._router.navigate(url, { hard: true });\n        } else {\n          document.location.href = url;\n        }\n      });\n      return dummyWidget(context);"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def as_sql(self, compiler, connection):\n        key_transforms = [self.key_name]\n        previous = self.lhs\n        while isinstance(previous, KeyTransform):\n            key_transforms.insert(0, previous.key_name)\n            previous = previous.lhs\n        lhs, params = compiler.compile(previous)\n        if len(key_transforms) > 1:\n            return \"(%s %s %%s)\" % (lhs, self.nested_operator), [key_transforms] + params\n        try:\n            int(self.key_name)\n        except ValueError:\n            lookup = \"'%s'\" % self.key_name\n        else:\n            lookup = \"%s\" % self.key_name\n        return \"(%s %s %s)\" % (lhs, self.operator, lookup), params\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def image(\n        self,\n        tokens: Sequence[Token],\n        idx: int,\n        options: OptionsDict,\n        env: MutableMapping,\n    ) -> str:\n        token = tokens[idx]\n\n        # \"alt\" attr MUST be set, even if empty. Because it's mandatory and\n        # should be placed on proper position for tests.\n\n        assert (\n            token.attrs and \"alt\" in token.attrs\n        ), '\"image\" token\\'s attrs must contain `alt`'\n\n        # Replace content with actual value\n\n        token.attrSet(\"alt\", self.renderInlineAsText(token.children, options, env))\n\n        return self.renderToken(tokens, idx, options, env)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ValidateInput(const OpInputList& indices_list_in,\n                     const OpInputList& values_list_in,\n                     const OpInputList& shapes_list_in,\n                     const OpInputList& dense_list_in) {\n  const auto size = indices_list_in.size();\n  // Validates indices_list_in OpInputList.\n  for (int i = 0; i < size; i++) {\n    if (!TensorShapeUtils::IsMatrix(indices_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input indices should be a matrix but received shape \",\n          indices_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n    if (indices_list_in[i].shape().dim_size(1) != 2) {\n      return errors::InvalidArgument(\"Expected D2 of index to be 2 got \",\n                                     indices_list_in[i].shape().dim_size(1),\n                                     \" at position \", i);\n    }\n  }\n\n  // Validates values_list_in OpInputList.\n  if (values_list_in.size() != size) {\n    return errors::InvalidArgument(\"Expected \", size, \" input values, got \",\n                                   values_list_in.size());\n  }\n  for (int i = 0; i < size; i++) {\n    if (!TensorShapeUtils::IsVector(values_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input values should be a vector but received shape \",\n          values_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n    if (indices_list_in[i].shape().dim_size(0) !=\n        values_list_in[i].shape().dim_size(0)) {\n      return errors::InvalidArgument(\n          \"Expected size of values to be \",\n          indices_list_in[i].shape().dim_size(0), \" got \",\n          values_list_in[i].shape().dim_size(0), \" at position \", i);\n    }\n  }\n\n  // Validates shapes_list_in OpInputList\n  if (shapes_list_in.size() != size) {\n    return errors::InvalidArgument(\"Expected \", size, \" input shapes, got \",\n                                   shapes_list_in.size());\n  }\n  for (int i = 0; i < size; i++) {\n    if (!TensorShapeUtils::IsVector(shapes_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input shapes should be a vector but received shape \",\n          shapes_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n\n    if (shapes_list_in[i].vec<int64>().size() != 2) {\n      return errors::InvalidArgument(\"shape should imply a 2D tensor, but got \",\n                                     shapes_list_in[i].shape().DebugString(),\n                                     \" at position \", i);\n    }\n  }\n\n  // Validates dense_list_in OpInputList\n  for (int i = 0; i < dense_list_in.size(); ++i) {\n    if (!TensorShapeUtils::IsMatrix(dense_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Dense inputs should be a matrix but received shape \",\n          dense_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n  }\n\n  // Validates batch sizes.  (Note: we do this after validating the input\n  // shapes, because CalculateBatchSize() depends on inputs having valid\n  // shapes).\n  const auto batch_size = CalculateBatchSize(shapes_list_in, dense_list_in);\n  for (int i = 0; i < size; i++) {\n    if (shapes_list_in[i].vec<int64>()(0) != batch_size) {\n      return errors::InvalidArgument(\"Expected batch size \", batch_size,\n                                     \" got \", shapes_list_in[i].vec<int64>()(0),\n                                     \" at position \", i);\n    }\n  }\n  for (int i = 0; i < dense_list_in.size(); ++i) {\n    if (dense_list_in[i].dim_size(0) != batch_size) {\n      return errors::InvalidArgument(\"Expected batch size \", batch_size,\n                                     \" got \", dense_list_in[i].dim_size(0),\n                                     \" at dense tensor \", i);\n    }\n  }\n\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(c, num_updates % N == 0,\n                    errors::InvalidArgument(\n                        \"shape of indices (\", indices.shape().DebugString(),\n                        \") is not compatible with the shape of updates (\",\n                        updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def verify(cls, message, signature, publicKey, hashfunc=sha256):\n        byteMessage = hashfunc(toBytes(message)).digest()\n        numberMessage = numberFromByteString(byteMessage)\n        curve = publicKey.curve\n        r = signature.r\n        s = signature.s\n        inv = Math.inv(s, curve.N)\n        u1 = Math.multiply(curve.G, n=(numberMessage * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)\n        u2 = Math.multiply(publicKey.point, n=(r * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)\n        add = Math.add(u1, u2, A=curve.A, P=curve.P)\n        modX = add.x % curve.N\n        return r == modX\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable\n        # Process the parameters.\n        profile_form = UserProfileForm(email=self.app.currentuser.email)\n        password_form = UserPasswordForm()\n        if action == \"set_profile_info\":\n            self._handle_set_profile_info(action, profile_form)\n        elif action == \"set_password\":\n            self._handle_set_password(action, password_form)\n        elif action == \"update_repos\":\n            self.app.currentuser.refresh_repos(delete=True)\n            flash(_(\"Repositories successfully updated\"), level='success')\n        elif action is None:\n            pass\n        else:\n            _logger.warning(\"unknown action: %s\", action)\n            raise cherrypy.NotFound(\"Unknown action\")\n        params = {\n            'profile_form': profile_form,\n            'password_form': password_form,\n        }\n        return \"prefs_general.html\", params\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _execute_helper(\n        self,\n        query: str,\n        timeout: int = 0,\n        statement_params: dict[str, str] | None = None,\n        binding_params: tuple | dict[str, dict[str, str]] = None,\n        binding_stage: str | None = None,\n        is_internal: bool = False,\n        describe_only: bool = False,\n        _no_results: bool = False,\n        _is_put_get=None,\n        _no_retry: bool = False,\n    ):\n        del self.messages[:]\n\n        if statement_params is not None and not isinstance(statement_params, dict):\n            Error.errorhandler_wrapper(\n                self.connection,\n                self,\n                ProgrammingError,\n                {\n                    \"msg\": \"The data type of statement params is invalid. It must be dict.\",\n                    \"errno\": ER_INVALID_VALUE,\n                },\n            )\n\n        # check if current installation include arrow extension or not,\n        # if not, we set statement level query result format to be JSON\n        if not CAN_USE_ARROW_RESULT_FORMAT:\n            logger.debug(\"Cannot use arrow result format, fallback to json format\")\n            if statement_params is None:\n                statement_params = {\n                    PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT: \"JSON\"\n                }\n            else:\n                result_format_val = statement_params.get(\n                    PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT\n                )\n                if str(result_format_val).upper() == \"ARROW\":\n                    self.check_can_use_arrow_resultset()\n                elif result_format_val is None:\n                    statement_params[\n                        PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT\n                    ] = \"JSON\"\n\n        self._sequence_counter = self._connection._next_sequence_counter()\n        self._request_id = uuid.uuid4()\n\n        logger.debug(f\"Request id: {self._request_id}\")\n\n        logger.debug(\"running query [%s]\", self._format_query_for_log(query))\n        if _is_put_get is not None:\n            # if told the query is PUT or GET, use the information\n            self._is_file_transfer = _is_put_get\n        else:\n            # or detect it.\n            self._is_file_transfer = self.PUT_SQL_RE.match(\n                query\n            ) or self.GET_SQL_RE.match(query)\n        logger.debug(\"is_file_transfer: %s\", self._is_file_transfer is not None)\n\n        real_timeout = (\n            timeout if timeout and timeout > 0 else self._connection.network_timeout\n        )\n\n        if real_timeout is not None:\n            self._timebomb = Timer(real_timeout, self.__cancel_query, [query])\n            self._timebomb.start()\n            logger.debug(\"started timebomb in %ss\", real_timeout)\n        else:\n            self._timebomb = None\n\n        original_sigint = signal.getsignal(signal.SIGINT)\n\n        def interrupt_handler(*_):  # pragma: no cover\n            try:\n                signal.signal(signal.SIGINT, exit_handler)\n            except (ValueError, TypeError):\n                # ignore failures\n                pass\n            try:\n                if self._timebomb is not None:\n                    self._timebomb.cancel()\n                    logger.debug(\"cancelled timebomb in finally\")\n                    self._timebomb = None\n                self.__cancel_query(query)\n            finally:\n                if original_sigint:\n                    try:\n                        signal.signal(signal.SIGINT, original_sigint)\n                    except (ValueError, TypeError):\n                        # ignore failures\n                        pass\n            raise KeyboardInterrupt\n\n        try:\n            if not original_sigint == exit_handler:\n                signal.signal(signal.SIGINT, interrupt_handler)\n        except ValueError:  # pragma: no cover\n            logger.debug(\n                \"Failed to set SIGINT handler. \" \"Not in main thread. Ignored...\"\n            )\n        ret = {\"data\": {}}\n        try:\n            ret = self._connection.cmd_query(\n                query,\n                self._sequence_counter,\n                self._request_id,\n                binding_params=binding_params,\n                binding_stage=binding_stage,\n                is_file_transfer=bool(self._is_file_transfer),\n                statement_params=statement_params,\n                is_internal=is_internal,\n                describe_only=describe_only,\n                _no_results=_no_results,\n                _no_retry=_no_retry,\n            )\n        finally:\n            try:\n                if original_sigint:\n                    signal.signal(signal.SIGINT, original_sigint)\n            except (ValueError, TypeError):  # pragma: no cover\n                logger.debug(\n                    \"Failed to reset SIGINT handler. Not in main \" \"thread. Ignored...\"\n                )\n            if self._timebomb is not None:\n                self._timebomb.cancel()\n                logger.debug(\"cancelled timebomb in finally\")\n\n        if \"data\" in ret and \"parameters\" in ret[\"data\"]:\n            parameters = ret[\"data\"][\"parameters\"]\n            # Set session parameters for cursor object\n            for kv in parameters:\n                if \"TIMESTAMP_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_output_format = kv[\"value\"]\n                if \"TIMESTAMP_NTZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_ntz_output_format = kv[\"value\"]\n                if \"TIMESTAMP_LTZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_ltz_output_format = kv[\"value\"]\n                if \"TIMESTAMP_TZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_tz_output_format = kv[\"value\"]\n                if \"DATE_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._date_output_format = kv[\"value\"]\n                if \"TIME_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._time_output_format = kv[\"value\"]\n                if \"TIMEZONE\" in kv[\"name\"]:\n                    self._timezone = kv[\"value\"]\n                if \"BINARY_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._binary_output_format = kv[\"value\"]\n            # Set session parameters for connection object\n            self._connection._update_parameters(\n                {p[\"name\"]: p[\"value\"] for p in parameters}\n            )\n\n        self.query = query\n        self._sequence_counter = -1\n        return ret\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const int64 axis_input = context->input(0).scalar<int64>()();\n    const Tensor& input_indices = context->input(1);\n    const Tensor& input_values = context->input(2);\n    const Tensor& input_shape = context->input(3);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values.shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape.shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape.shape().DebugString()));\n\n    const int64 input_rank = input_shape.vec<int64>().size();\n    const int64 axis = (axis_input < 0) ? input_rank + axis_input : axis_input;\n\n    OP_REQUIRES(\n        context, axis >= 0 && axis < input_rank,\n        errors::InvalidArgument(\"Input axis should be in range [\", -input_rank,\n                                \", \", input_rank, \"), got \", axis_input));\n\n    OP_REQUIRES(context,\n                num_split_ >= 1 && num_split_ <= input_shape.vec<int64>()(axis),\n                errors::InvalidArgument(\"Input num_split should be between 1 \"\n                                        \"and the splitting dimension size (\",\n                                        input_shape.vec<int64>()(axis),\n                                        \"), got \", num_split_));\n\n    sparse::SparseTensor sparse_tensor;\n    OP_REQUIRES_OK(context,\n                   sparse::SparseTensor::Create(\n                       input_indices, input_values,\n                       TensorShape(input_shape.vec<int64>()), &sparse_tensor));\n\n    std::vector<sparse::SparseTensor> outputs;\n    OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(\n                                sparse_tensor, axis, num_split_, &outputs));\n\n    for (int slice_index = 0; slice_index < num_split_; ++slice_index) {\n      context->set_output(slice_index, outputs[slice_index].indices());\n      context->set_output(slice_index + num_split_,\n                          outputs[slice_index].values());\n      Tensor* shape = nullptr;\n      OP_REQUIRES_OK(context, context->allocate_output(\n                                  slice_index + 2 * num_split_,\n                                  {outputs[slice_index].dims()}, &shape));\n      auto output_shape = outputs[slice_index].shape();\n      for (int dim = 0; dim < outputs[slice_index].dims(); ++dim) {\n        shape->vec<int64>()(dim) = output_shape[dim];\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def kickban(bot, trigger):\n    \"\"\"Kick and ban a user from the channel. The bot must be a channel operator for this command to work.\"\"\"\n    chanops = get_chanops(str(trigger.sender), bot.memory['channelmgnt']['jdcache'])\n    dodeop = False\n    if chanops:\n        if bot.channels[trigger.sender].privileges[bot.nick] < OP and trigger.account in chanops:\n            bot.say('Please wait...')\n            bot.say('op ' + trigger.sender, 'ChanServ')\n            time.sleep(1)\n            dodeop = True\n        text = trigger.group().split()\n        argc = len(text)\n        if argc < 3:\n            bot.reply('Syntax is: .kickban <nick> <reason>')\n            if dodeop:\n                deopbot(trigger.sender, bot)\n            return\n        nick = Identifier(text[1])\n        mask = text[2] if any(s in text[2] for s in '!@*') else ''\n        reasonidx = 3 if mask != '' else 2\n        reason = ' '.join(text[reasonidx:])\n        mask = parse_host_mask(trigger.group().split())\n        if mask == '':\n            mask = nick + '!*@*'\n        if trigger.account in chanops:\n            bot.write(['MODE', trigger.sender, '+b', mask])\n            bot.write(['KICK', trigger.sender, nick, ':' + reason])\n            if dodeop:\n                deopbot(trigger.sender, bot)\n        else:\n            bot.reply('Access Denied. If in error, please contact the channel founder.')\n    else:\n        bot.reply(f'No ChanOps Found. Please ask for assistance in {bot.settings.channelmgnt.support_channel}')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def on_POST(\n        self, request: SynapseRequest, room_id: str, receipt_type: str, event_id: str\n    ) -> Tuple[int, JsonDict]:\n        requester = await self.auth.get_user_by_req(request)\n\n        if not RoomID.is_valid(room_id) or not event_id.startswith(EventID.SIGIL):\n            raise SynapseError(400, \"A valid room ID and event ID must be specified\")\n\n        if receipt_type not in self._known_receipt_types:\n            raise SynapseError(\n                400,\n                f\"Receipt type must be {', '.join(self._known_receipt_types)}\",\n            )\n\n        body = parse_json_object_from_request(request)\n\n        # Pull the thread ID, if one exists.\n        thread_id = None\n        if \"thread_id\" in body:\n            thread_id = body.get(\"thread_id\")\n            if not thread_id or not isinstance(thread_id, str):\n                raise SynapseError(\n                    400,\n                    \"thread_id field must be a non-empty string\",\n                    Codes.INVALID_PARAM,\n                )\n\n            if receipt_type == ReceiptTypes.FULLY_READ:\n                raise SynapseError(\n                    400,\n                    f\"thread_id is not compatible with {ReceiptTypes.FULLY_READ} receipts.\",\n                    Codes.INVALID_PARAM,\n                )\n\n            # Ensure the event ID roughly correlates to the thread ID.\n            if not await self._is_event_in_thread(event_id, thread_id):\n                raise SynapseError(\n                    400,\n                    f\"event_id {event_id} is not related to thread {thread_id}\",\n                    Codes.INVALID_PARAM,\n                )\n\n        await self.presence_handler.bump_presence_active_time(\n            requester.user, requester.device_id\n        )\n\n        if receipt_type == ReceiptTypes.FULLY_READ:\n            await self.read_marker_handler.received_client_read_marker(\n                room_id,\n                user_id=requester.user.to_string(),\n                event_id=event_id,\n            )\n        else:\n            await self.receipts_handler.received_client_receipt(\n                room_id,\n                receipt_type,\n                user_id=requester.user.to_string(),\n                event_id=event_id,\n                thread_id=thread_id,\n            )\n\n        return 200, {}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& image = context->input(0);\n    OP_REQUIRES(context, image.dims() == 3,\n                errors::InvalidArgument(\"image must be 3-dimensional\",\n                                        image.shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n        errors::InvalidArgument(\"image cannot have >= int32 max elements\"));\n    const int32 height = static_cast<int32>(image.dim_size(0));\n    const int32 width = static_cast<int32>(image.dim_size(1));\n    const int32 channels = static_cast<int32>(image.dim_size(2));\n\n    // In some cases, we pass width*channels*2 to png.\n    const int32 max_row_width = std::numeric_limits<int32>::max() / 2;\n\n    OP_REQUIRES(context, FastBoundsCheck(width * channels, max_row_width),\n                errors::InvalidArgument(\"image too wide to encode\"));\n\n    OP_REQUIRES(context, channels >= 1 && channels <= 4,\n                errors::InvalidArgument(\n                    \"image must have 1, 2, 3, or 4 channels, got \", channels));\n\n    // Encode image to png string\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({}), &output));\n    if (desired_channel_bits_ == 8) {\n      OP_REQUIRES(context,\n                  png::WriteImageToBuffer(\n                      image.flat<uint8>().data(), width, height,\n                      width * channels, channels, desired_channel_bits_,\n                      compression_, &output->scalar<tstring>()(), nullptr),\n                  errors::Internal(\"PNG encoding failed\"));\n    } else {\n      OP_REQUIRES(context,\n                  png::WriteImageToBuffer(\n                      image.flat<uint16>().data(), width, height,\n                      width * channels * 2, channels, desired_channel_bits_,\n                      compression_, &output->scalar<tstring>()(), nullptr),\n                  errors::Internal(\"PNG encoding failed\"));\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, sydent):\n        self.sydent = sydent\n        # The default endpoint factory in Twisted 14.0.0 (which we require) uses the\n        # BrowserLikePolicyForHTTPS context factory which will do regular cert validation\n        # 'like a browser'\n        self.agent = Agent(\n            self.sydent.reactor,\n            connectTimeout=15,\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _update_load_status(self, ok: bool) -> None:\n        \"\"\"Update the load status after a page finished loading.\n\n        Needs to be called by subclasses to trigger a load status update, e.g.\n        as a response to a loadFinished signal.\n        \"\"\"\n        if ok and not self._has_ssl_errors:\n            if self.url().scheme() == 'https':\n                self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def on_incoming_transaction(self, transaction_data):\n        # keep this as early as possible to make the calculated origin ts as\n        # accurate as possible.\n        request_time = self._clock.time_msec()\n\n        transaction = Transaction(**transaction_data)\n\n        if not transaction.transaction_id:\n            raise Exception(\"Transaction missing transaction_id\")\n        if not transaction.origin:\n            raise Exception(\"Transaction missing origin\")\n\n        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)\n\n        # use a linearizer to ensure that we don't process the same transaction\n        # multiple times in parallel.\n        with (yield self._transaction_linearizer.queue(\n                (transaction.origin, transaction.transaction_id),\n        )):\n            result = yield self._handle_incoming_transaction(\n                transaction, request_time,\n            )\n\n        defer.returnValue(result)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _task_executor(self):\r\n        \"\"\"Worker that executes Tasks that have satisfied dependencies.\"\"\"\r\n        # this event blocks until the TaskGraph has signaled ready to execute\r\n        self._taskgraph_started_event.wait()\r\n        while True:\r\n            # this event blocks until the task graph has signaled it wants\r\n            # the executors to read the state of the queue or a stop event\r\n            self._executor_ready_event.wait()\r\n            # this lock synchronizes changes between the queue and\r\n            # executor_ready_event\r\n            if self._terminated:\r\n                LOGGER.debug(\r\n                    \"taskgraph is terminated, ending %s\",\r\n                    threading.currentThread())\r\n                break\r\n            task = None\r\n            try:\r\n                task = self._task_ready_priority_queue.get_nowait()\r\n                self._task_waiting_count -= 1\r\n                task_name_time_tuple = (task.task_name, time.time())\r\n                self._active_task_list.append(task_name_time_tuple)\r\n            except queue.Empty:\r\n                # no tasks are waiting could be because the taskgraph is\r\n                # closed or because the queue is just empty.\r\n                if self._closed and not self._task_dependent_map:\r\n                    # the task graph is signaling executors to stop,\r\n                    # since the self._task_dependent_map is empty the\r\n                    # executor can terminate.\r\n                    LOGGER.debug(\r\n                        \"no tasks are pending and taskgraph closed, normally \"\r\n                        \"terminating executor %s.\" %\r\n                        threading.currentThread())\r\n                    break\r\n                else:\r\n                    self._executor_ready_event.clear()\r\n            if task is None:\r\n                continue\r\n            try:\r\n                task._call()\r\n                task.task_done_executing_event.set()\r\n            except Exception as e:\r\n                # An error occurred on a call, terminate the taskgraph\r\n                task.exception_object = e\r\n                LOGGER.exception(\r\n                    'A taskgraph _task_executor failed on Task '\r\n                    '%s. Terminating taskgraph.', task.task_name)\r\n                self._terminate()\r\n                break\r\n\r\n            LOGGER.debug(\r\n                \"task %s is complete, checking to see if any dependent \"\r\n                \"tasks can be executed now\", task.task_name)\r\n            self._completed_task_names.add(task.task_name)\r\n            self._active_task_list.remove(task_name_time_tuple)\r\n            for waiting_task_name in (\r\n                    self._task_dependent_map[task.task_name]):\r\n                # remove `task` from the set of tasks that\r\n                # `waiting_task` was waiting on.\r\n                self._dependent_task_map[waiting_task_name].remove(\r\n                    task.task_name)\r\n                # if there aren't any left, we can push `waiting_task`\r\n                # to the work queue\r\n                if not self._dependent_task_map[waiting_task_name]:\r\n                    # if we removed the last task we can put it to the\r\n                    # work queue\r\n                    LOGGER.debug(\r\n                        \"Task %s is ready for processing, sending to \"\r\n                        \"task_ready_priority_queue\",\r\n                        waiting_task_name)\r\n                    del self._dependent_task_map[waiting_task_name]\r\n                    self._task_ready_priority_queue.put(\r\n                        self._task_name_map[waiting_task_name])\r\n                    self._task_waiting_count += 1\r\n                    # indicate to executors there is work to do\r\n                    self._executor_ready_event.set()\r\n            del self._task_dependent_map[task.task_name]\r\n            LOGGER.debug(\"task %s done processing\", task.task_name)\r\n        LOGGER.debug(\"task executor shutting down\")\r\n\r"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def run(self, login_url='/login/', logout_url='/logout', persistent_timeout=43200, absolute_timeout=30):\n        \"\"\"\n        A tool that verify if the session is associated to a user by tracking\n        a session key. If session is not authenticated, redirect user to login page.\n        \"\"\"\n        request = cherrypy.serving.request\n        # Skip execution of this tools when browsing the login page.\n        if request.path_info == login_url:\n            if self._is_login():\n                raise cherrypy.HTTPRedirect('/')\n            return\n\n        # Clear session when browsing /logout\n        if request.path_info == logout_url or request.path_info.startswith(logout_url):\n            self.logout()\n            raise cherrypy.HTTPRedirect('/')\n\n        # Check if login\n        if not self._is_login():\n            # Store original URL\n            self._set_redirect_url()\n            # And redirect to login page\n            raise cherrypy.HTTPRedirect(login_url)\n\n        self._update_session_timeout()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def kick(bot, trigger):\n    \"\"\"Kick a user from the channel.\"\"\"\n    chanops = get_chanops(str(trigger.sender), bot.memory['channelmgnt']['jdcache'])\n    dodeop = False\n    if chanops:\n        if bot.channels[trigger.sender].privileges[bot.nick] < OP and trigger.account in chanops:\n            bot.say('Please wait...')\n            bot.say('op ' + trigger.sender, 'ChanServ')\n            time.sleep(1)\n            dodeop = True\n        text = trigger.group().split()\n        argc = len(text)\n        if argc < 2:\n            return\n        nick = Identifier(text[1])\n        reason = ' '.join(text[2:])\n        if nick != bot.config.core.nick and trigger.account in chanops:\n            bot.write(['KICK', trigger.sender, nick, ':' + reason])\n            if dodeop:\n                deopbot(trigger.sender, bot)\n        else:\n            bot.reply('Access Denied. If in error, please contact the channel founder.')\n    else:\n        bot.reply(f'No ChanOps Found. Please ask for assistance in {bot.settings.channelmgnt.support_channel}')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def eval(expression, _dict={}, **kw):\n    \"\"\"\n    Evaluates an image expression.\n\n    :param expression: A string containing a Python-style expression.\n    :param options: Values to add to the evaluation context.  You\n                    can either use a dictionary, or one or more keyword\n                    arguments.\n    :return: The evaluated expression. This is usually an image object, but can\n             also be an integer, a floating point value, or a pixel tuple,\n             depending on the expression.\n    \"\"\"\n\n    # build execution namespace\n    args = ops.copy()\n    args.update(_dict)\n    args.update(kw)\n    for k, v in list(args.items()):\n        if hasattr(v, \"im\"):\n            args[k] = _Operand(v)\n\n    out = builtins.eval(expression, args)\n    try:\n        return out.im\n    except AttributeError:\n        return out\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        path = urlparse(self.url).path\n        content_disposition = resp.headers.get(\"Content-Disposition\")\n        if content_disposition is not None and (\n            file_name := next(re.finditer(r\"filename=(.+)\", content_disposition), None)\n        ):\n            # NB: If the filename is quoted, unquote it\n            basename = file_name[1].strip(\"'\\\"\")\n            if _is_path(basename):\n                raise MlflowException.invalid_parameter_value(\n                    f\"Invalid filename in Content-Disposition header: {basename}. \"\n                    \"It must be a file name, not a path.\"\n                )\n        elif path is not None and len(posixpath.basename(path)) > 0:\n            basename = posixpath.basename(path)\n        else:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if not url:\n        return False\n    netloc = urllib_parse.urlparse(url)[1]\n    return not netloc or netloc == host\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getlength(self, text, mode=\"\", direction=None, features=None, language=None):\n        \"\"\"\n        Returns length (in pixels with 1/64 precision) of given text when rendered\n        in font with provided direction, features, and language.\n\n        This is the amount by which following text should be offset.\n        Text bounding box may extend past the length in some fonts,\n        e.g. when using italics or accents.\n\n        The result is returned as a float; it is a whole number if using basic layout.\n\n        Note that the sum of two lengths may not equal the length of a concatenated\n        string due to kerning. If you need to adjust for kerning, include the following\n        character and subtract its length.\n\n        For example, instead of ::\n\n          hello = font.getlength(\"Hello\")\n          world = font.getlength(\"World\")\n          hello_world = hello + world  # not adjusted for kerning\n          assert hello_world == font.getlength(\"HelloWorld\")  # may fail\n\n        use ::\n\n          hello = font.getlength(\"HelloW\") - font.getlength(\"W\")  # adjusted for kerning\n          world = font.getlength(\"World\")\n          hello_world = hello + world  # adjusted for kerning\n          assert hello_world == font.getlength(\"HelloWorld\")  # True\n\n        or disable kerning with (requires libraqm) ::\n\n          hello = draw.textlength(\"Hello\", font, features=[\"-kern\"])\n          world = draw.textlength(\"World\", font, features=[\"-kern\"])\n          hello_world = hello + world  # kerning is disabled, no need to adjust\n          assert hello_world == draw.textlength(\"HelloWorld\", font, features=[\"-kern\"])\n\n        .. versionadded:: 8.0.0\n\n        :param text: Text to measure.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n        :return: Width for horizontal, height for vertical text.\n        \"\"\"\n        return self.font.getlength(text, mode, direction, features, language) / 64\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def secureModule(mname, *imp):\n    modsec = _moduleSecurity.get(mname, None)\n    if modsec is None:\n        if mname in _appliedModuleSecurity:\n            return sys.modules[mname]\n        return  # no MSI, no module\n\n    if imp:\n        __import__(mname, *imp)\n    del _moduleSecurity[mname]\n    module = sys.modules[mname]\n    modsec.apply(module.__dict__)\n    _appliedModuleSecurity[mname] = modsec\n    return module\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "      void context.ready.then(async () => {\n        const file = context.model;\n        const workspace = file.toJSON() as unknown as Workspace.IWorkspace;\n        const path = context.path;\n        const id = workspace.metadata.id;\n\n        // Save the file contents as a workspace.\n        await this._workspaces.save(id, workspace);\n\n        // Save last save location for the save command.\n        await this._state.save(LAST_SAVE_ID, path);\n\n        // Navigate to new workspace.\n        const url = URLExt.join(this._application, 'workspaces', id);\n        if (this._router) {\n          this._router.navigate(url, { hard: true });\n        } else {\n          document.location.href = url;\n        }\n      });\n      return dummyWidget(context);"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_ordering(self, *ordering):\n        \"\"\"\n        Add items from the 'ordering' sequence to the query's \"order by\"\n        clause. These items are either field names (not column names) --\n        possibly with a direction prefix ('-' or '?') -- or OrderBy\n        expressions.\n\n        If 'ordering' is empty, clear all ordering from the query.\n        \"\"\"\n        errors = []\n        for item in ordering:\n            if isinstance(item, str):\n                if '.' in item:\n                    warnings.warn(\n                        'Passing column raw column aliases to order_by() is '\n                        'deprecated. Wrap %r in a RawSQL expression before '\n                        'passing it to order_by().' % item,\n                        category=RemovedInDjango40Warning,\n                        stacklevel=3,\n                    )\n                    continue\n                if item == '?':\n                    continue\n                if item.startswith('-'):\n                    item = item[1:]\n                if item in self.annotations:\n                    continue\n                if self.extra and item in self.extra:\n                    continue\n                # names_to_path() validates the lookup. A descriptive\n                # FieldError will be raise if it's not.\n                self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n            elif not hasattr(item, 'resolve_expression'):\n                errors.append(item)\n            if getattr(item, 'contains_aggregate', False):\n                raise FieldError(\n                    'Using an aggregate in order_by() without also including '\n                    'it in annotate() is not allowed: %s' % item\n                )\n        if errors:\n            raise FieldError('Invalid order_by arguments: %s' % errors)\n        if ordering:\n            self.order_by += ordering\n        else:\n            self.default_ordering = False\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    OP_REQUIRES_OK(ctx, ctx->session_state()->DeleteTensor(name));\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def from_unix_seconds(seconds: Union[int, float]) -> datetime:\n    while abs(seconds) > MS_WATERSHED:\n        seconds /= 1000\n    dt = EPOCH + timedelta(seconds=seconds)\n    return dt.replace(tzinfo=timezone.utc)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def match(self, path):\n        match = self.regex.search(path)\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end():], args, kwargs\n        return None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def Ghostscript(tile, size, fp, scale=1):\n    \"\"\"Render an image using Ghostscript\"\"\"\n\n    # Unpack decoder tile\n    decoder, tile, offset, data = tile[0]\n    length, bbox = data\n\n    #Hack to support hi-res rendering\n    scale = int(scale) or 1\n    orig_size = size\n    orig_bbox = bbox\n    size = (size[0] * scale, size[1] * scale)\n    bbox = [bbox[0], bbox[1], bbox[2] * scale, bbox[3] * scale]\n    #print(\"Ghostscript\", scale, size, orig_size, bbox, orig_bbox)\n\n    import tempfile, os, subprocess\n\n    file = tempfile.mktemp()\n\n    # Build ghostscript command\n    command = [\"gs\",\n               \"-q\",                    # quite mode\n               \"-g%dx%d\" % size,        # set output geometry (pixels)\n               \"-r%d\" % (72*scale),     # set input DPI (dots per inch)\n               \"-dNOPAUSE -dSAFER\",     # don't pause between pages, safe mode\n               \"-sDEVICE=ppmraw\",       # ppm driver\n               \"-sOutputFile=%s\" % file,# output file\n            ]\n\n    if gs_windows_binary is not None:\n        if gs_windows_binary is False:\n            raise WindowsError('Unable to locate Ghostscript on paths')\n        command[0] = gs_windows_binary\n\n    # push data through ghostscript\n    try:\n        gs = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        # adjust for image origin\n        if bbox[0] != 0 or bbox[1] != 0:\n            gs.stdin.write((\"%d %d translate\\n\" % (-bbox[0], -bbox[1])).encode('ascii'))\n        fp.seek(offset)\n        while length > 0:\n            s = fp.read(8192)\n            if not s:\n                break\n            length = length - len(s)\n            gs.stdin.write(s)\n        gs.stdin.close()\n        status = gs.wait()\n        if status:\n            raise IOError(\"gs failed (status %d)\" % status)\n        im = Image.core.open_ppm(file)\n    finally:\n        try: os.unlink(file)\n        except: pass\n\n    return im\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render_POST(self, request):\n        send_cors(request)\n\n        args = get_args(request, (\"medium\", \"address\", \"room_id\", \"sender\",))\n        medium = args[\"medium\"]\n        address = args[\"address\"]\n        roomId = args[\"room_id\"]\n        sender = args[\"sender\"]\n\n        verified_sender = None\n        if self.require_auth:\n            account = authV2(self.sydent, request)\n            verified_sender = sender\n            if account.userId != sender:\n                raise MatrixRestError(403, \"M_UNAUTHORIZED\", \"'sender' doesn't match\")\n\n        globalAssocStore = GlobalAssociationStore(self.sydent)\n        mxid = globalAssocStore.getMxid(medium, address)\n        if mxid:\n            request.setResponseCode(400)\n            return {\n                \"errcode\": \"M_THREEPID_IN_USE\",\n                \"error\": \"Binding already known\",\n                \"mxid\": mxid,\n            }\n\n        if medium != \"email\":\n            request.setResponseCode(400)\n            return {\n                \"errcode\": \"M_UNRECOGNIZED\",\n                \"error\": \"Didn't understand medium '%s'\" % (medium,),\n            }\n\n        token = self._randomString(128)\n\n        tokenStore = JoinTokenStore(self.sydent)\n\n        ephemeralPrivateKey = nacl.signing.SigningKey.generate()\n        ephemeralPublicKey = ephemeralPrivateKey.verify_key\n\n        ephemeralPrivateKeyBase64 = encode_base64(ephemeralPrivateKey.encode(), True)\n        ephemeralPublicKeyBase64 = encode_base64(ephemeralPublicKey.encode(), True)\n\n        tokenStore.storeEphemeralPublicKey(ephemeralPublicKeyBase64)\n        tokenStore.storeToken(medium, address, roomId, sender, token)\n\n        # Variables to substitute in the template.\n        substitutions = {}\n        # Include all arguments sent via the request.\n        for k, v in args.items():\n            if isinstance(v, string_types):\n                substitutions[k] = v\n        substitutions[\"token\"] = token\n\n        # Substitutions that the template requires, but are optional to provide\n        # to the API.\n        extra_substitutions = [\n            'sender_display_name',\n            'token',\n            'room_name',\n            'bracketed_room_name',\n            'room_avatar_url',\n            'sender_avatar_url',\n            'guest_user_id',\n            'guest_access_token',\n        ]\n        for k in extra_substitutions:\n            substitutions.setdefault(k, '')\n\n        substitutions[\"bracketed_verified_sender\"] = \"\"\n        if verified_sender:\n            substitutions[\"bracketed_verified_sender\"] = \"(%s) \" % (verified_sender,)\n\n        substitutions[\"ephemeral_private_key\"] = ephemeralPrivateKeyBase64\n        if substitutions[\"room_name\"] != '':\n            substitutions[\"bracketed_room_name\"] = \"(%s) \" % substitutions[\"room_name\"]\n\n        substitutions[\"web_client_location\"] = self.sydent.default_web_client_location\n        if 'org.matrix.web_client_location' in substitutions:\n            substitutions[\"web_client_location\"] = substitutions.pop(\"org.matrix.web_client_location\")\n\n        subject_header = Header(self.sydent.cfg.get('email', 'email.invite.subject', raw=True) % substitutions, 'utf8')\n        substitutions[\"subject_header_value\"] = subject_header.encode()\n\n        brand = self.sydent.brand_from_request(request)\n        templateFile = self.sydent.get_branded_template(\n            brand,\n            \"invite_template.eml\",\n            ('email', 'email.invite_template'),\n        )\n\n        sendEmail(self.sydent, templateFile, address, substitutions)\n\n        pubKey = self.sydent.keyring.ed25519.verify_key\n        pubKeyBase64 = encode_base64(pubKey.encode())\n\n        baseUrl = \"%s/_matrix/identity/api/v1\" % (self.sydent.cfg.get('http', 'client_http_base'),)\n\n        keysToReturn = []\n        keysToReturn.append({\n            \"public_key\": pubKeyBase64,\n            \"key_validity_url\": baseUrl + \"/pubkey/isvalid\",\n        })\n        keysToReturn.append({\n            \"public_key\": ephemeralPublicKeyBase64,\n            \"key_validity_url\": baseUrl + \"/pubkey/ephemeral/isvalid\",\n        })\n\n        resp = {\n            \"token\": token,\n            \"public_key\": pubKeyBase64,\n            \"public_keys\": keysToReturn,\n            \"display_name\": self.redact_email_address(address),\n        }\n\n        return resp\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, loader):\n        loader.add_option(\n            \"connection_strategy\", str, \"eager\",\n            \"Determine when server connections should be established. When set to lazy, mitmproxy \"\n            \"tries to defer establishing an upstream connection as long as possible. This makes it possible to \"\n            \"use server replay while being offline. When set to eager, mitmproxy can detect protocols with \"\n            \"server-side greetings, as well as accurately mirror TLS ALPN negotiation.\",\n            choices=(\"eager\", \"lazy\")\n        )\n        loader.add_option(\n            \"stream_large_bodies\", Optional[str], None,\n            \"\"\"\n            Stream data to the client if response body exceeds the given\n            threshold. If streamed, the body will not be stored in any way.\n            Understands k/m/g suffixes, i.e. 3m for 3 megabytes.\n            \"\"\"\n        )\n        loader.add_option(\n            \"body_size_limit\", Optional[str], None,\n            \"\"\"\n            Byte size limit of HTTP request and response bodies. Understands\n            k/m/g suffixes, i.e. 3m for 3 megabytes.\n            \"\"\"\n        )\n        loader.add_option(\n            \"keep_host_header\", bool, False,\n            \"\"\"\n            Reverse Proxy: Keep the original host header instead of rewriting it\n            to the reverse proxy target.\n            \"\"\"\n        )\n        loader.add_option(\n            \"proxy_debug\", bool, False,\n            \"Enable debug logs in the proxy core.\",\n        )\n        loader.add_option(\n            \"normalize_outbound_headers\", bool, True,\n            \"\"\"\n            Normalize outgoing HTTP/2 header names, but emit a warning when doing so.\n            HTTP/2 does not allow uppercase header names. This option makes sure that HTTP/2 headers set\n            in custom scripts are lowercased before they are sent.\n            \"\"\",\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  virtual void ComputeWithReservedSpace(OpKernelContext* context,\n                                        bool use_reserved_space) {\n    Tensor x = context->input(0);\n    const Tensor& scale = context->input(1);\n    const Tensor& offset = context->input(2);\n    const Tensor& estimated_mean = context->input(3);\n    const Tensor& estimated_variance = context->input(4);\n    const Tensor* side_input = has_side_input_ ? &context->input(5) : nullptr;\n\n    OP_REQUIRES(context, x.dims() == 4 || x.dims() == 5,\n                errors::InvalidArgument(\"input must be 4 or 5-dimensional\",\n                                        x.shape().DebugString()));\n    OP_REQUIRES(context, scale.dims() == 1,\n                errors::InvalidArgument(\"scale must be 1-dimensional\",\n                                        scale.shape().DebugString()));\n    OP_REQUIRES(context, offset.dims() == 1,\n                errors::InvalidArgument(\"offset must be 1-dimensional\",\n                                        offset.shape().DebugString()));\n    OP_REQUIRES(context, estimated_mean.dims() == 1,\n                errors::InvalidArgument(\"estimated_mean must be 1-dimensional\",\n                                        estimated_mean.shape().DebugString()));\n    OP_REQUIRES(\n        context, estimated_variance.dims() == 1,\n        errors::InvalidArgument(\"estimated_variance must be 1-dimensional\",\n                                estimated_variance.shape().DebugString()));\n    bool use_reshape = (x.dims() == 5);\n    auto x_shape = x.shape();\n    TensorShape dest_shape;\n    if (use_reshape) {\n      const int64_t in_batch = GetTensorDim(x, tensor_format_, 'N');\n      int64_t in_planes = GetTensorDim(x, tensor_format_, '0');\n      int64_t in_rows = GetTensorDim(x, tensor_format_, '1');\n      int64_t in_cols = GetTensorDim(x, tensor_format_, '2');\n      const int64_t in_depth = GetTensorDim(x, tensor_format_, 'C');\n      dest_shape = ShapeFromFormat(tensor_format_, in_batch,\n                                   {{in_planes, in_rows * in_cols}}, in_depth);\n      OP_REQUIRES(context, x.CopyFrom(x, dest_shape),\n                  errors::InvalidArgument(\"Error during tensor copy.\"));\n    }\n\n    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n    OP_REQUIRES(\n        context, scale.NumElements() == num_channels,\n        errors::InvalidArgument(\"scale must have the same number of elements \"\n                                \"as the channels of x, got \",\n                                scale.NumElements(), \" and \", num_channels));\n    OP_REQUIRES(\n        context, offset.NumElements() == num_channels,\n        errors::InvalidArgument(\"offset must have the same number of elements \"\n                                \"as the channels of x, got \",\n                                offset.NumElements(), \" and \", num_channels));\n    if (estimated_mean.NumElements() != 0) {\n      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n                  errors::InvalidArgument(\n                      \"mean must be empty or have the same number of \"\n                      \"elements as the channels of x, got \",\n                      estimated_mean.NumElements(), \" and \", num_channels));\n    }\n    if (estimated_variance.NumElements() != 0) {\n      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n                  errors::InvalidArgument(\n                      \"variance must be empty or have the same number of \"\n                      \"elements as the channels of x, got \",\n                      estimated_variance.NumElements(), \" and \", num_channels));\n    }\n\n    if (has_side_input_) {\n      OP_REQUIRES(context, side_input->shape() == x.shape(),\n                  errors::InvalidArgument(\n                      \"side_input shape must be equal to input shape: \",\n                      side_input->shape().DebugString(),\n                      \" != \", x.shape().DebugString()));\n    }\n\n    if (activation_mode_ != FbnActivationMode::kIdentity) {\n      // NOTE(ezhulenev): This requirement is coming from implementation\n      // details of cudnnBatchNormalizationForwardTrainingEx.\n      OP_REQUIRES(\n          context, !is_training_ || num_channels % 4 == 0,\n          errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                  \"channel dimension to be a multiple of 4.\"));\n    }\n\n    Tensor* y = nullptr;\n    auto alloc_shape = use_reshape ? dest_shape : x_shape;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, alloc_shape, &y));\n\n    Tensor* batch_mean = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {3}, 1, scale.shape(), &batch_mean));\n    Tensor* batch_var = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {4}, 2, scale.shape(), &batch_var));\n    Tensor* saved_mean = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(3, scale.shape(), &saved_mean));\n    Tensor* saved_maybe_inv_var = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(4, scale.shape(),\n                                                     &saved_maybe_inv_var));\n\n    if (is_training_) {\n      functor::FusedBatchNorm<Device, T, U, true>()(\n          context, x, scale, offset, estimated_mean, estimated_variance,\n          side_input, epsilon_, exponential_avg_factor_, activation_mode_, y,\n          batch_mean, batch_var, saved_mean, saved_maybe_inv_var,\n          tensor_format_, use_reserved_space);\n    } else {\n      functor::FusedBatchNorm<Device, T, U, false>()(\n          context, x, scale, offset, estimated_mean, estimated_variance,\n          side_input, epsilon_, exponential_avg_factor_, activation_mode_, y,\n          batch_mean, batch_var, saved_mean, saved_maybe_inv_var,\n          tensor_format_, use_reserved_space);\n    }\n    if (use_reshape) {\n      OP_REQUIRES(context, y->CopyFrom(*y, x_shape),\n                  errors::InvalidArgument(\"Error during tensor copy.\"));\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& grad_in = context->input(1);\n    const Tensor& argmax = context->input(2);\n\n    PoolParameters params{context,\n                          ksize_,\n                          stride_,\n                          padding_,\n                          /*explicit_paddings=*/{},\n                          FORMAT_NHWC,\n                          tensor_in.shape()};\n    if (!context->status().ok()) {\n      return;\n    }\n\n    TensorShape out_shape({params.tensor_in_batch, params.tensor_in_rows,\n                           params.tensor_in_cols, params.depth});\n    Tensor* grad_out = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, out_shape, &grad_out));\n\n    LaunchMaxPoolingGradWithArgmax<Device, T>::launch(\n        context, params, grad_in, argmax, grad_out, include_batch_in_index_);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def requestStarted(self, job):\n        \"\"\"Handle a request for a qute: scheme.\n\n        This method must be reimplemented by all custom URL scheme handlers.\n        The request is asynchronous and does not need to be handled right away.\n\n        Args:\n            job: QWebEngineUrlRequestJob\n        \"\"\"\n        url = job.requestUrl()\n\n        if url.scheme() in ['chrome-error', 'chrome-extension']:\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-63378\n            job.fail(QWebEngineUrlRequestJob.UrlInvalid)\n            return\n\n        assert job.requestMethod() == b'GET'\n        assert url.scheme() == 'qute'\n        log.misc.debug(\"Got request for {}\".format(url.toDisplayString()))\n        try:\n            mimetype, data = qutescheme.data_for_url(url)\n        except qutescheme.NoHandlerFound:\n            log.misc.debug(\"No handler found for {}\".format(\n                url.toDisplayString()))\n            job.fail(QWebEngineUrlRequestJob.UrlNotFound)\n        except qutescheme.QuteSchemeOSError:\n            # FIXME:qtwebengine how do we show a better error here?\n            log.misc.exception(\"OSError while handling qute://* URL\")\n            job.fail(QWebEngineUrlRequestJob.UrlNotFound)\n        except qutescheme.QuteSchemeError:\n            # FIXME:qtwebengine how do we show a better error here?\n            log.misc.exception(\"Error while handling qute://* URL\")\n            job.fail(QWebEngineUrlRequestJob.RequestFailed)\n        except qutescheme.Redirect as e:\n            qtutils.ensure_valid(e.url)\n            job.redirect(e.url)\n        else:\n            log.misc.debug(\"Returning {} data\".format(mimetype))\n\n            # We can't just use the QBuffer constructor taking a QByteArray,\n            # because that somehow segfaults...\n            # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html\n            buf = QBuffer(parent=self)\n            buf.open(QIODevice.WriteOnly)\n            buf.write(data)\n            buf.seek(0)\n            buf.close()\n            job.reply(mimetype.encode('ascii'), buf)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "$.fn.reviewsAutoComplete = function(options) {\n    return this.each(function() {\n        $(this)\n            .autocomplete({\n                formatItem: function(data) {\n                    var s = data[options.nameKey];\n\n                    if (options.descKey) {\n                        s += \" <span>(\" + data[options.descKey] + \")</span>\";\n                    }\n\n                    return s;\n                },\n                matchCase: false,\n                multiple: true,\n                parse: function(data) {\n                    var jsonData = eval(\"(\" + data + \")\");\n                    var items = jsonData[options.fieldName];\n                    var parsed = [];\n\n                    for (var i = 0; i < items.length; i++) {\n                        var value = items[i];\n\n                        parsed.push({\n                            data: value,\n                            value: value[options.nameKey],\n                            result: value[options.nameKey]\n                        });\n                    }\n\n                    return parsed;\n                },\n                url: SITE_ROOT + gReviewRequestSitePrefix + \"api/\" + options.fieldName + \"/\",\n                extraParams: options.extraParams\n            })\n            .bind(\"autocompleteshow\", function() {\n                /*\n                 * Add the footer to the bottom of the results pane the\n                 * first time it's created.\n                 *\n                 * Note that we may have multiple .ui-autocomplete-results\n                 * elements, and we don't necessarily know which is tied to\n                 * this. So, we'll look for all instances that don't contain\n                 * a footer.\n                 */\n                var resultsPane = $(\".ui-autocomplete-results:not(\" +\n                                    \":has(.ui-autocomplete-footer))\");\n\n                if (resultsPane.length > 0) {\n                    $(\"<div/>\")\n                        .addClass(\"ui-autocomplete-footer\")\n                        .text(\"Press Tab to auto-complete.\")\n                        .appendTo(resultsPane);\n                }\n            });\n    });\n};\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  public static CloseableHttpClient createClient(\n      int maxConnections,\n      int timeoutMilliseconds,\n      ProxySettings proxySettings,\n      KeyStoreSettings trustStoreSettings,\n      boolean useSystemProperties) {\n    return createClient(\n        maxConnections,\n        timeoutMilliseconds,\n        proxySettings,\n        trustStoreSettings,\n        true,\n        Collections.<String>emptyList(),\n        useSystemProperties);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_newkeys(self, k: bytes, h: bytes) -> None:\n        \"\"\"Finish a key exchange and send a new keys message\"\"\"\n\n        if not self._session_id:\n            first_kex = True\n            self._session_id = h\n        else:\n            first_kex = False\n\n        enc_keysize_cs, enc_ivsize_cs, enc_blocksize_cs, \\\n        mac_keysize_cs, mac_hashsize_cs, etm_cs = \\\n            get_encryption_params(self._enc_alg_cs, self._mac_alg_cs)\n\n        enc_keysize_sc, enc_ivsize_sc, enc_blocksize_sc, \\\n        mac_keysize_sc, mac_hashsize_sc, etm_sc = \\\n            get_encryption_params(self._enc_alg_sc, self._mac_alg_sc)\n\n        if mac_keysize_cs == 0:\n            self._mac_alg_cs = self._enc_alg_cs\n\n        if mac_keysize_sc == 0:\n            self._mac_alg_sc = self._enc_alg_sc\n\n        cmp_after_auth_cs = get_compression_params(self._cmp_alg_cs)\n        cmp_after_auth_sc = get_compression_params(self._cmp_alg_sc)\n\n        self.logger.debug2('  Client to server:')\n        self.logger.debug2('    Encryption alg: %s', self._enc_alg_cs)\n        self.logger.debug2('    MAC alg: %s', self._mac_alg_cs)\n        self.logger.debug2('    Compression alg: %s', self._cmp_alg_cs)\n        self.logger.debug2('  Server to client:')\n        self.logger.debug2('    Encryption alg: %s', self._enc_alg_sc)\n        self.logger.debug2('    MAC alg: %s', self._mac_alg_sc)\n        self.logger.debug2('    Compression alg: %s', self._cmp_alg_sc)\n\n        assert self._kex is not None\n\n        iv_cs = self._kex.compute_key(k, h, b'A', self._session_id,\n                                      enc_ivsize_cs)\n        iv_sc = self._kex.compute_key(k, h, b'B', self._session_id,\n                                      enc_ivsize_sc)\n        enc_key_cs = self._kex.compute_key(k, h, b'C', self._session_id,\n                                           enc_keysize_cs)\n        enc_key_sc = self._kex.compute_key(k, h, b'D', self._session_id,\n                                           enc_keysize_sc)\n        mac_key_cs = self._kex.compute_key(k, h, b'E', self._session_id,\n                                           mac_keysize_cs)\n        mac_key_sc = self._kex.compute_key(k, h, b'F', self._session_id,\n                                           mac_keysize_sc)\n        self._kex = None\n\n        next_enc_cs = get_encryption(self._enc_alg_cs, enc_key_cs, iv_cs,\n                                     self._mac_alg_cs, mac_key_cs, etm_cs)\n        next_enc_sc = get_encryption(self._enc_alg_sc, enc_key_sc, iv_sc,\n                                     self._mac_alg_sc, mac_key_sc, etm_sc)\n\n        self.send_packet(MSG_NEWKEYS)\n\n        self._extensions_to_send[b'global-requests-ok'] = b''\n\n        if self.is_client():\n            self._send_encryption = next_enc_cs\n            self._send_enchdrlen = 1 if etm_cs else 5\n            self._send_blocksize = max(8, enc_blocksize_cs)\n            self._compressor = get_compressor(self._cmp_alg_cs)\n            self._compress_after_auth = cmp_after_auth_cs\n\n            self._next_recv_encryption = next_enc_sc\n            self._next_recv_blocksize = max(8, enc_blocksize_sc)\n            self._next_recv_macsize = mac_hashsize_sc\n            self._next_decompressor = get_decompressor(self._cmp_alg_sc)\n            self._next_decompress_after_auth = cmp_after_auth_sc\n\n            self.set_extra_info(\n                send_cipher=self._enc_alg_cs.decode('ascii'),\n                send_mac=self._mac_alg_cs.decode('ascii'),\n                send_compression=self._cmp_alg_cs.decode('ascii'),\n                recv_cipher=self._enc_alg_sc.decode('ascii'),\n                recv_mac=self._mac_alg_sc.decode('ascii'),\n                recv_compression=self._cmp_alg_sc.decode('ascii'))\n\n            if first_kex:\n                if self._wait == 'kex' and self._waiter and \\\n                        not self._waiter.cancelled():\n                    self._waiter.set_result(None)\n                    self._wait = None\n                else:\n                    self.send_service_request(_USERAUTH_SERVICE)\n        else:\n            self._send_encryption = next_enc_sc\n            self._send_enchdrlen = 1 if etm_sc else 5\n            self._send_blocksize = max(8, enc_blocksize_sc)\n            self._compressor = get_compressor(self._cmp_alg_sc)\n            self._compress_after_auth = cmp_after_auth_sc\n\n            self._next_recv_encryption = next_enc_cs\n            self._next_recv_blocksize = max(8, enc_blocksize_cs)\n            self._next_recv_macsize = mac_hashsize_cs\n            self._next_decompressor = get_decompressor(self._cmp_alg_cs)\n            self._next_decompress_after_auth = cmp_after_auth_cs\n\n            self.set_extra_info(\n                send_cipher=self._enc_alg_sc.decode('ascii'),\n                send_mac=self._mac_alg_sc.decode('ascii'),\n                send_compression=self._cmp_alg_sc.decode('ascii'),\n                recv_cipher=self._enc_alg_cs.decode('ascii'),\n                recv_mac=self._mac_alg_cs.decode('ascii'),\n                recv_compression=self._cmp_alg_cs.decode('ascii'))\n\n            if first_kex:\n                self._next_service = _USERAUTH_SERVICE\n\n                self._extensions_to_send[b'server-sig-algs'] = \\\n                    b','.join(self._sig_algs)\n\n        if self._can_send_ext_info:\n            self._send_ext_info()\n            self._can_send_ext_info = False\n\n        self._kex_complete = True\n        self._send_deferred_packets()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        headers = prepared_request.headers\n        scheme = urlparse(prepared_request.url).scheme\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n\n        if \"Proxy-Authorization\" in headers:\n            del headers[\"Proxy-Authorization\"]\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n            username, password = None, None\n\n        if username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_ip(ip: str) -> None:\n    \"\"\"Checks if an IP is local/private.\n\n    :param ip: IP address to be checked.\n    \"\"\"\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _load_prompt(config: dict) -> PromptTemplate:\n    \"\"\"Load the prompt template from config.\"\"\"\n    # Load the template from disk if necessary.\n    config = _load_template(\"template\", config)\n    config = _load_output_parser(config)\n    return PromptTemplate(**config)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(\n      GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,\n      const absl::Span<const int>& seq_lengths, bool time_major,\n      cudnnDataType_t data_type) {\n    CHECK_GT(max_seq_length, 0);\n    int dims[] = {batch_size, data_size, 1};\n    int strides[] = {dims[1] * dims[2], dims[2], 1};\n    TensorDescriptor tensor_desc = CreateTensorDescriptor();\n    RETURN_IF_CUDNN_ERROR(cudnnSetTensorNdDescriptor(\n        /*tensorDesc=*/tensor_desc.get(), /*dataType=*/data_type,\n        /*nbDims=*/sizeof(dims) / sizeof(dims[0]), /*dimA=*/dims,\n        /*strideA=*/strides));\n    const int* seq_lengths_array = seq_lengths.data();\n    RNNDataDescriptor data_desc = CreateRNNDataDescriptor();\n    float padding_fill = 0.0f;\n    cudnnRNNDataLayout_t layout;\n    if (time_major) {\n      layout = CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED;\n    } else {\n      layout = CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED;\n    }\n    RETURN_IF_CUDNN_ERROR(cudnnSetRNNDataDescriptor(\n        /*RNNDataDesc=*/data_desc.get(), /*dataType*/ data_type,\n        /*layout=*/layout,\n        /*maxSeqLength=*/max_seq_length,\n        /*batchSize=*/batch_size, /*vectorSize=*/data_size,\n        /*seqLengthArray=*/seq_lengths_array,\n        /*paddingFill*/ (void*)&padding_fill));\n    return CudnnRnnSequenceTensorDescriptor(\n        parent, max_seq_length, batch_size, data_size, data_type,\n        std::move(data_desc), std::move(tensor_desc));\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const float in_min = context->input(2).flat<float>()(0);\n    const float in_max = context->input(3).flat<float>()(0);\n\n    ImageResizerState st(align_corners_, false);\n    st.ValidateAndCreateOutput(context);\n\n    if (!context->status().ok()) return;\n\n    // Return if the output is empty.\n    if (st.output->NumElements() == 0) return;\n\n    typename TTypes<T, 4>::ConstTensor image_data(\n        context->input(0).tensor<T, 4>());\n    typename TTypes<T, 4>::Tensor output_data(st.output->tensor<T, 4>());\n\n    ResizeBilinear<T>(image_data, st.height_scale, st.width_scale, in_min,\n                      in_max, half_pixel_centers_, &output_data);\n    Tensor* out_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &out_min));\n    out_min->flat<float>()(0) = in_min;\n\n    Tensor* out_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &out_max));\n    out_max->flat<float>()(0) = in_max;\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def response_for_exception(request, exc):\n    if isinstance(exc, Http404):\n        if settings.DEBUG:\n            response = debug.technical_404_response(request, exc)\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 404, exc\n            )\n\n    elif isinstance(exc, PermissionDenied):\n        response = get_exception_response(\n            request, get_resolver(get_urlconf()), 403, exc\n        )\n        log_response(\n            \"Forbidden (Permission denied): %s\",\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    elif isinstance(exc, MultiPartParserError):\n        response = get_exception_response(\n            request, get_resolver(get_urlconf()), 400, exc\n        )\n        log_response(\n            \"Bad request (Unable to parse request body): %s\",\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    elif isinstance(exc, BadRequest):\n        if settings.DEBUG:\n            response = debug.technical_500_response(\n                request, *sys.exc_info(), status_code=400\n            )\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 400, exc\n            )\n        log_response(\n            \"%s: %s\",\n            str(exc),\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n    elif isinstance(exc, SuspiciousOperation):\n        if isinstance(exc, (RequestDataTooBig, TooManyFieldsSent)):\n            # POST data can't be accessed again, otherwise the original\n            # exception would be raised.\n            request._mark_post_parse_error()\n\n        # The request logger receives events for any problematic request\n        # The security logger receives events for all SuspiciousOperations\n        security_logger = logging.getLogger(\n            \"django.security.%s\" % exc.__class__.__name__\n        )\n        security_logger.error(\n            str(exc),\n            extra={\"status_code\": 400, \"request\": request},\n        )\n        if settings.DEBUG:\n            response = debug.technical_500_response(\n                request, *sys.exc_info(), status_code=400\n            )\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 400, exc\n            )\n\n    else:\n        signals.got_request_exception.send(sender=None, request=request)\n        response = handle_uncaught_exception(\n            request, get_resolver(get_urlconf()), sys.exc_info()\n        )\n        log_response(\n            \"%s: %s\",\n            response.reason_phrase,\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    # Force a TemplateResponse to be rendered.\n    if not getattr(response, \"is_rendered\", True) and callable(\n        getattr(response, \"render\", None)\n    ):\n        response = response.render()\n\n    return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def model_from_yaml(yaml_string, custom_objects=None):\n  \"\"\"Parses a yaml model configuration file and returns a model instance.\n\n  Usage:\n\n  >>> model = tf.keras.Sequential([\n  ...     tf.keras.layers.Dense(5, input_shape=(3,)),\n  ...     tf.keras.layers.Softmax()])\n  >>> try:\n  ...   import yaml\n  ...   config = model.to_yaml()\n  ...   loaded_model = tf.keras.models.model_from_yaml(config)\n  ... except ImportError:\n  ...   pass\n\n  Arguments:\n      yaml_string: YAML string or open file encoding a model configuration.\n      custom_objects: Optional dictionary mapping names\n          (strings) to custom classes or functions to be\n          considered during deserialization.\n\n  Returns:\n      A Keras model instance (uncompiled).\n\n  Raises:\n      ImportError: if yaml module is not found.\n  \"\"\"\n  if yaml is None:\n    raise ImportError('Requires yaml module installed (`pip install pyyaml`).')\n  # The method unsafe_load only exists in PyYAML 5.x+, so which branch of the\n  # try block is covered by tests depends on the installed version of PyYAML.\n  try:\n    # PyYAML 5.x+\n    config = yaml.unsafe_load(yaml_string)\n  except AttributeError:\n    config = yaml.load(yaml_string)\n  from tensorflow.python.keras.layers import deserialize  # pylint: disable=g-import-not-at-top\n  return deserialize(config, custom_objects=custom_objects)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def encryption_materials(self, encryption_context):\n        # type: (EncryptionContext) -> CryptographicMaterials\n        \"\"\"Return encryption materials.\n\n        :param EncryptionContext encryption_context: Encryption context for request\n        :raises AttributeError: if no encryption materials are available\n        \"\"\"\n        ttl_action = self._ttl_action()\n\n        _LOGGER.debug('TTL Action \"%s\" when getting encryption materials', ttl_action.name)\n\n        provider = None\n\n        if ttl_action is TtlActions.LIVE:\n            try:\n                _LOGGER.debug(\"Looking in cache for encryption materials provider version %d\", self._version)\n                provider = self._cache.get(self._version)\n            except KeyError:\n                _LOGGER.debug(\"Encryption materials provider not found in cache\")\n                ttl_action = TtlActions.EXPIRED\n\n        if provider is None:\n            # Just get the latest local version if we cannot acquire the lock.\n            # Otherwise, block until we can acquire the lock.\n            allow_local = bool(ttl_action is TtlActions.GRACE_PERIOD)\n\n            _LOGGER.debug(\"Getting most recent materials provider version\")\n            provider = self._get_most_recent_version(allow_local)\n\n        return provider.encryption_materials(encryption_context)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def execute_command(self, *args: Any, **kwargs: Any) -> Any:\n        # Acquire connection\n        connection = self.acquire_connection()\n\n        # Execute command\n        await connection.send_packed_command(connection.pack_command(*args), False)\n\n        # Read response\n        try:\n            return await self.parse_response(connection, args[0], **kwargs)\n        finally:\n            # Release connection\n            self._free.append(connection)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _property_resolver(arg):\n    \"\"\"\n    When arg is convertible to float, behave like operator.itemgetter(arg)\n    Otherwise, behave like Variable(arg).resolve\n\n    >>> _property_resolver(1)('abc')\n    'b'\n    >>> _property_resolver('1')('abc')\n    Traceback (most recent call last):\n    ...\n    TypeError: string indices must be integers\n    >>> class Foo:\n    ...     a = 42\n    ...     b = 3.14\n    ...     c = 'Hey!'\n    >>> _property_resolver('b')(Foo())\n    3.14\n    \"\"\"\n    try:\n        float(arg)\n    except ValueError:\n        return Variable(arg).resolve\n    else:\n        return itemgetter(arg)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def login():\n    from flask_login import current_user\n\n    redirect_url = request.args.get(\"redirect\", request.script_root + url_for(\"index\"))\n    permissions = sorted(\n        filter(\n            lambda x: x is not None and isinstance(x, OctoPrintPermission),\n            map(\n                lambda x: getattr(Permissions, x.strip()),\n                request.args.get(\"permissions\", \"\").split(\",\"),\n            ),\n        ),\n        key=lambda x: x.get_name(),\n    )\n    if not permissions:\n        permissions = [Permissions.STATUS, Permissions.SETTINGS_READ]\n\n    user_id = request.args.get(\"user_id\", \"\")\n\n    if (not user_id or current_user.get_id() == user_id) and has_permissions(\n        *permissions\n    ):\n        return redirect(redirect_url)\n\n    render_kwargs = {\n        \"theming\": [],\n        \"redirect_url\": redirect_url,\n        \"permission_names\": map(lambda x: x.get_name(), permissions),\n        \"user_id\": user_id,\n        \"logged_in\": not current_user.is_anonymous,\n    }\n\n    try:\n        additional_assets = _add_additional_assets(\"octoprint.theming.login\")\n\n        # backwards compatibility to forcelogin & loginui plugins which were replaced by this built-in dialog\n        additional_assets += _add_additional_assets(\"octoprint.plugin.forcelogin.theming\")\n        additional_assets += _add_additional_assets(\"octoprint.plugin.loginui.theming\")\n\n        render_kwargs.update({\"theming\": additional_assets})\n    except Exception:\n        _logger.exception(\"Error processing theming CSS, ignoring\")\n\n    return render_template(\"login.jinja2\", **render_kwargs)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_initial_logout(self):\n        \"\"\"\n        Get the initial logout request.\n\n        Raises ValueError if no sessions in INIT_LOGOUT state.\n        \"\"\"\n        candidates = self._ss.get_user_sessions(self.user)\n\n        # FIXME: what does it mean if there are multiple in init? We\n        #        just return the first one for now. How do we know\n        #        it's the \"right\" one if multiple logouts are started\n        #        at the same time from different SPs?\n        for c in candidates:\n            key = c.keys()[0]\n            if int(c[key].get('logoutstate', 0)) == INIT_LOGOUT:\n                samlsession = self._data_to_samlsession(key, c[key])\n                return samlsession\n        raise ValueError()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def generate_jsrun_rankfile(settings, path=None):\n    \"\"\"\n    Generates rankfile to use with jsrun.\n    It splits the cores among the processes, which leads to best performance according to experiments.\n\n    Args:\n        settings: Settings for running jsrun.\n                  Note: settings.num_proc and settings.hosts must not be None.\n        path: Optional path of the rankfile.\n              Note: this file will be overwritten.\n    \"\"\"\n    cpu_per_gpu = (lsf.LSFUtils.get_num_cores() * lsf.LSFUtils.get_num_threads()) // lsf.LSFUtils.get_num_gpus()\n    host_list = (x.split(':') for x in settings.hosts.split(','))\n\n    # Verify and truncate host list if necessary\n    validated_list = []\n    remaining_slots = settings.num_proc\n    for host, slots in host_list:\n        slots = int(slots)\n        if slots > lsf.LSFUtils.get_num_gpus():\n            raise ValueError('Invalid host input, slot count for host \\'{host}:{slots}\\' is greater '\n                             'than number of GPUs per host \\'{gpus}\\'.'.format(\n                host=host, slots=slots, gpus=lsf.LSFUtils.get_num_gpus()))\n        needed_slots = min(slots, remaining_slots)\n        validated_list.append((host, needed_slots))\n        remaining_slots -= needed_slots\n        if remaining_slots == 0:\n            break\n    if remaining_slots != 0:\n        raise ValueError('Not enough slots on the hosts to fulfill the {slots} requested.'.format(\n            slots=settings.num_proc))\n\n    # Generate rankfile\n    path = tempfile.mktemp() if path is None else path\n    with open(path, 'w') as tmp:\n        tmp.write('overlapping_rs: allow\\n')\n        tmp.write('cpu_index_using: logical\\n')\n        rank = 0\n        for host, slots in validated_list:\n            cpu_val = 0\n            tmp.write('\\n')\n            for s in range(slots):\n                tmp.write('rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\\n'.format(\n                    rank=rank,\n                    host=host,\n                    scpu=cpu_val,\n                    ecpu=cpu_val + cpu_per_gpu - 1\n                ))\n                rank += 1\n                cpu_val += cpu_per_gpu\n    return path\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def lookup_internal_function(self, method_name, args_ir, ast_source):\n        # TODO is this the right module for me?\n        \"\"\"\n        Using a list of args, find the internal method to use, and\n        the kwargs which need to be filled in by the compiler\n        \"\"\"\n\n        sig = self.sigs[\"self\"].get(method_name, None)\n\n        def _check(cond, s=\"Unreachable\"):\n            if not cond:\n                raise CompilerPanic(s)\n\n        # these should have been caught during type checking; sanity check\n        _check(sig is not None)\n        _check(sig.internal)\n        _check(len(sig.base_args) <= len(args_ir) <= len(sig.args))\n        # more sanity check, that the types match\n        # _check(all(l.typ == r.typ for (l, r) in zip(args_ir, sig.args))\n\n        num_provided_kwargs = len(args_ir) - len(sig.base_args)\n        num_kwargs = len(sig.default_args)\n        kwargs_needed = num_kwargs - num_provided_kwargs\n\n        kw_vals = list(sig.default_values.values())[:kwargs_needed]\n\n        return sig, kw_vals\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs: \"HomeServer\"):\n        super().__init__(hs)\n\n        self.hs = hs\n\n        self.store = hs.get_datastore()\n        self.storage = hs.get_storage()\n        self.state_store = self.storage.state\n        self.federation_client = hs.get_federation_client()\n        self.state_handler = hs.get_state_handler()\n        self._state_resolution_handler = hs.get_state_resolution_handler()\n        self.server_name = hs.hostname\n        self.keyring = hs.get_keyring()\n        self.action_generator = hs.get_action_generator()\n        self.is_mine_id = hs.is_mine_id\n        self.spam_checker = hs.get_spam_checker()\n        self.event_creation_handler = hs.get_event_creation_handler()\n        self._message_handler = hs.get_message_handler()\n        self._server_notices_mxid = hs.config.server_notices_mxid\n        self.config = hs.config\n        self.http_client = hs.get_simple_http_client()\n        self._instance_name = hs.get_instance_name()\n        self._replication = hs.get_replication_data_handler()\n\n        self._send_events = ReplicationFederationSendEventsRestServlet.make_client(hs)\n        self._clean_room_for_join_client = ReplicationCleanRoomRestServlet.make_client(\n            hs\n        )\n\n        if hs.config.worker_app:\n            self._user_device_resync = ReplicationUserDevicesResyncRestServlet.make_client(\n                hs\n            )\n            self._maybe_store_room_on_outlier_membership = ReplicationStoreRoomOnOutlierMembershipRestServlet.make_client(\n                hs\n            )\n        else:\n            self._device_list_updater = hs.get_device_handler().device_list_updater\n            self._maybe_store_room_on_outlier_membership = (\n                self.store.maybe_store_room_on_outlier_membership\n            )\n\n        # When joining a room we need to queue any events for that room up.\n        # For each room, a list of (pdu, origin) tuples.\n        self.room_queues = {}  # type: Dict[str, List[Tuple[EventBase, str]]]\n        self._room_pdu_linearizer = Linearizer(\"fed_room_pdu\")\n\n        self.third_party_event_rules = hs.get_third_party_event_rules()\n\n        self._ephemeral_messages_enabled = hs.config.enable_ephemeral_messages\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    int64 id = ctx->session_state()->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def writeDataFile(self, filename, text, content_type, subdir=None):\n        \"\"\" See IExportContext.\n        \"\"\"\n        if subdir is not None:\n            filename = '/'.join((subdir, filename))\n\n        sep = filename.rfind('/')\n        if sep != -1:\n            subdir = filename[:sep]\n            filename = filename[sep+1:]\n\n        if six.PY2 and isinstance(text, six.text_type):\n            encoding = self.getEncoding() or 'utf-8'\n            text = text.encode(encoding)\n\n        folder = self._ensureSnapshotsFolder(subdir)\n\n        # MISSING: switch on content_type\n        ob = self._createObjectByType(filename, text, content_type)\n        folder._setObject(str(filename), ob)  # No Unicode IDs!\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def raise_standardErrorMessage(\n        self, client=None, REQUEST={},\n        error_type=None, error_value=None, tb=None,\n        error_tb=None, error_message='',\n        tagSearch=re.compile(r'[a-zA-Z]>').search,\n        error_log_url=''):\n\n        try:\n            if error_type  is None: error_type =sys.exc_info()[0]\n            if error_value is None: error_value=sys.exc_info()[1]\n\n            # allow for a few different traceback options\n            if tb is None and error_tb is None:\n                tb=sys.exc_info()[2]\n            if type(tb) is not str and (error_tb is None):\n                error_tb = pretty_tb(error_type, error_value, tb)\n            elif type(tb) is str and not error_tb:\n                error_tb = tb\n\n            if hasattr(self, '_v_eek'):\n                # Stop if there is recursion.\n                raise error_type, error_value, tb\n            self._v_eek = 1\n\n            if hasattr(error_type, '__name__'):\n                error_name = error_type.__name__\n            else:\n                error_name = 'Unknown'\n\n            if not error_message:\n                try:\n                    s = ustr(error_value)\n                except:\n                    s = error_value\n                try:\n                    match = tagSearch(s)\n                except TypeError:\n                    match = None\n                if match is not None:\n                    error_message=error_value\n\n            if client is None:\n                client = self\n\n            if not REQUEST:\n                REQUEST = aq_acquire(self, 'REQUEST')\n\n            try:\n                s = aq_acquire(client, 'standard_error_message')\n\n                # For backward compatibility, we pass 'error_name' as\n                # 'error_type' here as historically this has always\n                # been a string.\n                kwargs = {'error_type': error_name,\n                          'error_value': error_value,\n                          'error_tb': error_tb,\n                          'error_traceback': error_tb,\n                          'error_message': error_message,\n                          'error_log_url': error_log_url}\n\n                if getattr(aq_base(s), 'isDocTemp', 0):\n                    v = s(client, REQUEST, **kwargs)\n                elif callable(s):\n                    v = s(**kwargs)\n                else:\n                    v = HTML.__call__(s, client, REQUEST, **kwargs)\n            except:\n                logger.error(\n                    'Exception while rendering an error message',\n                    exc_info=True\n                    )\n                try:\n                    strv = repr(error_value) # quotes tainted strings\n                except:\n                    strv = ('<unprintable %s object>' % \n                            str(type(error_value).__name__))\n                v = strv + (\n                    (\" (Also, the following error occurred while attempting \"\n                     \"to render the standard error message, please see the \"\n                     \"event log for full details: %s)\")%(\n                    html_quote(sys.exc_info()[1]),\n                    ))\n\n            # If we've been asked to handle errors, just return the rendered\n            # exception and let the ZPublisher Exception Hook deal with it.\n            return error_type, v, tb\n        finally:\n            if hasattr(self, '_v_eek'): del self._v_eek\n            tb = None\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def aws_kms_master_key_provider(discovery=True, **kwargs):\n    # type: (bool, **List[Union[Text, str]]) -> Union[DiscoveryAwsKmsMasterKeyProvider, StrictAwsKmsMasterKeyProvider]\n    \"\"\"Apply post-processing to transform ``KMSMasterKeyProvider``-specific values from CLI\n    arguments to valid ``KMSMasterKeyProvider`` parameters, then call ``KMSMasterKeyprovider``\n    with those parameters.\n\n    :param bool discovery: Return a DiscoveryAwsKmsMasterKeyProvider\n    :param dict kwargs: Named parameters collected from CLI arguments as prepared\n        in aws_encryption_sdk_cli.internal.master_key_parsing._parse_master_key_providers_from_args\n    :rtype: aws_encryption_sdk.key_providers.kms.BaseKMSMasterKeyProvider\n    \"\"\"\n    kwargs = copy.deepcopy(kwargs)\n    try:\n        profile_names = kwargs.pop(\"profile\")\n        if len(profile_names) != 1:\n            raise BadUserArgumentError(\n                \"Only one profile may be specified per master key provider configuration. {} provided.\".format(\n                    len(profile_names)\n                )\n            )\n        profile_name = profile_names[0]  # type: Optional[Text]\n    except KeyError:\n        profile_name = None\n\n    botocore_session = botocore.session.Session(profile=profile_name)\n    botocore_session.user_agent_extra = USER_AGENT_SUFFIX\n    kwargs[\"botocore_session\"] = botocore_session\n\n    try:\n        region_name = kwargs.pop(\"region\")\n        if len(region_name) != 1:\n            raise BadUserArgumentError(\n                \"Only one region may be specified per master key provider configuration. {} provided.\".format(\n                    len(region_name)\n                )\n            )\n        kwargs[\"region_names\"] = region_name\n    except KeyError:\n        pass\n    if discovery:\n        return DiscoveryAwsKmsMasterKeyProvider(**kwargs)\n    return StrictAwsKmsMasterKeyProvider(**kwargs)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __new__(cls, obj, *args, **kwargs):\n        # In our usage we should only receive unicode strings.\n        # This conditional and conversion exists to sanity check the values\n        # we're given but we may want to take it out for testing and sanitize\n        # our input instead.\n        if isinstance(obj, string_types):\n            obj = to_text(obj, errors='surrogate_or_strict')\n            return AnsibleUnsafeText(obj)\n        return obj\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_db_or_user_exists(db_name, db_user, config):\n    with _create_pg_connection(config) as con:\n        with con.cursor() as cur:\n            cur.execute(\"SELECT 1 FROM pg_database WHERE datname='{}';\".format(db_name))\n            db_exists = cur.fetchone() is not None\n            cur.execute(\"SELECT 1 FROM pg_roles WHERE rolname='{}';\".format(db_user))\n            user = cur.fetchone()\n            user_exists = user is not None\n            return db_exists or user_exists\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send(\n        self,\n        request_params: SaaSRequestParams,\n        ignore_errors: Optional[Union[bool, List[int]]] = False,\n    ) -> Response:\n        \"\"\"\n        Builds and executes an authenticated request.\n        Optionally ignores:\n          - all non-2xx/3xx responses if ignore_errors is set to True\n          - no non-2xx/3xx repsones if ignore_errors is set to False\n          - specific non-2xx/3xx responses if ignore_errors is set to a list of status codes\n        \"\"\"\n        rate_limit_requests = self.build_rate_limit_requests()\n        RateLimiter().limit(rate_limit_requests)\n\n        prepared_request: PreparedRequest = self.get_authenticated_request(\n            request_params\n        )\n        response = self.session.send(prepared_request)\n\n        log_request_and_response_for_debugging(\n            prepared_request, response\n        )  # Dev mode only\n\n        if not response.ok:\n            if self._should_ignore_error(\n                status_code=response.status_code,\n                errors_to_ignore=ignore_errors,\n            ):\n                logger.info(\n                    \"Ignoring errors on response with status code {} as configured.\",\n                    response.status_code,\n                )\n                return response\n            raise RequestFailureResponseException(response=response)\n        return response\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def render_and_merge_yaml(root, template_name, context_name):\n    \"\"\"\n    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return\n    result as a dictionary.\n\n    :param root: Root directory of the YAML files\n    :param template_name: Name of the template file\n    :param context_name: Name of the context file\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    import jinja2\n\n    template_path = os.path.join(root, template_name)\n    context_path = os.path.join(root, context_name)\n\n    for path in (template_path, context_path):\n        if not pathlib.Path(path).is_file():\n            raise MissingConfigException(f\"Yaml file '{path}' does not exist.\")\n\n    j2_env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(root, encoding=ENCODING),\n        undefined=jinja2.StrictUndefined,\n        line_comment_prefix=\"#\",\n    )\n\n    def from_json(input_var):\n        with open(input_var, encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    j2_env.filters[\"from_json\"] = from_json\n    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters\n    # like from_json as needed to load context information from files, then load into a dict\n    context_source = j2_env.get_template(context_name).render({})\n    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}\n\n    # Substitute parameters from context dict into template\n    source = j2_env.get_template(template_name).render(context_dict)\n    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)\n    return merge_dicts(rendered_template_dict, context_dict)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    \"\"\"\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(posixpath.sep)\n        or posixpath.isabs(path)\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def _make_well_known_request(\n        self, server_name: bytes, retry: bool\n    ) -> Tuple[IResponse, bytes]:\n        \"\"\"Make the well known request.\n\n        This will retry the request if requested and it fails (with unable\n        to connect or receives a 5xx error).\n\n        Args:\n            server_name: name of the server, from the requested url\n            retry: Whether to retry the request if it fails.\n\n        Returns:\n            Returns the response object and body. Response may be a non-200 response.\n        \"\"\"\n        uri = b\"https://%s/.well-known/matrix/server\" % (server_name,)\n        uri_str = uri.decode(\"ascii\")\n\n        headers = {\n            b\"User-Agent\": [self.user_agent],\n        }\n\n        i = 0\n        while True:\n            i += 1\n\n            logger.info(\"Fetching %s\", uri_str)\n            try:\n                response = await make_deferred_yieldable(\n                    self._well_known_agent.request(\n                        b\"GET\", uri, headers=Headers(headers)\n                    )\n                )\n                body = await make_deferred_yieldable(readBody(response))\n\n                if 500 <= response.code < 600:\n                    raise Exception(\"Non-200 response %s\" % (response.code,))\n\n                return response, body\n            except defer.CancelledError:\n                # Bail if we've been cancelled\n                raise\n            except Exception as e:\n                if not retry or i >= WELL_KNOWN_RETRY_ATTEMPTS:\n                    logger.info(\"Error fetching %s: %s\", uri_str, e)\n                    raise _FetchWellKnownFailure(temporary=True)\n\n                logger.info(\"Error fetching %s: %s. Retrying\", uri_str, e)\n\n            # Sleep briefly in the hopes that they come back up\n            await self._clock.sleep(0.5)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_event(self, url, authtoken, state, result, runtime):\n        if result._task_fields['args'].get('_ansible_check_mode') is True:\n            self.ansible_check_mode = True\n\n        if result._task_fields['args'].get('_ansible_version'):\n            self.ansible_version = \\\n                result._task_fields['args'].get('_ansible_version')\n\n        if result._task._role:\n            ansible_role = str(result._task._role)\n        else:\n            ansible_role = None\n\n        data = {}\n        data['uuid'] = result._task._uuid\n        data['session'] = self.session\n        data['status'] = state\n        data['timestamp'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S '\n                                                       '+0000')\n        data['host'] = self.host\n        data['ip_address'] = self.ip_address\n        data['user'] = self.user\n        data['runtime'] = runtime\n        data['ansible_version'] = self.ansible_version\n        data['ansible_check_mode'] = self.ansible_check_mode\n        data['ansible_host'] = result._host.name\n        data['ansible_playbook'] = self.ansible_playbook\n        data['ansible_role'] = ansible_role\n        data['ansible_task'] = result._task_fields\n        data['ansible_result'] = result._result\n\n        # This wraps the json payload in and outer json event needed by Splunk\n        jsondata = json.dumps(data, cls=AnsibleJSONEncoder, sort_keys=True)\n        jsondata = '{\"event\":' + jsondata + \"}\"\n\n        open_url(\n            url,\n            jsondata,\n            headers={\n                'Content-type': 'application/json',\n                'Authorization': 'Splunk ' + authtoken\n            },\n            method='POST'\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __iter__(self):\n        vmatch = self.vmatch\n        vdict = self.vdict\n\n        with self.source.open('rb') as xmlf:\n\n            tree = etree.parse(xmlf)\n            if not hasattr(tree, 'iterfind'):\n                # Python 2.6 compatibility\n                tree.iterfind = tree.findall\n\n            if vmatch is not None:\n                # simple case, all value paths are the same\n                for rowelm in tree.iterfind(self.rmatch):\n                    if self.attr is None:\n                        getv = attrgetter('text')\n                    else:\n                        getv = lambda e: e.get(self.attr)\n                    if isinstance(vmatch, string_types):\n                        # match only one path\n                        velms = rowelm.findall(vmatch)\n                    else:\n                        # match multiple paths\n                        velms = itertools.chain(*[rowelm.findall(enm)\n                                                  for enm in vmatch])\n                    yield tuple(getv(velm)\n                                for velm in velms)\n\n            else:\n                # difficult case, deal with different paths for each field\n\n                # determine output header\n                flds = tuple(sorted(map(text_type, vdict.keys())))\n                yield flds\n\n                # setup value getters\n                vmatches = dict()\n                vgetters = dict()\n                for f in flds:\n                    vmatch = self.vdict[f]\n                    if isinstance(vmatch, string_types):\n                        # match element path\n                        vmatches[f] = vmatch\n                        vgetters[f] = element_text_getter(self.missing)\n                    else:\n                        # match element path and attribute name\n                        vmatches[f] = vmatch[0]\n                        attr = vmatch[1]\n                        vgetters[f] = attribute_text_getter(attr, self.missing)\n\n                # determine data rows\n                for rowelm in tree.iterfind(self.rmatch):\n                    yield tuple(vgetters[f](rowelm.findall(vmatches[f]))\n                                for f in flds)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def lu_unpack(x, y, unpack_ludata=True, unpack_pivots=True, name=None):\n    r\"\"\"\n    Unpack L U and P to single matrix tensor .\n    unpack L and U matrix from LU, unpack permutation matrix P from Pivtos .\n\n    P mat can be get by pivots:\n\n    .. code-block:: text\n\n        ones = eye(rows) #eye matrix of rank rows\n        for i in range(cols):\n            swap(ones[i], ones[pivots[i]])\n\n\n    Args:\n        x (Tensor): The LU tensor get from paddle.linalg.lu, which is combined by L and U.\n\n        y (Tensor): Pivots get from paddle.linalg.lu.\n\n        unpack_ludata (bool,optional): whether to unpack L and U from x. Default: True.\n\n        unpack_pivots (bool, optional): whether to unpack permutation matrix P from Pivtos. Default: True.\n\n        name (str, optional): Name for the operation (optional, default is None).\n            For more information, please refer to :ref:`api_guide_Name`.\n\n    Returns:\n        P (Tensor), Permutation matrix P of lu factorization.\n\n        L (Tensor), The lower triangular matrix tensor of lu factorization.\n\n        U (Tensor), The upper triangular matrix tensor of lu factorization.\n\n\n    Examples:\n        .. code-block:: python\n\n            import paddle\n\n            x = paddle.to_tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]).astype('float64')\n            lu,p,info = paddle.linalg.lu(x, get_infos=True)\n\n            # >>> lu:\n            # Tensor(shape=[3, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            #    [[5.        , 6.        ],\n            #        [0.20000000, 0.80000000],\n            #        [0.60000000, 0.50000000]])\n            # >>> p\n            # Tensor(shape=[2], dtype=int32, place=CUDAPlace(0), stop_gradient=True,\n            #    [3, 3])\n            # >>> info\n            # Tensor(shape=[], dtype=int32, place=CUDAPlace(0), stop_gradient=True,\n            #    0)\n\n            P,L,U = paddle.linalg.lu_unpack(lu,p)\n\n            # >>> P\n            # (Tensor(shape=[3, 3], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[0., 1., 0.],\n            # [0., 0., 1.],\n            # [1., 0., 0.]]),\n            # >>> L\n            # Tensor(shape=[3, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[1.        , 0.        ],\n            # [0.20000000, 1.        ],\n            # [0.60000000, 0.50000000]]),\n            # >>> U\n            # Tensor(shape=[2, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[5.        , 6.        ],\n            # [0.        , 0.80000000]]))\n\n            # one can verify : X = P @ L @ U ;\n    \"\"\"\n\n    if in_dynamic_mode():\n        P, L, U = _C_ops.lu_unpack(x, y, unpack_ludata, unpack_pivots)\n        return P, L, U\n    else:\n        check_variable_and_dtype(\n            x, 'dtype', ['float32', 'float64'], 'lu_unpack'\n        )\n        helper = LayerHelper('lu_unpack', **locals())\n        p = helper.create_variable_for_type_inference(dtype=x.dtype)\n        l = helper.create_variable_for_type_inference(dtype=x.dtype)\n        u = helper.create_variable_for_type_inference(dtype=x.dtype)\n\n        attrs = {}\n        attrs['unpack_ludata'] = unpack_ludata\n        attrs['unpack_pivots'] = unpack_pivots\n        helper.append_op(\n            type='lu_unpack',\n            inputs={'X': x, 'Pivots': y},\n            outputs={'Pmat': p, 'L': l, 'U': u},\n            attrs=attrs,\n        )\n        return p, l, u\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_obj_absolute_path(obj_path):\n    return os.path.join(DATAROOT, obj_path)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def put_column_description() -> Response:\n\n    @action_logging\n    def _log_put_column_description(*, table_key: str, column_name: str, description: str, source: str) -> None:\n        pass  # pragma: no cover\n\n    try:\n        args = request.get_json()\n\n        table_key = get_query_param(args, 'key')\n        table_endpoint = _get_table_endpoint()\n\n        column_name = get_query_param(args, 'column_name')\n        description = get_query_param(args, 'description')\n\n        src = get_query_param(args, 'source')\n\n        url = '{0}/{1}/column/{2}/description'.format(table_endpoint, table_key, column_name)\n        _log_put_column_description(table_key=table_key, column_name=column_name, description=description, source=src)\n\n        response = request_metadata(url=url, method='PUT', data=json.dumps({'description': description}))\n        status_code = response.status_code\n\n        if status_code == HTTPStatus.OK:\n            message = 'Success'\n        else:\n            message = 'Update column description failed'\n\n        payload = jsonify({'msg': message})\n        return make_response(payload, status_code)\n    except Exception as e:\n        payload = jsonify({'msg': 'Encountered exception: ' + str(e)})\n        return make_response(payload, HTTPStatus.INTERNAL_SERVER_ERROR)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    exc = MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def file(path):\n    path = secure_filename(path)\n    if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n        with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:\n            encrypted_data = encrypted_file.read()\n        file_data = encryptor.decrypt(\n            app.interface.encryption_key, encrypted_data)\n        return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n    else:\n        return send_file(os.path.join(app.cwd, path))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            static_path = os.path.join(self.E.mod, \"web/\", self.vpath[5:])\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # os.makedirs applies the global umask, so we reset it,\n                # for consistency with file_permissions_mode behavior.\n                old_umask = os.umask(0)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _add_widgets(self, package_name: str, hook_class: type, widgets: dict[str, Any]):\n        conn_type = hook_class.conn_type  # type: ignore\n        for field_identifier, field in widgets.items():\n            if field_identifier.startswith(\"extra__\"):\n                prefixed_field_name = field_identifier\n            else:\n                prefixed_field_name = f\"extra__{conn_type}__{field_identifier}\"\n            if prefixed_field_name in self._connection_form_widgets:\n                log.warning(\n                    \"The field %s from class %s has already been added by another provider. Ignoring it.\",\n                    field_identifier,\n                    hook_class.__name__,\n                )\n                # In case of inherited hooks this might be happening several times\n                continue\n            self._connection_form_widgets[prefixed_field_name] = ConnectionFormWidgetInfo(\n                hook_class.__name__, package_name, field, field_identifier\n            )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _getResourceForRequest(self, request):\n        \"\"\"(Internal) Get the appropriate resource for the given host.\n        \"\"\"\n        host = string.lower(request.getHeader('host'))\n        return self.hosts.get(host, error.NoResource())\n        "}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, fobj):\n        \"\"\"\n        fobj is a file-like object as an icns resource\n        \"\"\"\n        # signature : (start, length)\n        self.dct = dct = {}\n        self.fobj = fobj\n        sig, filesize = nextheader(fobj)\n        if sig != b'icns':\n            raise SyntaxError('not an icns file')\n        i = HEADERSIZE\n        while i < filesize:\n            sig, blocksize = nextheader(fobj)\n            i += HEADERSIZE\n            blocksize -= HEADERSIZE\n            dct[sig] = (i, blocksize)\n            fobj.seek(blocksize, 1)\n            i += blocksize\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static int expandrow2(UINT8* dest, const UINT8* src, int n, int z)\n{\n    UINT8 pixel, count;\n\n\n    for (;n > 0; n--)\n    {\n        pixel = src[1];\n        src+=2;\n        if (n == 1 && pixel != 0)\n            return n;\n        count = pixel & RLE_MAX_RUN;\n        if (!count)\n            return count;\n        if (pixel & RLE_COPY_FLAG) {\n            while(count--) {\n                memcpy(dest, src, 2);\n                src += 2;\n                dest += z * 2;\n            }\n        }\n        else {\n            while (count--) {\n                memcpy(dest, src, 2);\n                dest += z * 2;\n            }\n            src+=2;\n        }\n    }\n    return 0;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.shutting_down, self.load_started])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* reverse_index_map_t;\n    const Tensor* grad_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"reverse_index_map\", &reverse_index_map_t));\n    OP_REQUIRES_OK(context, context->input(\"grad_values\", &grad_values_t));\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(reverse_index_map_t->shape()),\n        errors::InvalidArgument(\"reverse_index_map must be a vector, saw: \",\n                                reverse_index_map_t->shape().DebugString()));\n\n    const auto reverse_index_map = reverse_index_map_t->vec<int64>();\n    const auto grad_values = grad_values_t->vec<T>();\n\n    const int64 N = reverse_index_map_t->shape().dim_size(0);\n    const int64 N_full = grad_values_t->shape().dim_size(0);\n\n    Tensor* d_values_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"d_values\", TensorShape({N}), &d_values_t));\n    auto d_values = d_values_t->vec<T>();\n    Tensor* d_default_value_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"d_default_value\", TensorShape({}),\n                                            &d_default_value_t));\n    T& d_default_value = d_default_value_t->scalar<T>()();\n    d_default_value = T();\n\n    Tensor visited_t;\n    OP_REQUIRES_OK(context, context->allocate_temp(\n                                DT_BOOL, TensorShape({N_full}), &visited_t));\n    auto visited = visited_t.vec<bool>();\n    visited.device(d) = visited.constant(false);\n\n    for (int i = 0; i < N; ++i) {\n      // Locate the index of the output of the forward prop associated\n      // with this location in the input of the forward prop.  Copy\n      // the gradient into it.  Mark it as visited.\n      d_values(i) = grad_values(reverse_index_map(i));\n      visited(reverse_index_map(i)) = true;\n    }\n    for (int j = 0; j < N_full; ++j) {\n      // The default value gradient gets the accumulated remainder of\n      // the backprop values (since the default value was used to fill\n      // in these slots in the forward calculation).\n      if (!visited(j)) {\n        d_default_value += grad_values(j);\n      }\n    }\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def diff_objects(old_instance, new_instance, fields):\n    \"\"\"\n    Diff two objects by examining the given fields and\n    return a string.\n    \"\"\"\n    full_diff = []\n\n    for field in fields:\n        field_diff = []\n        old_value = getattr(old_instance, field.attname)\n        new_value = getattr(new_instance, field.attname)\n        for line in difflib.unified_diff(\n            str(old_value).split(\"\\n\"),\n            str(new_value).split(\"\\n\"),\n            fromfile=field.attname,\n            tofile=field.attname,\n            lineterm=\"\",\n        ):\n            field_diff.append(line)\n        full_diff.extend(field_diff)\n\n    return \"\\n\".join(full_diff)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment, REDUCTION_COLLECTIVE,\n                             resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV3 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static RList *create_cache_bins(RBinFile *bf, RDyldCache *cache) {\n\tRList *bins = r_list_newf ((RListFree)free_bin);\n\tif (!bins) {\n\t\treturn NULL;\n\t}\n\n\tchar *target_libs = NULL;\n\tRList *target_lib_names = NULL;\n\tint *deps = NULL;\n\ttarget_libs = r_sys_getenv (\"R_DYLDCACHE_FILTER\");\n\tif (target_libs) {\n\t\ttarget_lib_names = r_str_split_list (target_libs, \":\", 0);\n\t\tif (!target_lib_names) {\n\t\t\tr_list_free (bins);\n\t\t\treturn NULL;\n\t\t}\n\t\tdeps = R_NEWS0 (int, cache->hdr->imagesCount);\n\t\tif (!deps) {\n\t\t\tr_list_free (bins);\n\t\t\tr_list_free (target_lib_names);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tut32 i;\n\tfor (i = 0; i < cache->n_hdr; i++) {\n\t\tcache_hdr_t *hdr = &cache->hdr[i];\n\t\tut64 hdr_offset = cache->hdr_offset[i];\n\t\tut32 maps_index = cache->maps_index[i];\n\t\tcache_img_t *img = read_cache_images (cache->buf, hdr, hdr_offset);\n\t\tif (!img) {\n\t\t\tgoto next;\n\t\t}\n\n\t\tut32 j;\n\t\tut16 *depArray = NULL;\n\t\tcache_imgxtr_t *extras = NULL;\n\t\tif (target_libs) {\n\t\t\tHtPU *path_to_idx = NULL;\n\t\t\tif (cache->accel) {\n\t\t\t\tdepArray = R_NEWS0 (ut16, cache->accel->depListCount);\n\t\t\t\tif (!depArray) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\n\t\t\t\tif (r_buf_fread_at (cache->buf, cache->accel->depListOffset, (ut8*) depArray, \"s\", cache->accel->depListCount) != cache->accel->depListCount * 2) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\n\t\t\t\textras = read_cache_imgextra (cache->buf, hdr, cache->accel);\n\t\t\t\tif (!extras) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tpath_to_idx = create_path_to_index (cache->buf, img, hdr);\n\t\t\t}\n\n\t\t\tfor (j = 0; j < hdr->imagesCount; j++) {\n\t\t\t\tbool printing = !deps[j];\n\t\t\t\tchar *lib_name = get_lib_name (cache->buf, &img[j]);\n\t\t\t\tif (!lib_name) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (strstr (lib_name, \"libobjc.A.dylib\")) {\n\t\t\t\t\tdeps[j]++;\n\t\t\t\t}\n\t\t\t\tif (!r_list_find (target_lib_names, lib_name, string_contains)) {\n\t\t\t\t\tR_FREE (lib_name);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (printing) {\n\t\t\t\t\teprintf (\"FILTER: %s\\n\", lib_name);\n\t\t\t\t}\n\t\t\t\tR_FREE (lib_name);\n\t\t\t\tdeps[j]++;\n\n\t\t\t\tif (extras && depArray) {\n\t\t\t\t\tut32 k;\n\t\t\t\t\tfor (k = extras[j].dependentsStartArrayIndex; depArray[k] != 0xffff; k++) {\n\t\t\t\t\t\tut16 dep_index = depArray[k] & 0x7fff;\n\t\t\t\t\t\tdeps[dep_index]++;\n\n\t\t\t\t\t\tchar *dep_name = get_lib_name (cache->buf, &img[dep_index]);\n\t\t\t\t\t\tif (!dep_name) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (printing) {\n\t\t\t\t\t\t\teprintf (\"-> %s\\n\", dep_name);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (dep_name);\n\t\t\t\t\t}\n\t\t\t\t} else if (path_to_idx) {\n\t\t\t\t\tcarve_deps_at_address (cache, img, path_to_idx, img[j].address, deps, printing);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tht_pu_free (path_to_idx);\n\t\t\tR_FREE (depArray);\n\t\t\tR_FREE (extras);\n\t\t}\n\n\t\tfor (j = 0; j < hdr->imagesCount; j++) {\n\t\t\tif (deps && !deps[j]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tut64 pa = va2pa (img[j].address, hdr->mappingCount, &cache->maps[maps_index], cache->buf, 0, NULL, NULL);\n\t\t\tif (pa == UT64_MAX) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tut8 magicbytes[4];\n\t\t\tr_buf_read_at (cache->buf, pa, magicbytes, 4);\n\t\t\tint magic = r_read_le32 (magicbytes);\n\t\t\tswitch (magic) {\n\t\t\tcase MH_MAGIC_64:\n\t\t\t{\n\t\t\t\tchar file[256];\n\t\t\t\tRDyldBinImage *bin = R_NEW0 (RDyldBinImage);\n\t\t\t\tif (!bin) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tbin->header_at = pa;\n\t\t\t\tbin->hdr_offset = hdr_offset;\n\t\t\t\tbin->symbols_off = resolve_symbols_off (cache, pa);\n\t\t\t\tbin->va = img[j].address;\n\t\t\t\tif (r_buf_read_at (cache->buf, img[j].pathFileOffset, (ut8*) &file, sizeof (file)) == sizeof (file)) {\n\t\t\t\t\tfile[255] = 0;\n\t\t\t\t\tchar *last_slash = strrchr (file, '/');\n\t\t\t\t\tif (last_slash && *last_slash) {\n\t\t\t\t\t\tif (last_slash > file) {\n\t\t\t\t\t\t\tchar *scan = last_slash - 1;\n\t\t\t\t\t\t\twhile (scan > file && *scan != '/') {\n\t\t\t\t\t\t\t\tscan--;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (*scan == '/') {\n\t\t\t\t\t\t\t\tbin->file = strdup (scan + 1);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tbin->file = strdup (last_slash + 1);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tbin->file = strdup (last_slash + 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbin->file = strdup (file);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tr_list_append (bins, bin);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdefault:\n\t\t\t\teprintf (\"Unknown sub-bin\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\tR_FREE (depArray);\n\t\tR_FREE (extras);\n\t\tR_FREE (img);\n\t}\n\tif (r_list_empty (bins)) {\n\t\tr_list_free (bins);\n\t\tbins = NULL;\n\t}\n\tR_FREE (deps);\n\tR_FREE (target_libs);\n\tr_list_free (target_lib_names);\n\treturn bins;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sensitive_config_values(self) -> Set[tuple[str, str]]:  # noqa: UP006\n        if self.configuration_description is None:\n            return (\n                _get_empty_set_for_configuration()\n            )  # we can't use set() here because set is defined below # \u00af\\_(\u30c4)_/\u00af\n        flattened = {\n            (s, k): item\n            for s, s_c in self.configuration_description.items()\n            for k, item in s_c.get(\"options\").items()  # type: ignore[union-attr]\n        }\n        sensitive = {(section, key) for (section, key), v in flattened.items() if v.get(\"sensitive\") is True}\n        depr_option = {self.deprecated_options[x][:-1] for x in sensitive if x in self.deprecated_options}\n        depr_section = {\n            (self.deprecated_sections[s][0], k) for s, k in sensitive if s in self.deprecated_sections\n        }\n        sensitive.update(depr_section, depr_option)\n        return sensitive\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sanitize_file_name(self, file_name):\n        file_name = html.unescape(file_name)\n        # Cleanup Windows-style path separators.\n        file_name = file_name[file_name.rfind('\\\\') + 1:].strip()\n        return os.path.basename(file_name)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = os.path.join(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def is_select(self) -> bool:\n        # make sure we strip comments; prevents a bug with coments in the CTE\n        parsed = sqlparse.parse(self.strip_comments())\n        if parsed[0].get_type() == \"SELECT\":\n            return True\n\n        if parsed[0].get_type() != \"UNKNOWN\":\n            return False\n\n        # for `UNKNOWN`, check all DDL/DML explicitly: only `SELECT` DML is allowed,\n        # and no DDL is allowed\n        if any(token.ttype == DDL for token in parsed[0]) or any(\n            token.ttype == DML and token.value != \"SELECT\" for token in parsed[0]\n        ):\n            return False\n\n        # return false on `EXPLAIN`, `SET`, `SHOW`, etc.\n        if parsed[0][0].ttype == Keyword:\n            return False\n\n        return any(\n            token.ttype == DML and token.value == \"SELECT\" for token in parsed[0]\n        )\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    Tensor val;\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\n    ctx->set_output(0, val);\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "async def _can_passwordless_sudo() -> bool:\n    process = await asyncio.create_subprocess_shell(\n        \"sudo -n true\",\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        shell=True,\n    )\n    _, _ = await process.communicate()\n    return process.returncode == 0\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def copy_with(self, **kwargs: typing.Any) -> \"URL\":\n        \"\"\"\n        Copy this URL, returning a new URL with some components altered.\n        Accepts the same set of parameters as the components that are made\n        available via properties on the `URL` class.\n\n        For example:\n\n        url = httpx.URL(\"https://www.example.com\").copy_with(username=\"jo@gmail.com\", password=\"a secret\")\n        assert url == \"https://jo%40email.com:a%20secret@www.example.com\"\n        \"\"\"\n        allowed = {\n            \"scheme\": str,\n            \"username\": str,\n            \"password\": str,\n            \"userinfo\": bytes,\n            \"host\": str,\n            \"port\": int,\n            \"netloc\": bytes,\n            \"path\": str,\n            \"query\": bytes,\n            \"raw_path\": bytes,\n            \"fragment\": str,\n            \"params\": object,\n        }\n\n        # Step 1\n        # ======\n        #\n        # Perform type checking for all supported keyword arguments.\n        for key, value in kwargs.items():\n            if key not in allowed:\n                message = f\"{key!r} is an invalid keyword argument for copy_with()\"\n                raise TypeError(message)\n            if value is not None and not isinstance(value, allowed[key]):\n                expected = allowed[key].__name__\n                seen = type(value).__name__\n                message = f\"Argument {key!r} must be {expected} but got {seen}\"\n                raise TypeError(message)\n\n        # Step 2\n        # ======\n        #\n        # Consolidate \"username\", \"password\", \"userinfo\", \"host\", \"port\" and \"netloc\"\n        # into a single \"authority\" keyword, for `rfc3986`.\n        if \"username\" in kwargs or \"password\" in kwargs:\n            # Consolidate \"username\" and \"password\" into \"userinfo\".\n            username = quote(kwargs.pop(\"username\", self.username) or \"\")\n            password = quote(kwargs.pop(\"password\", self.password) or \"\")\n            userinfo = f\"{username}:{password}\" if password else username\n            kwargs[\"userinfo\"] = userinfo.encode(\"ascii\")\n\n        if \"host\" in kwargs or \"port\" in kwargs:\n            # Consolidate \"host\" and \"port\" into \"netloc\".\n            host = kwargs.pop(\"host\", self.host) or \"\"\n            port = kwargs.pop(\"port\", self.port)\n\n            if host and \":\" in host and host[0] != \"[\":\n                # IPv6 addresses need to be escaped within square brackets.\n                host = f\"[{host}]\"\n\n            kwargs[\"netloc\"] = (\n                f\"{host}:{port}\".encode(\"ascii\")\n                if port is not None\n                else host.encode(\"ascii\")\n            )\n\n        if \"userinfo\" in kwargs or \"netloc\" in kwargs:\n            # Consolidate \"userinfo\" and \"netloc\" into authority.\n            userinfo = (kwargs.pop(\"userinfo\", self.userinfo) or b\"\").decode(\"ascii\")\n            netloc = (kwargs.pop(\"netloc\", self.netloc) or b\"\").decode(\"ascii\")\n            authority = f\"{userinfo}@{netloc}\" if userinfo else netloc\n            kwargs[\"authority\"] = authority\n\n        # Step 3\n        # ======\n        #\n        # Wrangle any \"path\", \"query\", \"raw_path\" and \"params\" keywords into\n        # \"query\" and \"path\" keywords for `rfc3986`.\n        if \"raw_path\" in kwargs:\n            # If \"raw_path\" is included, then split it into \"path\" and \"query\" components.\n            raw_path = kwargs.pop(\"raw_path\") or b\"\"\n            path, has_query, query = raw_path.decode(\"ascii\").partition(\"?\")\n            kwargs[\"path\"] = path\n            kwargs[\"query\"] = query if has_query else None\n\n        else:\n            if kwargs.get(\"path\") is not None:\n                # Ensure `kwargs[\"path\"] = <url quoted str>` for `rfc3986`.\n                kwargs[\"path\"] = quote(kwargs[\"path\"])\n\n            if kwargs.get(\"query\") is not None:\n                # Ensure `kwargs[\"query\"] = <str>` for `rfc3986`.\n                #\n                # Note that `.copy_with(query=None)` and `.copy_with(query=b\"\")`\n                # are subtly different. The `None` style will not include an empty\n                # trailing \"?\" character.\n                kwargs[\"query\"] = kwargs[\"query\"].decode(\"ascii\")\n\n            if \"params\" in kwargs:\n                # Replace any \"params\" keyword with the raw \"query\" instead.\n                #\n                # Ensure that empty params use `kwargs[\"query\"] = None` rather\n                # than `kwargs[\"query\"] = \"\"`, so that generated URLs do not\n                # include an empty trailing \"?\".\n                params = kwargs.pop(\"params\")\n                kwargs[\"query\"] = None if not params else str(QueryParams(params))\n\n        # Step 4\n        # ======\n        #\n        # Ensure any fragment component is quoted.\n        if kwargs.get(\"fragment\") is not None:\n            kwargs[\"fragment\"] = quote(kwargs[\"fragment\"])\n\n        # Step 5\n        # ======\n        #\n        # At this point kwargs may include keys for \"scheme\", \"authority\", \"path\",\n        # \"query\" and \"fragment\". Together these constitute the entire URL.\n        #\n        # See https://tools.ietf.org/html/rfc3986#section-3\n        #\n        #  foo://example.com:8042/over/there?name=ferret#nose\n        #  \\_/   \\______________/\\_________/ \\_________/ \\__/\n        #   |           |            |            |        |\n        # scheme     authority       path        query   fragment\n        return URL(self._uri_reference.copy_with(**kwargs).unsplit())\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs, pusherdict):\n        self.hs = hs\n        self.store = self.hs.get_datastore()\n        self.storage = self.hs.get_storage()\n        self.clock = self.hs.get_clock()\n        self.state_handler = self.hs.get_state_handler()\n        self.user_id = pusherdict[\"user_name\"]\n        self.app_id = pusherdict[\"app_id\"]\n        self.app_display_name = pusherdict[\"app_display_name\"]\n        self.device_display_name = pusherdict[\"device_display_name\"]\n        self.pushkey = pusherdict[\"pushkey\"]\n        self.pushkey_ts = pusherdict[\"ts\"]\n        self.data = pusherdict[\"data\"]\n        self.last_stream_ordering = pusherdict[\"last_stream_ordering\"]\n        self.backoff_delay = HttpPusher.INITIAL_BACKOFF_SEC\n        self.failing_since = pusherdict[\"failing_since\"]\n        self.timed_call = None\n        self._is_processing = False\n        self._group_unread_count_by_room = hs.config.push_group_unread_count_by_room\n\n        # This is the highest stream ordering we know it's safe to process.\n        # When new events arrive, we'll be given a window of new events: we\n        # should honour this rather than just looking for anything higher\n        # because of potential out-of-order event serialisation. This starts\n        # off as None though as we don't know any better.\n        self.max_stream_ordering = None\n\n        if \"data\" not in pusherdict:\n            raise PusherConfigException(\"No 'data' key for HTTP pusher\")\n        self.data = pusherdict[\"data\"]\n\n        self.name = \"%s/%s/%s\" % (\n            pusherdict[\"user_name\"],\n            pusherdict[\"app_id\"],\n            pusherdict[\"pushkey\"],\n        )\n\n        if self.data is None:\n            raise PusherConfigException(\"data can not be null for HTTP pusher\")\n\n        if \"url\" not in self.data:\n            raise PusherConfigException(\"'url' required in data for HTTP pusher\")\n        self.url = self.data[\"url\"]\n        self.http_client = hs.get_proxied_http_client()\n        self.data_minus_url = {}\n        self.data_minus_url.update(self.data)\n        del self.data_minus_url[\"url\"]\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def log_request(handler):\n    \"\"\"log a bit more information about each request than tornado's default\n\n    - move static file get success to debug-level (reduces noise)\n    - get proxied IP instead of proxy IP\n    - log referer for redirect and failed requests\n    - log user-agent for failed requests\n    \"\"\"\n    status = handler.get_status()\n    request = handler.request\n    try:\n        logger = handler.log\n    except AttributeError:\n        logger = access_log\n\n    if status < 300 or status == 304:\n        # Successes (or 304 FOUND) are debug-level\n        log_method = logger.debug\n    elif status < 400:\n        log_method = logger.info\n    elif status < 500:\n        log_method = logger.warning\n    else:\n        log_method = logger.error\n\n    request_time = 1000.0 * handler.request.request_time()\n    ns = dict(\n        status=status,\n        method=request.method,\n        ip=request.remote_ip,\n        uri=request.uri,\n        request_time=request_time,\n    )\n    msg = \"{status} {method} {uri} ({ip}) {request_time:.2f}ms\"\n    if status >= 400:\n        # log bad referers\n        ns[\"referer\"] = request.headers.get(\"Referer\", \"None\")\n        msg = msg + \" referer={referer}\"\n    if status >= 500 and status != 502:\n        # log all headers if it caused an error\n        log_method(json.dumps(dict(request.headers), indent=2))\n    log_method(msg.format(**ns))\n    prometheus_log_method(handler)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def redirect(redirect_path, redirect_params=None, **kw):\n    \"\"\"Redirect (via cherrypy.HTTPRedirect).\n\n    Raises the exception instead of returning it, this to allow\n    users to both call it as a function or to raise it as an exception.\n\n    \"\"\"\n    if not isinstance(redirect_path, basestring):\n        redirect_path = '/'.join(list(redirect_path))\n    if not redirect_path.startswith('/'):\n        path = request.path_info\n        check_app_root()\n        if path.startswith(request.app_root):\n            path = path[len(request.app_root):]\n        redirect_path = urlparse.urljoin(path, redirect_path)\n    raise cherrypy.HTTPRedirect(url(tgpath=redirect_path,\n        tgparams=redirect_params, **kw))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices = ctx->input(0);\n    const auto values = ctx->input(1).flat<Tidx>();\n    const Tensor& dense_shape = ctx->input(2);\n    const Tensor& size_t = ctx->input(3);\n    const auto weights = ctx->input(4).flat<T>();\n    const int64_t weights_size = weights.size();\n\n    Tidx size = size_t.scalar<Tidx>()();\n    OP_REQUIRES(\n        ctx, size >= 0,\n        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n\n    bool is_1d = dense_shape.NumElements() == 1;\n\n    Tensor* out_t;\n    functor::SetZeroFunctor<Device, T> fill;\n    if (is_1d) {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({size}), &out_t));\n      auto out = out_t->flat<T>();\n      fill(ctx->eigen_device<Device>(), out);\n      if (binary_output_) {\n        OP_REQUIRES_OK(ctx,\n                       functor::BincountFunctor<Device, Tidx, T, true>::Compute(\n                           ctx, values, weights, out, size));\n      } else {\n        OP_REQUIRES_OK(\n            ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(\n                     ctx, values, weights, out, size));\n      }\n    } else {\n      const auto shape = dense_shape.flat<int64_t>();\n      const int64_t num_rows = shape(0);\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n      const auto out = out_t->matrix<T>();\n      fill(ctx->eigen_device<Device>(), out_t->flat<T>());\n      const auto indices_mat = indices.matrix<int64_t>();\n      for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n        const int64_t batch = indices_mat(i, 0);\n        const Tidx bin = values(i);\n        if (bin < size) {\n          if (binary_output_) {\n            out(batch, bin) = T(1);\n          } else {\n            if (weights_size) {\n              out(batch, bin) += weights(i);\n            } else {\n              out(batch, bin) += T(1);\n            }\n          }\n        }\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _extract_tar_file(tar, filename, b_dest, b_temp_path, expected_hash=None):\n    n_filename = to_native(filename, errors='surrogate_or_strict')\n    try:\n        member = tar.getmember(n_filename)\n    except KeyError:\n        raise AnsibleError(\"Collection tar at '%s' does not contain the expected file '%s'.\" % (to_native(tar.name),\n                                                                                                n_filename))\n\n    with tempfile.NamedTemporaryFile(dir=b_temp_path, delete=False) as tmpfile_obj:\n        bufsize = 65536\n        sha256_digest = sha256()\n        with _tarfile_extract(tar, member) as tar_obj:\n            data = tar_obj.read(bufsize)\n            while data:\n                tmpfile_obj.write(data)\n                tmpfile_obj.flush()\n                sha256_digest.update(data)\n                data = tar_obj.read(bufsize)\n\n        actual_hash = sha256_digest.hexdigest()\n\n        if expected_hash and actual_hash != expected_hash:\n            raise AnsibleError(\"Checksum mismatch for '%s' inside collection at '%s'\"\n                               % (n_filename, to_native(tar.name)))\n\n        b_dest_filepath = os.path.join(b_dest, to_bytes(filename, errors='surrogate_or_strict'))\n        b_parent_dir = os.path.split(b_dest_filepath)[0]\n        if not os.path.exists(b_parent_dir):\n            # Seems like Galaxy does not validate if all file entries have a corresponding dir ftype entry. This check\n            # makes sure we create the parent directory even if it wasn't set in the metadata.\n            os.makedirs(b_parent_dir, mode=0o0755)\n\n        shutil.move(to_bytes(tmpfile_obj.name, errors='surrogate_or_strict'), b_dest_filepath)\n\n        # Default to rw-r--r-- and only add execute if the tar file has execute.\n        new_mode = 0o644\n        if stat.S_IMODE(member.mode) & stat.S_IXUSR:\n            new_mode |= 0o0111\n\n        os.chmod(b_dest_filepath, new_mode)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def logout(self, message, relaystate=None, samlresponse=None):\n        \"\"\"\n        Handle HTTP logout. The supported logout methods are stored\n        in each session. First all the SOAP sessions are logged out\n        then the HTTP Redirect method is used for any remaining\n        sessions.\n\n        The basic process is this:\n         1. A logout request is received. It is processed and the response\n            cached.\n         2. If any other SP's have also logged in as this user then the\n            first such session is popped off and a logout request is\n            generated and forwarded to the SP.\n         3. If a logout response is received then the user is marked\n            as logged out from that SP.\n         Repeat steps 2-3 until only the initial logout request is\n         left unhandled, at which time the pre-generated response is sent\n         back to the SP that originated the logout request.\n\n        The final logout response is always a redirect.\n        \"\"\"\n        logout = self.cfg.idp.get_logout_handler()\n\n        us = UserSession()\n\n        saml_sessions = self.cfg.idp.sessionfactory\n\n        logout_type = None\n        try:\n            if lasso.SAML2_FIELD_REQUEST in message:\n                logout_type = \"request\"\n                self._handle_logout_request(us, logout, saml_sessions,\n                                            message)\n            elif samlresponse:\n                logout_type = \"response\"\n                self._handle_logout_response(us, logout, saml_sessions,\n                                             message, samlresponse)\n            else:\n                raise cherrypy.HTTPError(400, 'Bad Request. Not a ' +\n                                         'logout request or response.')\n        except InvalidRequest as e:\n            raise cherrypy.HTTPError(400, 'Bad Request. %s' % e)\n        except UnknownProvider as e:\n            raise cherrypy.HTTPError(\n                400, 'Invalid logout %s: %s' % (logout_type, e)\n            )\n\n        # Fall through to handle any remaining sessions.\n\n        # Find the next SP to logout and send a LogoutRequest\n        logout_order = [\n            lasso.SAML2_METADATA_BINDING_SOAP,\n            lasso.SAML2_METADATA_BINDING_REDIRECT,\n        ]\n        (logout_mech, session) = saml_sessions.get_next_logout(\n            logout_mechs=logout_order)\n        while session:\n            self.debug('Going to log out %s' % session.provider_id)\n\n            try:\n                logout.setSessionFromDump(session.login_session)\n            except lasso.ProfileBadSessionDumpError as e:\n                self.error('Failed to load session: %s' % e)\n                raise cherrypy.HTTPRedirect(400, 'Failed to log out user: %s '\n                                            % e)\n            try:\n                if logout_mech == lasso.SAML2_METADATA_BINDING_REDIRECT:\n                    logout.initRequest(session.provider_id,\n                                       lasso.HTTP_METHOD_REDIRECT)\n                else:\n                    logout.initRequest(session.provider_id,\n                                       lasso.HTTP_METHOD_SOAP)\n            except lasso.ServerProviderNotFoundError:\n                self.error(\n                    'Service Provider %s not found. Trying next session' %\n                    session.provider_id\n                )\n                saml_sessions.remove_session(session)\n                (logout_mech, session) = saml_sessions.get_next_logout(\n                    logout_mechs=logout_order)\n                continue\n\n            try:\n                logout.buildRequestMsg()\n            except lasso.Error, e:\n                self.error('failure to build logout request msg: %s' % e)\n                raise cherrypy.HTTPRedirect(400, 'Failed to log out user: %s '\n                                            % e)\n\n            # Set the full list of session indexes for this provider to\n            # log out\n            self.debug('logging out provider id %s' % session.provider_id)\n            indexes = saml_sessions.get_session_id_by_provider_id(\n                session.provider_id\n            )\n            self.debug('Requesting logout for sessions %s' % (indexes,))\n            req = logout.get_request()\n            req.setSessionIndexes(indexes)\n\n            session.set_logoutstate(relaystate=logout.msgUrl,\n                                    request_id=logout.request.id)\n            saml_sessions.start_logout(session, initial=False)\n\n            self.debug('Request logout ID %s for session ID %s' %\n                       (logout.request.id, session.session_id))\n\n            if logout_mech == lasso.SAML2_METADATA_BINDING_REDIRECT:\n                self.debug('Redirecting to another SP to logout on %s at %s' %\n                           (logout.remoteProviderId, logout.msgUrl))\n                raise cherrypy.HTTPRedirect(logout.msgUrl)\n            else:\n                self.debug('SOAP request to another SP to logout on %s at %s' %\n                           (logout.remoteProviderId, logout.msgUrl))\n                if logout.msgBody:\n                    message = self._soap_logout(logout)\n                    try:\n                        self._handle_logout_response(us,\n                                                     logout,\n                                                     saml_sessions,\n                                                     message,\n                                                     samlresponse)\n                    except Exception as e:  # pylint: disable=broad-except\n                        self.error('SOAP SLO failed %s' % e)\n                else:\n                    self.error('Provider does not support SOAP')\n\n            (logout_mech, session) = saml_sessions.get_next_logout(\n                logout_mechs=logout_order)\n\n        # done while\n\n        # All sessions should be logged out now. Respond to the\n        # original request using the response we cached earlier.\n\n        try:\n            session = saml_sessions.get_initial_logout()\n        except ValueError:\n            self.debug('SLO get_last_session() unable to find last session')\n            raise cherrypy.HTTPError(400, 'Unable to determine logout state')\n\n        redirect = session.relaystate\n        if not redirect:\n            redirect = self.basepath\n\n        saml_sessions.remove_session(session)\n\n        # Log out of cherrypy session\n        user = us.get_user()\n        self._audit('Logged out user: %s [%s] from %s' %\n                    (user.name, user.fullname,\n                     session.provider_id))\n        us.logout(user)\n\n        self.debug('SLO redirect to %s' % redirect)\n\n        raise cherrypy.HTTPRedirect(redirect)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\n\")\n    for line in lines:\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % tostr(line))\n            r[-1] += line\n        else:\n            r.append(line)\n    return r\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::CreateSparseFeatureRepresentation(\n    const DeviceBase::CpuWorkerThreads& worker_threads, const int num_examples,\n    const int num_sparse_features, const ModelWeights& weights,\n    const OpInputList& sparse_example_indices_inputs,\n    const OpInputList& sparse_feature_indices_inputs,\n    const OpInputList& sparse_feature_values_inputs,\n    std::vector<Example>* const examples) {\n  mutex mu;\n  Status result;  // Guarded by mu\n  auto parse_partition = [&](const int64 begin, const int64 end) {\n    // The static_cast here is safe since begin and end can be at most\n    // num_examples which is an int.\n    for (int i = static_cast<int>(begin); i < end; ++i) {\n      auto example_indices =\n          sparse_example_indices_inputs[i].template flat<int64>();\n      auto feature_indices =\n          sparse_feature_indices_inputs[i].template flat<int64>();\n\n      // Parse features for each example. Features for a particular example\n      // are at the offsets (start_id, end_id]\n      int start_id = -1;\n      int end_id = 0;\n      for (int example_id = 0; example_id < num_examples; ++example_id) {\n        start_id = end_id;\n        while (end_id < example_indices.size() &&\n               example_indices(end_id) == example_id) {\n          ++end_id;\n        }\n        Example::SparseFeatures* const sparse_features =\n            &(*examples)[example_id].sparse_features_[i];\n        if (start_id < example_indices.size() &&\n            example_indices(start_id) == example_id) {\n          sparse_features->indices.reset(new UnalignedInt64Vector(\n              &(feature_indices(start_id)), end_id - start_id));\n          if (sparse_feature_values_inputs.size() > i) {\n            auto feature_weights =\n                sparse_feature_values_inputs[i].flat<float>();\n            sparse_features->values.reset(new UnalignedFloatVector(\n                &(feature_weights(start_id)), end_id - start_id));\n          }\n          // If features are non empty.\n          if (end_id - start_id > 0) {\n            // TODO(sibyl-Aix6ihai): Write this efficiently using vectorized\n            // operations from eigen.\n            for (int64 k = 0; k < sparse_features->indices->size(); ++k) {\n              const int64 feature_index = (*sparse_features->indices)(k);\n              if (!weights.SparseIndexValid(i, feature_index)) {\n                mutex_lock l(mu);\n                result = errors::InvalidArgument(\n                    \"Found sparse feature indices out of valid range: \",\n                    (*sparse_features->indices)(k));\n                return;\n              }\n            }\n          }\n        } else {\n          // Add a Tensor that has size 0.\n          sparse_features->indices.reset(\n              new UnalignedInt64Vector(&(feature_indices(0)), 0));\n          // If values exist for this feature group.\n          if (sparse_feature_values_inputs.size() > i) {\n            auto feature_weights =\n                sparse_feature_values_inputs[i].flat<float>();\n            sparse_features->values.reset(\n                new UnalignedFloatVector(&(feature_weights(0)), 0));\n          }\n        }\n      }\n    }\n  };\n  // For each column, the cost of parsing it is O(num_examples). We use\n  // num_examples here, as empirically Shard() creates the right amount of\n  // threads based on the problem size.\n  // TODO(sibyl-Aix6ihai): Tune this as a function of dataset size.\n  const int64 kCostPerUnit = num_examples;\n  Shard(worker_threads.num_threads, worker_threads.workers, num_sparse_features,\n        kCostPerUnit, parse_partition);\n  return result;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  Status ValidateInputsGenerateOutputs(\n      OpKernelContext* ctx, const Tensor** inputs, const Tensor** seq_len,\n      Tensor** log_prob, OpOutputList* decoded_indices,\n      OpOutputList* decoded_values, OpOutputList* decoded_shape) const {\n    Status status = ctx->input(\"inputs\", inputs);\n    if (!status.ok()) return status;\n    status = ctx->input(\"sequence_length\", seq_len);\n    if (!status.ok()) return status;\n\n    const TensorShape& inputs_shape = (*inputs)->shape();\n\n    if (inputs_shape.dims() != 3) {\n      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n    }\n\n    const int64 max_time = inputs_shape.dim_size(0);\n    const int64 batch_size = inputs_shape.dim_size(1);\n\n    if (max_time == 0) {\n      return errors::InvalidArgument(\"max_time is 0\");\n    }\n    if (!TensorShapeUtils::IsVector((*seq_len)->shape())) {\n      return errors::InvalidArgument(\"sequence_length is not a vector\");\n    }\n\n    if (!(batch_size == (*seq_len)->dim_size(0))) {\n      return errors::FailedPrecondition(\n          \"len(sequence_length) != batch_size.  \",\n          \"len(sequence_length):  \", (*seq_len)->dim_size(0),\n          \" batch_size: \", batch_size);\n    }\n\n    auto seq_len_t = (*seq_len)->vec<int32>();\n\n    for (int b = 0; b < batch_size; ++b) {\n      if (!(seq_len_t(b) <= max_time)) {\n        return errors::FailedPrecondition(\"sequence_length(\", b,\n                                          \") <= \", max_time);\n      }\n    }\n\n    Status s = ctx->allocate_output(\n        \"log_probability\", TensorShape({batch_size, top_paths_}), log_prob);\n    if (!s.ok()) return s;\n\n    s = ctx->output_list(\"decoded_indices\", decoded_indices);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_values\", decoded_values);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_shape\", decoded_shape);\n    if (!s.ok()) return s;\n\n    return Status::OK();\n  }\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_commenting_notifications(self, changes):\n        \"\"\"\n        Sends notifications about any changes to comments to anyone who is subscribed.\n        \"\"\"\n        relevant_comment_ids = []\n        relevant_comment_ids.extend(comment.pk for comment in changes['resolved_comments'])\n        relevant_comment_ids.extend(comment.pk for comment, replies in changes['new_replies'])\n\n        # Skip if no changes were made\n        # Note: We don't email about edited comments so ignore those here\n        if (not changes['new_comments']\n                and not changes['deleted_comments']\n                and not changes['resolved_comments']\n                and not changes['new_replies']):\n            return\n\n        # Get global page comment subscribers\n        subscribers = PageSubscription.objects.filter(page=self.page, comment_notifications=True).select_related('user')\n        global_recipient_users = [subscriber.user for subscriber in subscribers if subscriber.user != self.request.user]\n\n        # Get subscribers to individual threads\n        replies = CommentReply.objects.filter(comment_id__in=relevant_comment_ids)\n        comments = Comment.objects.filter(id__in=relevant_comment_ids)\n        thread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).prefetch_related(\n            Prefetch('comment_replies', queryset=replies),\n            Prefetch(COMMENTS_RELATION_NAME, queryset=comments)\n        ).exclude(\n            Q(comment_replies__isnull=True) & Q(**{('%s__isnull' % COMMENTS_RELATION_NAME): True})\n        )\n\n        # Skip if no recipients\n        if not (global_recipient_users or thread_users):\n            return\n        thread_users = [(user, set(list(user.comment_replies.values_list('comment_id', flat=True)) + list(getattr(user, COMMENTS_RELATION_NAME).values_list('pk', flat=True)))) for user in thread_users]\n        mailed_users = set()\n\n        for current_user, current_threads in thread_users:\n            # We are trying to avoid calling send_notification for each user for performance reasons\n            # so group the users receiving the same thread notifications together here\n            if current_user in mailed_users:\n                continue\n            users = [current_user]\n            mailed_users.add(current_user)\n            for user, threads in thread_users:\n                if user not in mailed_users and threads == current_threads:\n                    users.append(user)\n                    mailed_users.add(user)\n            send_notification(users, 'updated_comments', {\n                'page': self.page,\n                'editor': self.request.user,\n                'new_comments': [comment for comment in changes['new_comments'] if comment.pk in threads],\n                'resolved_comments': [comment for comment in changes['resolved_comments'] if comment.pk in threads],\n                'deleted_comments': [],\n                'replied_comments': [\n                    {\n                        'comment': comment,\n                        'replies': replies,\n                    }\n                    for comment, replies in changes['new_replies']\n                    if comment.pk in threads\n                ]\n            })\n\n        return send_notification(global_recipient_users, 'updated_comments', {\n            'page': self.page,\n            'editor': self.request.user,\n            'new_comments': changes['new_comments'],\n            'resolved_comments': changes['resolved_comments'],\n            'deleted_comments': changes['deleted_comments'],\n            'replied_comments': [\n                {\n                    'comment': comment,\n                    'replies': replies,\n                }\n                for comment, replies in changes['new_replies']\n            ]\n        })\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n\n  return ProtoParseFromString(to_parse, out);\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs):\n        super().__init__(hs)\n\n        self.http_client = SimpleHttpClient(hs)\n        # We create a blacklisting instance of SimpleHttpClient for contacting identity\n        # servers specified by clients\n        self.blacklisting_http_client = SimpleHttpClient(\n            hs, ip_blacklist=hs.config.federation_ip_range_blacklist\n        )\n        self.federation_http_client = hs.get_http_client()\n        self.hs = hs\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        self._has_ssl_errors = True\n\n        url = error.url()\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "expandrow(UINT8 *dest, UINT8 *src, int n, int z, int xsize) {\n    UINT8 pixel, count;\n    int x = 0;\n\n    for (; n > 0; n--) {\n        pixel = *src++;\n        if (n == 1 && pixel != 0) {\n            return n;\n        }\n        count = pixel & RLE_MAX_RUN;\n        if (!count) {\n            return count;\n        }\n        if (x + count > xsize) {\n            return -1;\n        }\n        x += count;\n        if (pixel & RLE_COPY_FLAG) {\n            while (count--) {\n                *dest = *src++;\n                dest += z;\n            }\n\n        } else {\n            pixel = *src++;\n            while (count--) {\n                *dest = pixel;\n                dest += z;\n            }\n        }\n    }\n    return 0;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer (on the other hand, the Python part of the driver\n       makes sure this is always the case) */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment,\n                             ALL_TO_ALL_COLLECTIVE, resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    VLOG(1) << \"CollectiveAllToAll group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_request_handler(\n    dependant: Dependant,\n    body_field: Optional[ModelField] = None,\n    status_code: int = 200,\n    response_class: Union[Type[Response], DefaultPlaceholder] = Default(JSONResponse),\n    response_field: Optional[ModelField] = None,\n    response_model_include: Optional[Union[SetIntStr, DictIntStrAny]] = None,\n    response_model_exclude: Optional[Union[SetIntStr, DictIntStrAny]] = None,\n    response_model_by_alias: bool = True,\n    response_model_exclude_unset: bool = False,\n    response_model_exclude_defaults: bool = False,\n    response_model_exclude_none: bool = False,\n    dependency_overrides_provider: Optional[Any] = None,\n) -> Callable[[Request], Coroutine[Any, Any, Response]]:\n    assert dependant.call is not None, \"dependant.call must be a function\"\n    is_coroutine = asyncio.iscoroutinefunction(dependant.call)\n    is_body_form = body_field and isinstance(body_field.field_info, params.Form)\n    if isinstance(response_class, DefaultPlaceholder):\n        actual_response_class: Type[Response] = response_class.value\n    else:\n        actual_response_class = response_class\n\n    async def app(request: Request) -> Response:\n        try:\n            body = None\n            if body_field:\n                if is_body_form:\n                    body = await request.form()\n                else:\n                    body_bytes = await request.body()\n                    if body_bytes:\n                        body = await request.json()\n        except json.JSONDecodeError as e:\n            raise RequestValidationError([ErrorWrapper(e, (\"body\", e.pos))], body=e.doc)\n        except Exception as e:\n            raise HTTPException(\n                status_code=400, detail=\"There was an error parsing the body\"\n            ) from e\n        solved_result = await solve_dependencies(\n            request=request,\n            dependant=dependant,\n            body=body,\n            dependency_overrides_provider=dependency_overrides_provider,\n        )\n        values, errors, background_tasks, sub_response, _ = solved_result\n        if errors:\n            raise RequestValidationError(errors, body=body)\n        else:\n            raw_response = await run_endpoint_function(\n                dependant=dependant, values=values, is_coroutine=is_coroutine\n            )\n\n            if isinstance(raw_response, Response):\n                if raw_response.background is None:\n                    raw_response.background = background_tasks\n                return raw_response\n            response_data = await serialize_response(\n                field=response_field,\n                response_content=raw_response,\n                include=response_model_include,\n                exclude=response_model_exclude,\n                by_alias=response_model_by_alias,\n                exclude_unset=response_model_exclude_unset,\n                exclude_defaults=response_model_exclude_defaults,\n                exclude_none=response_model_exclude_none,\n                is_coroutine=is_coroutine,\n            )\n            response = actual_response_class(\n                content=response_data,\n                status_code=status_code,\n                background=background_tasks,  # type: ignore # in Starlette\n            )\n            response.headers.raw.extend(sub_response.headers.raw)\n            if sub_response.status_code:\n                response.status_code = sub_response.status_code\n            return response\n\n    return app\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "handle_keywordonly_args(struct compiling *c, const node *n, int start,\n                        asdl_seq *kwonlyargs, asdl_seq *kwdefaults)\n{\n    PyObject *argname;\n    node *ch;\n    expr_ty expression, annotation;\n    arg_ty arg = NULL;\n    int i = start;\n    int j = 0; /* index for kwdefaults and kwonlyargs */\n\n    if (kwonlyargs == NULL) {\n        ast_error(c, CHILD(n, start), \"named arguments must follow bare *\");\n        return -1;\n    }\n    assert(kwdefaults != NULL);\n    while (i < NCH(n)) {\n        ch = CHILD(n, i);\n        switch (TYPE(ch)) {\n            case vfpdef:\n            case tfpdef:\n                if (i + 1 < NCH(n) && TYPE(CHILD(n, i + 1)) == EQUAL) {\n                    expression = ast_for_expr(c, CHILD(n, i + 2));\n                    if (!expression)\n                        goto error;\n                    asdl_seq_SET(kwdefaults, j, expression);\n                    i += 2; /* '=' and test */\n                }\n                else { /* setting NULL if no default value exists */\n                    asdl_seq_SET(kwdefaults, j, NULL);\n                }\n                if (NCH(ch) == 3) {\n                    /* ch is NAME ':' test */\n                    annotation = ast_for_expr(c, CHILD(ch, 2));\n                    if (!annotation)\n                        goto error;\n                }\n                else {\n                    annotation = NULL;\n                }\n                ch = CHILD(ch, 0);\n                argname = NEW_IDENTIFIER(ch);\n                if (!argname)\n                    goto error;\n                if (forbidden_name(c, argname, ch, 0))\n                    goto error;\n                arg = arg(argname, annotation, NULL, LINENO(ch), ch->n_col_offset,\n                          c->c_arena);\n                if (!arg)\n                    goto error;\n                asdl_seq_SET(kwonlyargs, j++, arg);\n                i += 1; /* the name */\n                if (TYPE(CHILD(n, i)) == COMMA)\n                    i += 1; /* the comma, if present */\n                break;\n            case TYPE_COMMENT:\n                /* arg will be equal to the last argument processed */\n                arg->type_comment = NEW_TYPE_COMMENT(ch);\n                if (!arg->type_comment)\n                    goto error;\n                i += 1;\n                break;\n            case DOUBLESTAR:\n                return i;\n            default:\n                ast_error(c, ch, \"unexpected node\");\n                goto error;\n        }\n    }\n    return i;\n error:\n    return -1;\n}\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def index():\n    \"\"\" Index handler \"\"\"\n\n    send = request.vars.send\n    if DEMO_MODE:\n        session.authorized = True\n        session.last_time = t0\n    if not send:\n        send = URL('site')\n    if session.authorized:\n        redirect(send)\n    elif failed_login_count() >= allowed_number_of_attempts:\n        time.sleep(2 ** allowed_number_of_attempts)\n        raise HTTP(403)\n    elif request.vars.password:\n        if verify_password(request.vars.password[:1024]):\n            session.authorized = True\n            login_record(True)\n\n            if CHECK_VERSION:\n                session.check_version = True\n            else:\n                session.check_version = False\n\n            session.last_time = t0\n            if isinstance(send, list):  # ## why does this happen?\n                send = str(send[0])\n\n            redirect(send)\n        else:\n            times_denied = login_record(False)\n            if times_denied >= allowed_number_of_attempts:\n                response.flash = \\\n                    T('admin disabled because too many invalid login attempts')\n            elif times_denied == allowed_number_of_attempts - 1:\n                response.flash = \\\n                    T('You have one more login attempt before you are locked out')\n            else:\n                response.flash = T('invalid password.')\n    return dict(send=send)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def post(self):\n        \"\"\"This method handles the POST requests to add agents to the Cloud Verifier.\n\n        Currently, only agents resources are available for POSTing, i.e. /agents. All other POST uri's will return errors.\n        agents requests require a json block sent in the body\n        \"\"\"\n        session = get_session()\n        try:\n            rest_params = web_util.get_restful_params(self.request.uri)\n            if rest_params is None:\n                web_util.echo_json_response(\n                    self, 405, \"Not Implemented: Use /agents/ interface\")\n                return\n\n            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):\n                return\n\n            if \"agents\" not in rest_params:\n                web_util.echo_json_response(self, 400, \"uri not supported\")\n                logger.warning('POST returning 400 response. uri not supported: %s', self.request.path)\n                return\n\n            agent_id = rest_params[\"agents\"]\n\n            if agent_id is not None:\n                # If the agent ID is not valid (wrong set of\n                # characters), just do nothing.\n                if not validators.valid_agent_id(agent_id):\n                    web_util.echo_json_response(self, 400, \"agent_id not not valid\")\n                    logger.error(\"POST received an invalid agent ID: %s\", agent_id)\n                    return\n\n                content_length = len(self.request.body)\n                if content_length == 0:\n                    web_util.echo_json_response(\n                        self, 400, \"Expected non zero content length\")\n                    logger.warning('POST returning 400 response. Expected non zero content length.')\n                else:\n                    json_body = json.loads(self.request.body)\n                    agent_data = {}\n                    agent_data['v'] = json_body['v']\n                    agent_data['ip'] = json_body['cloudagent_ip']\n                    agent_data['port'] = int(json_body['cloudagent_port'])\n                    agent_data['operational_state'] = states.START\n                    agent_data['public_key'] = \"\"\n                    agent_data['tpm_policy'] = json_body['tpm_policy']\n                    agent_data['meta_data'] = json_body['metadata']\n                    agent_data['allowlist'] = json_body['allowlist']\n                    agent_data['mb_refstate'] = json_body['mb_refstate']\n                    agent_data['ima_sign_verification_keys'] = json_body['ima_sign_verification_keys']\n                    agent_data['revocation_key'] = json_body['revocation_key']\n                    agent_data['accept_tpm_hash_algs'] = json_body['accept_tpm_hash_algs']\n                    agent_data['accept_tpm_encryption_algs'] = json_body['accept_tpm_encryption_algs']\n                    agent_data['accept_tpm_signing_algs'] = json_body['accept_tpm_signing_algs']\n                    agent_data['supported_version'] = json_body['supported_version']\n                    agent_data['hash_alg'] = \"\"\n                    agent_data['enc_alg'] = \"\"\n                    agent_data['sign_alg'] = \"\"\n                    agent_data['agent_id'] = agent_id\n                    agent_data['boottime'] = 0\n                    agent_data['ima_pcrs'] = []\n                    agent_data['pcr10'] = None\n                    agent_data['next_ima_ml_entry'] = 0\n                    agent_data['learned_ima_keyrings'] = {}\n                    agent_data['verifier_id'] = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)\n                    agent_data['verifier_ip'] = config.get('cloud_verifier', 'cloudverifier_ip')\n                    agent_data['verifier_port'] = config.get('cloud_verifier', 'cloudverifier_port')\n\n                    # We fetch the registrar data directly here because we require it for connecting to the agent\n                    # using mTLS\n                    registrar_client.init_client_tls('cloud_verifier')\n                    registrar_data = registrar_client.getData(config.get(\"cloud_verifier\", \"registrar_ip\"),\n                                                              config.get(\"cloud_verifier\", \"registrar_port\"), agent_id)\n                    if registrar_data is None:\n                        web_util.echo_json_response(self, 400,\n                                                    f\"Data for agent {agent_id} could not be found in registrar!\")\n                        logger.warning(\"Data for agent %s could not be found in registrar!\", agent_id)\n                        return\n\n                    agent_data['mtls_cert'] = registrar_data.get('mtls_cert', None)\n                    agent_data['ak_tpm'] = registrar_data['aik_tpm']\n\n                    # TODO: Always error for v1.0 version after initial upgrade\n                    if registrar_data.get('mtls_cert', None) is None and agent_data['supported_version'] != \"1.0\":\n                        web_util.echo_json_response(self, 400, \"mTLS certificate for agent is required!\")\n                        return\n\n                    is_valid, err_msg = cloud_verifier_common.validate_agent_data(agent_data)\n                    if not is_valid:\n                        web_util.echo_json_response(self, 400, err_msg)\n                        logger.warning(err_msg)\n                        return\n\n                    try:\n                        new_agent_count = session.query(\n                            VerfierMain).filter_by(agent_id=agent_id).count()\n                    except SQLAlchemyError as e:\n                        logger.error('SQLAlchemy Error: %s', e)\n                        raise e\n\n                    # don't allow overwriting\n\n                    if new_agent_count > 0:\n                        web_util.echo_json_response(\n                            self, 409, f\"Agent of uuid {agent_id} already exists\")\n                        logger.warning(\"Agent of uuid %s already exists\", agent_id)\n                    else:\n                        try:\n                            # Add the agent and data\n                            session.add(VerfierMain(**agent_data))\n                            session.commit()\n                        except SQLAlchemyError as e:\n                            logger.error('SQLAlchemy Error: %s', e)\n                            raise e\n\n                        # add default fields that are ephemeral\n                        for key,val in exclude_db.items():\n                            agent_data[key] = val\n\n                        # Prepare SSLContext for mTLS connections\n                        agent_mtls_cert_enabled = config.getboolean('cloud_verifier', 'agent_mtls_cert_enabled', fallback=False)\n                        mtls_cert = registrar_data.get('mtls_cert', None)\n                        agent_data['ssl_context'] = None\n                        if agent_mtls_cert_enabled and mtls_cert:\n                            agent_data['ssl_context'] = web_util.generate_agent_mtls_context(mtls_cert, self.mtls_options)\n\n                        if agent_data['ssl_context'] is None:\n                            logger.warning('Connecting to agent without mTLS: %s', agent_id)\n\n                        asyncio.ensure_future(\n                            process_agent(agent_data, states.GET_QUOTE))\n                        web_util.echo_json_response(self, 200, \"Success\")\n                        logger.info('POST returning 200 response for adding agent id: %s', agent_id)\n            else:\n                web_util.echo_json_response(self, 400, \"uri not supported\")\n                logger.warning(\"POST returning 400 response. uri not supported\")\n        except Exception as e:\n            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")\n            logger.warning(\"POST returning 400 response. Exception error: %s\", e)\n            logger.exception(e)\n"}, {"role": "assistant", "content": "True"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = get_safe_url(request.form.get('origin'))\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def extract_js(response):\n    \"\"\"\n    extracts javascript from a given string\n    \"\"\"\n    scripts = []\n    for part in re.split('(?i)<script[> ]', response):\n        actual_parts = re.split('(?i)</script>', part, maxsplit=2)\n        if len(actual_parts) > 1:\n            scripts.append(actual_parts[0])\n    return scripts\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n\n    TensorShape tensor_input_shape;\n    OP_REQUIRES_OK(context, TensorShape::BuildTensorShape(input_shape_vec,\n                                                          &tensor_input_shape));\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def rpn(self, irc, msg, args):\n        \"\"\"<rpn math expression>\n\n        Returns the value of an RPN expression.\n        \"\"\"\n        stack = []\n        for arg in args:\n            try:\n                x = complex(arg)\n                if x == abs(x):\n                    x = abs(x)\n                stack.append(x)\n            except ValueError: # Not a float.\n                if arg in SAFE_ENV:\n                    f = SAFE_ENV[arg]\n                    if callable(f):\n                        called = False\n                        arguments = []\n                        while not called and stack:\n                            arguments.append(stack.pop())\n                            try:\n                                stack.append(f(*arguments))\n                                called = True\n                            except TypeError:\n                                pass\n                        if not called:\n                            irc.error(_('Not enough arguments for %s') % arg)\n                            return\n                    else:\n                        stack.append(f)\n                elif arg in self._rpnEnv:\n                    self._rpnEnv[arg](stack)\n                else:\n                    arg2 = stack.pop()\n                    arg1 = stack.pop()\n                    s = '%s%s%s' % (arg1, arg, arg2)\n                    try:\n                        stack.append(safe_eval(s, allow_ints=False))\n                    except SyntaxError:\n                        irc.error(format(_('%q is not a defined function.'),\n                                         arg))\n                        return\n        if len(stack) == 1:\n            irc.reply(str(self._complexToString(complex(stack[0]))))\n        else:\n            s = ', '.join(map(self._complexToString, list(map(complex, stack))))\n            irc.reply(_('Stack: [%s]') % s)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def append(self, key, value):\n        self.dict.setdefault(_hkey(key), []).append(_hval(value))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) final {\n    // Extract inputs and validate shapes and types.\n    const CSRSparseMatrix* input_matrix;\n    OP_REQUIRES_OK(ctx, ExtractVariantFromInput(ctx, 0, &input_matrix));\n    const Tensor& input_permutation_indices = ctx->input(1);\n\n    int64 num_rows;\n    int batch_size;\n    OP_REQUIRES_OK(ctx, ValidateInputs(*input_matrix, input_permutation_indices,\n                                       &batch_size, &num_rows));\n\n    // Allocate batch pointers.\n    Tensor batch_ptr(cpu_allocator(), DT_INT32, TensorShape({batch_size + 1}));\n    auto batch_ptr_vec = batch_ptr.vec<int32>();\n    batch_ptr_vec(0) = 0;\n\n    // Temporary vector of Eigen SparseMatrices to store the Sparse Cholesky\n    // factors.\n    // Note: we use column-compressed (CSC) SparseMatrix because SimplicialLLT\n    // returns the factors in column major format. Since our input should be\n    // symmetric, column major and row major is identical in storage. We just\n    // have to switch to reading the upper triangular part of the input, which\n    // corresponds to the lower triangular part in row major format.\n    std::vector<SparseMatrix> sparse_cholesky_factors(batch_size);\n\n    // TODO(anudhyan): Tune the cost per unit based on benchmarks.\n    const double nnz_per_row =\n        (input_matrix->total_nnz() / batch_size) / num_rows;\n    const int64 sparse_cholesky_cost_per_batch =\n        nnz_per_row * nnz_per_row * num_rows;\n    // Perform sparse Cholesky factorization of each batch in parallel.\n    auto worker_threads = *(ctx->device()->tensorflow_cpu_worker_threads());\n    std::atomic<int64> invalid_input_index(-1);\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          sparse_cholesky_cost_per_batch,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              // Define an Eigen SparseMatrix Map to operate on the\n              // CSRSparseMatrix component without copying the data.\n              Eigen::Map<const SparseMatrix> sparse_matrix(\n                  num_rows, num_rows, input_matrix->nnz(batch_index),\n                  input_matrix->row_pointers_vec(batch_index).data(),\n                  input_matrix->col_indices_vec(batch_index).data(),\n                  input_matrix->values_vec<T>(batch_index).data());\n\n              Eigen::SimplicialLLT<SparseMatrix, Eigen::Upper,\n                                   Eigen::NaturalOrdering<int>>\n                  solver;\n              auto permutation_indices_flat =\n                  input_permutation_indices.flat<int32>().data();\n\n              // Invert the fill-in reducing ordering and apply it to the input\n              // sparse matrix.\n              Eigen::Map<\n                  Eigen::PermutationMatrix<Eigen::Dynamic, Eigen::Dynamic, int>>\n                  permutation(permutation_indices_flat + batch_index * num_rows,\n                              num_rows);\n              auto permutation_inverse = permutation.inverse();\n\n              SparseMatrix permuted_sparse_matrix;\n              permuted_sparse_matrix.template selfadjointView<Eigen::Upper>() =\n                  sparse_matrix.template selfadjointView<Eigen::Upper>()\n                      .twistedBy(permutation_inverse);\n\n              // Compute the Cholesky decomposition.\n              solver.compute(permuted_sparse_matrix);\n              if (solver.info() != Eigen::Success) {\n                invalid_input_index = batch_index;\n                return;\n              }\n\n              // Get the upper triangular factor, which would end up in the\n              // lower triangular part of the output CSRSparseMatrix when\n              // interpreted in row major format.\n              sparse_cholesky_factors[batch_index] =\n                  std::move(solver.matrixU());\n              // For now, batch_ptr contains the number of nonzeros in each\n              // batch.\n              batch_ptr_vec(batch_index + 1) =\n                  sparse_cholesky_factors[batch_index].nonZeros();\n            }\n          });\n\n    // Check for invalid input.\n    OP_REQUIRES(\n        ctx, invalid_input_index == -1,\n        errors::InvalidArgument(\n            \"Sparse Cholesky factorization failed for batch index \",\n            invalid_input_index.load(), \". The input might not be valid.\"));\n\n    // Compute a cumulative sum to obtain the batch pointers.\n    std::partial_sum(batch_ptr_vec.data(),\n                     batch_ptr_vec.data() + batch_size + 1,\n                     batch_ptr_vec.data());\n\n    // Allocate output Tensors.\n    const int64 total_nnz = batch_ptr_vec(batch_size);\n    Tensor output_row_ptr(cpu_allocator(), DT_INT32,\n                          TensorShape({(num_rows + 1) * batch_size}));\n    Tensor output_col_ind(cpu_allocator(), DT_INT32, TensorShape({total_nnz}));\n    Tensor output_values(cpu_allocator(), DataTypeToEnum<T>::value,\n                         TensorShape({total_nnz}));\n    auto output_row_ptr_ptr = output_row_ptr.flat<int32>().data();\n    auto output_col_ind_ptr = output_col_ind.flat<int32>().data();\n    auto output_values_ptr = output_values.flat<T>().data();\n\n    // Copy the output matrices from each batch into the CSRSparseMatrix\n    // Tensors.\n    // TODO(b/129906419): Factor out the copy from Eigen SparseMatrix to\n    // CSRSparseMatrix into common utils. This is also used in\n    // SparseMatrixSparseMatMul.\n    Shard(worker_threads.num_threads, worker_threads.workers, batch_size,\n          (3 * total_nnz) / batch_size /* cost per unit */,\n          [&](int64 batch_begin, int64 batch_end) {\n            for (int64 batch_index = batch_begin; batch_index < batch_end;\n                 ++batch_index) {\n              const SparseMatrix& cholesky_factor =\n                  sparse_cholesky_factors[batch_index];\n              const int64 nnz = cholesky_factor.nonZeros();\n\n              std::copy(cholesky_factor.outerIndexPtr(),\n                        cholesky_factor.outerIndexPtr() + num_rows + 1,\n                        output_row_ptr_ptr + batch_index * (num_rows + 1));\n              std::copy(cholesky_factor.innerIndexPtr(),\n                        cholesky_factor.innerIndexPtr() + nnz,\n                        output_col_ind_ptr + batch_ptr_vec(batch_index));\n              std::copy(cholesky_factor.valuePtr(),\n                        cholesky_factor.valuePtr() + nnz,\n                        output_values_ptr + batch_ptr_vec(batch_index));\n            }\n          });\n\n    // Create the CSRSparseMatrix instance from its component Tensors and\n    // prepare the Variant output Tensor.\n    CSRSparseMatrix output_csr_matrix;\n    OP_REQUIRES_OK(\n        ctx,\n        CSRSparseMatrix::CreateCSRSparseMatrix(\n            DataTypeToEnum<T>::value, input_matrix->dense_shape(), batch_ptr,\n            output_row_ptr, output_col_ind, output_values, &output_csr_matrix));\n    Tensor* output_csr_matrix_tensor;\n    AllocatorAttributes cpu_alloc;\n    cpu_alloc.set_on_host(true);\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({}), &output_csr_matrix_tensor,\n                                  cpu_alloc));\n    output_csr_matrix_tensor->scalar<Variant>()() =\n        std::move(output_csr_matrix);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ALGnew(PyObject *self, PyObject *args, PyObject *kwdict)\n{\n\tunsigned char *key, *IV;\n\tALGobject * new=NULL;\n\tint keylen, IVlen=0, mode=MODE_ECB, segment_size=0;\n\tPyObject *counter = NULL;\n\tint counter_shortcut = 0;\n#ifdef PCT_ARC2_MODULE\n        int effective_keylen = 1024;    /* this is a weird default, but it's compatible with old versions of PyCrypto */\n#endif\n\t/* Set default values */\n\tif (!PyArg_ParseTupleAndKeywords(args, kwdict, \"s#|is#Oi\"\n#ifdef PCT_ARC2_MODULE\n\t\t\t\t\t \"i\"\n#endif\n\t\t\t\t\t , kwlist,\n\t\t\t\t\t &key, &keylen, &mode, &IV, &IVlen,\n\t\t\t\t\t &counter, &segment_size\n#ifdef PCT_ARC2_MODULE\n\t\t\t\t\t , &effective_keylen\n#endif\n\t\t)) \n\t{\n\t\treturn NULL;\n\t}\n\n\tif (mode<MODE_ECB || mode>MODE_CTR) \n\t{\n\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t     \"Unknown cipher feedback mode %i\",\n\t\t\t     mode);\n\t\treturn NULL;\n\t}\n\tif (mode == MODE_PGP) {\n\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t     \"MODE_PGP is not supported anymore\");\n\t\treturn NULL;\n\t}\n\tif (KEY_SIZE!=0 && keylen!=KEY_SIZE)\n\t{\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"Key must be %i bytes long, not %i\",\n\t\t\t     KEY_SIZE, keylen);\n\t\treturn NULL;\n\t}\n\tif (KEY_SIZE==0 && keylen==0)\n\t{\n\t\tPyErr_SetString(PyExc_ValueError,\n\t\t\t\t\"Key cannot be the null string\");\n\t\treturn NULL;\n\t}\n\tif (IVlen != 0 && mode == MODE_ECB)\n\t{\n\t\tPyErr_Format(PyExc_ValueError, \"ECB mode does not use IV\");\n\t\treturn NULL;\n\t}\n\tif (IVlen != 0 && mode == MODE_CTR)\n\t{\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t\"CTR mode needs counter parameter, not IV\");\n\t\treturn NULL;\n\t}\n\tif (IVlen != BLOCK_SIZE && mode != MODE_ECB && mode != MODE_CTR)\n\t{\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"IV must be %i bytes long\", BLOCK_SIZE);\n\t\treturn NULL;\n\t}\n\n\t/* Mode-specific checks */\n\tif (mode == MODE_CFB) {\n\t\tif (segment_size == 0) segment_size = 8;\n\t\tif (segment_size < 1 || segment_size > BLOCK_SIZE*8 || ((segment_size & 7) != 0)) {\n\t\t\tPyErr_Format(PyExc_ValueError, \n\t\t\t\t     \"segment_size must be multiple of 8 (bits) \"\n\t\t\t\t     \"between 1 and %i\", BLOCK_SIZE*8);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\tif (mode == MODE_CTR) {\n\t\tif (counter == NULL) {\n\t\t\tPyErr_SetString(PyExc_TypeError,\n\t\t\t\t\t\"'counter' keyword parameter is required with CTR mode\");\n\t\t\treturn NULL;\n\t\t} else if (Py_TYPE(counter) == PCT_CounterBEType || Py_TYPE(counter) == PCT_CounterLEType) {\n\t\t\tcounter_shortcut = 1;\n\t\t} else if (!PyCallable_Check(counter)) {\n\t\t\tPyErr_SetString(PyExc_ValueError, \n\t\t\t\t\t\"'counter' parameter must be a callable object\");\n\t\t\treturn NULL;\n\t\t}\n\t} else {\n\t\tif (counter != NULL) {\n\t\t\tPyErr_SetString(PyExc_ValueError, \n\t\t\t\t\t\"'counter' parameter only useful with CTR mode\");\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\t/* Cipher-specific checks */\n#ifdef PCT_ARC2_MODULE\n        if (effective_keylen<0 || effective_keylen>1024) {\n\t\tPyErr_Format(PyExc_ValueError,\n\t\t\t     \"RC2: effective_keylen must be between 0 and 1024, not %i\",\n\t\t\t     effective_keylen);\n\t\treturn NULL;\n        }\n#endif\n\n\t/* Copy parameters into object */\n\tnew = newALGobject();\n\tnew->segment_size = segment_size;\n\tnew->counter = counter;\n\tPy_XINCREF(counter);\n\tnew->counter_shortcut = counter_shortcut;\n#ifdef PCT_ARC2_MODULE\n        new->st.effective_keylen = effective_keylen;\n#endif\n\n\tblock_init(&(new->st), key, keylen);\n\tif (PyErr_Occurred())\n\t{\n\t\tPy_DECREF(new);\n\t\treturn NULL;\n\t}\n\tmemset(new->IV, 0, BLOCK_SIZE);\n\tmemset(new->oldCipher, 0, BLOCK_SIZE);\n\tmemcpy(new->IV, IV, IVlen);\n\tnew->mode = mode;\n\tnew->count=BLOCK_SIZE;   /* stores how many bytes in new->oldCipher have been used */\n\treturn new;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext *ctx) override {\n    // (0) validations\n    const Tensor *a_indices, *b_indices, *a_values_t, *b_values_t, *a_shape,\n        *b_shape, *thresh_t;\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_indices\", &a_indices));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_indices\", &b_indices));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsMatrix(a_indices->shape()) &&\n                    TensorShapeUtils::IsMatrix(b_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be matrices but received shapes: \",\n                    a_indices->shape().DebugString(), \" and \",\n                    b_indices->shape().DebugString()));\n    const int64 a_nnz = a_indices->dim_size(0);\n    const int64 b_nnz = b_indices->dim_size(0);\n    const int num_dims = a_indices->dim_size(1);\n    OP_REQUIRES(ctx, b_indices->dim_size(1) == num_dims,\n                errors::InvalidArgument(\n                    \"Input indices must have the same dimension, got \",\n                    num_dims, \" and \", b_indices->dim_size(1)));\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_values\", &a_values_t));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_values\", &b_values_t));\n\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_values_t->shape()) &&\n                    TensorShapeUtils::IsVector(b_values_t->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be vectors but received shapes: \",\n                    a_values_t->shape().DebugString(), \" and \",\n                    b_values_t->shape().DebugString()));\n    auto a_values = ctx->input(1).vec<T>();\n    auto b_values = ctx->input(4).vec<T>();\n    OP_REQUIRES(\n        ctx, a_values.size() == a_nnz && b_values.size() == b_nnz,\n        errors::InvalidArgument(\"Expected \", a_nnz, \" and \", b_nnz,\n                                \" non-empty input values, got \",\n                                a_values.size(), \" and \", b_values.size()));\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"a_shape\", &a_shape));\n    OP_REQUIRES_OK(ctx, ctx->input(\"b_shape\", &b_shape));\n    OP_REQUIRES(ctx,\n                TensorShapeUtils::IsVector(a_shape->shape()) &&\n                    TensorShapeUtils::IsVector(b_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shapes should be a vector but received shapes \",\n                    a_shape->shape().DebugString(), \" and \",\n                    b_shape->shape().DebugString()));\n    OP_REQUIRES(\n        ctx, a_shape->NumElements() == num_dims,\n        errors::InvalidArgument(\"Second dimension of a_indices and length of \"\n                                \"a_shape must match, got \",\n                                num_dims, \" and \", a_shape->NumElements()));\n    OP_REQUIRES(ctx, num_dims > 0,\n                errors::InvalidArgument(\"Tesors must not be empty\"));\n    OP_REQUIRES(\n        ctx, a_shape->IsSameSize(*b_shape),\n        errors::InvalidArgument(\n            \"Operands do not have the same ranks; got shapes: \",\n            a_shape->SummarizeValue(10), \" and \", b_shape->SummarizeValue(10)));\n    const auto a_shape_flat = a_shape->flat<int64>();\n    const auto b_shape_flat = b_shape->flat<int64>();\n    for (int i = 0; i < a_shape->NumElements(); ++i) {\n      OP_REQUIRES(ctx, a_shape_flat(i) == b_shape_flat(i),\n                  errors::InvalidArgument(\n                      \"Operands' shapes do not match: got \", a_shape_flat(i),\n                      \" and \", b_shape_flat(i), \" for dimension \", i));\n    }\n\n    OP_REQUIRES_OK(ctx, ctx->input(\"thresh\", &thresh_t));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(thresh_t->shape()),\n                errors::InvalidArgument(\n                    \"The magnitude threshold must be a scalar: got shape \",\n                    thresh_t->shape().DebugString()));\n    // std::abs() so that it works for complex{64,128} values as well\n    const Treal thresh = thresh_t->scalar<Treal>()();\n\n    // (1) do a pass over inputs, and append values and indices to vectors\n    auto a_indices_mat = a_indices->matrix<int64>();\n    auto b_indices_mat = b_indices->matrix<int64>();\n    std::vector<std::pair<bool, int64>> entries_to_copy;  // from_a?, idx\n    entries_to_copy.reserve(a_nnz + b_nnz);\n    std::vector<T> out_values;\n\n    // The input and output sparse tensors are assumed to be ordered along\n    // increasing dimension number.\n    int64 i = 0, j = 0;\n    T s;\n    while (i < a_nnz && j < b_nnz) {\n      switch (sparse::DimComparator::cmp(a_indices_mat, b_indices_mat, i, j,\n                                         num_dims)) {\n        case -1:\n          entries_to_copy.emplace_back(true, i);\n          out_values.push_back(a_values(i));\n          ++i;\n          break;\n        case 0:\n          s = a_values(i) + b_values(j);\n          if (thresh <= std::abs(s)) {\n            entries_to_copy.emplace_back(true, i);\n            out_values.push_back(s);\n          }\n          ++i;\n          ++j;\n          break;\n        case 1:\n          entries_to_copy.emplace_back(false, j);\n          out_values.push_back(b_values(j));\n          ++j;\n          break;\n      }\n    }\n\n#define HANDLE_LEFTOVERS(A_OR_B, IDX, IS_A)     \\\n  while (IDX < A_OR_B##_nnz) {                  \\\n    entries_to_copy.emplace_back(IS_A, IDX);    \\\n    out_values.push_back(A_OR_B##_values(IDX)); \\\n    ++IDX;                                      \\\n  }\n\n    // at most one of these calls appends new values\n    HANDLE_LEFTOVERS(a, i, true);\n    HANDLE_LEFTOVERS(b, j, false);\n#undef HANDLE_LEFTOVERS\n\n    // (2) allocate and fill output tensors\n    const int64 sum_nnz = out_values.size();\n    Tensor *out_indices_t, *out_values_t;\n    OP_REQUIRES_OK(ctx,\n                   ctx->allocate_output(0, TensorShape({sum_nnz, num_dims}),\n                                        &out_indices_t));\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(1, TensorShape({sum_nnz}), &out_values_t));\n    auto out_indices_mat = out_indices_t->matrix<int64>();\n    auto out_values_flat = out_values_t->vec<T>();\n\n    for (i = 0; i < sum_nnz; ++i) {\n      const bool from_a = entries_to_copy[i].first;\n      const int64 idx = entries_to_copy[i].second;\n      out_indices_mat.chip<0>(i) =\n          from_a ? a_indices_mat.chip<0>(idx) : b_indices_mat.chip<0>(idx);\n    }\n    if (sum_nnz > 0) {\n      std::copy_n(out_values.begin(), sum_nnz, &out_values_flat(0));\n    }\n    ctx->set_output(2, *a_shape);\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def received_client_receipt(\n        self,\n        room_id: str,\n        receipt_type: str,\n        user_id: UserID,\n        event_id: str,\n        thread_id: Optional[str],\n    ) -> None:\n        \"\"\"Called when a client tells us a local user has read up to the given\n        event_id in the room.\n        \"\"\"\n\n        # Ensure the room/event exists, this will raise an error if the user\n        # cannot view the event.\n        if not await self.event_handler.get_event(user_id, room_id, event_id):\n            return\n\n        receipt = ReadReceipt(\n            room_id=room_id,\n            receipt_type=receipt_type,\n            user_id=user_id.to_string(),\n            event_ids=[event_id],\n            thread_id=thread_id,\n            data={\"ts\": int(self.clock.time_msec())},\n        )\n\n        is_new = await self._handle_new_receipts([receipt])\n        if not is_new:\n            return\n\n        if self.federation_sender and receipt_type != ReceiptTypes.READ_PRIVATE:\n            await self.federation_sender.send_read_receipt(receipt)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def sendEmail(\n    sydent: \"Sydent\",\n    templateFile: str,\n    mailTo: str,\n    substitutions: Dict[str, str],\n    log_send_errors: bool = True,\n) -> None:\n    \"\"\"\n    Sends an email with the given parameters.\n\n    :param sydent: The Sydent instance to use when building the configuration to send the\n        email with.\n    :param templateFile: The filename of the template to use when building the body of the\n        email.\n    :param mailTo: The email address to send the email to.\n    :param substitutions: The substitutions to use with the template.\n    :param log_send_errors: Whether to log errors happening when sending an email.\n    \"\"\"\n    mailFrom = sydent.config.email.sender\n    myHostname = sydent.config.email.host_name\n\n    midRandom = \"\".join([random.choice(string.ascii_letters) for _ in range(16)])\n    messageid = \"<%d%s@%s>\" % (time_msec(), midRandom, myHostname)\n\n    substitutions.update(\n        {\n            \"messageid\": messageid,\n            \"date\": email.utils.formatdate(localtime=False),\n            \"to\": mailTo,\n            \"from\": mailFrom,\n        }\n    )\n\n    # use jinja for rendering if jinja templates are present\n    if templateFile.endswith(\".j2\"):\n        # We add randomize the multipart boundary to stop user input from\n        # conflicting with it.\n        substitutions[\"multipart_boundary\"] = generateAlphanumericTokenOfLength(32)\n        template = sydent.config.general.template_environment.get_template(templateFile)\n        mailString = template.render(substitutions)\n    else:\n        allSubstitutions = {}\n        for k, v in substitutions.items():\n            allSubstitutions[k] = v\n            allSubstitutions[k + \"_forhtml\"] = escape(v)\n            allSubstitutions[k + \"_forurl\"] = urllib.parse.quote(v)\n        allSubstitutions[\"multipart_boundary\"] = generateAlphanumericTokenOfLength(32)\n        with open(templateFile) as template_file:\n            mailString = template_file.read() % allSubstitutions\n\n    try:\n        check_valid_email_address(mailTo, allow_description=False)\n    except EmailAddressException:\n        logger.warning(\"Invalid email address %s\", mailTo)\n        raise\n\n    mailServer = sydent.config.email.smtp_server\n    mailPort = int(sydent.config.email.smtp_port)\n    mailUsername = sydent.config.email.smtp_username\n    mailPassword = sydent.config.email.smtp_password\n    mailTLSMode = sydent.config.email.tls_mode\n\n    logger.info(\n        \"Sending mail to %s with mail server: %s\"\n        % (\n            mailTo,\n            mailServer,\n        )\n    )\n    try:\n        smtp: smtplib.SMTP\n        # Explicitly create a context, to ensure we verify the server's certificate\n        # and hostname.\n        ctx = ssl.create_default_context(purpose=ssl.Purpose.SERVER_AUTH)\n        if mailTLSMode == \"SSL\" or mailTLSMode == \"TLS\":\n            smtp = smtplib.SMTP_SSL(mailServer, mailPort, myHostname, context=ctx)\n        elif mailTLSMode == \"STARTTLS\":\n            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n            smtp.starttls(context=ctx)\n        else:\n            smtp = smtplib.SMTP(mailServer, mailPort, myHostname)\n        if mailUsername != \"\":\n            smtp.login(mailUsername, mailPassword)\n\n        email_counter.inc()\n\n        # We're using the parsing above to do basic validation, but instead of\n        # failing it may munge the address it returns. So we should *not* use\n        # that parsed address, as it may not match any validation done\n        # elsewhere.\n        smtp.sendmail(mailFrom, mailTo, mailString.encode(\"utf-8\"))\n        smtp.quit()\n    except Exception as origException:\n        if log_send_errors:\n            twisted.python.log.err()\n        raise EmailSendException() from origException\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def write_data_table(self, report, report_data, has_totals=True):\n        self.data.append([c[\"title\"] for c in report.schema])\n        for datum in report_data:\n            datum = report.read_datum(datum)\n            self.data.append([format_data(remove_unsafe_chars(data), format_iso_dates=True) for data in datum])\n\n        if has_totals:\n            for datum in report.get_totals(report_data):\n                datum = report.read_datum(datum)\n                self.data.append([format_data(remove_unsafe_chars(data)) for data in datum])\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static Status ValidateSavedTensors(const GraphDef& graph_def) {\n  for (const auto& node : graph_def.node()) {\n    const auto node_iterator = node.attr().find(\"value\");\n    if (node_iterator != node.attr().end()) {\n      AttrValue node_value = node_iterator->second;\n      if (node_value.has_tensor()) {\n        const PartialTensorShape node_shape(node_value.tensor().tensor_shape());\n        if (node_shape.num_elements() < 0) {\n          return errors::FailedPrecondition(\n              \"Saved model contains node \\\"\", node.name(), \"\\\" (op \\\"\",\n              node.op(), \"\\\") which initializes from a tensor with \",\n              node_shape.num_elements(), \" elements\");\n        }\n      }\n    } else if (node.op() == \"Const\") {\n      return errors::FailedPrecondition(\n          \"Saved model contains node \\\"\", node.name(),\n          \"\\\" which is a constant tensor but no value has been provided\");\n    }\n  }\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    OP_REQUIRES(\n        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n                                \" but is rank \", input.shape().dims()));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def users(self, criteria=u\"\", search=u\"\", action=u\"\", **kwargs):\n\n        # If we're just showing the initial page, just do that\n        form = UserForm()\n        if action in [\"add\", \"edit\"]:\n            self._add_or_edit_user(action, form)\n        elif action == 'delete':\n            self._delete_user(action, DeleteUserForm())\n\n        params = {\n            \"form\": UserForm(formdata=None),\n            \"criteria\": criteria,\n            \"search\": search,\n            \"users\": list(self.app.store.users(search=search, criteria=criteria))}\n\n        # Build users page\n        return self._compile_template(\"admin_users.html\", **params)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_lm_corpus(datadir, dataset):\n    fn = os.path.join(datadir, \"cache.pt\")\n    fn_pickle = os.path.join(datadir, \"cache.pkl\")\n    if os.path.exists(fn):\n        logger.info(\"Loading cached dataset...\")\n        corpus = torch.load(fn_pickle)\n    elif os.path.exists(fn):\n        logger.info(\"Loading cached dataset from pickle...\")\n        if not strtobool(os.environ.get(\"TRUST_REMOTE_CODE\", \"False\")):\n            raise ValueError(\n                \"This part uses `pickle.load` which is insecure and will execute arbitrary code that is potentially \"\n                \"malicious. It's recommended to never unpickle data that could have come from an untrusted source, or \"\n                \"that could have been tampered with. If you already verified the pickle data and decided to use it, \"\n                \"you can set the environment variable `TRUST_REMOTE_CODE` to `True` to allow it.\"\n            )\n        with open(fn, \"rb\") as fp:\n            corpus = pickle.load(fp)\n    else:\n        logger.info(f\"Producing dataset {dataset}...\")\n        kwargs = {}\n        if dataset in [\"wt103\", \"wt2\"]:\n            kwargs[\"special\"] = [\"<eos>\"]\n            kwargs[\"lower_case\"] = False\n        elif dataset == \"ptb\":\n            kwargs[\"special\"] = [\"<eos>\"]\n            kwargs[\"lower_case\"] = True\n        elif dataset == \"lm1b\":\n            kwargs[\"special\"] = []\n            kwargs[\"lower_case\"] = False\n            kwargs[\"vocab_file\"] = os.path.join(datadir, \"1b_word_vocab.txt\")\n        elif dataset in [\"enwik8\", \"text8\"]:\n            pass\n\n        corpus = TransfoXLCorpus(datadir, dataset, **kwargs)\n        torch.save(corpus, fn)\n\n    return corpus\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def list_artifacts(self, path=None):\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, tail = self.artifact_uri.split(endpoint, maxsplit=1)\n        root = tail.lstrip(\"/\")\n        params = {\"path\": posixpath.join(root, path) if path else root}\n        host_creds = _get_default_host_creds(url)\n        resp = http_request(host_creds, endpoint, \"GET\", params=params)\n        augmented_raise_for_status(resp)\n        file_infos = []\n        for f in resp.json().get(\"files\", []):\n            validated_path = validate_path_is_safe(f[\"path\"])\n            file_info = FileInfo(\n                posixpath.join(path, validated_path) if path else validated_path,\n                f[\"is_dir\"],\n                int(f[\"file_size\"]) if (\"file_size\" in f) else None,\n            )\n            file_infos.append(file_info)\n\n        return sorted(file_infos, key=lambda f: f.path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def window():\n    target_url = request.args.get('location')\n    if target_url.startswith('gAAAAA'):\n        cipher_suite = Fernet(g.session_key)\n        target_url = cipher_suite.decrypt(target_url.encode()).decode()\n\n    content_filter = Filter(\n        g.session_key,\n        root_url=request.url_root,\n        config=g.user_config)\n    target = urlparse.urlparse(target_url)\n\n    # Ensure requested URL has a valid domain\n    if not validators.domain(target.netloc):\n        return render_template(\n            'error.html',\n            error_message='Invalid location'), 400\n\n    host_url = f'{target.scheme}://{target.netloc}'\n\n    get_body = g.user_request.send(base_url=target_url).text\n\n    results = bsoup(get_body, 'html.parser')\n    src_attrs = ['src', 'href', 'srcset', 'data-srcset', 'data-src']\n\n    # Parse HTML response and replace relative links w/ absolute\n    for element in results.find_all():\n        for attr in src_attrs:\n            if not element.has_attr(attr) or not element[attr].startswith('/'):\n                continue\n\n            element[attr] = host_url + element[attr]\n\n    # Replace or remove javascript sources\n    for script in results.find_all('script', {'src': True}):\n        if 'nojs' in request.args:\n            script.decompose()\n        else:\n            content_filter.update_element_src(script, 'application/javascript')\n\n    # Replace all possible image attributes\n    img_sources = ['src', 'data-src', 'data-srcset', 'srcset']\n    for img in results.find_all('img'):\n        _ = [\n            content_filter.update_element_src(img, 'image/png', attr=_)\n            for _ in img_sources if img.has_attr(_)\n        ]\n\n    # Replace all stylesheet sources\n    for link in results.find_all('link', {'href': True}):\n        content_filter.update_element_src(link, 'text/css', attr='href')\n\n    # Use anonymous view for all links on page\n    for a in results.find_all('a', {'href': True}):\n        a['href'] = f'{Endpoint.window}?location=' + a['href'] + (\n            '&nojs=1' if 'nojs' in request.args else '')\n\n    # Remove all iframes -- these are commonly used inside of <noscript> tags\n    # to enforce loading Google Analytics\n    for iframe in results.find_all('iframe'):\n        iframe.decompose()\n\n    return render_template(\n        'display.html',\n        response=results,\n        translation=app.config['TRANSLATIONS'][\n            g.user_config.get_localization_lang()\n        ]\n    )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def delete(request, name):\n  name = str_param('name', name)\n  if 'delete' not in getPermissions(request.user):\n    return json_response( dict(error=\"Must be logged in with appropriate permissions to delete\") )\n\n  try:\n    dashboard = Dashboard.objects.get(name=name)\n  except Dashboard.DoesNotExist:\n    return json_response( dict(error=\"Dashboard '%s' does not exist. \" % name) )\n  else:\n    dashboard.delete()\n    return json_response( dict(success=True) )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, **kwargs):\n        \"\"\"Initialize HTMLSerializer.\n\n        Keyword options (default given first unless specified) include:\n\n        inject_meta_charset=True|False\n          Whether it insert a meta element to define the character set of the\n          document.\n        quote_attr_values=\"legacy\"|\"spec\"|\"always\"\n          Whether to quote attribute values that don't require quoting\n          per legacy browser behaviour, when required by the standard, or always.\n        quote_char=u'\"'|u\"'\"\n          Use given quote character for attribute quoting. Default is to\n          use double quote unless attribute value contains a double quote,\n          in which case single quotes are used instead.\n        escape_lt_in_attrs=False|True\n          Whether to escape < in attribute values.\n        escape_rcdata=False|True\n          Whether to escape characters that need to be escaped within normal\n          elements within rcdata elements such as style.\n        resolve_entities=True|False\n          Whether to resolve named character entities that appear in the\n          source tree. The XML predefined entities &lt; &gt; &amp; &quot; &apos;\n          are unaffected by this setting.\n        strip_whitespace=False|True\n          Whether to remove semantically meaningless whitespace. (This\n          compresses all whitespace to a single space except within pre.)\n        minimize_boolean_attributes=True|False\n          Shortens boolean attributes to give just the attribute value,\n          for example <input disabled=\"disabled\"> becomes <input disabled>.\n        use_trailing_solidus=False|True\n          Includes a close-tag slash at the end of the start tag of void\n          elements (empty elements whose end tag is forbidden). E.g. <hr/>.\n        space_before_trailing_solidus=True|False\n          Places a space immediately before the closing slash in a tag\n          using a trailing solidus. E.g. <hr />. Requires use_trailing_solidus.\n        sanitize=False|True\n          Strip all unsafe or unknown constructs from output.\n          See `html5lib user documentation`_\n        omit_optional_tags=True|False\n          Omit start/end tags that are optional.\n        alphabetical_attributes=False|True\n          Reorder attributes to be in alphabetical order.\n\n        .. _html5lib user documentation: http://code.google.com/p/html5lib/wiki/UserDocumentation\n        \"\"\"\n        if 'quote_char' in kwargs:\n            self.use_best_quote_char = False\n        for attr in self.options:\n            setattr(self, attr, kwargs.get(attr, getattr(self, attr)))\n        self.errors = []\n        self.strict = False\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def reset_password(self, userid, password):\n        \"\"\"\n        Change/Reset a user's password for authdb.\n\n        Password will be hashed and saved.\n        :param userid: the user id to reset the password\n        :param password: the clear text password to reset and save hashed on the db\n        \"\"\"\n        user = self.get_user_by_id(userid)\n        user.password = generate_password_hash(password)\n        self.reset_user_sessions(user)\n        self.update_user(user)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def archive(request, bookmark_id: int):\n    try:\n        bookmark = Bookmark.objects.get(pk=bookmark_id, owner=request.user)\n    except Bookmark.DoesNotExist:\n        raise Http404('Bookmark does not exist')\n\n    archive_bookmark(bookmark)\n    return_url = request.GET.get('return_url')\n    return_url = return_url if return_url else reverse('bookmarks:index')\n    return HttpResponseRedirect(return_url)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const auto splits = ctx->input(0).flat<int64_t>();\n    const auto values = ctx->input(1).flat<Tidx>();\n    const Tensor& size_t = ctx->input(2);\n    const auto weights = ctx->input(3).flat<T>();\n    const int64_t weights_size = weights.size();\n\n    OP_REQUIRES(ctx, size_t.dims() == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        size_t.dims()));\n    Tidx size = size_t.scalar<Tidx>()();\n    OP_REQUIRES(\n        ctx, size >= 0,\n        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n\n    int num_rows = splits.size() - 1;\n    int num_values = values.size();\n    int batch_idx = 0;\n\n    OP_REQUIRES(ctx, splits(0) == 0,\n                errors::InvalidArgument(\"Splits must start with 0, not with \",\n                                        splits(0)));\n\n    OP_REQUIRES(ctx, splits(num_rows) == num_values,\n                errors::InvalidArgument(\n                    \"Splits must end with the number of values, got \",\n                    splits(num_rows), \" instead of \", num_values));\n\n    Tensor* out_t;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n    functor::SetZeroFunctor<Device, T> fill;\n    fill(ctx->eigen_device<Device>(), out_t->flat<T>());\n    const auto out = out_t->matrix<T>();\n\n    for (int idx = 0; idx < num_values; ++idx) {\n      while (idx >= splits(batch_idx)) {\n        batch_idx++;\n      }\n      Tidx bin = values(idx);\n      OP_REQUIRES(ctx, bin >= 0,\n                  errors::InvalidArgument(\"Input must be non-negative\"));\n      if (bin < size) {\n        if (binary_output_) {\n          out(batch_idx - 1, bin) = T(1);\n        } else {\n          T value = (weights_size > 0) ? weights(idx) : T(1);\n          out(batch_idx - 1, bin) += value;\n        }\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __call__(self, value):\n        if not isinstance(value, str) or len(value) > self.max_length:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        if self.unsafe_chars.intersection(value):\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        # Check if the scheme is valid.\n        scheme = value.split(\"://\")[0].lower()\n        if scheme not in self.schemes:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n\n        # Then check full URL\n        try:\n            splitted_url = urlsplit(value)\n        except ValueError:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n        try:\n            super().__call__(value)\n        except ValidationError as e:\n            # Trivial case failed. Try for possible IDN domain\n            if value:\n                scheme, netloc, path, query, fragment = splitted_url\n                try:\n                    netloc = punycode(netloc)  # IDN -> ACE\n                except UnicodeError:  # invalid domain part\n                    raise e\n                url = urlunsplit((scheme, netloc, path, query, fragment))\n                super().__call__(url)\n            else:\n                raise\n        else:\n            # Now verify IPv6 in the netloc part\n            host_match = re.search(r\"^\\[(.+)\\](?::[0-9]{1,5})?$\", splitted_url.netloc)\n            if host_match:\n                potential_ip = host_match[1]\n                try:\n                    validate_ipv6_address(potential_ip)\n                except ValidationError:\n                    raise ValidationError(\n                        self.message, code=self.code, params={\"value\": value}\n                    )\n\n        # The maximum length of a full host name is 253 characters per RFC 1034\n        # section 3.1. It's defined to be 255 bytes or less, but this includes\n        # one byte for the length of the name and one byte for the trailing dot\n        # that's used to indicate absolute names in DNS.\n        if splitted_url.hostname is None or len(splitted_url.hostname) > 253:\n            raise ValidationError(self.message, code=self.code, params={\"value\": value})\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def parse_command_line(argv: List[str]) -> argparse.Namespace:  # noqa: C901.\n    defaults: Dict[str, Any] = {\n        \"json_indent\": None,\n        \"ordered\": True,\n        \"stringify\": False,\n        \"yaml_options\": {},\n    }\n\n    me = Path(argv[0]).name\n    argv0_from, argv0_to = argv0_to_format(me)\n    format_from_argv0 = argv0_to != \"\"\n\n    parser = argparse.ArgumentParser(\n        description=\"Convert between CBOR, JSON, MessagePack, TOML, and YAML.\"\n    )\n    parser.add_argument(\"-v\", \"--version\", action=\"version\", version=__version__)\n\n    input_group = parser.add_mutually_exclusive_group()\n    input_group.add_argument(\"input\", nargs=\"?\", default=\"-\", help=\"input file\")\n    input_group.add_argument(\n        \"-i\",\n        \"--input\",\n        dest=\"input_flag\",\n        metavar=\"input\",\n        default=None,\n        help=\"input file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--if\",\n            \"-if\",\n            \"--input-format\",\n            dest=\"input_format\",\n            default=\"\",\n            help=\"input format\",\n            choices=FORMATS,\n        )\n\n    if not format_from_argv0 or argv0_to == \"json\":\n        parser.add_argument(\n            \"--json-indent\",\n            \"--indent-json\",\n            dest=\"json_indent\",\n            metavar=\"n\",\n            type=int,\n            default=defaults[\"json_indent\"],\n            help=\"JSON indentation\",\n        )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\"}:\n        parser.add_argument(\n            \"-k\",\n            \"--stringify\",\n            dest=\"stringify\",\n            action=\"store_true\",\n            help=(\n                \"Turn into strings boolean, date-time, and null keys for JSON \"\n                \"and TOML and null values for TOML\"\n            ),\n        )\n\n    parser.add_argument(\n        \"--max-nodes\",\n        dest=\"max_nodes\",\n        metavar=\"n\",\n        type=int,\n        default=DEFAULT_MAX_NODES,\n        help=\"maximum number of nodes in input data (default %(default)s)\",\n    )\n\n    output_group = parser.add_mutually_exclusive_group()\n    output_group.add_argument(\"output\", nargs=\"?\", default=\"-\", help=\"output file\")\n    output_group.add_argument(\n        \"-o\",\n        \"--output\",\n        dest=\"output_flag\",\n        metavar=\"output\",\n        default=None,\n        help=\"output file\",\n    )\n\n    if not format_from_argv0:\n        parser.add_argument(\n            \"--of\",\n            \"-of\",\n            \"--output-format\",\n            dest=\"output_format\",\n            default=\"\",\n            help=\"output format\",\n            choices=FORMATS,\n        )\n\n    parser.add_argument(\n        \"-p\",\n        \"--preserve-key-order\",\n        help=argparse.SUPPRESS,\n    )\n\n    if not format_from_argv0 or argv0_to in {\"json\", \"toml\", \"yaml\"}:\n        parser.add_argument(\n            \"-s\",\n            \"--sort-keys\",\n            dest=\"ordered\",\n            action=\"store_false\",\n            help=\"sort JSON, TOML, YAML keys instead of preserving key order\",\n        )\n\n    parser.add_argument(\n        \"--unwrap\",\n        dest=\"unwrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"only output the data stored under the given key\",\n    )\n    parser.add_argument(\n        \"--wrap\",\n        dest=\"wrap\",\n        metavar=\"key\",\n        default=None,\n        help=\"wrap the data in a map type with the given key\",\n    )\n\n    if not format_from_argv0 or argv0_to == \"yaml\":\n        parser.add_argument(\n            \"--yaml-indent\",\n            dest=\"yaml_indent\",\n            metavar=\"n\",\n            type=int,\n            default=2,\n            help=\"YAML indentation\",\n        )\n        parser.add_argument(\n            \"--yaml-style\",\n            dest=\"yaml_style\",\n            default=None,\n            help=\"YAML formatting style\",\n            choices=[\"\", \"'\", '\"', \"|\", \">\"],\n        )\n\n        def yaml_width(value: str) -> int:\n            # This is theoretically compatible with LibYAML.\n            return (1 << 32) - 1 if value.lower() == \"inf\" else int(value)\n\n        parser.add_argument(\n            \"--yaml-width\",\n            dest=\"yaml_width\",\n            metavar=\"n\",\n            type=yaml_width,  # Allow \"inf\".\n            default=80,\n            help=\"YAML line width for long strings\",\n        )\n\n    args = parser.parse_args(args=argv[1:])\n\n    # Use the positional input and output arguments.\n    if args.input_flag is not None:\n        args.input = args.input_flag\n\n    if args.output_flag is not None:\n        args.output = args.output_flag\n\n    # Determine the implicit input and output format if possible.\n    if format_from_argv0:\n        args.input_format = argv0_from\n        args.output_format = argv0_to\n    else:\n        if args.input_format == \"\":\n            args.input_format = extension_to_format(args.input)\n            if args.input_format == \"\":\n                parser.error(\"Need an explicit input format\")\n\n        if args.output_format == \"\":\n            args.output_format = extension_to_format(args.output)\n            if args.output_format == \"\":\n                parser.error(\"Need an explicit output format\")\n\n    for key, value in defaults.items():\n        vars(args).setdefault(key, value)\n\n    # Wrap the yaml_* option.\n    if \"yaml_indent\" in vars(args):\n        vars(args)[\"yaml_options\"] = {\n            \"default_style\": args.yaml_style,\n            \"indent\": args.yaml_indent,\n            \"width\": args.yaml_width,\n        }\n        for key in [\"yaml_indent\", \"yaml_style\", \"yaml_width\"]:\n            del vars(args)[key]\n\n    return args\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def generate_filename(self, filename):\n        \"\"\"\n        Validate the filename by calling get_valid_name() and return a filename\n        to be passed to the save() method.\n        \"\"\"\n        # `filename` may include a path as returned by FileField.upload_to.\n        dirname, filename = os.path.split(filename)\n        if '..' in pathlib.PurePath(dirname).parts:\n            raise SuspiciousFileOperation(\"Detected path traversal attempt in '%s'\" % dirname)\n        return os.path.normpath(os.path.join(dirname, self.get_valid_name(filename)))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def serve(request, path, document_root=None, show_indexes=False):\n    \"\"\"\n    Serve static files below a given point in the directory structure.\n\n    To use, put a URL pattern such as::\n\n        (r'^(?P<path>.*)$', 'django.views.static.serve', {'document_root': '/path/to/my/files/'})\n\n    in your URLconf. You must provide the ``document_root`` param. You may\n    also set ``show_indexes`` to ``True`` if you'd like to serve a basic index\n    of the directory.  This index view will use the template hardcoded below,\n    but if you'd like to override it, you can create a template called\n    ``static/directory_index.html``.\n    \"\"\"\n    path = posixpath.normpath(unquote(path))\n    path = path.lstrip('/')\n    newpath = ''\n    for part in path.split('/'):\n        if not part:\n            # Strip empty path components.\n            continue\n        drive, part = os.path.splitdrive(part)\n        head, part = os.path.split(part)\n        if part in (os.curdir, os.pardir):\n            # Strip '.' and '..' in path.\n            continue\n        newpath = os.path.join(newpath, part).replace('\\\\', '/')\n    if newpath and path != newpath:\n        return HttpResponseRedirect(newpath)\n    fullpath = os.path.join(document_root, newpath)\n    if os.path.isdir(fullpath):\n        if show_indexes:\n            return directory_index(newpath, fullpath)\n        raise Http404(_(\"Directory indexes are not allowed here.\"))\n    if not os.path.exists(fullpath):\n        raise Http404(_('\"%(path)s\" does not exist') % {'path': fullpath})\n    # Respect the If-Modified-Since header.\n    statobj = os.stat(fullpath)\n    if not was_modified_since(request.META.get('HTTP_IF_MODIFIED_SINCE'),\n                              statobj.st_mtime, statobj.st_size):\n        return HttpResponseNotModified()\n    content_type, encoding = mimetypes.guess_type(fullpath)\n    content_type = content_type or 'application/octet-stream'\n    f = open(fullpath, 'rb')\n    response = StreamingHttpResponse(iter(lambda: f.read(STREAM_CHUNK_SIZE), b''),\n                                     content_type=content_type)\n    response[\"Last-Modified\"] = http_date(statobj.st_mtime)\n    if stat.S_ISREG(statobj.st_mode):\n        response[\"Content-Length\"] = statobj.st_size\n    if encoding:\n        response[\"Content-Encoding\"] = encoding\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def create_table(\n        self,\n        name: str,\n        obj: pd.DataFrame | pa.Table | ir.Table | None = None,\n        *,\n        schema: sch.Schema | None = None,\n        database: str | None = None,\n        temp: bool = False,\n        overwrite: bool = False,\n    ) -> ir.Table:\n        \"\"\"Create a table.\n\n        Parameters\n        ----------\n        name\n            Name of the new table.\n        obj\n            An Ibis table expression or pandas table that will be used to\n            extract the schema and the data of the new table. If not provided,\n            `schema` must be given.\n        schema\n            The schema for the new table. Only one of `schema` or `obj` can be\n            provided.\n        database\n            Name of the database where the table will be created, if not the\n            default.\n        temp\n            Should the table be temporary for the session.\n        overwrite\n            Clobber existing data\n\n        Returns\n        -------\n        Table\n            The table that was created.\n        \"\"\"\n        if obj is None and schema is None:\n            raise com.IbisError(\"The schema or obj parameter is required\")\n\n        import pandas as pd\n        import pyarrow as pa\n        import pyarrow_hotfix  # noqa: F401\n\n        if isinstance(obj, (pd.DataFrame, pa.Table)):\n            obj = ibis.memtable(obj)\n\n        if database == self.current_database:\n            # avoid fully qualified name\n            database = None\n\n        if database is not None:\n            raise NotImplementedError(\n                \"Creating tables from a different database is not yet implemented\"\n            )\n\n        if obj is not None and schema is not None:\n            if not obj.schema().equals(ibis.schema(schema)):\n                raise com.IbisTypeError(\n                    \"Expression schema is not equal to passed schema. \"\n                    \"Try passing the expression without the schema\"\n                )\n        if schema is None:\n            schema = obj.schema()\n\n        self._schemas[self._fully_qualified_name(name, database)] = schema\n\n        if has_expr := obj is not None:\n            # this has to happen outside the `begin` block, so that in-memory\n            # tables are visible inside the transaction created by it\n            self._run_pre_execute_hooks(obj)\n\n        table = self._table_from_schema(\n            name,\n            schema,\n            # most databases don't allow temporary tables in a specific\n            # database so let the backend decide\n            #\n            # the ones that do (e.g., snowflake) should implement their own\n            # `create_table`\n            database=None if temp else (database or self.current_database),\n            temp=temp,\n        )\n\n        if has_expr:\n            if self.supports_create_or_replace:\n                ctas = CreateTableAs(\n                    name,\n                    self.compile(obj),\n                    temp=temp,\n                    overwrite=overwrite,\n                    quote=self.compiler.translator_class._quote_table_names,\n                )\n                with self.begin() as bind:\n                    bind.execute(ctas)\n            else:\n                tmptable = self._table_from_schema(\n                    util.gen_name(\"tmp_table_insert\"),\n                    schema,\n                    # some backends don't support temporary tables\n                    temp=self.supports_temporary_tables,\n                )\n                method = self._get_insert_method(obj)\n                insert = table.insert().from_select(tmptable.columns, tmptable.select())\n\n                with self.begin() as bind:\n                    # 1. write `obj` to a unique temp table\n                    tmptable.create(bind=bind)\n\n                # try/finally here so that a successfully created tmptable gets\n                # cleaned up no matter what\n                try:\n                    with self.begin() as bind:\n                        bind.execute(method(tmptable.insert()))\n\n                        # 2. recreate the existing table\n                        if overwrite:\n                            table.drop(bind=bind, checkfirst=True)\n                        table.create(bind=bind)\n\n                        # 3. insert the temp table's data into the (re)created table\n                        bind.execute(insert)\n                finally:\n                    self._clean_up_tmp_table(tmptable)\n        else:\n            with self.begin() as bind:\n                if overwrite:\n                    table.drop(bind=bind, checkfirst=True)\n                table.create(bind=bind)\n        return self.table(name, database=database)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def message_to_binary(self, message, message_type=ua.MessageType.SecureMessage, request_id=0):\n        \"\"\"\n        Convert OPC UA secure message to binary.\n        The only supported types are SecureOpen, SecureMessage, SecureClose.\n        If message_type is SecureMessage, the AlgorithmHeader should be passed as arg.\n        \"\"\"\n        chunks = MessageChunk.message_to_chunks(\n            self.security_policy,\n            message,\n            self._limits.max_send_buffer,\n            message_type=message_type,\n            channel_id=self.security_token.ChannelId,\n            request_id=request_id,\n            token_id=self.security_token.TokenId,\n        )\n        for chunk in chunks:\n            self._sequence_number += 1\n            if self._sequence_number >= (1 << 32):\n                logger.debug(\"Wrapping sequence number: %d -> 1\", self._sequence_number)\n                self._sequence_number = 1\n            chunk.SequenceHeader.SequenceNumber = self._sequence_number\n        return b\"\".join([chunk.to_binary() for chunk in chunks])\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def from_unix_seconds(seconds: Union[int, float]) -> datetime:\n    if seconds > MAX_NUMBER:\n        return datetime.max\n    elif seconds < -MAX_NUMBER:\n        return datetime.min\n\n    while abs(seconds) > MS_WATERSHED:\n        seconds /= 1000\n    dt = EPOCH + timedelta(seconds=seconds)\n    return dt.replace(tzinfo=timezone.utc)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "inline void ComputeInterpolationWeights(\n    const int64 out_size, const int64 in_size, const float scale,\n    const int resolution, InterpolationCache<T_SCALE>* interpolation) {\n  const Scaler scaler;\n  interpolation->lower.resize(out_size + 1);\n  interpolation->upper.resize(out_size + 1);\n  interpolation->lerp.resize(out_size + 1);\n  interpolation->ilerp.resize(out_size + 1);\n\n  interpolation->lower[out_size] = 0;\n  interpolation->upper[out_size] = 0;\n  for (int64 i = out_size - 1; i >= 0; --i) {\n    const float in = scaler(i, scale);\n    const float in_f = std::floor(in);\n    interpolation->lower[i] =\n        std::max(static_cast<int64>(in_f), static_cast<int64>(0));\n    interpolation->upper[i] =\n        std::min(static_cast<int64>(std::ceil(in)), in_size - 1);\n    interpolation->lower[i] =\n        std::min(interpolation->lower[i], interpolation->upper[i]);\n    interpolation->lerp[i] = in - in_f;\n    interpolation->ilerp[i] =\n        static_cast<T_SCALE>((in - in_f) * (1 << resolution));\n  }\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_attributes(self):\n        \"\"\"\n        Gets the Attributes from the AttributeStatement element.\n        EncryptedAttributes are not supported\n        \"\"\"\n        attributes = {}\n        attribute_nodes = self.__query_assertion('/saml:AttributeStatement/saml:Attribute')\n        for attribute_node in attribute_nodes:\n            attr_name = attribute_node.get('Name')\n            if attr_name in attributes.keys():\n                raise OneLogin_Saml2_ValidationError(\n                    'Found an Attribute element with duplicated Name',\n                    OneLogin_Saml2_ValidationError.DUPLICATED_ATTRIBUTE_NAME_FOUND\n                )\n\n            values = []\n            for attr in attribute_node.iterchildren('{%s}AttributeValue' % OneLogin_Saml2_Constants.NSMAP[OneLogin_Saml2_Constants.NS_PREFIX_SAML]):\n                # Remove any whitespace (which may be present where attributes are\n                # nested inside NameID children).\n                attr_text = OneLogin_Saml2_Utils.element_text(attr)\n                if attr_text:\n                    attr_text = attr_text.strip()\n                    if attr_text:\n                        values.append(attr_text)\n\n                # Parse any nested NameID children\n                for nameid in attr.iterchildren('{%s}NameID' % OneLogin_Saml2_Constants.NSMAP[OneLogin_Saml2_Constants.NS_PREFIX_SAML]):\n                    values.append({\n                        'NameID': {\n                            'Format': nameid.get('Format'),\n                            'NameQualifier': nameid.get('NameQualifier'),\n                            'value': OneLogin_Saml2_Utils.element_text(nameid)\n                        }\n                    })\n\n            attributes[attr_name] = values\n        return attributes\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void MakeDataset(OpKernelContext* ctx, DatasetBase** output) override {\n    // Create a new SparseTensorSliceDatasetOp::Dataset, insert it in\n    // the step container, and return it as the output.\n    const Tensor* indices;\n    OP_REQUIRES_OK(ctx, ctx->input(\"indices\", &indices));\n    const Tensor* values;\n    OP_REQUIRES_OK(ctx, ctx->input(\"values\", &values));\n    const Tensor* dense_shape;\n    OP_REQUIRES_OK(ctx, ctx->input(\"dense_shape\", &dense_shape));\n\n    OP_REQUIRES(ctx, TensorShapeUtils::IsMatrix(indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    indices->shape().DebugString()));\n\n    const auto num_indices = indices->NumElements();\n    const auto num_values = values->NumElements();\n    if (num_indices == 0 || num_values == 0) {\n      OP_REQUIRES(ctx, num_indices == num_values,\n                  errors::InvalidArgument(\n                      \"If indices or values are empty, the other one must also \"\n                      \"be. Got indices of shape \",\n                      indices->shape().DebugString(), \" and values of shape \",\n                      values->shape().DebugString()));\n    }\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    indices->shape().DebugString()));\n    OP_REQUIRES(ctx, TensorShapeUtils::IsVector(dense_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    dense_shape->shape().DebugString()));\n\n    // We currently ensure that `sparse_tensor` is ordered in the\n    // batch dimension.\n    // TODO(mrry): Investigate ways to avoid this unconditional check\n    // if we can be sure that the sparse tensor was produced in an\n    // appropriate order (e.g. by `tf.parse_example()` or a Dataset\n    // that batches elements into rows of a SparseTensor).\n    int64_t previous_batch_index = -1;\n    for (int64_t i = 0; i < indices->dim_size(0); ++i) {\n      int64_t next_batch_index = indices->matrix<int64>()(i, 0);\n      OP_REQUIRES(\n          ctx, next_batch_index >= previous_batch_index,\n          errors::Unimplemented(\"The SparseTensor must be ordered in the batch \"\n                                \"dimension; handling arbitrarily ordered input \"\n                                \"is not currently supported.\"));\n      previous_batch_index = next_batch_index;\n    }\n    gtl::InlinedVector<int64, 8> std_order(dense_shape->NumElements(), 0);\n    sparse::SparseTensor tensor;\n    OP_REQUIRES_OK(\n        ctx, sparse::SparseTensor::Create(\n                 *indices, *values, TensorShape(dense_shape->vec<int64>()),\n                 std_order, &tensor));\n    *output = new Dataset<T>(ctx, std::move(tensor));\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void TensorSliceReader::LoadShard(int shard) const {\n  CHECK_LT(shard, sss_.size());\n  if (sss_[shard] || !status_.ok()) {\n    return;  // Already loaded, or invalid.\n  }\n  string value;\n  SavedTensorSlices sts;\n  const string fname = fnames_[shard];\n  VLOG(1) << \"Reading meta data from file \" << fname << \"...\";\n  Table* table;\n  Status s = open_function_(fname, &table);\n  if (!s.ok()) {\n    status_ = errors::DataLoss(\"Unable to open table file \", fname, \": \",\n                               s.ToString());\n    return;\n  }\n  sss_[shard].reset(table);\n  if (!(table->Get(kSavedTensorSlicesKey, &value) &&\n        ParseProtoUnlimited(&sts, value))) {\n    status_ = errors::Internal(\n        \"Failed to find the saved tensor slices at the beginning of the \"\n        \"checkpoint file: \",\n        fname);\n    return;\n  }\n  status_ = CheckVersions(sts.meta().versions(), TF_CHECKPOINT_VERSION,\n                          TF_CHECKPOINT_VERSION_MIN_PRODUCER, \"Checkpoint\",\n                          \"checkpoint\");\n  if (!status_.ok()) return;\n  for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n    TensorShape ssm_shape;\n    status_ = TensorShape::BuildTensorShapeBase(ssm.shape(), &ssm_shape);\n    if (!status_.ok()) return;\n    for (const TensorSliceProto& tsp : ssm.slice()) {\n      TensorSlice ss_slice;\n      status_ = TensorSlice::BuildTensorSlice(tsp, &ss_slice);\n      if (!status_.ok()) return;\n      status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\n                                    ss_slice, &tensors_);\n      if (!status_.ok()) return;\n    }\n  }\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  public ProxyResponseRenderer(\n      ProxySettings proxySettings,\n      KeyStoreSettings trustStoreSettings,\n      boolean preserveHostHeader,\n      String hostHeaderValue,\n      SettingsStore settingsStore,\n      boolean trustAllProxyTargets,\n      List<String> trustedProxyTargets,\n      boolean stubCorsEnabled,\n      NetworkAddressRules targetAddressRules,\n      int proxyTimeout) {\n    this.settingsStore = settingsStore;\n    reverseProxyClient =\n        HttpClientFactory.createClient(\n            1000,\n            proxyTimeout,\n            proxySettings,\n            trustStoreSettings,\n            true,\n            Collections.emptyList(),\n            true,\n            targetAddressRules);\n    forwardProxyClient =\n        HttpClientFactory.createClient(\n            1000,\n            proxyTimeout,\n            proxySettings,\n            trustStoreSettings,\n            trustAllProxyTargets,\n            trustAllProxyTargets ? Collections.emptyList() : trustedProxyTargets,\n            false,\n            targetAddressRules);\n\n    this.preserveHostHeader = preserveHostHeader;\n    this.hostHeaderValue = hostHeaderValue;\n    this.stubCorsEnabled = stubCorsEnabled;\n    this.targetAddressRules = targetAddressRules;\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def evaluate_link(self, link: Link) -> Package | None:\n        \"\"\"\n        Evaluate the link and return the package if it matches or None if it doesn't.\n        \"\"\"\n        try:\n            self.format_control.check_format(link, self.package_name)\n            self.check_yanked(link)\n            self.check_requires_python(link)\n            version: str | None = None\n            if link.is_wheel:\n                try:\n                    wheel_info = parse_wheel_filename(link.filename)\n                except (InvalidWheelFilename, InvalidVersion) as e:\n                    raise LinkMismatchError(str(e))\n                if self._canonical_name != wheel_info[0]:\n                    raise LinkMismatchError(\n                        f\"The package name doesn't match {wheel_info[0]}\"\n                    )\n                if not self.ignore_compatibility and wheel_info[3].isdisjoint(\n                    self.target_python.supported_tags()\n                ):\n                    raise LinkMismatchError(\n                        \"none of the wheel tags({}) are compatible\".format(\n                            \", \".join(sorted(str(tag) for tag in wheel_info[3]))\n                        ),\n                    )\n                version = str(wheel_info[1])\n            else:\n                if link._fragment_dict.get(\"egg\"):\n                    egg_info = strip_extras(link._fragment_dict[\"egg\"])\n                else:\n                    egg_info, ext = splitext(link.filename)\n                    if not ext:\n                        raise LinkMismatchError(f\"Not a file: {link.filename}\")\n                    if ext not in ARCHIVE_EXTENSIONS:\n                        raise LinkMismatchError(\n                            f\"Unsupported archive format: {link.filename}\"\n                        )\n                LOOSE_FILENAME = os.getenv(\n                    \"UNEARTH_LOOSE_FILENAME\", \"false\"\n                ).lower() in (\"1\", \"true\")\n                if LOOSE_FILENAME:\n                    version = parse_version_from_egg_info(\n                        egg_info, self._canonical_name\n                    )\n                    if version is None:\n                        raise LinkMismatchError(\n                            f\"Missing version in the filename: {egg_info}\"\n                        )\n                else:\n                    # For source releases, we know that the version should not contain\n                    # any hyphens, so we can split on the last hyphen to get the\n                    # project name.\n                    filename_prefix, has_version, version = egg_info.rpartition(\"-\")\n                    if not has_version:\n                        raise LinkMismatchError(\n                            f\"Missing version in the filename: {egg_info}\"\n                        )\n                    if canonicalize_name(filename_prefix) != self._canonical_name:\n                        raise LinkMismatchError(\n                            f\"The package name doesn't match {egg_info}, set env var \"\n                            \"UNEARTH_LOOSE_FILENAME=1 to allow legacy filename.\"\n                        )\n                try:\n                    Version(version)\n                except InvalidVersion:\n                    raise LinkMismatchError(\n                        f\"Invalid version in the filename {egg_info}: {version}\"\n                    )\n        except LinkMismatchError as e:\n            logger.debug(\"Skipping link %s: %s\", link, e)\n            return None\n        return Package(name=self.package_name, version=version, link=link)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def post(self, kernel_id, action):\n        \"\"\"Interrupt or restart a kernel.\"\"\"\n        km = self.kernel_manager\n        if action == \"interrupt\":\n            await ensure_async(km.interrupt_kernel(kernel_id))  # type:ignore[func-returns-value]\n            self.set_status(204)\n        if action == \"restart\":\n            try:\n                await km.restart_kernel(kernel_id)\n            except Exception as e:\n                message = \"Exception restarting kernel\"\n                self.log.error(message, exc_info=True)\n                self.write(json.dumps({\"message\": message, \"traceback\": \"\"}))\n                self.set_status(500)\n            else:\n                model = await ensure_async(km.kernel_model(kernel_id))\n                self.write(json.dumps(model, default=json_default))\n        self.finish()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def compat_shlex_quote(s):\n        import re\n        return s if re.match(r'^[-_\\w./]+$', s) else s.replace('\"', '\"\"').join('\"\"')\nelse:"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "      void context.ready.then(async () => {\n        const file = context.model;\n        const workspace = (file.toJSON() as unknown) as Workspace.IWorkspace;\n        const path = context.path;\n        const id = workspace.metadata.id;\n\n        // Save the file contents as a workspace.\n        await this._workspaces.save(id, workspace);\n\n        // Save last save location for the save command.\n        await this._state.save(LAST_SAVE_ID, path);\n\n        // Navigate to new workspace.\n        const workspacesBase = URLExt.join(this._application, 'workspaces');\n        const url = URLExt.join(workspacesBase, id);\n        if (!workspacesBase.startsWith(url)) {\n          throw new Error('Can only be used for workspaces');\n        }\n        if (this._router) {\n          this._router.navigate(url, { hard: true });\n        } else {\n          document.location.href = url;\n        }\n      });\n      return dummyWidget(context);"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def as_sql(self, compiler, connection):\n        key_transforms = [self.key_name]\n        previous = self.lhs\n        while isinstance(previous, KeyTransform):\n            key_transforms.insert(0, previous.key_name)\n            previous = previous.lhs\n        lhs, params = compiler.compile(previous)\n        if len(key_transforms) > 1:\n            return \"(%s %s %%s)\" % (lhs, self.nested_operator), [key_transforms] + params\n        try:\n            lookup = int(self.key_name)\n        except ValueError:\n            lookup = self.key_name\n        return '(%s %s %%s)' % (lhs, self.operator), [lookup] + params\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def image(\n        self,\n        tokens: Sequence[Token],\n        idx: int,\n        options: OptionsDict,\n        env: MutableMapping,\n    ) -> str:\n        token = tokens[idx]\n\n        # \"alt\" attr MUST be set, even if empty. Because it's mandatory and\n        # should be placed on proper position for tests.\n        if token.children:\n            token.attrSet(\"alt\", self.renderInlineAsText(token.children, options, env))\n        else:\n            token.attrSet(\"alt\", \"\")\n\n        return self.renderToken(tokens, idx, options, env)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status ValidateInput(const OpInputList& indices_list_in,\n                     const OpInputList& values_list_in,\n                     const OpInputList& shapes_list_in,\n                     const OpInputList& dense_list_in,\n                     const DataType& internal_type) {\n  const auto size = indices_list_in.size();\n  // Only perform internal_type check for SparseCrossOp.\n  // Check if the internal_type is not invalid before doing so.\n  bool check_type = internal_type != DT_INVALID;\n  // Validates indices_list_in OpInputList.\n  for (int i = 0; i < size; i++) {\n    if (check_type && indices_list_in[i].dtype() != DT_INT64) {\n      return errors::InvalidArgument(\"Input indices should be of type \",\n                                     DT_INT64, \" but received \",\n                                     indices_list_in[i].dtype());\n    }\n    if (!TensorShapeUtils::IsMatrix(indices_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input indices should be a matrix but received shape \",\n          indices_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n    if (indices_list_in[i].shape().dim_size(1) != 2) {\n      return errors::InvalidArgument(\"Expected D2 of index to be 2 got \",\n                                     indices_list_in[i].shape().dim_size(1),\n                                     \" at position \", i);\n    }\n  }\n\n  // Validates values_list_in OpInputList.\n  if (values_list_in.size() != size) {\n    return errors::InvalidArgument(\"Expected \", size, \" input values, got \",\n                                   values_list_in.size());\n  }\n  for (int i = 0; i < size; i++) {\n    // Make sure to avoid the expected type to be string, but input values to be\n    // int64.\n    if (check_type && internal_type == DT_STRING &&\n        values_list_in[i].dtype() == DT_INT64) {\n      return errors::InvalidArgument(\"Input values should be of internal type \",\n                                     internal_type, \" but received \",\n                                     values_list_in[i].dtype());\n    }\n    if (!TensorShapeUtils::IsVector(values_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input values should be a vector but received shape \",\n          values_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n    if (indices_list_in[i].shape().dim_size(0) !=\n        values_list_in[i].shape().dim_size(0)) {\n      return errors::InvalidArgument(\n          \"Expected size of values to be \",\n          indices_list_in[i].shape().dim_size(0), \" got \",\n          values_list_in[i].shape().dim_size(0), \" at position \", i);\n    }\n  }\n\n  // Validates shapes_list_in OpInputList\n  if (shapes_list_in.size() != size) {\n    return errors::InvalidArgument(\"Expected \", size, \" input shapes, got \",\n                                   shapes_list_in.size());\n  }\n  for (int i = 0; i < size; i++) {\n    if (check_type && shapes_list_in[i].dtype() != DT_INT64) {\n      return errors::InvalidArgument(\"Input shape should be of type \", DT_INT64,\n                                     \" but received \",\n                                     shapes_list_in[i].dtype());\n    }\n    if (!TensorShapeUtils::IsVector(shapes_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Input shapes should be a vector but received shape \",\n          shapes_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n\n    if (shapes_list_in[i].vec<int64>().size() != 2) {\n      return errors::InvalidArgument(\"shape should imply a 2D tensor, but got \",\n                                     shapes_list_in[i].shape().DebugString(),\n                                     \" at position \", i);\n    }\n  }\n\n  // Validates dense_list_in OpInputList\n  for (int i = 0; i < dense_list_in.size(); ++i) {\n    // Make sure to avoid the expected type to be string, but input values to be\n    // int64.\n    if (check_type && internal_type == DT_STRING &&\n        dense_list_in[i].dtype() == DT_INT64) {\n      return errors::InvalidArgument(\"Dense inputs should be of internal type \",\n                                     internal_type, \" but received \",\n                                     dense_list_in[i].dtype());\n    }\n    if (!TensorShapeUtils::IsMatrix(dense_list_in[i].shape())) {\n      return errors::InvalidArgument(\n          \"Dense inputs should be a matrix but received shape \",\n          dense_list_in[i].shape().DebugString(), \" at position \", i);\n    }\n  }\n\n  // Validates batch sizes.  (Note: we do this after validating the input\n  // shapes, because CalculateBatchSize() depends on inputs having valid\n  // shapes).\n  const auto batch_size = CalculateBatchSize(shapes_list_in, dense_list_in);\n  for (int i = 0; i < size; i++) {\n    if (shapes_list_in[i].vec<int64>()(0) != batch_size) {\n      return errors::InvalidArgument(\"Expected batch size \", batch_size,\n                                     \" got \", shapes_list_in[i].vec<int64>()(0),\n                                     \" at position \", i);\n    }\n  }\n  for (int i = 0; i < dense_list_in.size(); ++i) {\n    if (dense_list_in[i].dim_size(0) != batch_size) {\n      return errors::InvalidArgument(\"Expected batch size \", batch_size,\n                                     \" got \", dense_list_in[i].dim_size(0),\n                                     \" at dense tensor \", i);\n    }\n  }\n\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void DoCompute(OpKernelContext* c) {\n    core::RefCountPtr<Var> v;\n    OP_REQUIRES_OK(c, LookupResource(c, HandleFromInput(c, 0), &v));\n    Tensor* params = v->tensor();\n    const Tensor& indices = c->input(1);\n    const Tensor& updates = c->input(2);\n\n    // Check that rank(updates.shape) = rank(indices.shape + params.shape[1:])\n    OP_REQUIRES(c,\n                updates.dims() == 0 ||\n                    updates.dims() == indices.dims() + params->dims() - 1,\n                errors::InvalidArgument(\n                    \"Must have updates.shape = indices.shape + \"\n                    \"params.shape[1:] or updates.shape = [], got \",\n                    \"updates.shape \", updates.shape().DebugString(),\n                    \", indices.shape \", indices.shape().DebugString(),\n                    \", params.shape \", params->shape().DebugString()));\n\n    // Check that we have enough index space\n    const int64_t N_big = indices.NumElements();\n    OP_REQUIRES(\n        c, N_big <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"indices has too many elements for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", N_big, \" > \",\n                                std::numeric_limits<Index>::max()));\n    const Index N = static_cast<Index>(N_big);\n    OP_REQUIRES(\n        c, params->dim_size(0) <= std::numeric_limits<Index>::max(),\n        errors::InvalidArgument(\"params.shape[0] too large for \",\n                                DataTypeString(DataTypeToEnum<Index>::v()),\n                                \" indexing: \", params->dim_size(0), \" > \",\n                                std::numeric_limits<Index>::max()));\n\n    if (N > 0) {\n      auto indices_flat = indices.flat<Index>();\n      auto params_flat = params->flat_outer_dims<T>();\n      if (TensorShapeUtils::IsScalar(updates.shape())) {\n        const auto update = updates.scalar<T>();\n\n        functor::ScatterScalarFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, update, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      } else {\n        int64_t num_updates = updates.NumElements();\n        OP_REQUIRES(\n            c, TensorShapeUtils::StartsWith(updates.shape(), indices.shape()),\n            errors::InvalidArgument(\n                \"The shape of indices (\", indices.shape().DebugString(),\n                \") must be a prefix of the shape of updates (\",\n                updates.shape().DebugString(), \")\"));\n        auto updates_flat = updates.shaped<T, 2>({N, num_updates / N});\n\n        functor::ScatterFunctor<Device, T, Index, op> functor;\n        const Index bad_i = functor(c, c->template eigen_device<Device>(),\n                                    params_flat, updates_flat, indices_flat);\n        OP_REQUIRES(c, bad_i < 0,\n                    errors::InvalidArgument(\n                        \"indices\", SliceDebugString(indices.shape(), bad_i),\n                        \" = \", indices_flat(bad_i), \" is not in [0, \",\n                        params->dim_size(0), \")\"));\n      }\n    }\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def verify(cls, message, signature, publicKey, hashfunc=sha256):\n        byteMessage = hashfunc(toBytes(message)).digest()\n        numberMessage = numberFromByteString(byteMessage)\n        curve = publicKey.curve\n        r = signature.r\n        s = signature.s\n        if not 1 <= r <= curve.N - 1:\n            return False\n        if not 1 <= s <= curve.N - 1:\n            return False\n        inv = Math.inv(s, curve.N)\n        u1 = Math.multiply(curve.G, n=(numberMessage * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)\n        u2 = Math.multiply(publicKey.point, n=(r * inv) % curve.N, N=curve.N, A=curve.A, P=curve.P)\n        add = Math.add(u1, u2, A=curve.A, P=curve.P)\n        modX = add.x % curve.N\n        return r == modX\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render_prefs_panel(self, panelid, action=None, **kwargs):  # @UnusedVariable\n        # Process the parameters.\n        profile_form = UserProfileForm(email=self.app.currentuser.email)\n        password_form = UserPasswordForm()\n        if cherrypy.request.method == 'POST':\n            if action == \"set_profile_info\":\n                self._handle_set_profile_info(action, profile_form)\n            elif action == \"set_password\":\n                self._handle_set_password(action, password_form)\n            elif action == \"update_repos\":\n                self.app.currentuser.refresh_repos(delete=True)\n                flash(_(\"Repositories successfully updated\"), level='success')\n            elif action is None:\n                pass\n            else:\n                _logger.warning(\"unknown action: %s\", action)\n                raise cherrypy.NotFound(\"Unknown action\")\n        params = {\n            'profile_form': profile_form,\n            'password_form': password_form,\n        }\n        return \"prefs_general.html\", params\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status AutoParallel::Initialize(const GrapplerItem& item) {\n  num_gpus_ = GetNumAvailableGPUs();\n  LOG(INFO) << \"Number of GPUs: \" << num_gpus_;\n  item_ = &item;\n  graph_ = item.graph;\n  LOG(INFO) << \"Original graph size: \" << graph_.node_size();\n  if (item.fetch.empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No fetch nodes provided.\");\n  }\n\n  if (item.MainVariables().empty()) {\n    return Status(error::INVALID_ARGUMENT, \"No variables provided.\");\n  }\n\n  for (const auto& init : item.init_ops) {\n    VLOG(1) << \"Init node: \" << init;\n  }\n\n  for (const auto& fetch : item.fetch) {\n    VLOG(1) << \"Fetch node: \" << fetch;\n  }\n\n  for (const auto& var : item.MainVariables()) {\n    VLOG(2) << \"Variable: \" << var->name();\n  }\n\n  const std::set<string> apply_gradients_ops = {\"ApplyGradientDescent\",\n                                                \"ApplyProximalGradientDescent\",\n                                                \"ApplyAdadelta\",\n                                                \"ApplyAdagrad\",\n                                                \"ApplyProximalAdagrad\",\n                                                \"ApplyAdagradDA\",\n                                                \"ApplyFtrl\",\n                                                \"ApplyMomentum\",\n                                                \"ApplyAdam\",\n                                                \"ApplyRMSProp\",\n                                                \"ApplyCenteredRMSProp\"};\n  for (int i = 0; i < graph_.node_size(); i++) {\n    all_nodes_.insert(\n        std::make_pair(graph_.node(i).name(), graph_.mutable_node(i)));\n    if (apply_gradients_ops.find(graph_.node(i).op()) !=\n        apply_gradients_ops.end()) {\n      apply_gradients_nodes_.insert(graph_.node(i).name());\n      VLOG(2) << \"Apply gradients node: \" << graph_.node(i).name();\n    }\n  }\n\n  auto div_const_node = AddNodeDivConst();\n  all_nodes_.insert(std::make_pair(div_const_node->name(), div_const_node));\n  std::map<string, int> gradient_pos = {{\"ApplyGradientDescent\", 2},\n                                        {\"ApplyProximalGradientDescent\", 4},\n                                        {\"ApplyAdadelta\", 6},\n                                        {\"ApplyAdagrad\", 3},\n                                        {\"ApplyProximalAdagrad\", 5},\n                                        {\"ApplyAdagradDA\", 3},\n                                        {\"ApplyFtrl\", 3},\n                                        {\"ApplyMomentum\", 3},\n                                        {\"ApplyAdam\", 9},\n                                        {\"ApplyRMSProp\", 7},\n                                        {\"ApplyCenteredRMSProp\", 8}};\n  for (const auto& apply_gradient_node_name : apply_gradients_nodes_) {\n    auto apply_gradients_op = all_nodes_[apply_gradient_node_name]->op();\n    auto apply_gradients_node = all_nodes_[apply_gradient_node_name];\n\n    auto div_node = AddNodeDiv(\n        apply_gradient_node_name,\n        apply_gradients_node->input(gradient_pos[apply_gradients_op]),\n        div_const_node->name());\n    all_nodes_.insert(std::make_pair(div_node->name(), div_node));\n    *apply_gradients_node->mutable_input(gradient_pos[apply_gradients_op]) =\n        div_node->name();\n  }\n  LOG(INFO) << \"Graph size after adding div nodes: \" << all_nodes_.size();\n\n  std::vector<const NodeDef*> train_nodes;\n  TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, item.fetch, &train_nodes));\n  LOG(INFO) << \"Number of training nodes: \" << train_nodes.size();\n\n  const NodeDef* dequeue_node = nullptr;\n  for (const auto& train_node : train_nodes) {\n    if (IsDequeueOp(*train_node)) {\n      dequeue_node = train_node;\n      break;\n    }\n  }\n\n  std::vector<const NodeDef*> input_nodes;\n  if (dequeue_node) {\n    LOG(INFO) << \"Dequeue node: \" << dequeue_node->name();\n    TF_RETURN_IF_ERROR(ComputeTransitiveFanin(graph_, {dequeue_node->name()},\n                                              {}, &input_nodes));\n  }\n  LOG(INFO) << \"Number of input nodes: \" << input_nodes.size();\n\n  std::set<string> dont_replicate_nodes;\n  for (const auto& variable : item.MainVariables()) {\n    dont_replicate_nodes.insert(variable->name());\n  }\n\n  for (const auto& init : item.init_ops) {\n    dont_replicate_nodes.insert(NodeName(init));\n  }\n\n  // Don't replicate all input nodes, except the dequeue node.\n  for (const auto& input_node : input_nodes) {\n    if (input_node->name() != dequeue_node->name()) {\n      dont_replicate_nodes.insert(input_node->name());\n    }\n  }\n\n  for (const auto& node : train_nodes) {\n    if (dont_replicate_nodes.find(node->name()) == dont_replicate_nodes.end()) {\n      replica_nodes_.insert(node->name());\n    }\n  }\n  LOG(INFO) << \"Number of replica nodes: \" << replica_nodes_.size();\n\n  for (const auto& node : all_nodes_) {\n    if (replica_nodes_.find(node.first) == replica_nodes_.end()) {\n      shared_nodes_.insert(node.first);\n    }\n  }\n  LOG(INFO) << \"Number of shared nodes: \" << shared_nodes_.size();\n  return Status::OK();\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _execute_helper(\n        self,\n        query: str,\n        timeout: int = 0,\n        statement_params: dict[str, str] | None = None,\n        binding_params: tuple | dict[str, dict[str, str]] = None,\n        binding_stage: str | None = None,\n        is_internal: bool = False,\n        describe_only: bool = False,\n        _no_results: bool = False,\n        _is_put_get=None,\n        _no_retry: bool = False,\n    ):\n        del self.messages[:]\n\n        if statement_params is not None and not isinstance(statement_params, dict):\n            Error.errorhandler_wrapper(\n                self.connection,\n                self,\n                ProgrammingError,\n                {\n                    \"msg\": \"The data type of statement params is invalid. It must be dict.\",\n                    \"errno\": ER_INVALID_VALUE,\n                },\n            )\n\n        # check if current installation include arrow extension or not,\n        # if not, we set statement level query result format to be JSON\n        if not CAN_USE_ARROW_RESULT_FORMAT:\n            logger.debug(\"Cannot use arrow result format, fallback to json format\")\n            if statement_params is None:\n                statement_params = {\n                    PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT: \"JSON\"\n                }\n            else:\n                result_format_val = statement_params.get(\n                    PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT\n                )\n                if str(result_format_val).upper() == \"ARROW\":\n                    self.check_can_use_arrow_resultset()\n                elif result_format_val is None:\n                    statement_params[\n                        PARAMETER_PYTHON_CONNECTOR_QUERY_RESULT_FORMAT\n                    ] = \"JSON\"\n\n        self._sequence_counter = self._connection._next_sequence_counter()\n        self._request_id = uuid.uuid4()\n\n        logger.debug(f\"Request id: {self._request_id}\")\n\n        logger.debug(\"running query [%s]\", self._format_query_for_log(query))\n        if _is_put_get is not None:\n            # if told the query is PUT or GET, use the information\n            self._is_file_transfer = _is_put_get\n        else:\n            # or detect it.\n            self._is_file_transfer = get_file_transfer_type(query) is not None\n        logger.debug(\"is_file_transfer: %s\", self._is_file_transfer is not None)\n\n        real_timeout = (\n            timeout if timeout and timeout > 0 else self._connection.network_timeout\n        )\n\n        if real_timeout is not None:\n            self._timebomb = Timer(real_timeout, self.__cancel_query, [query])\n            self._timebomb.start()\n            logger.debug(\"started timebomb in %ss\", real_timeout)\n        else:\n            self._timebomb = None\n\n        original_sigint = signal.getsignal(signal.SIGINT)\n\n        def interrupt_handler(*_):  # pragma: no cover\n            try:\n                signal.signal(signal.SIGINT, exit_handler)\n            except (ValueError, TypeError):\n                # ignore failures\n                pass\n            try:\n                if self._timebomb is not None:\n                    self._timebomb.cancel()\n                    logger.debug(\"cancelled timebomb in finally\")\n                    self._timebomb = None\n                self.__cancel_query(query)\n            finally:\n                if original_sigint:\n                    try:\n                        signal.signal(signal.SIGINT, original_sigint)\n                    except (ValueError, TypeError):\n                        # ignore failures\n                        pass\n            raise KeyboardInterrupt\n\n        try:\n            if not original_sigint == exit_handler:\n                signal.signal(signal.SIGINT, interrupt_handler)\n        except ValueError:  # pragma: no cover\n            logger.debug(\n                \"Failed to set SIGINT handler. \" \"Not in main thread. Ignored...\"\n            )\n        ret = {\"data\": {}}\n        try:\n            ret = self._connection.cmd_query(\n                query,\n                self._sequence_counter,\n                self._request_id,\n                binding_params=binding_params,\n                binding_stage=binding_stage,\n                is_file_transfer=bool(self._is_file_transfer),\n                statement_params=statement_params,\n                is_internal=is_internal,\n                describe_only=describe_only,\n                _no_results=_no_results,\n                _no_retry=_no_retry,\n            )\n        finally:\n            try:\n                if original_sigint:\n                    signal.signal(signal.SIGINT, original_sigint)\n            except (ValueError, TypeError):  # pragma: no cover\n                logger.debug(\n                    \"Failed to reset SIGINT handler. Not in main \" \"thread. Ignored...\"\n                )\n            if self._timebomb is not None:\n                self._timebomb.cancel()\n                logger.debug(\"cancelled timebomb in finally\")\n\n        if \"data\" in ret and \"parameters\" in ret[\"data\"]:\n            parameters = ret[\"data\"][\"parameters\"]\n            # Set session parameters for cursor object\n            for kv in parameters:\n                if \"TIMESTAMP_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_output_format = kv[\"value\"]\n                if \"TIMESTAMP_NTZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_ntz_output_format = kv[\"value\"]\n                if \"TIMESTAMP_LTZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_ltz_output_format = kv[\"value\"]\n                if \"TIMESTAMP_TZ_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._timestamp_tz_output_format = kv[\"value\"]\n                if \"DATE_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._date_output_format = kv[\"value\"]\n                if \"TIME_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._time_output_format = kv[\"value\"]\n                if \"TIMEZONE\" in kv[\"name\"]:\n                    self._timezone = kv[\"value\"]\n                if \"BINARY_OUTPUT_FORMAT\" in kv[\"name\"]:\n                    self._binary_output_format = kv[\"value\"]\n            # Set session parameters for connection object\n            self._connection._update_parameters(\n                {p[\"name\"]: p[\"value\"] for p in parameters}\n            )\n\n        self.query = query\n        self._sequence_counter = -1\n        return ret\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const int64 axis_input = context->input(0).scalar<int64>()();\n    const Tensor& input_indices = context->input(1);\n    const Tensor& input_values = context->input(2);\n    const Tensor& input_shape = context->input(3);\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices.shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values.shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_indices.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape.shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape.shape().DebugString()));\n\n    const int64 input_rank = input_shape.vec<int64>().size();\n    const int64 axis = (axis_input < 0) ? input_rank + axis_input : axis_input;\n\n    OP_REQUIRES(\n        context, axis >= 0 && axis < input_rank,\n        errors::InvalidArgument(\"Input axis should be in range [\", -input_rank,\n                                \", \", input_rank, \"), got \", axis_input));\n\n    OP_REQUIRES(context,\n                num_split_ >= 1 && num_split_ <= input_shape.vec<int64>()(axis),\n                errors::InvalidArgument(\"Input num_split should be between 1 \"\n                                        \"and the splitting dimension size (\",\n                                        input_shape.vec<int64>()(axis),\n                                        \"), got \", num_split_));\n\n    // Prevent overflow by constructing the dense shape separately\n    TensorShape dense_shape;\n    const auto input_shape_flat = input_shape.flat<int64>();\n    for (int i = 0; i < input_shape.NumElements(); i++) {\n      OP_REQUIRES_OK(context,\n                     dense_shape.AddDimWithStatus(input_shape_flat(i)));\n    }\n\n    sparse::SparseTensor sparse_tensor;\n    OP_REQUIRES_OK(context,\n                   sparse::SparseTensor::Create(input_indices, input_values,\n                                                dense_shape, &sparse_tensor));\n\n    std::vector<sparse::SparseTensor> outputs;\n    OP_REQUIRES_OK(context, sparse::SparseTensor::Split<T>(\n                                sparse_tensor, axis, num_split_, &outputs));\n\n    for (int slice_index = 0; slice_index < num_split_; ++slice_index) {\n      context->set_output(slice_index, outputs[slice_index].indices());\n      context->set_output(slice_index + num_split_,\n                          outputs[slice_index].values());\n      Tensor* shape = nullptr;\n      OP_REQUIRES_OK(context, context->allocate_output(\n                                  slice_index + 2 * num_split_,\n                                  {outputs[slice_index].dims()}, &shape));\n      auto output_shape = outputs[slice_index].shape();\n      for (int dim = 0; dim < outputs[slice_index].dims(); ++dim) {\n        shape->vec<int64>()(dim) = output_shape[dim];\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def kickban(bot, trigger):\n    \"\"\"Kick and ban a user from the channel. The bot must be a channel operator for this command to work.\"\"\"\n    chanops = get_chanops(str(trigger.sender), bot.memory['channelmgnt']['jdcache'])\n    dodeop = False\n    if chanops:\n        if bot.channels[trigger.sender].privileges[bot.nick] < OP and trigger.account in chanops:\n            bot.say('Please wait...')\n            bot.say('op ' + trigger.sender, 'ChanServ')\n            time.sleep(1)\n            dodeop = True\n        text = trigger.group().split()\n        argc = len(text)\n        if argc < 3:\n            bot.reply('Syntax is: .kickban <nick> <reason>')\n            if dodeop:\n                deopbot(trigger.sender, bot)\n            return\n        nick = Identifier(text[1])\n        if ',' in str(nick):\n            return bot.reply('Unable to kickban. Kickbanning multiple users is not allowed.')\n        if '#' in str(nick):\n            return bot.reply('Unable to kickban. Use of # when kickbanning is not expected.')\n        mask = text[2] if any(s in text[2] for s in '!@*') else ''\n        reasonidx = 3 if mask != '' else 2\n        reason = ' '.join(text[reasonidx:])\n        mask = parse_host_mask(trigger.group().split())\n        if mask == '':\n            mask = nick + '!*@*'\n        if trigger.account in chanops:\n            bot.write(['MODE', trigger.sender, '+b', mask])\n            bot.write(['KICK', trigger.sender, nick, ':' + reason])\n            if dodeop:\n                deopbot(trigger.sender, bot)\n        else:\n            bot.reply('Access Denied. If in error, please contact the channel founder.')\n    else:\n        bot.reply(f'No ChanOps Found. Please ask for assistance in {bot.settings.channelmgnt.support_channel}')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def on_POST(\n        self, request: SynapseRequest, room_id: str, receipt_type: str, event_id: str\n    ) -> Tuple[int, JsonDict]:\n        requester = await self.auth.get_user_by_req(request)\n\n        if not RoomID.is_valid(room_id) or not event_id.startswith(EventID.SIGIL):\n            raise SynapseError(400, \"A valid room ID and event ID must be specified\")\n\n        if receipt_type not in self._known_receipt_types:\n            raise SynapseError(\n                400,\n                f\"Receipt type must be {', '.join(self._known_receipt_types)}\",\n            )\n\n        body = parse_json_object_from_request(request)\n\n        # Pull the thread ID, if one exists.\n        thread_id = None\n        if \"thread_id\" in body:\n            thread_id = body.get(\"thread_id\")\n            if not thread_id or not isinstance(thread_id, str):\n                raise SynapseError(\n                    400,\n                    \"thread_id field must be a non-empty string\",\n                    Codes.INVALID_PARAM,\n                )\n\n            if receipt_type == ReceiptTypes.FULLY_READ:\n                raise SynapseError(\n                    400,\n                    f\"thread_id is not compatible with {ReceiptTypes.FULLY_READ} receipts.\",\n                    Codes.INVALID_PARAM,\n                )\n\n            # Ensure the event ID roughly correlates to the thread ID.\n            if not await self._is_event_in_thread(event_id, thread_id):\n                raise SynapseError(\n                    400,\n                    f\"event_id {event_id} is not related to thread {thread_id}\",\n                    Codes.INVALID_PARAM,\n                )\n\n        await self.presence_handler.bump_presence_active_time(\n            requester.user, requester.device_id\n        )\n\n        if receipt_type == ReceiptTypes.FULLY_READ:\n            await self.read_marker_handler.received_client_read_marker(\n                room_id,\n                user_id=requester.user.to_string(),\n                event_id=event_id,\n            )\n        else:\n            await self.receipts_handler.received_client_receipt(\n                room_id,\n                receipt_type,\n                user_id=requester.user,\n                event_id=event_id,\n                thread_id=thread_id,\n            )\n\n        return 200, {}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& image = context->input(0);\n    OP_REQUIRES(context, image.dims() == 3,\n                errors::InvalidArgument(\"image must be 3-dimensional\",\n                                        image.shape().DebugString()));\n    OP_REQUIRES(context, image.NumElements() > 0,\n                errors::Internal(\"Invalid image provided.\"));\n    OP_REQUIRES(\n        context,\n        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n        errors::InvalidArgument(\"image cannot have >= int32 max elements\"));\n    const int32 height = static_cast<int32>(image.dim_size(0));\n    const int32 width = static_cast<int32>(image.dim_size(1));\n    const int32 channels = static_cast<int32>(image.dim_size(2));\n\n    // In some cases, we pass width*channels*2 to png.\n    const int32 max_row_width = std::numeric_limits<int32>::max() / 2;\n\n    OP_REQUIRES(context, FastBoundsCheck(width * channels, max_row_width),\n                errors::InvalidArgument(\"image too wide to encode\"));\n\n    OP_REQUIRES(context, channels >= 1 && channels <= 4,\n                errors::InvalidArgument(\n                    \"image must have 1, 2, 3, or 4 channels, got \", channels));\n\n    // Encode image to png string\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(0, TensorShape({}), &output));\n    if (desired_channel_bits_ == 8) {\n      OP_REQUIRES(context,\n                  png::WriteImageToBuffer(\n                      image.flat<uint8>().data(), width, height,\n                      width * channels, channels, desired_channel_bits_,\n                      compression_, &output->scalar<tstring>()(), nullptr),\n                  errors::Internal(\"PNG encoding failed\"));\n    } else {\n      OP_REQUIRES(context,\n                  png::WriteImageToBuffer(\n                      image.flat<uint16>().data(), width, height,\n                      width * channels * 2, channels, desired_channel_bits_,\n                      compression_, &output->scalar<tstring>()(), nullptr),\n                  errors::Internal(\"PNG encoding failed\"));\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, sydent):\n        self.sydent = sydent\n        # The default endpoint factory in Twisted 14.0.0 (which we require) uses the\n        # BrowserLikePolicyForHTTPS context factory which will do regular cert validation\n        # 'like a browser'\n        self.agent = Agent(\n            BlacklistingReactorWrapper(\n                reactor=self.sydent.reactor,\n                ip_whitelist=sydent.ip_whitelist,\n                ip_blacklist=sydent.ip_blacklist,\n            ),\n            connectTimeout=15,\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _update_load_status(self, ok: bool) -> None:\n        \"\"\"Update the load status after a page finished loading.\n\n        Needs to be called by subclasses to trigger a load status update, e.g.\n        as a response to a loadFinished signal.\n        \"\"\"\n        if ok:\n            if self.url().scheme() == 'https':\n                if self.url().host() in self._insecure_hosts:\n                    self._set_load_status(usertypes.LoadStatus.warn)\n                else:\n                    self._set_load_status(usertypes.LoadStatus.success_https)\n            else:\n                self._set_load_status(usertypes.LoadStatus.success)\n        elif ok:\n            self._set_load_status(usertypes.LoadStatus.warn)\n        else:\n            self._set_load_status(usertypes.LoadStatus.error)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def on_incoming_transaction(self, origin, transaction_data):\n        # keep this as early as possible to make the calculated origin ts as\n        # accurate as possible.\n        request_time = self._clock.time_msec()\n\n        transaction = Transaction(**transaction_data)\n\n        if not transaction.transaction_id:\n            raise Exception(\"Transaction missing transaction_id\")\n\n        logger.debug(\"[%s] Got transaction\", transaction.transaction_id)\n\n        # use a linearizer to ensure that we don't process the same transaction\n        # multiple times in parallel.\n        with (yield self._transaction_linearizer.queue(\n                (origin, transaction.transaction_id),\n        )):\n            result = yield self._handle_incoming_transaction(\n                origin, transaction, request_time,\n            )\n\n        defer.returnValue(result)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _task_executor(self):\r\n        \"\"\"Worker that executes Tasks that have satisfied dependencies.\"\"\"\r\n        # this event blocks until the TaskGraph has signaled ready to execute\r\n        self._taskgraph_started_event.wait()\r\n        while True:\r\n            # this event blocks until the task graph has signaled it wants\r\n            # the executors to read the state of the queue or a stop event or\r\n            # a timeout exceeded just to protect against a worst case deadlock\r\n            self._executor_ready_event.wait(_MAX_TIMEOUT)\r\n            # this lock synchronizes changes between the queue and\r\n            # executor_ready_event\r\n            if self._terminated:\r\n                LOGGER.debug(\r\n                    \"taskgraph is terminated, ending %s\",\r\n                    threading.currentThread())\r\n                break\r\n            task = None\r\n            try:\r\n                task = self._task_ready_priority_queue.get_nowait()\r\n                self._task_waiting_count -= 1\r\n                task_name_time_tuple = (task.task_name, time.time())\r\n                self._active_task_list.append(task_name_time_tuple)\r\n            except queue.Empty:\r\n                # no tasks are waiting could be because the taskgraph is\r\n                # closed or because the queue is just empty.\r\n                if self._closed and not self._task_dependent_map:\r\n                    # the task graph is signaling executors to stop,\r\n                    # since the self._task_dependent_map is empty the\r\n                    # executor can terminate.\r\n                    LOGGER.debug(\r\n                        \"no tasks are pending and taskgraph closed, normally \"\r\n                        \"terminating executor %s.\" % threading.currentThread())\r\n                    break\r\n                else:\r\n                    # there's still the possibility for work to be added or\r\n                    # still work in the pipeline\r\n                    self._executor_ready_event.clear()\r\n            if task is None:\r\n                continue\r\n            try:\r\n                task._call()\r\n                task.task_done_executing_event.set()\r\n            except Exception as e:\r\n                # An error occurred on a call, terminate the taskgraph\r\n                task.exception_object = e\r\n                LOGGER.exception(\r\n                    'A taskgraph _task_executor failed on Task '\r\n                    '%s. Terminating taskgraph.', task.task_name)\r\n                self._terminate()\r\n                break\r\n\r\n            LOGGER.debug(\r\n                \"task %s is complete, checking to see if any dependent \"\r\n                \"tasks can be executed now\", task.task_name)\r\n            self._completed_task_names.add(task.task_name)\r\n            self._active_task_list.remove(task_name_time_tuple)\r\n            for waiting_task_name in (\r\n                    self._task_dependent_map[task.task_name]):\r\n                # remove `task` from the set of tasks that\r\n                # `waiting_task` was waiting on.\r\n                self._dependent_task_map[waiting_task_name].remove(\r\n                    task.task_name)\r\n                # if there aren't any left, we can push `waiting_task`\r\n                # to the work queue\r\n                if not self._dependent_task_map[waiting_task_name]:\r\n                    # if we removed the last task we can put it to the\r\n                    # work queue\r\n                    LOGGER.debug(\r\n                        \"Task %s is ready for processing, sending to \"\r\n                        \"task_ready_priority_queue\",\r\n                        waiting_task_name)\r\n                    del self._dependent_task_map[waiting_task_name]\r\n                    self._task_ready_priority_queue.put(\r\n                        self._task_name_map[waiting_task_name])\r\n                    self._task_waiting_count += 1\r\n                    # indicate to executors there is work to do\r\n                    self._executor_ready_event.set()\r\n            del self._task_dependent_map[task.task_name]\r\n            # this extra set ensures that recently emptied map won't get\r\n            # ignored by the exeuctor if no work is left to do and the graph is\r\n            # closed\r\n            self._executor_ready_event.set()\r\n            LOGGER.debug(\"task %s done processing\", task.task_name)\r\n        LOGGER.debug(\"task executor shutting down\")\r\n\r"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def run(self, login_url='/login/', logout_url='/logout', persistent_timeout=43200, absolute_timeout=30):\n        \"\"\"\n        A tool that verify if the session is associated to a user by tracking\n        a session key. If session is not authenticated, redirect user to login page.\n        \"\"\"\n        request = cherrypy.serving.request\n        # Skip execution of this tools when browsing the login page.\n        if request.path_info == login_url:\n            if self._is_login():\n                raise cherrypy.HTTPRedirect('/')\n            return\n\n        # Clear session when browsing /logout\n        if request.path_info == logout_url or request.path_info.startswith(logout_url):\n            if request.method != 'POST':\n                raise cherrypy.HTTPError(405)\n            self.logout()\n            raise cherrypy.HTTPRedirect('/')\n\n        # Check if login\n        if not self._is_login():\n            # Store original URL\n            self._set_redirect_url()\n            # And redirect to login page\n            raise cherrypy.HTTPRedirect(login_url)\n\n        self._update_session_timeout()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def kick(bot, trigger):\n    \"\"\"Kick a user from the channel.\"\"\"\n    chanops = get_chanops(str(trigger.sender), bot.memory['channelmgnt']['jdcache'])\n    dodeop = False\n    if chanops:\n        if bot.channels[trigger.sender].privileges[bot.nick] < OP and trigger.account in chanops:\n            bot.say('Please wait...')\n            bot.say('op ' + trigger.sender, 'ChanServ')\n            time.sleep(1)\n            dodeop = True\n        text = trigger.group().split()\n        argc = len(text)\n        if argc < 2:\n            return\n        nick = Identifier(text[1])\n        reason = ' '.join(text[2:])\n        if ',' in str(nick):\n            return bot.reply('Unable to kick. Kicking multiple users is not allowed.')\n        if '#' in str(nick):\n            return bot.reply('Unable to kick. Use of # when kicking is not expected.')\n        if nick != bot.config.core.nick and trigger.account in chanops:\n            bot.write(['KICK', trigger.sender, nick, ':' + reason])\n            if dodeop:\n                deopbot(trigger.sender, bot)\n        else:\n            bot.reply('Access Denied. If in error, please contact the channel founder.')\n    else:\n        bot.reply(f'No ChanOps Found. Please ask for assistance in {bot.settings.channelmgnt.support_channel}')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def eval(expression, _dict={}, **kw):\n    \"\"\"\n    Evaluates an image expression.\n\n    :param expression: A string containing a Python-style expression.\n    :param options: Values to add to the evaluation context.  You\n                    can either use a dictionary, or one or more keyword\n                    arguments.\n    :return: The evaluated expression. This is usually an image object, but can\n             also be an integer, a floating point value, or a pixel tuple,\n             depending on the expression.\n    \"\"\"\n\n    # build execution namespace\n    args = ops.copy()\n    args.update(_dict)\n    args.update(kw)\n    for k, v in list(args.items()):\n        if hasattr(v, \"im\"):\n            args[k] = _Operand(v)\n\n    code = compile(expression, \"<string>\", \"eval\")\n    for name in code.co_names:\n        if name not in args and name != \"abs\":\n            raise ValueError(f\"'{name}' not allowed\")\n\n    out = builtins.eval(expression, {\"__builtins\": {\"abs\": abs}}, args)\n    try:\n        return out.im\n    except AttributeError:\n        return out\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, dst_path=None) -> str:\n        \"\"\"\n        Downloads the dataset source to the local filesystem.\n\n        :param dst_path: Path of the local filesystem destination directory to which to download the\n                         dataset source. If the directory does not exist, it is created. If\n                         unspecified, the dataset source is downloaded to a new uniquely-named\n                         directory on the local filesystem.\n        :return: The path to the downloaded dataset source on the local filesystem.\n        \"\"\"\n        resp = cloud_storage_http_request(\n            method=\"GET\",\n            url=self.url,\n            stream=True,\n        )\n        augmented_raise_for_status(resp)\n\n        basename = self._extract_filename(resp)\n\n        if not basename:\n            basename = \"dataset_source\"\n\n        if dst_path is None:\n            dst_path = create_tmp_dir()\n\n        dst_path = os.path.join(dst_path, basename)\n        with open(dst_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                f.write(chunk)\n\n        return dst_path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if not url:\n        return False\n    url_info = urllib_parse.urlparse(url)\n    return (not url_info.netloc or url_info.netloc == host) and \\\n        (not url_info.scheme or url_info.scheme in ['http', 'https'])\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def getlength(self, text, mode=\"\", direction=None, features=None, language=None):\n        \"\"\"\n        Returns length (in pixels with 1/64 precision) of given text when rendered\n        in font with provided direction, features, and language.\n\n        This is the amount by which following text should be offset.\n        Text bounding box may extend past the length in some fonts,\n        e.g. when using italics or accents.\n\n        The result is returned as a float; it is a whole number if using basic layout.\n\n        Note that the sum of two lengths may not equal the length of a concatenated\n        string due to kerning. If you need to adjust for kerning, include the following\n        character and subtract its length.\n\n        For example, instead of ::\n\n          hello = font.getlength(\"Hello\")\n          world = font.getlength(\"World\")\n          hello_world = hello + world  # not adjusted for kerning\n          assert hello_world == font.getlength(\"HelloWorld\")  # may fail\n\n        use ::\n\n          hello = font.getlength(\"HelloW\") - font.getlength(\"W\")  # adjusted for kerning\n          world = font.getlength(\"World\")\n          hello_world = hello + world  # adjusted for kerning\n          assert hello_world == font.getlength(\"HelloWorld\")  # True\n\n        or disable kerning with (requires libraqm) ::\n\n          hello = draw.textlength(\"Hello\", font, features=[\"-kern\"])\n          world = draw.textlength(\"World\", font, features=[\"-kern\"])\n          hello_world = hello + world  # kerning is disabled, no need to adjust\n          assert hello_world == draw.textlength(\"HelloWorld\", font, features=[\"-kern\"])\n\n        .. versionadded:: 8.0.0\n\n        :param text: Text to measure.\n        :param mode: Used by some graphics drivers to indicate what mode the\n                     driver prefers; if empty, the renderer may return either\n                     mode. Note that the mode is always a string, to simplify\n                     C-level implementations.\n\n        :param direction: Direction of the text. It can be 'rtl' (right to\n                          left), 'ltr' (left to right) or 'ttb' (top to bottom).\n                          Requires libraqm.\n\n        :param features: A list of OpenType font features to be used during text\n                         layout. This is usually used to turn on optional\n                         font features that are not enabled by default,\n                         for example 'dlig' or 'ss01', but can be also\n                         used to turn off default font features for\n                         example '-liga' to disable ligatures or '-kern'\n                         to disable kerning.  To get all supported\n                         features, see\n                         https://learn.microsoft.com/en-us/typography/opentype/spec/featurelist\n                         Requires libraqm.\n\n        :param language: Language of the text. Different languages may use\n                         different glyph shapes or ligatures. This parameter tells\n                         the font which language the text is in, and to apply the\n                         correct substitutions as appropriate, if available.\n                         It should be a `BCP 47 language code\n                         <https://www.w3.org/International/articles/language-tags/>`_\n                         Requires libraqm.\n\n        :return: Width for horizontal, height for vertical text.\n        \"\"\"\n        _string_length_check(text)\n        return self.font.getlength(text, mode, direction, features, language) / 64\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def secureModule(mname, *imp):\n    modsec = _moduleSecurity.get(mname, None)\n    if modsec is None:\n        if mname in _appliedModuleSecurity:\n            return sys.modules[mname]\n        return  # no MSI, no module\n\n    if imp:\n        __import__(mname, *imp)\n    module = sys.modules[mname]\n    modsec.apply(module.__dict__)\n    _appliedModuleSecurity[mname] = modsec\n    try:\n        del _moduleSecurity[mname]\n    except KeyError:\n        # In case of access from multiple threads, the del might fail, but that\n        # is OK.\n        pass\n    return module\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "      void context.ready.then(async () => {\n        const file = context.model;\n        const workspace = file.toJSON() as unknown as Workspace.IWorkspace;\n        const path = context.path;\n        const id = workspace.metadata.id;\n\n        // Save the file contents as a workspace.\n        await this._workspaces.save(id, workspace);\n\n        // Save last save location for the save command.\n        await this._state.save(LAST_SAVE_ID, path);\n\n        // Navigate to new workspace.\n        const workspacesBase = URLExt.join(this._application, 'workspaces');\n        const url = URLExt.join(workspacesBase, id);\n        if (!workspacesBase.startsWith(url)) {\n          throw new Error('Can only be used for workspaces');\n        }\n        if (this._router) {\n          this._router.navigate(url, { hard: true });\n        } else {\n          document.location.href = url;\n        }\n      });\n      return dummyWidget(context);"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def add_ordering(self, *ordering):\n        \"\"\"\n        Add items from the 'ordering' sequence to the query's \"order by\"\n        clause. These items are either field names (not column names) --\n        possibly with a direction prefix ('-' or '?') -- or OrderBy\n        expressions.\n\n        If 'ordering' is empty, clear all ordering from the query.\n        \"\"\"\n        errors = []\n        for item in ordering:\n            if isinstance(item, str):\n                if '.' in item and ORDER_PATTERN.match(item):\n                    warnings.warn(\n                        'Passing column raw column aliases to order_by() is '\n                        'deprecated. Wrap %r in a RawSQL expression before '\n                        'passing it to order_by().' % item,\n                        category=RemovedInDjango40Warning,\n                        stacklevel=3,\n                    )\n                    continue\n                if item == '?':\n                    continue\n                if item.startswith('-'):\n                    item = item[1:]\n                if item in self.annotations:\n                    continue\n                if self.extra and item in self.extra:\n                    continue\n                # names_to_path() validates the lookup. A descriptive\n                # FieldError will be raise if it's not.\n                self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)\n            elif not hasattr(item, 'resolve_expression'):\n                errors.append(item)\n            if getattr(item, 'contains_aggregate', False):\n                raise FieldError(\n                    'Using an aggregate in order_by() without also including '\n                    'it in annotate() is not allowed: %s' % item\n                )\n        if errors:\n            raise FieldError('Invalid order_by arguments: %s' % errors)\n        if ordering:\n            self.order_by += ordering\n        else:\n            self.default_ordering = False\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    const string& name = handle.scalar<tstring>()();\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"DeleteSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->DeleteTensor(name));\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def from_unix_seconds(seconds: Union[int, float]) -> datetime:\n    if seconds > MAX_NUMBER:\n        return datetime.max\n    elif seconds < -MAX_NUMBER:\n        return datetime.min\n\n    while abs(seconds) > MS_WATERSHED:\n        seconds /= 1000\n    dt = EPOCH + timedelta(seconds=seconds)\n    return dt.replace(tzinfo=timezone.utc)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def match(self, path):\n        match = (\n            self.regex.fullmatch(path)\n            if self._is_endpoint and self.regex.pattern.endswith('$')\n            else self.regex.search(path)\n        )\n        if match:\n            # If there are any named groups, use those as kwargs, ignoring\n            # non-named groups. Otherwise, pass all non-named arguments as\n            # positional arguments.\n            kwargs = match.groupdict()\n            args = () if kwargs else match.groups()\n            kwargs = {k: v for k, v in kwargs.items() if v is not None}\n            return path[match.end():], args, kwargs\n        return None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static Status ParseEquation(const string& equation,\n                              OperandLabels* input_labels,\n                              Labels* output_labels,\n                              std::vector<DimensionType>* label_types,\n                              OperandLabelCounts* input_label_counts,\n                              LabelCounts* output_label_counts,\n                              gtl::InlinedVector<bool, 2>* input_has_ellipsis,\n                              bool* output_has_ellipsis) {\n    gtl::InlinedVector<string, 2> input_str;\n    string output_str;\n    TF_RETURN_IF_ERROR(ParseEinsumEquation(equation, &input_str, &output_str));\n\n    // Temporary map from single character labels to (consecutive) integer\n    // labels.\n    absl::flat_hash_map<char, int> label_mapping;\n    int num_inputs = input_str.size();\n    input_labels->resize(num_inputs);\n\n    // Map from single characters to integer labels.\n    for (int i = 0; i < num_inputs; ++i) {\n      MapToLabels(input_str[i], &input_labels->at(i), &label_mapping);\n    }\n    MapToLabels(output_str, output_labels, &label_mapping);\n\n    // Compute counts for input and output labels.\n    int num_labels = label_mapping.size();\n    input_label_counts->resize(num_inputs);\n    input_has_ellipsis->resize(num_inputs);\n    for (int i = 0; i < num_inputs; ++i) {\n      input_label_counts->at(i).resize(num_labels);\n      input_has_ellipsis->at(i) = false;\n      for (const int label : input_labels->at(i)) {\n        if (label != kEllipsisLabel)\n          input_label_counts->at(i)[label] += 1;\n        else\n          input_has_ellipsis->at(i) = true;\n      }\n    }\n    output_label_counts->resize(num_labels);\n    *output_has_ellipsis = false;\n    for (const int label : *output_labels) {\n      if (label != kEllipsisLabel)\n        output_label_counts->at(label) += 1;\n      else\n        *output_has_ellipsis = true;\n    }\n\n    // Map each label to a unique DimensionType.\n    label_types->resize(num_labels);\n    for (int label = 0; label < num_labels; ++label) {\n      if (label == kEllipsisLabel) continue;\n      bool removed = (*output_label_counts)[label] == 0;\n      bool unique = num_inputs == 1 || (*input_label_counts)[0][label] == 0 ||\n                    (*input_label_counts)[1][label] == 0;\n      (*label_types)[label] = GetDimensionType(removed, unique);\n    }\n    return Status::OK();\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def Ghostscript(tile, size, fp, scale=1):\n    \"\"\"Render an image using Ghostscript\"\"\"\n\n    # Unpack decoder tile\n    decoder, tile, offset, data = tile[0]\n    length, bbox = data\n\n    #Hack to support hi-res rendering\n    scale = int(scale) or 1\n    orig_size = size\n    orig_bbox = bbox\n    size = (size[0] * scale, size[1] * scale)\n    bbox = [bbox[0], bbox[1], bbox[2] * scale, bbox[3] * scale]\n    #print(\"Ghostscript\", scale, size, orig_size, bbox, orig_bbox)\n\n    import tempfile, os, subprocess\n\n    out_fd, file = tempfile.mkstemp()\n    os.close(out_fd)\n\n    # Build ghostscript command\n    command = [\"gs\",\n               \"-q\",                    # quite mode\n               \"-g%dx%d\" % size,        # set output geometry (pixels)\n               \"-r%d\" % (72*scale),     # set input DPI (dots per inch)\n               \"-dNOPAUSE -dSAFER\",     # don't pause between pages, safe mode\n               \"-sDEVICE=ppmraw\",       # ppm driver\n               \"-sOutputFile=%s\" % file,# output file\n            ]\n\n    if gs_windows_binary is not None:\n        if gs_windows_binary is False:\n            raise WindowsError('Unable to locate Ghostscript on paths')\n        command[0] = gs_windows_binary\n\n    # push data through ghostscript\n    try:\n        gs = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        # adjust for image origin\n        if bbox[0] != 0 or bbox[1] != 0:\n            gs.stdin.write((\"%d %d translate\\n\" % (-bbox[0], -bbox[1])).encode('ascii'))\n        fp.seek(offset)\n        while length > 0:\n            s = fp.read(8192)\n            if not s:\n                break\n            length = length - len(s)\n            gs.stdin.write(s)\n        gs.stdin.close()\n        status = gs.wait()\n        if status:\n            raise IOError(\"gs failed (status %d)\" % status)\n        im = Image.core.open_ppm(file)\n    finally:\n        try: os.unlink(file)\n        except: pass\n\n    return im\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def render_POST(self, request):\n        send_cors(request)\n\n        args = get_args(request, (\"medium\", \"address\", \"room_id\", \"sender\",))\n        medium = args[\"medium\"]\n        address = args[\"address\"]\n        roomId = args[\"room_id\"]\n        sender = args[\"sender\"]\n\n        verified_sender = None\n        if self.require_auth:\n            account = authV2(self.sydent, request)\n            verified_sender = sender\n            if account.userId != sender:\n                raise MatrixRestError(403, \"M_UNAUTHORIZED\", \"'sender' doesn't match\")\n\n        globalAssocStore = GlobalAssociationStore(self.sydent)\n        mxid = globalAssocStore.getMxid(medium, address)\n        if mxid:\n            request.setResponseCode(400)\n            return {\n                \"errcode\": \"M_THREEPID_IN_USE\",\n                \"error\": \"Binding already known\",\n                \"mxid\": mxid,\n            }\n\n        if medium != \"email\":\n            request.setResponseCode(400)\n            return {\n                \"errcode\": \"M_UNRECOGNIZED\",\n                \"error\": \"Didn't understand medium '%s'\" % (medium,),\n            }\n\n        if not (0 < len(address) <= MAX_EMAIL_ADDRESS_LENGTH):\n            request.setResponseCode(400)\n            return {\n                'errcode': 'M_INVALID_PARAM',\n                'error': 'Invalid email provided'\n            }\n\n        token = self._randomString(128)\n\n        tokenStore = JoinTokenStore(self.sydent)\n\n        ephemeralPrivateKey = nacl.signing.SigningKey.generate()\n        ephemeralPublicKey = ephemeralPrivateKey.verify_key\n\n        ephemeralPrivateKeyBase64 = encode_base64(ephemeralPrivateKey.encode(), True)\n        ephemeralPublicKeyBase64 = encode_base64(ephemeralPublicKey.encode(), True)\n\n        tokenStore.storeEphemeralPublicKey(ephemeralPublicKeyBase64)\n        tokenStore.storeToken(medium, address, roomId, sender, token)\n\n        # Variables to substitute in the template.\n        substitutions = {}\n        # Include all arguments sent via the request.\n        for k, v in args.items():\n            if isinstance(v, string_types):\n                substitutions[k] = v\n        substitutions[\"token\"] = token\n\n        # Substitutions that the template requires, but are optional to provide\n        # to the API.\n        extra_substitutions = [\n            'sender_display_name',\n            'token',\n            'room_name',\n            'bracketed_room_name',\n            'room_avatar_url',\n            'sender_avatar_url',\n            'guest_user_id',\n            'guest_access_token',\n        ]\n        for k in extra_substitutions:\n            substitutions.setdefault(k, '')\n\n        substitutions[\"bracketed_verified_sender\"] = \"\"\n        if verified_sender:\n            substitutions[\"bracketed_verified_sender\"] = \"(%s) \" % (verified_sender,)\n\n        substitutions[\"ephemeral_private_key\"] = ephemeralPrivateKeyBase64\n        if substitutions[\"room_name\"] != '':\n            substitutions[\"bracketed_room_name\"] = \"(%s) \" % substitutions[\"room_name\"]\n\n        substitutions[\"web_client_location\"] = self.sydent.default_web_client_location\n        if 'org.matrix.web_client_location' in substitutions:\n            substitutions[\"web_client_location\"] = substitutions.pop(\"org.matrix.web_client_location\")\n\n        subject_header = Header(self.sydent.cfg.get('email', 'email.invite.subject', raw=True) % substitutions, 'utf8')\n        substitutions[\"subject_header_value\"] = subject_header.encode()\n\n        brand = self.sydent.brand_from_request(request)\n        templateFile = self.sydent.get_branded_template(\n            brand,\n            \"invite_template.eml\",\n            ('email', 'email.invite_template'),\n        )\n\n        sendEmail(self.sydent, templateFile, address, substitutions)\n\n        pubKey = self.sydent.keyring.ed25519.verify_key\n        pubKeyBase64 = encode_base64(pubKey.encode())\n\n        baseUrl = \"%s/_matrix/identity/api/v1\" % (self.sydent.cfg.get('http', 'client_http_base'),)\n\n        keysToReturn = []\n        keysToReturn.append({\n            \"public_key\": pubKeyBase64,\n            \"key_validity_url\": baseUrl + \"/pubkey/isvalid\",\n        })\n        keysToReturn.append({\n            \"public_key\": ephemeralPublicKeyBase64,\n            \"key_validity_url\": baseUrl + \"/pubkey/ephemeral/isvalid\",\n        })\n\n        resp = {\n            \"token\": token,\n            \"public_key\": pubKeyBase64,\n            \"public_keys\": keysToReturn,\n            \"display_name\": self.redact_email_address(address),\n        }\n\n        return resp\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def load(self, loader):\n        loader.add_option(\n            \"connection_strategy\", str, \"eager\",\n            \"Determine when server connections should be established. When set to lazy, mitmproxy \"\n            \"tries to defer establishing an upstream connection as long as possible. This makes it possible to \"\n            \"use server replay while being offline. When set to eager, mitmproxy can detect protocols with \"\n            \"server-side greetings, as well as accurately mirror TLS ALPN negotiation.\",\n            choices=(\"eager\", \"lazy\")\n        )\n        loader.add_option(\n            \"stream_large_bodies\", Optional[str], None,\n            \"\"\"\n            Stream data to the client if response body exceeds the given\n            threshold. If streamed, the body will not be stored in any way.\n            Understands k/m/g suffixes, i.e. 3m for 3 megabytes.\n            \"\"\"\n        )\n        loader.add_option(\n            \"body_size_limit\", Optional[str], None,\n            \"\"\"\n            Byte size limit of HTTP request and response bodies. Understands\n            k/m/g suffixes, i.e. 3m for 3 megabytes.\n            \"\"\"\n        )\n        loader.add_option(\n            \"keep_host_header\", bool, False,\n            \"\"\"\n            Reverse Proxy: Keep the original host header instead of rewriting it\n            to the reverse proxy target.\n            \"\"\"\n        )\n        loader.add_option(\n            \"proxy_debug\", bool, False,\n            \"Enable debug logs in the proxy core.\",\n        )\n        loader.add_option(\n            \"normalize_outbound_headers\", bool, True,\n            \"\"\"\n            Normalize outgoing HTTP/2 header names, but emit a warning when doing so.\n            HTTP/2 does not allow uppercase header names. This option makes sure that HTTP/2 headers set\n            in custom scripts are lowercased before they are sent.\n            \"\"\",\n        )\n        loader.add_option(\n            \"validate_inbound_headers\", bool, True,\n            \"\"\"\n            Make sure that incoming HTTP requests are not malformed.\n            Disabling this option makes mitmproxy vulnerable to HTTP smuggling attacks.\n            \"\"\",\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compile(XlaOpKernelContext* ctx) override {\n    int64_t output_size;\n    xla::XlaOp output_size_param = ctx->Input(\"size\");\n    StatusOr<xla::Shape> output_shape_or =\n        ctx->builder()->GetShape(output_size_param);\n    OP_REQUIRES_OK(ctx, output_shape_or.status());\n    auto output_shape_param = output_shape_or.ValueOrDie();\n    auto output_rank = output_shape_param.rank();\n    OP_REQUIRES(ctx, output_rank == 0,\n                errors::InvalidArgument(\"Shape must be rank 0 but is rank \",\n                                        output_rank));\n    OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"size\", &output_size));\n    OP_REQUIRES(ctx, output_size >= 0,\n                errors::InvalidArgument(\"size (\", output_size,\n                                        \") must be non-negative\"));\n    xla::XlaOp idx, updates, output;\n    xla::XlaOp input = ctx->Input(0);\n    auto input_xla_type = ctx->input_xla_type(0);\n    xla::PrimitiveType dtype = ctx->InputXlaType(\"weights\");\n    auto zero = xla::Zero(ctx->builder(), dtype);\n    auto one = xla::One(ctx->builder(), dtype);\n    StatusOr<xla::Shape> input_shape_or = ctx->builder()->GetShape(input);\n    OP_REQUIRES_OK(ctx, input_shape_or.status());\n    auto input_shape = input_shape_or.ValueOrDie();\n    auto size = input_shape.dimensions(0);\n\n    if (!size) {\n      output = xla::Broadcast(zero, {output_size});\n      ctx->SetOutput(0, output);\n      return;\n    }\n    auto rank = input_shape.rank();\n\n    OP_REQUIRES(ctx, rank <= 2,\n                errors::InvalidArgument(\n                    \"Shape must be at most rank 2 but is rank \", rank));\n\n    xla::XlaOp weights = ctx->Input(2);\n    StatusOr<xla::Shape> weights_shape_or = ctx->builder()->GetShape(weights);\n    OP_REQUIRES_OK(ctx, weights_shape_or.status());\n\n    auto weights_shape = weights_shape_or.ValueOrDie();\n    OP_REQUIRES(ctx,\n                xla::ShapeUtil::CompatibleIgnoringElementType(weights_shape,\n                                                              input_shape) ||\n                    (weights_shape.dimensions_size() > 0 &&\n                     weights_shape.dimensions(0) == 0),\n                errors::InvalidArgument(\n                    \"`weights` must be the same shape as `arr` or a length-0 \"\n                    \"`Tensor`, in which case it acts as all weights equal to \"\n                    \"1. Received \",\n                    weights_shape.DebugString()));\n\n    auto weights_size = weights_shape.dimensions(0);\n    bool has_weights = false;\n    if (weights_size) {\n      has_weights = true;\n    }\n    xla::Shape output_shape = xla::ShapeUtil::MakeShape(dtype, {output_size});\n    xla::ScatterDimensionNumbers scatter_dnums;\n    scatter_dnums.set_index_vector_dim(1);\n    scatter_dnums.add_inserted_window_dims(0);\n    scatter_dnums.add_scatter_dims_to_operand_dims(0);\n\n    if (rank == 2) {\n      output_shape = xla::ShapeUtil::MakeShape(dtype, {size, output_size});\n      scatter_dnums.add_inserted_window_dims(1);\n      scatter_dnums.add_scatter_dims_to_operand_dims(1);\n      auto i_shape =\n          xla::ShapeUtil::MakeShape(input_xla_type, {input_shape.dimensions()});\n      auto i = xla::Iota(ctx->builder(), i_shape, 0);\n      i = xla::Reshape(\n          i, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      auto j = xla::Reshape(\n          input, {input_shape.dimensions(0) * input_shape.dimensions(1), 1});\n      std::vector<xla::XlaOp> iotas_to_concat;\n      iotas_to_concat.push_back(i);\n      iotas_to_concat.push_back(j);\n      idx = xla::ConcatInDim(ctx->builder(), iotas_to_concat, 1);\n      updates = xla::Broadcast(\n          one, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n      output = xla::Broadcast(\n          zero, {output_shape.dimensions(0), output_shape.dimensions(1)});\n      if (has_weights && !binary_output_) {\n        weights = xla::Reshape(\n            weights, {input_shape.dimensions(0) * input_shape.dimensions(1)});\n        updates = weights;\n      }\n    } else {\n      input = xla::Reshape(input, {size, 1});\n      idx = xla::Reshape(input, {size, 1});\n      updates = xla::Broadcast(one, {size});\n      output = xla::Broadcast(zero, {output_size});\n      if (has_weights && !binary_output_) {\n        updates = weights;\n      }\n    }\n\n    xla::XlaComputation assn_computation = [&] {\n      std::unique_ptr<xla::XlaBuilder> subb =\n          ctx->builder()->CreateSubBuilder(\"scatter_bincount\");\n      xla::Shape param_shape = xla::ShapeUtil::MakeShape(dtype, {});\n      auto p0 = xla::Parameter(subb.get(), 0, param_shape, \"p0\");\n      auto p1 = xla::Parameter(subb.get(), 1, param_shape, \"p1\");\n      if (!binary_output_) {\n        xla::Add(p0, p1);\n      }\n      return subb->BuildAndNoteError();\n    }();\n    output = xla::Scatter(output, idx, updates, assn_computation, scatter_dnums,\n                          false, false);\n    ctx->SetOutput(0, output);\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  virtual void ComputeWithReservedSpace(OpKernelContext* context,\n                                        bool use_reserved_space) {\n    Tensor x = context->input(0);\n    const Tensor& scale = context->input(1);\n    const Tensor& offset = context->input(2);\n    const Tensor& estimated_mean = context->input(3);\n    const Tensor& estimated_variance = context->input(4);\n    const Tensor* side_input = has_side_input_ ? &context->input(5) : nullptr;\n\n    OP_REQUIRES(context, x.dims() == 4 || x.dims() == 5,\n                errors::InvalidArgument(\"input must be 4 or 5-dimensional\",\n                                        x.shape().DebugString()));\n    OP_REQUIRES(context, scale.dims() == 1,\n                errors::InvalidArgument(\"scale must be 1-dimensional\",\n                                        scale.shape().DebugString()));\n    OP_REQUIRES(context, offset.dims() == 1,\n                errors::InvalidArgument(\"offset must be 1-dimensional\",\n                                        offset.shape().DebugString()));\n    OP_REQUIRES(context, estimated_mean.dims() == 1,\n                errors::InvalidArgument(\"estimated_mean must be 1-dimensional\",\n                                        estimated_mean.shape().DebugString()));\n    OP_REQUIRES(\n        context, estimated_variance.dims() == 1,\n        errors::InvalidArgument(\"estimated_variance must be 1-dimensional\",\n                                estimated_variance.shape().DebugString()));\n    bool use_reshape = (x.dims() == 5);\n    auto x_shape = x.shape();\n    TensorShape dest_shape;\n    if (use_reshape) {\n      const int64_t in_batch = GetTensorDim(x, tensor_format_, 'N');\n      int64_t in_planes = GetTensorDim(x, tensor_format_, '0');\n      int64_t in_rows = GetTensorDim(x, tensor_format_, '1');\n      int64_t in_cols = GetTensorDim(x, tensor_format_, '2');\n      const int64_t in_depth = GetTensorDim(x, tensor_format_, 'C');\n      dest_shape = ShapeFromFormat(tensor_format_, in_batch,\n                                   {{in_planes, in_rows * in_cols}}, in_depth);\n      OP_REQUIRES(context, x.CopyFrom(x, dest_shape),\n                  errors::InvalidArgument(\"Error during tensor copy.\"));\n    }\n\n    const auto num_channels = GetTensorDim(x, tensor_format_, 'C');\n    OP_REQUIRES(\n        context, scale.NumElements() == num_channels,\n        errors::InvalidArgument(\"scale must have the same number of elements \"\n                                \"as the channels of x, got \",\n                                scale.NumElements(), \" and \", num_channels));\n    OP_REQUIRES(\n        context, offset.NumElements() == num_channels,\n        errors::InvalidArgument(\"offset must have the same number of elements \"\n                                \"as the channels of x, got \",\n                                offset.NumElements(), \" and \", num_channels));\n    if (!is_training_ || exponential_avg_factor_ != 1.) {\n      std::string prefix_msg = is_training_ ? \"When exponential_avg_factor != 1\"\n                                            : \"When is_training=false\";\n      OP_REQUIRES(context, estimated_mean.NumElements() == num_channels,\n                  errors::InvalidArgument(\n                      prefix_msg,\n                      \", mean must have the same number \"\n                      \"of elements as the channels of x, got \",\n                      estimated_mean.NumElements(), \" and \", num_channels));\n      OP_REQUIRES(context, estimated_variance.NumElements() == num_channels,\n                  errors::InvalidArgument(\n                      prefix_msg,\n                      \", variance must have the same \"\n                      \"number of elements as the channels of x, got \",\n                      estimated_variance.NumElements(), \" and \", num_channels));\n    }\n\n    if (has_side_input_) {\n      OP_REQUIRES(context, side_input->shape() == x.shape(),\n                  errors::InvalidArgument(\n                      \"side_input shape must be equal to input shape: \",\n                      side_input->shape().DebugString(),\n                      \" != \", x.shape().DebugString()));\n    }\n\n    if (activation_mode_ != FbnActivationMode::kIdentity) {\n      // NOTE(ezhulenev): This requirement is coming from implementation\n      // details of cudnnBatchNormalizationForwardTrainingEx.\n      OP_REQUIRES(\n          context, !is_training_ || num_channels % 4 == 0,\n          errors::InvalidArgument(\"FusedBatchNorm with activation requires \"\n                                  \"channel dimension to be a multiple of 4.\"));\n    }\n\n    Tensor* y = nullptr;\n    auto alloc_shape = use_reshape ? dest_shape : x_shape;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, alloc_shape, &y));\n\n    Tensor* batch_mean = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {3}, 1, scale.shape(), &batch_mean));\n    Tensor* batch_var = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {4}, 2, scale.shape(), &batch_var));\n    Tensor* saved_mean = nullptr;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(3, scale.shape(), &saved_mean));\n    Tensor* saved_maybe_inv_var = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(4, scale.shape(),\n                                                     &saved_maybe_inv_var));\n\n    if (is_training_) {\n      functor::FusedBatchNorm<Device, T, U, true>()(\n          context, x, scale, offset, estimated_mean, estimated_variance,\n          side_input, epsilon_, exponential_avg_factor_, activation_mode_, y,\n          batch_mean, batch_var, saved_mean, saved_maybe_inv_var,\n          tensor_format_, use_reserved_space);\n    } else {\n      functor::FusedBatchNorm<Device, T, U, false>()(\n          context, x, scale, offset, estimated_mean, estimated_variance,\n          side_input, epsilon_, exponential_avg_factor_, activation_mode_, y,\n          batch_mean, batch_var, saved_mean, saved_maybe_inv_var,\n          tensor_format_, use_reserved_space);\n    }\n    if (use_reshape) {\n      OP_REQUIRES(context, y->CopyFrom(*y, x_shape),\n                  errors::InvalidArgument(\"Error during tensor copy.\"));\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor& tensor_in = context->input(0);\n    const Tensor& grad_in = context->input(1);\n    const Tensor& argmax = context->input(2);\n\n    PoolParameters params{context,\n                          ksize_,\n                          stride_,\n                          padding_,\n                          /*explicit_paddings=*/{},\n                          FORMAT_NHWC,\n                          tensor_in.shape()};\n    if (!context->status().ok()) {\n      return;\n    }\n\n    TensorShape out_shape({params.tensor_in_batch, params.tensor_in_rows,\n                           params.tensor_in_cols, params.depth});\n    Tensor* grad_out = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, out_shape, &grad_out));\n\n    if (out_shape.num_elements() == 0) return;  // nothing to be done\n\n    LaunchMaxPoolingGradWithArgmax<Device, T>::launch(\n        context, params, grad_in, argmax, grad_out, include_batch_in_index_);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def requestStarted(self, job):\n        \"\"\"Handle a request for a qute: scheme.\n\n        This method must be reimplemented by all custom URL scheme handlers.\n        The request is asynchronous and does not need to be handled right away.\n\n        Args:\n            job: QWebEngineUrlRequestJob\n        \"\"\"\n        url = job.requestUrl()\n\n        if url.scheme() in ['chrome-error', 'chrome-extension']:\n            # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-63378\n            job.fail(QWebEngineUrlRequestJob.UrlInvalid)\n            return\n\n        # Only the browser itself or qute:// pages should access any of those\n        # URLs.\n        # The request interceptor further locks down qute://settings/set.\n        try:\n            initiator = job.initiator()\n        except AttributeError:\n            # Added in Qt 5.11\n            pass\n        else:\n            if initiator.isValid() and initiator.scheme() != 'qute':\n                log.misc.warning(\"Blocking malicious request from {} to {}\"\n                                 .format(initiator.toDisplayString(),\n                                         url.toDisplayString()))\n                job.fail(QWebEngineUrlRequestJob.RequestDenied)\n                return\n\n        if job.requestMethod() != b'GET':\n            job.fail(QWebEngineUrlRequestJob.RequestDenied)\n            return\n\n        assert url.scheme() == 'qute'\n\n        log.misc.debug(\"Got request for {}\".format(url.toDisplayString()))\n        try:\n            mimetype, data = qutescheme.data_for_url(url)\n        except qutescheme.NoHandlerFound:\n            log.misc.debug(\"No handler found for {}\".format(\n                url.toDisplayString()))\n            job.fail(QWebEngineUrlRequestJob.UrlNotFound)\n        except qutescheme.QuteSchemeOSError:\n            # FIXME:qtwebengine how do we show a better error here?\n            log.misc.exception(\"OSError while handling qute://* URL\")\n            job.fail(QWebEngineUrlRequestJob.UrlNotFound)\n        except qutescheme.QuteSchemeError:\n            # FIXME:qtwebengine how do we show a better error here?\n            log.misc.exception(\"Error while handling qute://* URL\")\n            job.fail(QWebEngineUrlRequestJob.RequestFailed)\n        except qutescheme.Redirect as e:\n            qtutils.ensure_valid(e.url)\n            job.redirect(e.url)\n        else:\n            log.misc.debug(\"Returning {} data\".format(mimetype))\n\n            # We can't just use the QBuffer constructor taking a QByteArray,\n            # because that somehow segfaults...\n            # https://www.riverbankcomputing.com/pipermail/pyqt/2016-September/038075.html\n            buf = QBuffer(parent=self)\n            buf.open(QIODevice.WriteOnly)\n            buf.write(data)\n            buf.seek(0)\n            buf.close()\n            job.reply(mimetype.encode('ascii'), buf)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "$.fn.reviewsAutoComplete = function(options) {\n    return this.each(function() {\n        $(this)\n            .autocomplete({\n                formatItem: function(data) {\n                    var s = data[options.nameKey],\n                        desc;\n\n                    if (options.descKey) {\n                        desc = $('<div/>').text(data[options.descKey]).html();\n                        s += \" <span>(\" + desc + \")</span>\";\n                    }\n\n                    return s;\n                },\n                matchCase: false,\n                multiple: true,\n                parse: function(data) {\n                    var jsonData = eval(\"(\" + data + \")\");\n                    var items = jsonData[options.fieldName];\n                    var parsed = [];\n\n                    for (var i = 0; i < items.length; i++) {\n                        var value = items[i];\n\n                        parsed.push({\n                            data: value,\n                            value: value[options.nameKey],\n                            result: value[options.nameKey]\n                        });\n                    }\n\n                    return parsed;\n                },\n                url: SITE_ROOT + gReviewRequestSitePrefix + \"api/\" + options.fieldName + \"/\",\n                extraParams: options.extraParams\n            })\n            .bind(\"autocompleteshow\", function() {\n                /*\n                 * Add the footer to the bottom of the results pane the\n                 * first time it's created.\n                 *\n                 * Note that we may have multiple .ui-autocomplete-results\n                 * elements, and we don't necessarily know which is tied to\n                 * this. So, we'll look for all instances that don't contain\n                 * a footer.\n                 */\n                var resultsPane = $(\".ui-autocomplete-results:not(\" +\n                                    \":has(.ui-autocomplete-footer))\");\n\n                if (resultsPane.length > 0) {\n                    $(\"<div/>\")\n                        .addClass(\"ui-autocomplete-footer\")\n                        .text(\"Press Tab to auto-complete.\")\n                        .appendTo(resultsPane);\n                }\n            });\n    });\n};\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  public static CloseableHttpClient createClient(\n      int maxConnections,\n      int timeoutMilliseconds,\n      ProxySettings proxySettings,\n      KeyStoreSettings trustStoreSettings,\n      boolean useSystemProperties,\n      NetworkAddressRules networkAddressRules) {\n    return createClient(\n        maxConnections,\n        timeoutMilliseconds,\n        proxySettings,\n        trustStoreSettings,\n        true,\n        Collections.<String>emptyList(),\n        useSystemProperties,\n        networkAddressRules);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_newkeys(self, k: bytes, h: bytes) -> None:\n        \"\"\"Finish a key exchange and send a new keys message\"\"\"\n\n        if not self._session_id:\n            first_kex = True\n            self._session_id = h\n        else:\n            first_kex = False\n\n        enc_keysize_cs, enc_ivsize_cs, enc_blocksize_cs, \\\n        mac_keysize_cs, mac_hashsize_cs, etm_cs = \\\n            get_encryption_params(self._enc_alg_cs, self._mac_alg_cs)\n\n        enc_keysize_sc, enc_ivsize_sc, enc_blocksize_sc, \\\n        mac_keysize_sc, mac_hashsize_sc, etm_sc = \\\n            get_encryption_params(self._enc_alg_sc, self._mac_alg_sc)\n\n        if mac_keysize_cs == 0:\n            self._mac_alg_cs = self._enc_alg_cs\n\n        if mac_keysize_sc == 0:\n            self._mac_alg_sc = self._enc_alg_sc\n\n        cmp_after_auth_cs = get_compression_params(self._cmp_alg_cs)\n        cmp_after_auth_sc = get_compression_params(self._cmp_alg_sc)\n\n        self.logger.debug2('  Client to server:')\n        self.logger.debug2('    Encryption alg: %s', self._enc_alg_cs)\n        self.logger.debug2('    MAC alg: %s', self._mac_alg_cs)\n        self.logger.debug2('    Compression alg: %s', self._cmp_alg_cs)\n        self.logger.debug2('  Server to client:')\n        self.logger.debug2('    Encryption alg: %s', self._enc_alg_sc)\n        self.logger.debug2('    MAC alg: %s', self._mac_alg_sc)\n        self.logger.debug2('    Compression alg: %s', self._cmp_alg_sc)\n\n        assert self._kex is not None\n\n        iv_cs = self._kex.compute_key(k, h, b'A', self._session_id,\n                                      enc_ivsize_cs)\n        iv_sc = self._kex.compute_key(k, h, b'B', self._session_id,\n                                      enc_ivsize_sc)\n        enc_key_cs = self._kex.compute_key(k, h, b'C', self._session_id,\n                                           enc_keysize_cs)\n        enc_key_sc = self._kex.compute_key(k, h, b'D', self._session_id,\n                                           enc_keysize_sc)\n        mac_key_cs = self._kex.compute_key(k, h, b'E', self._session_id,\n                                           mac_keysize_cs)\n        mac_key_sc = self._kex.compute_key(k, h, b'F', self._session_id,\n                                           mac_keysize_sc)\n        self._kex = None\n\n        next_enc_cs = get_encryption(self._enc_alg_cs, enc_key_cs, iv_cs,\n                                     self._mac_alg_cs, mac_key_cs, etm_cs)\n        next_enc_sc = get_encryption(self._enc_alg_sc, enc_key_sc, iv_sc,\n                                     self._mac_alg_sc, mac_key_sc, etm_sc)\n\n        self.send_packet(MSG_NEWKEYS)\n\n        self._extensions_to_send[b'global-requests-ok'] = b''\n\n        if self.is_client():\n            self._send_encryption = next_enc_cs\n            self._send_enchdrlen = 1 if etm_cs else 5\n            self._send_blocksize = max(8, enc_blocksize_cs)\n            self._compressor = get_compressor(self._cmp_alg_cs)\n            self._compress_after_auth = cmp_after_auth_cs\n\n            self._next_recv_encryption = next_enc_sc\n            self._next_recv_blocksize = max(8, enc_blocksize_sc)\n            self._next_recv_macsize = mac_hashsize_sc\n            self._next_decompressor = get_decompressor(self._cmp_alg_sc)\n            self._next_decompress_after_auth = cmp_after_auth_sc\n\n            self.set_extra_info(\n                send_cipher=self._enc_alg_cs.decode('ascii'),\n                send_mac=self._mac_alg_cs.decode('ascii'),\n                send_compression=self._cmp_alg_cs.decode('ascii'),\n                recv_cipher=self._enc_alg_sc.decode('ascii'),\n                recv_mac=self._mac_alg_sc.decode('ascii'),\n                recv_compression=self._cmp_alg_sc.decode('ascii'))\n\n            if first_kex:\n                if self._wait == 'kex' and self._waiter and \\\n                        not self._waiter.cancelled():\n                    self._waiter.set_result(None)\n                    self._wait = None\n                    return\n        else:\n            self._extensions_to_send[b'server-sig-algs'] = \\\n                b','.join(self._sig_algs)\n\n            self._send_encryption = next_enc_sc\n            self._send_enchdrlen = 1 if etm_sc else 5\n            self._send_blocksize = max(8, enc_blocksize_sc)\n            self._compressor = get_compressor(self._cmp_alg_sc)\n            self._compress_after_auth = cmp_after_auth_sc\n\n            self._next_recv_encryption = next_enc_cs\n            self._next_recv_blocksize = max(8, enc_blocksize_cs)\n            self._next_recv_macsize = mac_hashsize_cs\n            self._next_decompressor = get_decompressor(self._cmp_alg_cs)\n            self._next_decompress_after_auth = cmp_after_auth_cs\n\n            self.set_extra_info(\n                send_cipher=self._enc_alg_sc.decode('ascii'),\n                send_mac=self._mac_alg_sc.decode('ascii'),\n                send_compression=self._cmp_alg_sc.decode('ascii'),\n                recv_cipher=self._enc_alg_cs.decode('ascii'),\n                recv_mac=self._mac_alg_cs.decode('ascii'),\n                recv_compression=self._cmp_alg_cs.decode('ascii'))\n\n        if self._can_send_ext_info:\n            self._send_ext_info()\n            self._can_send_ext_info = False\n\n        self._kex_complete = True\n\n        if first_kex:\n            if self.is_client():\n                self.send_service_request(_USERAUTH_SERVICE)\n            else:\n                self._next_service = _USERAUTH_SERVICE\n\n        self._send_deferred_packets()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def rebuild_proxies(self, prepared_request, proxies):\n        \"\"\"This method re-evaluates the proxy configuration by considering the\n        environment variables. If we are redirected to a URL covered by\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n        proxy keys for this URL (in case they were stripped by a previous\n        redirect).\n\n        This method also replaces the Proxy-Authorization header where\n        necessary.\n\n        :rtype: dict\n        \"\"\"\n        headers = prepared_request.headers\n        scheme = urlparse(prepared_request.url).scheme\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\n\n        if \"Proxy-Authorization\" in headers:\n            del headers[\"Proxy-Authorization\"]\n\n        try:\n            username, password = get_auth_from_url(new_proxies[scheme])\n        except KeyError:\n            username, password = None, None\n\n        # urllib3 handles proxy authorization for us in the standard adapter.\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\n        if not scheme.startswith('https') and username and password:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return new_proxies\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_ip(ip: str) -> None:\n    \"\"\"If settings.USE_DEFAULT_BANNED_SUBNETS is True, this function checks\n    if an IP is reserved for any of the reasons in\n    https://en.wikipedia.org/wiki/Reserved_IP_addresses\n    and raises an exception if so. Additionally, if settings.USER_ADDITIONAL_BANNED_SUBNETS\n    is set, it will also check against those subnets.\n\n    If settings.USE_DEFAULT_BANNED_SUBNETS is False, this function will only check\n    the IP against settings.USER_ADDITIONAL_BANNED_SUBNETS. Turning off the default\n    subnets is **risky** and should only be done if you know what you're doing.\n\n    :param ip: IP address to be checked.\n    \"\"\"\n\n    default_banned_subnets = [\n        '0.0.0.0/8',  # current network\n        '10.0.0.0/8',  # private network\n        '100.64.0.0/10',  # shared address space\n        '127.0.0.0/8',  # loopback\n        '169.254.0.0/16',  # link-local\n        '172.16.0.0/12',  # private network\n        '192.0.0.0/24',  # IETF protocol assignments\n        '192.0.2.0/24',  # TEST-NET-1\n        '192.88.99.0/24',  # Reserved, formerly ipv6 to ipv4 relay\n        '192.168.0.0/16',  # private network\n        '198.18.0.0/15',  # network interconnect device benchmark testing\n        '198.51.100.0/24',  # TEST-NET-2\n        '203.0.113.0/24',  # TEST-NET-3\n        '224.0.0.0/4',  # multicast\n        '233.252.0.0/24',  # MCAST-TEST-NET\n        '240.0.0.0/4',  # reserved for future use\n        '255.255.255.255/32',  # limited broadcast\n        '::/128',  # unspecified address\n        '::1/128',  # loopback\n        '::ffff:0:0/96',  # IPv4-mapped address\n        '::ffff:0:0:0/96',  # IPv4-translated address\n        '64:ff9b::/96',  # IPv4/IPv6 translation\n        '64:ff9b:1::/48',  # IPv4/IPv6 translation\n        '100::/64',  # discard prefix\n        '2001:0000::/32',  # Teredo tunneling\n        '2001:20::/28',  # ORCHIDv2\n        '2001:db8::/32',  # documentation\n        '2002::/16',  # 6to4\n        'fc00::/7',  # unique local\n        'fe80::/10',  # link-local\n        'ff00::/8',  # multicast\n    ]\n\n    banned_subnets = [\n        *(default_banned_subnets if settings.USE_DEFAULT_BANNED_SUBNETS else []),\n        *(settings.USER_ADDITIONAL_BANNED_SUBNETS or []),\n    ]\n\n    for subnet in banned_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError(f'URL resolves to a reserved network address (block: {subnet})')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _load_prompt(config: dict) -> PromptTemplate:\n    \"\"\"Load the prompt template from config.\"\"\"\n    # Load the template from disk if necessary.\n    config = _load_template(\"template\", config)\n    config = _load_output_parser(config)\n\n    template_format = config.get(\"template_format\", \"f-string\")\n    if template_format == \"jinja2\":\n        # Disabled due to:\n        # https://github.com/langchain-ai/langchain/issues/4394\n        raise ValueError(\n            f\"Loading templates with '{template_format}' format is no longer supported \"\n            f\"since it can lead to arbitrary code execution. Please migrate to using \"\n            f\"the 'f-string' template format, which does not suffer from this issue.\"\n        )\n\n    return PromptTemplate(**config)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  static port::StatusOr<CudnnRnnSequenceTensorDescriptor> Create(\n      GpuExecutor* parent, int max_seq_length, int batch_size, int data_size,\n      const absl::Span<const int>& seq_lengths, bool time_major,\n      cudnnDataType_t data_type) {\n    if (max_seq_length <= 0) {\n      return port::Status(port::error::INVALID_ARGUMENT, \"max_seq_length <= 0\");\n    }\n    int dims[] = {batch_size, data_size, 1};\n    int strides[] = {dims[1] * dims[2], dims[2], 1};\n    TensorDescriptor tensor_desc = CreateTensorDescriptor();\n    RETURN_IF_CUDNN_ERROR(cudnnSetTensorNdDescriptor(\n        /*tensorDesc=*/tensor_desc.get(), /*dataType=*/data_type,\n        /*nbDims=*/sizeof(dims) / sizeof(dims[0]), /*dimA=*/dims,\n        /*strideA=*/strides));\n    const int* seq_lengths_array = seq_lengths.data();\n    RNNDataDescriptor data_desc = CreateRNNDataDescriptor();\n    float padding_fill = 0.0f;\n    cudnnRNNDataLayout_t layout;\n    if (time_major) {\n      layout = CUDNN_RNN_DATA_LAYOUT_SEQ_MAJOR_UNPACKED;\n    } else {\n      layout = CUDNN_RNN_DATA_LAYOUT_BATCH_MAJOR_UNPACKED;\n    }\n    RETURN_IF_CUDNN_ERROR(cudnnSetRNNDataDescriptor(\n        /*RNNDataDesc=*/data_desc.get(), /*dataType*/ data_type,\n        /*layout=*/layout,\n        /*maxSeqLength=*/max_seq_length,\n        /*batchSize=*/batch_size, /*vectorSize=*/data_size,\n        /*seqLengthArray=*/seq_lengths_array,\n        /*paddingFill*/ (void*)&padding_fill));\n    return CudnnRnnSequenceTensorDescriptor(\n        parent, max_seq_length, batch_size, data_size, data_type,\n        std::move(data_desc), std::move(tensor_desc));\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const auto& in_min_tensor = context->input(2);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_min_tensor.shape()),\n                errors::InvalidArgument(\"min must be a scalar\"));\n    const float in_min = in_min_tensor.flat<float>()(0);\n    const auto& in_max_tensor = context->input(3);\n    OP_REQUIRES(context, TensorShapeUtils::IsScalar(in_max_tensor.shape()),\n                errors::InvalidArgument(\"max must be a scalar\"));\n    const float in_max = in_max_tensor.flat<float>()(0);\n\n    ImageResizerState st(align_corners_, false);\n    st.ValidateAndCreateOutput(context);\n\n    if (!context->status().ok()) return;\n\n    // Return if the output is empty.\n    if (st.output->NumElements() == 0) return;\n\n    typename TTypes<T, 4>::ConstTensor image_data(\n        context->input(0).tensor<T, 4>());\n    typename TTypes<T, 4>::Tensor output_data(st.output->tensor<T, 4>());\n\n    ResizeBilinear<T>(image_data, st.height_scale, st.width_scale, in_min,\n                      in_max, half_pixel_centers_, &output_data);\n    Tensor* out_min = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(1, {}, &out_min));\n    out_min->flat<float>()(0) = in_min;\n\n    Tensor* out_max = nullptr;\n    OP_REQUIRES_OK(context, context->allocate_output(2, {}, &out_max));\n    out_max->flat<float>()(0) = in_max;\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def response_for_exception(request, exc):\n    if isinstance(exc, Http404):\n        if settings.DEBUG:\n            response = debug.technical_404_response(request, exc)\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 404, exc\n            )\n\n    elif isinstance(exc, PermissionDenied):\n        response = get_exception_response(\n            request, get_resolver(get_urlconf()), 403, exc\n        )\n        log_response(\n            \"Forbidden (Permission denied): %s\",\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    elif isinstance(exc, MultiPartParserError):\n        response = get_exception_response(\n            request, get_resolver(get_urlconf()), 400, exc\n        )\n        log_response(\n            \"Bad request (Unable to parse request body): %s\",\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    elif isinstance(exc, BadRequest):\n        if settings.DEBUG:\n            response = debug.technical_500_response(\n                request, *sys.exc_info(), status_code=400\n            )\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 400, exc\n            )\n        log_response(\n            \"%s: %s\",\n            str(exc),\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n    elif isinstance(exc, SuspiciousOperation):\n        if isinstance(exc, (RequestDataTooBig, TooManyFieldsSent, TooManyFilesSent)):\n            # POST data can't be accessed again, otherwise the original\n            # exception would be raised.\n            request._mark_post_parse_error()\n\n        # The request logger receives events for any problematic request\n        # The security logger receives events for all SuspiciousOperations\n        security_logger = logging.getLogger(\n            \"django.security.%s\" % exc.__class__.__name__\n        )\n        security_logger.error(\n            str(exc),\n            extra={\"status_code\": 400, \"request\": request},\n        )\n        if settings.DEBUG:\n            response = debug.technical_500_response(\n                request, *sys.exc_info(), status_code=400\n            )\n        else:\n            response = get_exception_response(\n                request, get_resolver(get_urlconf()), 400, exc\n            )\n\n    else:\n        signals.got_request_exception.send(sender=None, request=request)\n        response = handle_uncaught_exception(\n            request, get_resolver(get_urlconf()), sys.exc_info()\n        )\n        log_response(\n            \"%s: %s\",\n            response.reason_phrase,\n            request.path,\n            response=response,\n            request=request,\n            exc_info=sys.exc_info(),\n        )\n\n    # Force a TemplateResponse to be rendered.\n    if not getattr(response, \"is_rendered\", True) and callable(\n        getattr(response, \"render\", None)\n    ):\n        response = response.render()\n\n    return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def model_from_yaml(yaml_string, custom_objects=None):\n  \"\"\"Parses a yaml model configuration file and returns a model instance.\n\n  Note: Since TF 2.6, this method is no longer supported and will raise a\n  RuntimeError.\n\n  Arguments:\n      yaml_string: YAML string or open file encoding a model configuration.\n      custom_objects: Optional dictionary mapping names\n          (strings) to custom classes or functions to be\n          considered during deserialization.\n\n  Returns:\n      A Keras model instance (uncompiled).\n\n  Raises:\n      RuntimeError: announces that the method poses a security risk\n  \"\"\"\n  raise RuntimeError(\n      'Method `model_from_yaml()` has been removed due to security risk of '\n      'arbitrary code execution. Please use `Model.to_json()` and '\n      '`model_from_json()` instead.'\n  )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def encryption_materials(self, encryption_context):\n        # type: (EncryptionContext) -> CryptographicMaterials\n        \"\"\"Return encryption materials.\n\n        :param EncryptionContext encryption_context: Encryption context for request\n        :raises AttributeError: if no encryption materials are available\n        \"\"\"\n        ttl_action = self._ttl_action(self._version, _ENCRYPT_ACTION)\n\n        _LOGGER.debug('TTL Action \"%s\" when getting encryption materials', ttl_action.name)\n\n        provider = None\n\n        if ttl_action is TtlActions.EXPIRED:\n            self._cache.evict(self._version)\n\n        if ttl_action is TtlActions.LIVE:\n            try:\n                _LOGGER.debug(\"Looking in cache for encryption materials provider version %d\", self._version)\n                _, provider = self._cache.get(self._version)\n            except KeyError:\n                _LOGGER.debug(\"Encryption materials provider not found in cache\")\n                ttl_action = TtlActions.EXPIRED\n\n        if provider is None:\n            _LOGGER.debug(\"Getting most recent materials provider version\")\n            provider = self._get_most_recent_version(ttl_action)\n\n        return provider.encryption_materials(encryption_context)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def execute_command(self, *args: Any, **kwargs: Any) -> Any:\n        # Acquire connection\n        connection = self.acquire_connection()\n\n        # Execute command\n        await connection.send_packed_command(connection.pack_command(*args), False)\n\n        # Read response\n        return await asyncio.shield(\n            self._parse_and_release(connection, args[0], **kwargs)\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _property_resolver(arg):\n    \"\"\"\n    When arg is convertible to float, behave like operator.itemgetter(arg)\n    Otherwise, chain __getitem__() and getattr().\n\n    >>> _property_resolver(1)('abc')\n    'b'\n    >>> _property_resolver('1')('abc')\n    Traceback (most recent call last):\n    ...\n    TypeError: string indices must be integers\n    >>> class Foo:\n    ...     a = 42\n    ...     b = 3.14\n    ...     c = 'Hey!'\n    >>> _property_resolver('b')(Foo())\n    3.14\n    \"\"\"\n    try:\n        float(arg)\n    except ValueError:\n        if VARIABLE_ATTRIBUTE_SEPARATOR + '_' in arg or arg[0] == '_':\n            raise AttributeError('Access to private variables is forbidden.')\n        parts = arg.split(VARIABLE_ATTRIBUTE_SEPARATOR)\n\n        def resolve(value):\n            for part in parts:\n                try:\n                    value = value[part]\n                except (AttributeError, IndexError, KeyError, TypeError, ValueError):\n                    value = getattr(value, part)\n            return value\n\n        return resolve\n    else:\n        return itemgetter(arg)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def login():\n    from flask_login import current_user\n\n    default_redirect_url = request.script_root + url_for(\"index\")\n    redirect_url = request.args.get(\"redirect\", default_redirect_url)\n\n    parsed = urlparse(redirect_url)  # check if redirect url is valid\n    if parsed.scheme != \"\" or parsed.netloc != \"\":\n        _logger.warning(\n            f\"Got an invalid redirect URL with the login attempt, misconfiguration or attack attempt: {redirect_url}\"\n        )\n        redirect_url = default_redirect_url\n\n    permissions = sorted(\n        filter(\n            lambda x: x is not None and isinstance(x, OctoPrintPermission),\n            map(\n                lambda x: getattr(Permissions, x.strip()),\n                request.args.get(\"permissions\", \"\").split(\",\"),\n            ),\n        ),\n        key=lambda x: x.get_name(),\n    )\n    if not permissions:\n        permissions = [Permissions.STATUS, Permissions.SETTINGS_READ]\n\n    user_id = request.args.get(\"user_id\", \"\")\n\n    if (not user_id or current_user.get_id() == user_id) and has_permissions(\n        *permissions\n    ):\n        return redirect(redirect_url)\n\n    render_kwargs = {\n        \"theming\": [],\n        \"redirect_url\": redirect_url,\n        \"permission_names\": map(lambda x: x.get_name(), permissions),\n        \"user_id\": user_id,\n        \"logged_in\": not current_user.is_anonymous,\n    }\n\n    try:\n        additional_assets = _add_additional_assets(\"octoprint.theming.login\")\n\n        # backwards compatibility to forcelogin & loginui plugins which were replaced by this built-in dialog\n        additional_assets += _add_additional_assets(\"octoprint.plugin.forcelogin.theming\")\n        additional_assets += _add_additional_assets(\"octoprint.plugin.loginui.theming\")\n\n        render_kwargs.update({\"theming\": additional_assets})\n    except Exception:\n        _logger.exception(\"Error processing theming CSS, ignoring\")\n\n    return render_template(\"login.jinja2\", **render_kwargs)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def get_initial_logout(self, user):\n        \"\"\"\n        Get the initial logout request.\n\n        Raises ValueError if no sessions in INIT_LOGOUT state.\n        \"\"\"\n        candidates = self._ss.get_user_sessions(user)\n\n        # FIXME: what does it mean if there are multiple in init? We\n        #        just return the first one for now. How do we know\n        #        it's the \"right\" one if multiple logouts are started\n        #        at the same time from different SPs?\n        for c in candidates:\n            key = c.keys()[0]\n            if int(c[key].get('logoutstate', 0)) == INIT_LOGOUT:\n                samlsession = self._data_to_samlsession(key, c[key])\n                return samlsession\n        raise ValueError()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def generate_jsrun_rankfile(settings, path=None):\n    \"\"\"\n    Generates rankfile to use with jsrun.\n    It splits the cores among the processes, which leads to best performance according to experiments.\n\n    Args:\n        settings: Settings for running jsrun.\n                  Note: settings.num_proc and settings.hosts must not be None.\n        path: Optional path of the rankfile.\n              Note: this file will be overwritten.\n    \"\"\"\n    cpu_per_gpu = (lsf.LSFUtils.get_num_cores() * lsf.LSFUtils.get_num_threads()) // lsf.LSFUtils.get_num_gpus()\n    host_list = (x.split(':') for x in settings.hosts.split(','))\n\n    # Verify and truncate host list if necessary\n    validated_list = []\n    remaining_slots = settings.num_proc\n    for host, slots in host_list:\n        slots = int(slots)\n        if slots > lsf.LSFUtils.get_num_gpus():\n            raise ValueError('Invalid host input, slot count for host \\'{host}:{slots}\\' is greater '\n                             'than number of GPUs per host \\'{gpus}\\'.'.format(\n                host=host, slots=slots, gpus=lsf.LSFUtils.get_num_gpus()))\n        needed_slots = min(slots, remaining_slots)\n        validated_list.append((host, needed_slots))\n        remaining_slots -= needed_slots\n        if remaining_slots == 0:\n            break\n    if remaining_slots != 0:\n        raise ValueError('Not enough slots on the hosts to fulfill the {slots} requested.'.format(\n            slots=settings.num_proc))\n\n    # Generate rankfile\n    # using mkstemp here instead of insecure mktemp.\n    # note that the caller is responsible for cleaning up this file\n    if path is None:\n        fd, path = tempfile.mkstemp()\n        fd.close()\n\n    with open(path, 'w') as tmp:\n        tmp.write('overlapping_rs: allow\\n')\n        tmp.write('cpu_index_using: logical\\n')\n        rank = 0\n        for host, slots in validated_list:\n            cpu_val = 0\n            tmp.write('\\n')\n            for s in range(slots):\n                tmp.write('rank: {rank}: {{ hostname: {host}; cpu: {{{scpu}-{ecpu}}} ; gpu: * ; mem: * }}\\n'.format(\n                    rank=rank,\n                    host=host,\n                    scpu=cpu_val,\n                    ecpu=cpu_val + cpu_per_gpu - 1\n                ))\n                rank += 1\n                cpu_val += cpu_per_gpu\n    return path\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def lookup_internal_function(self, method_name, args_ir, ast_source):\n        # TODO is this the right module for me?\n        \"\"\"\n        Using a list of args, find the internal method to use, and\n        the kwargs which need to be filled in by the compiler\n        \"\"\"\n\n        sig = self.sigs[\"self\"].get(method_name, None)\n\n        def _check(cond, s=\"Unreachable\"):\n            if not cond:\n                raise CompilerPanic(s)\n\n        # these should have been caught during type checking; sanity check\n        _check(sig is not None)\n        _check(sig.internal)\n        _check(len(sig.base_args) <= len(args_ir) <= len(sig.args))\n        # more sanity check, that the types match\n        # _check(all(l.typ == r.typ for (l, r) in zip(args_ir, sig.args))\n\n        num_provided_kwargs = len(args_ir) - len(sig.base_args)\n\n        kw_vals = list(sig.default_values.values())[num_provided_kwargs:]\n\n        return sig, kw_vals\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs: \"HomeServer\"):\n        super().__init__(hs)\n\n        self.hs = hs\n\n        self.store = hs.get_datastore()\n        self.storage = hs.get_storage()\n        self.state_store = self.storage.state\n        self.federation_client = hs.get_federation_client()\n        self.state_handler = hs.get_state_handler()\n        self._state_resolution_handler = hs.get_state_resolution_handler()\n        self.server_name = hs.hostname\n        self.keyring = hs.get_keyring()\n        self.action_generator = hs.get_action_generator()\n        self.is_mine_id = hs.is_mine_id\n        self.spam_checker = hs.get_spam_checker()\n        self.event_creation_handler = hs.get_event_creation_handler()\n        self._message_handler = hs.get_message_handler()\n        self._server_notices_mxid = hs.config.server_notices_mxid\n        self.config = hs.config\n        self.http_client = hs.get_proxied_blacklisted_http_client()\n        self._instance_name = hs.get_instance_name()\n        self._replication = hs.get_replication_data_handler()\n\n        self._send_events = ReplicationFederationSendEventsRestServlet.make_client(hs)\n        self._clean_room_for_join_client = ReplicationCleanRoomRestServlet.make_client(\n            hs\n        )\n\n        if hs.config.worker_app:\n            self._user_device_resync = ReplicationUserDevicesResyncRestServlet.make_client(\n                hs\n            )\n            self._maybe_store_room_on_outlier_membership = ReplicationStoreRoomOnOutlierMembershipRestServlet.make_client(\n                hs\n            )\n        else:\n            self._device_list_updater = hs.get_device_handler().device_list_updater\n            self._maybe_store_room_on_outlier_membership = (\n                self.store.maybe_store_room_on_outlier_membership\n            )\n\n        # When joining a room we need to queue any events for that room up.\n        # For each room, a list of (pdu, origin) tuples.\n        self.room_queues = {}  # type: Dict[str, List[Tuple[EventBase, str]]]\n        self._room_pdu_linearizer = Linearizer(\"fed_room_pdu\")\n\n        self.third_party_event_rules = hs.get_third_party_event_rules()\n\n        self._ephemeral_messages_enabled = hs.config.enable_ephemeral_messages\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& val = ctx->input(0);\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionHandle called on null session state\"));\n    int64 id = session_state->GetNewId();\n    TensorStore::TensorAndKey tk{val, id, requested_device()};\n    OP_REQUIRES_OK(ctx, ctx->tensor_store()->AddTensor(name(), tk));\n\n    Tensor* handle = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &handle));\n    if (ctx->expected_output_dtype(0) == DT_RESOURCE) {\n      ResourceHandle resource_handle = MakeResourceHandle<Tensor>(\n          ctx, SessionState::kTensorHandleResourceTypeName,\n          tk.GetHandle(name()));\n      resource_handle.set_maybe_type_name(\n          SessionState::kTensorHandleResourceTypeName);\n      handle->scalar<ResourceHandle>()() = resource_handle;\n    } else {\n      // Legacy behavior in V1.\n      handle->flat<tstring>().setConstant(tk.GetHandle(name()));\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def writeDataFile(self, filename, text, content_type, subdir=None):\n        \"\"\" See IExportContext.\n        \"\"\"\n        if subdir is not None:\n            filename = '/'.join((subdir, filename))\n\n        sep = filename.rfind('/')\n        if sep != -1:\n            subdir = filename[:sep]\n            filename = filename[sep+1:]\n\n        if six.PY2 and isinstance(text, six.text_type):\n            encoding = self.getEncoding() or 'utf-8'\n            text = text.encode(encoding)\n\n        folder = self._ensureSnapshotsFolder(subdir)\n\n        # MISSING: switch on content_type\n        ob = self._createObjectByType(filename, text, content_type)\n        folder._setObject(str(filename), ob)  # No Unicode IDs!\n        # Tighten the View permission on the new object.\n        # Only the owner and Manager users may view the log.\n        # file_ob = self._getOb(name)\n        ob.manage_permission(view, ('Manager', 'Owner'), 0)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def raise_standardErrorMessage(\n        self, client=None, REQUEST={},\n        error_type=None, error_value=None, tb=None,\n        error_tb=None, error_message='',\n        tagSearch=re.compile(r'[a-zA-Z]>').search,\n        error_log_url=''):\n\n        try:\n            if error_type  is None: error_type =sys.exc_info()[0]\n            if error_value is None: error_value=sys.exc_info()[1]\n\n            # allow for a few different traceback options\n            if tb is None and error_tb is None:\n                tb=sys.exc_info()[2]\n            if type(tb) is not str and (error_tb is None):\n                error_tb = pretty_tb(error_type, error_value, tb)\n            elif type(tb) is str and not error_tb:\n                error_tb = tb\n\n            if hasattr(self, '_v_eek'):\n                # Stop if there is recursion.\n                raise error_type, error_value, tb\n            self._v_eek = 1\n\n            if hasattr(error_type, '__name__'):\n                error_name = error_type.__name__\n            else:\n                error_name = 'Unknown'\n\n            if not error_message:\n                try:\n                    s = ustr(error_value)\n                except:\n                    s = error_value\n                try:\n                    match = tagSearch(s)\n                except TypeError:\n                    match = None\n                if match is not None:\n                    error_message=error_value\n\n            if client is None:\n                client = self\n\n            if not REQUEST:\n                REQUEST = aq_acquire(self, 'REQUEST')\n\n            try:\n                s = aq_acquire(client, 'standard_error_message')\n\n                # For backward compatibility, we pass 'error_name' as\n                # 'error_type' here as historically this has always\n                # been a string.\n                kwargs = {'error_type': error_name,\n                          'error_value': error_value,\n                          'error_tb': error_tb,\n                          'error_traceback': error_tb,\n                          'error_message': xml_escape(str(error_message)),\n                          'error_log_url': error_log_url}\n\n                if getattr(aq_base(s), 'isDocTemp', 0):\n                    v = s(client, REQUEST, **kwargs)\n                elif callable(s):\n                    v = s(**kwargs)\n                else:\n                    v = HTML.__call__(s, client, REQUEST, **kwargs)\n            except:\n                logger.error(\n                    'Exception while rendering an error message',\n                    exc_info=True\n                    )\n                try:\n                    strv = repr(error_value) # quotes tainted strings\n                except:\n                    strv = ('<unprintable %s object>' % \n                            str(type(error_value).__name__))\n                v = strv + (\n                    (\" (Also, the following error occurred while attempting \"\n                     \"to render the standard error message, please see the \"\n                     \"event log for full details: %s)\")%(\n                    html_quote(sys.exc_info()[1]),\n                    ))\n\n            # If we've been asked to handle errors, just return the rendered\n            # exception and let the ZPublisher Exception Hook deal with it.\n            return error_type, v, tb\n        finally:\n            if hasattr(self, '_v_eek'): del self._v_eek\n            tb = None\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def aws_kms_master_key_provider(discovery=True, **kwargs):\n    # type: (bool, **List[Union[Text, str]]) -> Union[DiscoveryAwsKmsMasterKeyProvider, StrictAwsKmsMasterKeyProvider]\n    \"\"\"Apply post-processing to transform ``KMSMasterKeyProvider``-specific values from CLI\n    arguments to valid ``KMSMasterKeyProvider`` parameters, then call ``KMSMasterKeyprovider``\n    with those parameters.\n\n    :param bool discovery: Return a DiscoveryAwsKmsMasterKeyProvider\n    :param dict kwargs: Named parameters collected from CLI arguments as prepared\n        in aws_encryption_sdk_cli.internal.master_key_parsing._parse_master_key_providers_from_args\n    :rtype: aws_encryption_sdk.key_providers.kms.BaseKMSMasterKeyProvider\n    \"\"\"\n    kwargs = copy.deepcopy(kwargs)\n    try:\n        profile_names = kwargs.pop(\"profile\")\n        if len(profile_names) != 1:\n            raise BadUserArgumentError(\n                \"Only one profile may be specified per master key provider configuration. {} provided.\".format(\n                    len(profile_names)\n                )\n            )\n        profile_name = profile_names[0]  # type: Optional[Text]\n    except KeyError:\n        profile_name = None\n\n    botocore_session = botocore.session.Session(profile=profile_name)\n    botocore_session.user_agent_extra = USER_AGENT_SUFFIX\n    kwargs[\"botocore_session\"] = botocore_session\n\n    try:\n        region_name = kwargs.pop(\"region\")\n        if len(region_name) != 1:\n            raise BadUserArgumentError(\n                \"Only one region may be specified per master key provider configuration. {} provided.\".format(\n                    len(region_name)\n                )\n            )\n        kwargs[\"region_names\"] = region_name\n    except KeyError:\n        pass\n    if discovery:\n        accounts = kwargs.pop(\"discovery-account\", None)\n        partition = kwargs.pop(\"discovery-partition\", None)\n        if accounts and partition:\n            discovery_filter = DiscoveryFilter(account_ids=accounts, partition=partition)\n            kwargs[\"discovery_filter\"] = discovery_filter  # type: ignore\n\n        return DiscoveryAwsKmsMasterKeyProvider(**kwargs)\n    return StrictAwsKmsMasterKeyProvider(**kwargs)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __new__(cls, obj, *args, **kwargs):\n        # In our usage we should only receive unicode strings.\n        # This conditional and conversion exists to sanity check the values\n        # we're given but we may want to take it out for testing and sanitize\n        # our input instead.\n        if isinstance(obj, string_types) and not isinstance(obj, AnsibleUnsafeBytes):\n            obj = AnsibleUnsafeText(to_text(obj, errors='surrogate_or_strict'))\n        return obj\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def check_db_or_user_exists(db_name, db_user, config):\n    with _create_pg_connection(config) as con:\n        with con.cursor() as cur:\n            cur.execute(\"SELECT 1 FROM pg_database WHERE datname=%s;\", (db_name, ))\n            db_exists = cur.fetchone() is not None\n            cur.execute(\"SELECT 1 FROM pg_roles WHERE rolname=%s;\", (db_user, ))\n            user = cur.fetchone()\n            user_exists = user is not None\n            return db_exists or user_exists\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "void ReshapeSparseTensor(OpKernelContext *context,\n                         const Tensor &input_indices_in,\n                         const Tensor &input_shape_in,\n                         const Tensor &target_shape_in, int output_indices_idx,\n                         int output_shape_idx) {\n  OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices_in.shape()),\n              errors::InvalidArgument(\n                  \"Input indices should be a matrix but received shape \",\n                  input_indices_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Input shape should be a vector but received shape \",\n                  input_shape_in.shape().DebugString()));\n  OP_REQUIRES(context, TensorShapeUtils::IsVector(target_shape_in.shape()),\n              errors::InvalidArgument(\n                  \"Target shape should be a vector but received shape \",\n                  target_shape_in.shape().DebugString()));\n\n  const int64_t output_rank = target_shape_in.NumElements();\n  const TensorShape input_shape(input_shape_in.vec<int64>());\n  const int64_t dense_size = input_shape.num_elements();\n  const int64_t nnz = input_indices_in.shape().dim_size(0);\n\n  // Compute the output shape. Determine product of specified dimensions, and\n  // find the index of the unspecified one.\n  TensorShape output_shape;\n  int64_t product = 1;\n  int unknown_index = -1;\n  auto target_shape = target_shape_in.vec<int64>();\n  for (int d = 0; d < output_rank; ++d) {\n    const int64_t size = target_shape(d);\n    if (size == -1) {\n      OP_REQUIRES(\n          context, unknown_index == -1,\n          errors::InvalidArgument(\"only one output dimension may be -1, \"\n                                  \"not both \",\n                                  unknown_index, \" and \", d));\n      unknown_index = d;\n      output_shape.AddDim(1);\n    } else {\n      OP_REQUIRES(context, size >= 0,\n                  errors::InvalidArgument(\"size \", d,\n                                          \" must be non-negative, not \", size));\n      product *= size;\n      output_shape.AddDim(size);\n    }\n  }\n  if (unknown_index != -1) {\n    OP_REQUIRES(\n        context, product > 0,\n        errors::InvalidArgument(\"reshape cannot infer the missing \"\n                                \"input size for an empty tensor unless all \"\n                                \"specified input sizes are non-zero\"));\n    const int64_t missing = dense_size / product;\n    OP_REQUIRES(\n        context, product * missing == dense_size,\n        errors::InvalidArgument(\n            \"Input to reshape is a SparseTensor with \", dense_size,\n            \" dense values, but the requested shape requires a multiple of \",\n            product, \". input_shape=\", input_shape.DebugString(),\n            \" output_shape=\", output_shape.DebugString()));\n    output_shape.set_dim(unknown_index, missing);\n  }\n\n  OP_REQUIRES(\n      context, output_shape.num_elements() == dense_size,\n      errors::InvalidArgument(\"Input to reshape is a tensor with \", dense_size,\n                              \" dense values, but the requested shape has \",\n                              output_shape.num_elements(),\n                              \". input_shape=\", input_shape.DebugString(),\n                              \" output_shape=\", output_shape.DebugString()));\n\n  // Optimize for reshaping to the same shape.\n  if (input_shape == output_shape) {\n    context->set_output(output_indices_idx, input_indices_in);\n    context->set_output(output_shape_idx, input_shape_in);\n    return;\n  }\n\n  Tensor *result_shape = nullptr;\n  OP_REQUIRES_OK(context, context->allocate_output(output_shape_idx,\n                                                   TensorShape({output_rank}),\n                                                   &result_shape));\n  auto output_shape_vec = result_shape->vec<int64>();\n  for (int j = 0; j < output_shape.dims(); ++j) {\n    output_shape_vec(j) = output_shape.dim_size(j);\n  }\n\n  Tensor *result_indices = nullptr;\n  OP_REQUIRES_OK(context,\n                 context->allocate_output(output_indices_idx,\n                                          TensorShape({nnz, output_rank}),\n                                          &result_indices));\n  if (nnz > 0) {\n    OP_REQUIRES(\n        context, dense_size > 0 && product > 0,\n        errors::InvalidArgument(\n            \"Input tensor has \", nnz, \" non zero elements but input shape (\",\n            input_shape.DebugString(), \") or output shape (\",\n            output_shape.DebugString(), \") is empty\"));\n    OP_REQUIRES_OK(context, functor::ReshapeSparseTensorFunctor<Device>()(\n                                context, input_shape, output_shape,\n                                input_indices_in.matrix<int64>(),\n                                result_indices->matrix<int64>()));\n  }\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send(\n        self,\n        request_params: SaaSRequestParams,\n        ignore_errors: Optional[Union[bool, List[int]]] = False,\n    ) -> Response:\n        \"\"\"\n        Builds and executes an authenticated request.\n        Optionally ignores:\n          - all non-2xx/3xx responses if ignore_errors is set to True\n          - no non-2xx/3xx responses if ignore_errors is set to False\n          - specific non-2xx/3xx responses if ignore_errors is set to a list of status codes\n        \"\"\"\n        rate_limit_requests = self.build_rate_limit_requests()\n        RateLimiter().limit(rate_limit_requests)\n\n        prepared_request: PreparedRequest = self.get_authenticated_request(\n            request_params\n        )\n        if not prepared_request.url:\n            raise ValueError(\"The URL for the prepared request is missing.\")\n\n        # extract the hostname from the complete URL and verify its safety\n        deny_unsafe_hosts(urlparse(prepared_request.url).netloc)\n\n        response = self.session.send(prepared_request)\n\n        log_request_and_response_for_debugging(\n            prepared_request, response\n        )  # Dev mode only\n\n        if not response.ok:\n            if self._should_ignore_error(\n                status_code=response.status_code,\n                errors_to_ignore=ignore_errors,\n            ):\n                logger.info(\n                    \"Ignoring errors on response with status code {} as configured.\",\n                    response.status_code,\n                )\n                return response\n            raise RequestFailureResponseException(response=response)\n        return response\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def render_and_merge_yaml(root, template_name, context_name):\n    \"\"\"\n    Renders a Jinja2-templated YAML file based on a YAML context file, merge them, and return\n    result as a dictionary.\n\n    :param root: Root directory of the YAML files\n    :param template_name: Name of the template file\n    :param context_name: Name of the context file\n    :return: Data in yaml file as dictionary\n    \"\"\"\n    from jinja2 import FileSystemLoader, StrictUndefined\n    from jinja2.sandbox import SandboxedEnvironment\n\n    template_path = os.path.join(root, template_name)\n    context_path = os.path.join(root, context_name)\n\n    for path in (template_path, context_path):\n        if not pathlib.Path(path).is_file():\n            raise MissingConfigException(f\"Yaml file '{path}' does not exist.\")\n\n    j2_env = SandboxedEnvironment(\n        loader=FileSystemLoader(root, encoding=ENCODING),\n        undefined=StrictUndefined,\n        line_comment_prefix=\"#\",\n    )\n\n    def from_json(input_var):\n        with open(input_var, encoding=\"utf-8\") as f:\n            return json.load(f)\n\n    j2_env.filters[\"from_json\"] = from_json\n    # Compute final source of context file (e.g. my-profile.yml), applying Jinja filters\n    # like from_json as needed to load context information from files, then load into a dict\n    context_source = j2_env.get_template(context_name).render({})\n    context_dict = yaml.load(context_source, Loader=UniqueKeyLoader) or {}\n\n    # Substitute parameters from context dict into template\n    source = j2_env.get_template(template_name).render(context_dict)\n    rendered_template_dict = yaml.load(source, Loader=UniqueKeyLoader)\n    return merge_dicts(rendered_template_dict, context_dict)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    async def _make_well_known_request(\n        self, server_name: bytes, retry: bool\n    ) -> Tuple[IResponse, bytes]:\n        \"\"\"Make the well known request.\n\n        This will retry the request if requested and it fails (with unable\n        to connect or receives a 5xx error).\n\n        Args:\n            server_name: name of the server, from the requested url\n            retry: Whether to retry the request if it fails.\n\n        Raises:\n            _FetchWellKnownFailure if we fail to lookup a result\n\n        Returns:\n            Returns the response object and body. Response may be a non-200 response.\n        \"\"\"\n        uri = b\"https://%s/.well-known/matrix/server\" % (server_name,)\n        uri_str = uri.decode(\"ascii\")\n\n        headers = {\n            b\"User-Agent\": [self.user_agent],\n        }\n\n        i = 0\n        while True:\n            i += 1\n\n            logger.info(\"Fetching %s\", uri_str)\n            try:\n                response = await make_deferred_yieldable(\n                    self._well_known_agent.request(\n                        b\"GET\", uri, headers=Headers(headers)\n                    )\n                )\n                body_stream = BytesIO()\n                await make_deferred_yieldable(\n                    read_body_with_max_size(response, body_stream, WELL_KNOWN_MAX_SIZE)\n                )\n                body = body_stream.getvalue()\n\n                if 500 <= response.code < 600:\n                    raise Exception(\"Non-200 response %s\" % (response.code,))\n\n                return response, body\n            except defer.CancelledError:\n                # Bail if we've been cancelled\n                raise\n            except BodyExceededMaxSize:\n                # If the well-known file was too large, do not keep attempting\n                # to download it, but consider it a temporary error.\n                logger.warning(\n                    \"Requested .well-known file for %s is too large > %r bytes\",\n                    server_name.decode(\"ascii\"),\n                    WELL_KNOWN_MAX_SIZE,\n                )\n                raise _FetchWellKnownFailure(temporary=True)\n            except Exception as e:\n                if not retry or i >= WELL_KNOWN_RETRY_ATTEMPTS:\n                    logger.info(\"Error fetching %s: %s\", uri_str, e)\n                    raise _FetchWellKnownFailure(temporary=True)\n\n                logger.info(\"Error fetching %s: %s. Retrying\", uri_str, e)\n\n            # Sleep briefly in the hopes that they come back up\n            await self._clock.sleep(0.5)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_event(self, url, authtoken, state, result, runtime):\n        if result._task_fields['args'].get('_ansible_check_mode') is True:\n            self.ansible_check_mode = True\n\n        if result._task_fields['args'].get('_ansible_version'):\n            self.ansible_version = \\\n                result._task_fields['args'].get('_ansible_version')\n\n        if result._task._role:\n            ansible_role = str(result._task._role)\n        else:\n            ansible_role = None\n\n        if 'args' in result._task_fields:\n            del result._task_fields['args']\n\n        data = {}\n        data['uuid'] = result._task._uuid\n        data['session'] = self.session\n        data['status'] = state\n        data['timestamp'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S '\n                                                       '+0000')\n        data['host'] = self.host\n        data['ip_address'] = self.ip_address\n        data['user'] = self.user\n        data['runtime'] = runtime\n        data['ansible_version'] = self.ansible_version\n        data['ansible_check_mode'] = self.ansible_check_mode\n        data['ansible_host'] = result._host.name\n        data['ansible_playbook'] = self.ansible_playbook\n        data['ansible_role'] = ansible_role\n        data['ansible_task'] = result._task_fields\n        data['ansible_result'] = result._result\n\n        # This wraps the json payload in and outer json event needed by Splunk\n        jsondata = json.dumps(data, cls=AnsibleJSONEncoder, sort_keys=True)\n        jsondata = '{\"event\":' + jsondata + \"}\"\n\n        open_url(\n            url,\n            jsondata,\n            headers={\n                'Content-type': 'application/json',\n                'Authorization': 'Splunk ' + authtoken\n            },\n            method='POST'\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __iter__(self):\n        vmatch = self.vmatch\n        vdict = self.vdict\n\n        with self.source.open('rb') as xmlf:\n            parser2 = _create_xml_parser(self.user_parser)\n            tree = etree.parse(xmlf, parser=parser2)\n            if not hasattr(tree, 'iterfind'):\n                # Python 2.6 compatibility\n                tree.iterfind = tree.findall\n\n            if vmatch is not None:\n                # simple case, all value paths are the same\n                for rowelm in tree.iterfind(self.rmatch):\n                    if self.attr is None:\n                        getv = attrgetter('text')\n                    else:\n                        getv = lambda e: e.get(self.attr)\n                    if isinstance(vmatch, string_types):\n                        # match only one path\n                        velms = rowelm.findall(vmatch)\n                    else:\n                        # match multiple paths\n                        velms = itertools.chain(*[rowelm.findall(enm)\n                                                  for enm in vmatch])\n                    yield tuple(getv(velm)\n                                for velm in velms)\n\n            else:\n                # difficult case, deal with different paths for each field\n\n                # determine output header\n                flds = tuple(sorted(map(text_type, vdict.keys())))\n                yield flds\n\n                # setup value getters\n                vmatches = dict()\n                vgetters = dict()\n                for f in flds:\n                    vmatch = self.vdict[f]\n                    if isinstance(vmatch, string_types):\n                        # match element path\n                        vmatches[f] = vmatch\n                        vgetters[f] = element_text_getter(self.missing)\n                    else:\n                        # match element path and attribute name\n                        vmatches[f] = vmatch[0]\n                        attr = vmatch[1]\n                        vgetters[f] = attribute_text_getter(attr, self.missing)\n\n                # determine data rows\n                for rowelm in tree.iterfind(self.rmatch):\n                    yield tuple(vgetters[f](rowelm.findall(vmatches[f]))\n                                for f in flds)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def lu_unpack(x, y, unpack_ludata=True, unpack_pivots=True, name=None):\n    r\"\"\"\n    Unpack L U and P to single matrix tensor .\n    unpack L and U matrix from LU, unpack permutation matrix P from Pivtos .\n\n    P mat can be get by pivots:\n\n    .. code-block:: text\n\n        ones = eye(rows) #eye matrix of rank rows\n        for i in range(cols):\n            swap(ones[i], ones[pivots[i]])\n\n\n    Args:\n        x (Tensor): The LU tensor get from paddle.linalg.lu, which is combined by L and U.\n\n        y (Tensor): Pivots get from paddle.linalg.lu.\n\n        unpack_ludata (bool,optional): whether to unpack L and U from x. Default: True.\n\n        unpack_pivots (bool, optional): whether to unpack permutation matrix P from Pivtos. Default: True.\n\n        name (str, optional): Name for the operation (optional, default is None).\n            For more information, please refer to :ref:`api_guide_Name`.\n\n    Returns:\n        P (Tensor), Permutation matrix P of lu factorization.\n\n        L (Tensor), The lower triangular matrix tensor of lu factorization.\n\n        U (Tensor), The upper triangular matrix tensor of lu factorization.\n\n\n    Examples:\n        .. code-block:: python\n\n            import paddle\n\n            x = paddle.to_tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]]).astype('float64')\n            lu,p,info = paddle.linalg.lu(x, get_infos=True)\n\n            # >>> lu:\n            # Tensor(shape=[3, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            #    [[5.        , 6.        ],\n            #        [0.20000000, 0.80000000],\n            #        [0.60000000, 0.50000000]])\n            # >>> p\n            # Tensor(shape=[2], dtype=int32, place=CUDAPlace(0), stop_gradient=True,\n            #    [3, 3])\n            # >>> info\n            # Tensor(shape=[], dtype=int32, place=CUDAPlace(0), stop_gradient=True,\n            #    0)\n\n            P,L,U = paddle.linalg.lu_unpack(lu,p)\n\n            # >>> P\n            # (Tensor(shape=[3, 3], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[0., 1., 0.],\n            # [0., 0., 1.],\n            # [1., 0., 0.]]),\n            # >>> L\n            # Tensor(shape=[3, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[1.        , 0.        ],\n            # [0.20000000, 1.        ],\n            # [0.60000000, 0.50000000]]),\n            # >>> U\n            # Tensor(shape=[2, 2], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n            # [[5.        , 6.        ],\n            # [0.        , 0.80000000]]))\n\n            # one can verify : X = P @ L @ U ;\n    \"\"\"\n    if x.ndim < 2:\n        raise ValueError(\n            f\"The shape of x should be (*, M, N), but received ndim is [{x.ndim} < 2]\"\n        )\n    if y.ndim < 1:\n        raise ValueError(\n            f\"The shape of Pivots should be (*, K), but received ndim is [{y.ndim} < 1]\"\n        )\n    if in_dynamic_mode():\n        P, L, U = _C_ops.lu_unpack(x, y, unpack_ludata, unpack_pivots)\n        return P, L, U\n    else:\n        check_variable_and_dtype(\n            x, 'dtype', ['float32', 'float64'], 'lu_unpack'\n        )\n        helper = LayerHelper('lu_unpack', **locals())\n        p = helper.create_variable_for_type_inference(dtype=x.dtype)\n        l = helper.create_variable_for_type_inference(dtype=x.dtype)\n        u = helper.create_variable_for_type_inference(dtype=x.dtype)\n\n        attrs = {}\n        attrs['unpack_ludata'] = unpack_ludata\n        attrs['unpack_pivots'] = unpack_pivots\n        helper.append_op(\n            type='lu_unpack',\n            inputs={'X': x, 'Pivots': y},\n            outputs={'Pmat': p, 'L': l, 'U': u},\n            attrs=attrs,\n        )\n        return p, l, u\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _get_obj_absolute_path(obj_path):\n    return safe_join(DATAROOT, obj_path)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def put_column_description() -> Response:\n\n    @action_logging\n    def _log_put_column_description(*, table_key: str, column_name: str, description: str, source: str) -> None:\n        pass  # pragma: no cover\n\n    try:\n        args = request.get_json()\n\n        table_key = get_query_param(args, 'key')\n        table_endpoint = _get_table_endpoint()\n\n        column_name = get_query_param(args, 'column_name')\n        description = get_query_param(args, 'description')\n\n        src = get_query_param(args, 'source')\n\n        table_uri = TableUri.from_uri(table_key)\n        if not is_table_editable(table_uri.schema, table_uri.table):\n            return make_response('', HTTPStatus.FORBIDDEN)\n\n        url = '{0}/{1}/column/{2}/description'.format(table_endpoint, table_key, column_name)\n        _log_put_column_description(table_key=table_key, column_name=column_name, description=description, source=src)\n\n        response = request_metadata(url=url, method='PUT', data=json.dumps({'description': description}))\n        status_code = response.status_code\n\n        if status_code == HTTPStatus.OK:\n            message = 'Success'\n        else:\n            message = 'Update column description failed'\n\n        payload = jsonify({'msg': message})\n        return make_response(payload, status_code)\n    except Exception as e:\n        payload = jsonify({'msg': 'Encountered exception: ' + str(e)})\n        return make_response(payload, HTTPStatus.INTERNAL_SERVER_ERROR)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    # We must decode URL before validating it\n    path = urllib.parse.unquote(path)\n\n    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def file(path):\n    if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n        with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:\n            encrypted_data = encrypted_file.read()\n        file_data = encryptor.decrypt(\n            app.interface.encryption_key, encrypted_data)\n        return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n    else:\n        return send_file(safe_join(app.cwd, path))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            path_base = os.path.join(self.E.mod, \"web\")\n            static_path = absreal(os.path.join(path_base, self.vpath[5:]))\n            if not static_path.startswith(path_base):\n                t = \"attempted path traversal [{}] => [{}]\"\n                self.log(t.format(self.vpath, static_path), 1)\n                self.tx_404()\n                return False\n\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _save(self, name, content):\n        full_path = self.path(name)\n\n        # Create any intermediate directories that do not exist.\n        directory = os.path.dirname(full_path)\n        try:\n            if self.directory_permissions_mode is not None:\n                # Set the umask because os.makedirs() doesn't apply the \"mode\"\n                # argument to intermediate-level directories.\n                old_umask = os.umask(0o777 & ~self.directory_permissions_mode)\n                try:\n                    os.makedirs(directory, self.directory_permissions_mode, exist_ok=True)\n                finally:\n                    os.umask(old_umask)\n            else:\n                os.makedirs(directory, exist_ok=True)\n        except FileExistsError:\n            raise FileExistsError('%s exists and is not a directory.' % directory)\n\n        # There's a potential race condition between get_available_name and\n        # saving the file; it's possible that two threads might return the\n        # same name, at which point all sorts of fun happens. So we need to\n        # try to create the file, but if it already exists we have to go back\n        # to get_available_name() and try again.\n\n        while True:\n            try:\n                # This file has a file path that we can move.\n                if hasattr(content, 'temporary_file_path'):\n                    file_move_safe(content.temporary_file_path(), full_path)\n\n                # This is a normal uploadedfile that we can stream.\n                else:\n                    # The current umask value is masked out by os.open!\n                    fd = os.open(full_path, self.OS_OPEN_FLAGS, 0o666)\n                    _file = None\n                    try:\n                        locks.lock(fd, locks.LOCK_EX)\n                        for chunk in content.chunks():\n                            if _file is None:\n                                mode = 'wb' if isinstance(chunk, bytes) else 'wt'\n                                _file = os.fdopen(fd, mode)\n                            _file.write(chunk)\n                    finally:\n                        locks.unlock(fd)\n                        if _file is not None:\n                            _file.close()\n                        else:\n                            os.close(fd)\n            except FileExistsError:\n                # A new name is needed if the file exists.\n                name = self.get_available_name(name)\n                full_path = self.path(name)\n            else:\n                # OK, the file save worked. Break out of the loop.\n                break\n\n        if self.file_permissions_mode is not None:\n            os.chmod(full_path, self.file_permissions_mode)\n\n        # Store filenames with forward slashes, even on Windows.\n        return str(name).replace('\\\\', '/')\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _add_widgets(self, package_name: str, hook_class: type, widgets: dict[str, Any]):\n        conn_type = hook_class.conn_type  # type: ignore\n        for field_identifier, field in widgets.items():\n            if field_identifier.startswith(\"extra__\"):\n                prefixed_field_name = field_identifier\n            else:\n                prefixed_field_name = f\"extra__{conn_type}__{field_identifier}\"\n            if prefixed_field_name in self._connection_form_widgets:\n                log.warning(\n                    \"The field %s from class %s has already been added by another provider. Ignoring it.\",\n                    field_identifier,\n                    hook_class.__name__,\n                )\n                # In case of inherited hooks this might be happening several times\n                continue\n            self._connection_form_widgets[prefixed_field_name] = ConnectionFormWidgetInfo(\n                hook_class.__name__,\n                package_name,\n                field,\n                field_identifier,\n                hasattr(field.field_class.widget, \"input_type\")\n                and field.field_class.widget.input_type == \"password\",\n            )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _getResourceForRequest(self, request):\n        \"\"\"(Internal) Get the appropriate resource for the given host.\n        \"\"\"\n        host = string.lower(request.getHeader('host'))\n        return self.hosts.get(host, error.NoResource(\"host %s not in vhost map\" % repr(host)))\n        "}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, fobj):\n        \"\"\"\n        fobj is a file-like object as an icns resource\n        \"\"\"\n        # signature : (start, length)\n        self.dct = dct = {}\n        self.fobj = fobj\n        sig, filesize = nextheader(fobj)\n        if sig != b'icns':\n            raise SyntaxError('not an icns file')\n        i = HEADERSIZE\n        while i < filesize:\n            sig, blocksize = nextheader(fobj)\n            if blocksize <= 0:\n                raise SyntaxError('invalid block header')\n            i += HEADERSIZE\n            blocksize -= HEADERSIZE\n            dct[sig] = (i, blocksize)\n            fobj.seek(blocksize, 1)\n            i += blocksize\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static int expandrow2(UINT8* dest, const UINT8* src, int n, int z, int xsize)\n{\n    UINT8 pixel, count;\n\n\n    for (;n > 0; n--)\n    {\n        pixel = src[1];\n        src+=2;\n        if (n == 1 && pixel != 0)\n            return n;\n        count = pixel & RLE_MAX_RUN;\n        if (!count)\n            return count;\n        if (count > xsize) {\n            return -1;\n        }\n        if (pixel & RLE_COPY_FLAG) {\n            while(count--) {\n                memcpy(dest, src, 2);\n                src += 2;\n                dest += z * 2;\n            }\n        }\n        else {\n            while (count--) {\n                memcpy(dest, src, 2);\n                dest += z * 2;\n            }\n            src+=2;\n        }\n    }\n    return 0;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.shutting_down, self.load_started])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if (not qtutils.version_check('5.9') and\n                not error.ignore and\n                url.matches(self.url(requested=True), QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* reverse_index_map_t;\n    const Tensor* grad_values_t;\n    OP_REQUIRES_OK(context,\n                   context->input(\"reverse_index_map\", &reverse_index_map_t));\n    OP_REQUIRES_OK(context, context->input(\"grad_values\", &grad_values_t));\n\n    const CPUDevice& d = context->eigen_device<CPUDevice>();\n\n    OP_REQUIRES(\n        context, TensorShapeUtils::IsVector(reverse_index_map_t->shape()),\n        errors::InvalidArgument(\"reverse_index_map must be a vector, saw: \",\n                                reverse_index_map_t->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(grad_values_t->shape()),\n                errors::InvalidArgument(\"grad_values must be a vector, saw: \",\n                                        grad_values_t->shape().DebugString()));\n\n    const auto reverse_index_map = reverse_index_map_t->vec<int64>();\n    const auto grad_values = grad_values_t->vec<T>();\n\n    const int64 N = reverse_index_map_t->shape().dim_size(0);\n    const int64 N_full = grad_values_t->shape().dim_size(0);\n\n    Tensor* d_values_t;\n    OP_REQUIRES_OK(context, context->allocate_output(\n                                \"d_values\", TensorShape({N}), &d_values_t));\n    auto d_values = d_values_t->vec<T>();\n    Tensor* d_default_value_t;\n    OP_REQUIRES_OK(context,\n                   context->allocate_output(\"d_default_value\", TensorShape({}),\n                                            &d_default_value_t));\n    T& d_default_value = d_default_value_t->scalar<T>()();\n    d_default_value = T();\n\n    Tensor visited_t;\n    OP_REQUIRES_OK(context, context->allocate_temp(\n                                DT_BOOL, TensorShape({N_full}), &visited_t));\n    auto visited = visited_t.vec<bool>();\n    visited.device(d) = visited.constant(false);\n\n    for (int i = 0; i < N; ++i) {\n      // Locate the index of the output of the forward prop associated\n      // with this location in the input of the forward prop.  Copy\n      // the gradient into it.  Mark it as visited.\n      int64 reverse_index = reverse_index_map(i);\n      OP_REQUIRES(\n          context, 0 <= reverse_index && reverse_index < N_full,\n          errors::InvalidArgument(\"Elements in reverse index must be in [0, \",\n                                  N_full, \") but got \", reverse_index));\n      d_values(i) = grad_values(reverse_index);\n      visited(reverse_index) = true;\n    }\n    for (int j = 0; j < N_full; ++j) {\n      // The default value gradient gets the accumulated remainder of\n      // the backprop values (since the default value was used to fill\n      // in these slots in the forward calculation).\n      if (!visited(j)) {\n        d_default_value += grad_values(j);\n      }\n    }\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def diff_objects(old_instance, new_instance, fields):\n    \"\"\"\n    Diff two objects by examining the given fields and\n    return a string.\n    \"\"\"\n    full_diff = []\n\n    for field in fields:\n        field_diff = []\n        old_value = getattr(old_instance, field.attname)\n        new_value = getattr(new_instance, field.attname)\n\n        # clean stored XSS\n        if isinstance(old_value, str):\n            old_value = bleach_input(old_value)\n        if isinstance(new_value, str):\n            new_value = bleach_input(new_value)\n\n        for line in difflib.unified_diff(\n            str(old_value).split(\"\\n\"),\n            str(new_value).split(\"\\n\"),\n            fromfile=field.attname,\n            tofile=field.attname,\n            lineterm=\"\",\n        ):\n            field_diff.append(line)\n        full_diff.extend(field_diff)\n\n    return \"\\n\".join(full_diff)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done_with_cleanup);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment, REDUCTION_COLLECTIVE,\n                             resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    col_params->merge_op = merge_op_.get();\n    col_params->final_op = final_op_.get();\n    VLOG(1) << \"CollectiveReduceV3 group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "static RList *create_cache_bins(RBinFile *bf, RDyldCache *cache) {\n\tRList *bins = r_list_newf ((RListFree)free_bin);\n\tut16 *depArray = NULL;\n\tcache_imgxtr_t *extras = NULL;\n\tif (!bins) {\n\t\treturn NULL;\n\t}\n\n\tchar *target_libs = NULL;\n\tRList *target_lib_names = NULL;\n\tint *deps = NULL;\n\ttarget_libs = r_sys_getenv (\"R_DYLDCACHE_FILTER\");\n\tif (target_libs) {\n\t\ttarget_lib_names = r_str_split_list (target_libs, \":\", 0);\n\t\tif (!target_lib_names) {\n\t\t\tr_list_free (bins);\n\t\t\treturn NULL;\n\t\t}\n\t\tdeps = R_NEWS0 (int, cache->hdr->imagesCount);\n\t\tif (!deps) {\n\t\t\tr_list_free (bins);\n\t\t\tr_list_free (target_lib_names);\n\t\t\treturn NULL;\n\t\t}\n\t}\n\n\tut32 i;\n\tfor (i = 0; i < cache->n_hdr; i++) {\n\t\tcache_hdr_t *hdr = &cache->hdr[i];\n\t\tut64 hdr_offset = cache->hdr_offset[i];\n\t\tut32 maps_index = cache->maps_index[i];\n\t\tcache_img_t *img = read_cache_images (cache->buf, hdr, hdr_offset);\n\t\tif (!img) {\n\t\t\tgoto next;\n\t\t}\n\n\t\tut32 j;\n\t\tif (target_libs) {\n\t\t\tHtPU *path_to_idx = NULL;\n\t\t\tif (cache->accel) {\n\t\t\t\tdepArray = R_NEWS0 (ut16, cache->accel->depListCount);\n\t\t\t\tif (!depArray) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\n\t\t\t\tif (r_buf_fread_at (cache->buf, cache->accel->depListOffset, (ut8*) depArray, \"s\", cache->accel->depListCount) != cache->accel->depListCount * 2) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\n\t\t\t\textras = read_cache_imgextra (cache->buf, hdr, cache->accel);\n\t\t\t\tif (!extras) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tpath_to_idx = create_path_to_index (cache->buf, img, hdr);\n\t\t\t}\n\n\t\t\tfor (j = 0; j < hdr->imagesCount; j++) {\n\t\t\t\tbool printing = !deps[j];\n\t\t\t\tchar *lib_name = get_lib_name (cache->buf, &img[j]);\n\t\t\t\tif (!lib_name) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (strstr (lib_name, \"libobjc.A.dylib\")) {\n\t\t\t\t\tdeps[j]++;\n\t\t\t\t}\n\t\t\t\tif (!r_list_find (target_lib_names, lib_name, string_contains)) {\n\t\t\t\t\tR_FREE (lib_name);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tif (printing) {\n\t\t\t\t\teprintf (\"FILTER: %s\\n\", lib_name);\n\t\t\t\t}\n\t\t\t\tR_FREE (lib_name);\n\t\t\t\tdeps[j]++;\n\n\t\t\t\tif (extras && depArray) {\n\t\t\t\t\tut32 k;\n\t\t\t\t\tfor (k = extras[j].dependentsStartArrayIndex; depArray[k] != 0xffff; k++) {\n\t\t\t\t\t\tut16 dep_index = depArray[k] & 0x7fff;\n\t\t\t\t\t\tdeps[dep_index]++;\n\n\t\t\t\t\t\tchar *dep_name = get_lib_name (cache->buf, &img[dep_index]);\n\t\t\t\t\t\tif (!dep_name) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (printing) {\n\t\t\t\t\t\t\teprintf (\"-> %s\\n\", dep_name);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (dep_name);\n\t\t\t\t\t}\n\t\t\t\t} else if (path_to_idx) {\n\t\t\t\t\tcarve_deps_at_address (cache, img, path_to_idx, img[j].address, deps, printing);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tht_pu_free (path_to_idx);\n\t\t\tR_FREE (depArray);\n\t\t\tR_FREE (extras);\n\t\t}\n\n\t\tfor (j = 0; j < hdr->imagesCount; j++) {\n\t\t\tif (deps && !deps[j]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tut64 pa = va2pa (img[j].address, hdr->mappingCount, &cache->maps[maps_index], cache->buf, 0, NULL, NULL);\n\t\t\tif (pa == UT64_MAX) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tut8 magicbytes[4];\n\t\t\tr_buf_read_at (cache->buf, pa, magicbytes, 4);\n\t\t\tint magic = r_read_le32 (magicbytes);\n\t\t\tswitch (magic) {\n\t\t\tcase MH_MAGIC_64:\n\t\t\t{\n\t\t\t\tchar file[256];\n\t\t\t\tRDyldBinImage *bin = R_NEW0 (RDyldBinImage);\n\t\t\t\tif (!bin) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tbin->header_at = pa;\n\t\t\t\tbin->hdr_offset = hdr_offset;\n\t\t\t\tbin->symbols_off = resolve_symbols_off (cache, pa);\n\t\t\t\tbin->va = img[j].address;\n\t\t\t\tif (r_buf_read_at (cache->buf, img[j].pathFileOffset, (ut8*) &file, sizeof (file)) == sizeof (file)) {\n\t\t\t\t\tfile[255] = 0;\n\t\t\t\t\tchar *last_slash = strrchr (file, '/');\n\t\t\t\t\tif (last_slash && *last_slash) {\n\t\t\t\t\t\tif (last_slash > file) {\n\t\t\t\t\t\t\tchar *scan = last_slash - 1;\n\t\t\t\t\t\t\twhile (scan > file && *scan != '/') {\n\t\t\t\t\t\t\t\tscan--;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (*scan == '/') {\n\t\t\t\t\t\t\t\tbin->file = strdup (scan + 1);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tbin->file = strdup (last_slash + 1);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tbin->file = strdup (last_slash + 1);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tbin->file = strdup (file);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tr_list_append (bins, bin);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdefault:\n\t\t\t\teprintf (\"Unknown sub-bin\\n\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\nnext:\n\t\tR_FREE (depArray);\n\t\tR_FREE (extras);\n\t\tR_FREE (img);\n\t}\n\tif (r_list_empty (bins)) {\n\t\tr_list_free (bins);\n\t\tbins = NULL;\n\t}\n\tR_FREE (deps);\n\tR_FREE (target_libs);\n\tr_list_free (target_lib_names);\n\treturn bins;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sensitive_config_values(self) -> Set[tuple[str, str]]:  # noqa: UP006\n        if self.configuration_description is None:\n            return (\n                _get_empty_set_for_configuration()\n            )  # we can't use set() here because set is defined below # \u00af\\_(\u30c4)_/\u00af\n        flattened = {\n            (s, k): item\n            for s, s_c in self.configuration_description.items()\n            for k, item in s_c.get(\"options\").items()  # type: ignore[union-attr]\n        }\n        sensitive = {\n            (section.lower(), key.lower())\n            for (section, key), v in flattened.items()\n            if v.get(\"sensitive\") is True\n        }\n        depr_option = {self.deprecated_options[x][:-1] for x in sensitive if x in self.deprecated_options}\n        depr_section = {\n            (self.deprecated_sections[s][0], k) for s, k in sensitive if s in self.deprecated_sections\n        }\n        sensitive.update(depr_section, depr_option)\n        return sensitive\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def sanitize_file_name(self, file_name):\n        \"\"\"\n        Sanitize the filename of an upload.\n\n        Remove all possible path separators, even though that might remove more\n        than actually required by the target system. Filenames that could\n        potentially cause problems (current/parent dir) are also discarded.\n\n        It should be noted that this function could still return a \"filepath\"\n        like \"C:some_file.txt\" which is handled later on by the storage layer.\n        So while this function does sanitize filenames to some extent, the\n        resulting filename should still be considered as untrusted user input.\n        \"\"\"\n        file_name = html.unescape(file_name)\n        file_name = file_name.rsplit('/')[-1]\n        file_name = file_name.rsplit('\\\\')[-1]\n\n        if file_name in {'', '.', '..'}:\n            return None\n        return file_name\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def extract(self, to_path):\n        members = self._archive.getmembers()\n        leading = self.has_leading_dir(x.name for x in members)\n        for member in members:\n            name = member.name\n            if leading:\n                name = self.split_leading_dir(name)[1]\n            filename = self.target_filename(to_path, name)\n            if member.isdir():\n                if filename:\n                    os.makedirs(filename, exist_ok=True)\n            else:\n                try:\n                    extracted = self._archive.extractfile(member)\n                except (KeyError, AttributeError) as exc:\n                    # Some corrupt tar files seem to produce this\n                    # (specifically bad symlinks)\n                    print(\"In the tar file %s the member %s is invalid: %s\" %\n                          (name, member.name, exc))\n                else:\n                    dirname = os.path.dirname(filename)\n                    if dirname:\n                        os.makedirs(dirname, exist_ok=True)\n                    with open(filename, 'wb') as outfile:\n                        shutil.copyfileobj(extracted, outfile)\n                        self._copy_permissions(member.mode, filename)\n                finally:\n                    if extracted:\n                        extracted.close()\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* context) override {\n    const Tensor* input_indices;\n    const Tensor* input_values;\n    const Tensor* input_shape;\n    SparseTensorsMap* map;\n\n    OP_REQUIRES_OK(context, context->input(\"sparse_indices\", &input_indices));\n    OP_REQUIRES_OK(context, context->input(\"sparse_values\", &input_values));\n    OP_REQUIRES_OK(context, context->input(\"sparse_shape\", &input_shape));\n    OP_REQUIRES_OK(context, GetMap(context, true /* is_writing */, &map));\n\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrix(input_indices->shape()),\n                errors::InvalidArgument(\n                    \"Input indices should be a matrix but received shape \",\n                    input_indices->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_values->shape()),\n                errors::InvalidArgument(\n                    \"Input values should be a vector but received shape \",\n                    input_values->shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVector(input_shape->shape()),\n                errors::InvalidArgument(\n                    \"Input shape should be a vector but received shape \",\n                    input_shape->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_values->shape().dim_size(0) == input_indices->shape().dim_size(0),\n        errors::InvalidArgument(\n            \"Number of values must match first dimension of indices. \", \"Got \",\n            input_values->shape().dim_size(0),\n            \" values, indices shape: \", input_indices->shape().DebugString()));\n    OP_REQUIRES(\n        context,\n        input_shape->shape().dim_size(0) == input_indices->shape().dim_size(1),\n        errors::InvalidArgument(\n            \"Number of dimensions must match second dimension of indices. \",\n            \"Got \", input_shape->shape().dim_size(0),\n            \" dimensions, indices shape: \",\n            input_indices->shape().DebugString()));\n\n    int rank = input_shape->NumElements();\n\n    OP_REQUIRES(\n        context, rank > 1,\n        errors::InvalidArgument(\n            \"Rank of input SparseTensor should be > 1, but saw rank: \", rank));\n\n    auto input_shape_vec = input_shape->vec<int64_t>();\n    int new_num_elements = 1;\n    bool overflow_ocurred = false;\n    for (int i = 0; i < input_shape_vec.size(); i++) {\n      new_num_elements =\n          MultiplyWithoutOverflow(new_num_elements, input_shape_vec(i));\n      if (new_num_elements < 0) {\n        overflow_ocurred = true;\n        break;\n      }\n    }\n\n    OP_REQUIRES(\n        context, !overflow_ocurred,\n        errors::Internal(\"Encountered overflow from large input shape.\"));\n\n    TensorShape tensor_input_shape(input_shape_vec);\n    gtl::InlinedVector<int64_t, 8> std_order(rank);\n    std::iota(std_order.begin(), std_order.end(), 0);\n    SparseTensor input_st;\n    OP_REQUIRES_OK(context, SparseTensor::Create(*input_indices, *input_values,\n                                                 tensor_input_shape, std_order,\n                                                 &input_st));\n\n    const int64_t N = input_shape_vec(0);\n\n    Tensor sparse_handles(DT_INT64, TensorShape({N}));\n    auto sparse_handles_t = sparse_handles.vec<int64_t>();\n\n    OP_REQUIRES_OK(context, input_st.IndicesValid());\n\n    // We can generate the output shape proto string now, for all\n    // minibatch entries.\n    TensorShape output_shape;\n    OP_REQUIRES_OK(context, TensorShapeUtils::MakeShape(\n                                input_shape_vec.data() + 1,\n                                input_shape->NumElements() - 1, &output_shape));\n\n    // Get groups by minibatch dimension\n    std::unordered_set<int64_t> visited;\n    sparse::GroupIterable minibatch = input_st.group({0});\n    for (const auto& subset : minibatch) {\n      const int64_t b = subset.group()[0];\n      visited.insert(b);\n      OP_REQUIRES(\n          context, b > -1 && b < N,\n          errors::InvalidArgument(\n              \"Received unexpected column 0 value in input SparseTensor: \", b,\n              \" < 0 or >= N (= \", N, \")\"));\n\n      const auto indices = subset.indices();\n      const auto values = subset.values<T>();\n      const int64_t num_entries = values.size();\n\n      Tensor output_indices = Tensor(DT_INT64, {num_entries, rank - 1});\n      Tensor output_values = Tensor(DataTypeToEnum<T>::value, {num_entries});\n\n      auto output_indices_t = output_indices.matrix<int64_t>();\n      auto output_values_t = output_values.vec<T>();\n\n      for (int i = 0; i < num_entries; ++i) {\n        for (int d = 1; d < rank; ++d) {\n          output_indices_t(i, d - 1) = indices(i, d);\n        }\n        output_values_t(i) = values(i);\n      }\n\n      SparseTensor st_i;\n      OP_REQUIRES_OK(context,\n                     SparseTensor::Create(output_indices, output_values,\n                                          output_shape, &st_i));\n      int64_t handle;\n      OP_REQUIRES_OK(context, map->AddSparseTensor(context, st_i, &handle));\n      sparse_handles_t(b) = handle;\n    }\n\n    // Fill in any gaps; we must provide an empty ST for batch entries\n    // the grouper didn't find.\n    if (visited.size() < N) {\n      Tensor empty_indices(DT_INT64, {0, rank - 1});\n      Tensor empty_values(DataTypeToEnum<T>::value, {0});\n      SparseTensor empty_st;\n      OP_REQUIRES_OK(context, SparseTensor::Create(empty_indices, empty_values,\n                                                   output_shape, &empty_st));\n\n      for (int64_t b = 0; b < N; ++b) {\n        // We skipped this batch entry.\n        if (visited.find(b) == visited.end()) {\n          int64_t handle;\n          OP_REQUIRES_OK(context,\n                         map->AddSparseTensor(context, empty_st, &handle));\n          sparse_handles_t(b) = handle;\n        }\n      }\n    }\n\n    context->set_output(0, sparse_handles);\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def is_select(self) -> bool:\n        # make sure we strip comments; prevents a bug with coments in the CTE\n        parsed = sqlparse.parse(self.strip_comments())\n\n        # Check if this is a CTE\n        if parsed[0].is_group and parsed[0][0].ttype == Keyword.CTE:\n            if sqloxide_parse is not None:\n                try:\n                    if not self._check_cte_is_select(\n                        sqloxide_parse(self.strip_comments(), dialect=\"ansi\")\n                    ):\n                        return False\n                except ValueError:\n                    # sqloxide was not able to parse the query, so let's continue with\n                    # sqlparse\n                    pass\n            inner_cte = self.get_inner_cte_expression(parsed[0].tokens) or []\n            # Check if the inner CTE is a not a SELECT\n            if any(token.ttype == DDL for token in inner_cte) or any(\n                token.ttype == DML and token.normalized != \"SELECT\"\n                for token in inner_cte\n            ):\n                return False\n\n        if parsed[0].get_type() == \"SELECT\":\n            return True\n\n        if parsed[0].get_type() != \"UNKNOWN\":\n            return False\n\n        # for `UNKNOWN`, check all DDL/DML explicitly: only `SELECT` DML is allowed,\n        # and no DDL is allowed\n        if any(token.ttype == DDL for token in parsed[0]) or any(\n            token.ttype == DML and token.value != \"SELECT\" for token in parsed[0]\n        ):\n            return False\n\n        # return false on `EXPLAIN`, `SET`, `SHOW`, etc.\n        if parsed[0][0].ttype == Keyword:\n            return False\n\n        return any(\n            token.ttype == DML and token.value == \"SELECT\" for token in parsed[0]\n        )\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& handle = ctx->input(0);\n    OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(handle.shape()),\n                errors::InvalidArgument(\"handle must be scalar\"));\n    const string& name = handle.scalar<tstring>()();\n    Tensor val;\n    auto session_state = ctx->session_state();\n    OP_REQUIRES(ctx, session_state != nullptr,\n                errors::FailedPrecondition(\n                    \"GetSessionTensor called on null session state\"));\n    OP_REQUIRES_OK(ctx, session_state->GetTensor(name, &val));\n    ctx->set_output(0, val);\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "async def _can_passwordless_sudo() -> bool:\n    process = await asyncio.create_subprocess_exec(\n        \"sudo\",\n        \"-n\",\n        \"true\",\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n    )\n    _, _ = await process.communicate()\n    return process.returncode == 0\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def copy_with(self, **kwargs: typing.Any) -> \"URL\":\n        \"\"\"\n        Copy this URL, returning a new URL with some components altered.\n        Accepts the same set of parameters as the components that are made\n        available via properties on the `URL` class.\n\n        For example:\n\n        url = httpx.URL(\"https://www.example.com\").copy_with(username=\"jo@gmail.com\", password=\"a secret\")\n        assert url == \"https://jo%40email.com:a%20secret@www.example.com\"\n        \"\"\"\n        allowed = {\n            \"scheme\": str,\n            \"username\": str,\n            \"password\": str,\n            \"userinfo\": bytes,\n            \"host\": str,\n            \"port\": int,\n            \"netloc\": bytes,\n            \"path\": str,\n            \"query\": bytes,\n            \"raw_path\": bytes,\n            \"fragment\": str,\n            \"params\": object,\n        }\n\n        # Step 1\n        # ======\n        #\n        # Perform type checking for all supported keyword arguments.\n        for key, value in kwargs.items():\n            if key not in allowed:\n                message = f\"{key!r} is an invalid keyword argument for copy_with()\"\n                raise TypeError(message)\n            if value is not None and not isinstance(value, allowed[key]):\n                expected = allowed[key].__name__\n                seen = type(value).__name__\n                message = f\"Argument {key!r} must be {expected} but got {seen}\"\n                raise TypeError(message)\n\n        # Step 2\n        # ======\n        #\n        # Consolidate \"username\", \"password\", \"userinfo\", \"host\", \"port\" and \"netloc\"\n        # into a single \"authority\" keyword, for `rfc3986`.\n        if \"username\" in kwargs or \"password\" in kwargs:\n            # Consolidate \"username\" and \"password\" into \"userinfo\".\n            username = quote(kwargs.pop(\"username\", self.username) or \"\")\n            password = quote(kwargs.pop(\"password\", self.password) or \"\")\n            userinfo = f\"{username}:{password}\" if password else username\n            kwargs[\"userinfo\"] = userinfo.encode(\"ascii\")\n\n        if \"host\" in kwargs or \"port\" in kwargs:\n            # Consolidate \"host\" and \"port\" into \"netloc\".\n            host = kwargs.pop(\"host\", self.host) or \"\"\n            port = kwargs.pop(\"port\", self.port)\n\n            if host and \":\" in host and host[0] != \"[\":\n                # IPv6 addresses need to be escaped within square brackets.\n                host = f\"[{host}]\"\n\n            kwargs[\"netloc\"] = (\n                f\"{host}:{port}\".encode(\"ascii\")\n                if port is not None\n                else host.encode(\"ascii\")\n            )\n\n        if \"userinfo\" in kwargs or \"netloc\" in kwargs:\n            # Consolidate \"userinfo\" and \"netloc\" into authority.\n            userinfo = (kwargs.pop(\"userinfo\", self.userinfo) or b\"\").decode(\"ascii\")\n            netloc = (kwargs.pop(\"netloc\", self.netloc) or b\"\").decode(\"ascii\")\n            authority = f\"{userinfo}@{netloc}\" if userinfo else netloc\n            kwargs[\"authority\"] = authority\n\n        # Step 3\n        # ======\n        #\n        # Wrangle any \"path\", \"query\", \"raw_path\" and \"params\" keywords into\n        # \"query\" and \"path\" keywords for `rfc3986`.\n        if \"raw_path\" in kwargs:\n            # If \"raw_path\" is included, then split it into \"path\" and \"query\" components.\n            raw_path = kwargs.pop(\"raw_path\") or b\"\"\n            path, has_query, query = raw_path.decode(\"ascii\").partition(\"?\")\n            kwargs[\"path\"] = path\n            kwargs[\"query\"] = query if has_query else None\n\n        else:\n            if kwargs.get(\"path\") is not None:\n                # Ensure `kwargs[\"path\"] = <url quoted str>` for `rfc3986`.\n                kwargs[\"path\"] = quote(kwargs[\"path\"])\n\n            if kwargs.get(\"query\") is not None:\n                # Ensure `kwargs[\"query\"] = <str>` for `rfc3986`.\n                #\n                # Note that `.copy_with(query=None)` and `.copy_with(query=b\"\")`\n                # are subtly different. The `None` style will not include an empty\n                # trailing \"?\" character.\n                kwargs[\"query\"] = kwargs[\"query\"].decode(\"ascii\")\n\n            if \"params\" in kwargs:\n                # Replace any \"params\" keyword with the raw \"query\" instead.\n                #\n                # Ensure that empty params use `kwargs[\"query\"] = None` rather\n                # than `kwargs[\"query\"] = \"\"`, so that generated URLs do not\n                # include an empty trailing \"?\".\n                params = kwargs.pop(\"params\")\n                kwargs[\"query\"] = None if not params else str(QueryParams(params))\n\n        # Step 4\n        # ======\n        #\n        # Ensure any fragment component is quoted.\n        if kwargs.get(\"fragment\") is not None:\n            kwargs[\"fragment\"] = quote(kwargs[\"fragment\"])\n\n        # Step 5\n        # ======\n        #\n        # At this point kwargs may include keys for \"scheme\", \"authority\", \"path\",\n        # \"query\" and \"fragment\". Together these constitute the entire URL.\n        #\n        # See https://tools.ietf.org/html/rfc3986#section-3\n        #\n        #  foo://example.com:8042/over/there?name=ferret#nose\n        #  \\_/   \\______________/\\_________/ \\_________/ \\__/\n        #   |           |            |            |        |\n        # scheme     authority       path        query   fragment\n        new_url = URL(self)\n        new_url._uri_reference = self._uri_reference.copy_with(**kwargs)\n        if new_url.is_absolute_url:\n            new_url._uri_reference = new_url._uri_reference.normalize()\n        return URL(new_url)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs, pusherdict):\n        self.hs = hs\n        self.store = self.hs.get_datastore()\n        self.storage = self.hs.get_storage()\n        self.clock = self.hs.get_clock()\n        self.state_handler = self.hs.get_state_handler()\n        self.user_id = pusherdict[\"user_name\"]\n        self.app_id = pusherdict[\"app_id\"]\n        self.app_display_name = pusherdict[\"app_display_name\"]\n        self.device_display_name = pusherdict[\"device_display_name\"]\n        self.pushkey = pusherdict[\"pushkey\"]\n        self.pushkey_ts = pusherdict[\"ts\"]\n        self.data = pusherdict[\"data\"]\n        self.last_stream_ordering = pusherdict[\"last_stream_ordering\"]\n        self.backoff_delay = HttpPusher.INITIAL_BACKOFF_SEC\n        self.failing_since = pusherdict[\"failing_since\"]\n        self.timed_call = None\n        self._is_processing = False\n        self._group_unread_count_by_room = hs.config.push_group_unread_count_by_room\n\n        # This is the highest stream ordering we know it's safe to process.\n        # When new events arrive, we'll be given a window of new events: we\n        # should honour this rather than just looking for anything higher\n        # because of potential out-of-order event serialisation. This starts\n        # off as None though as we don't know any better.\n        self.max_stream_ordering = None\n\n        if \"data\" not in pusherdict:\n            raise PusherConfigException(\"No 'data' key for HTTP pusher\")\n        self.data = pusherdict[\"data\"]\n\n        self.name = \"%s/%s/%s\" % (\n            pusherdict[\"user_name\"],\n            pusherdict[\"app_id\"],\n            pusherdict[\"pushkey\"],\n        )\n\n        if self.data is None:\n            raise PusherConfigException(\"data can not be null for HTTP pusher\")\n\n        if \"url\" not in self.data:\n            raise PusherConfigException(\"'url' required in data for HTTP pusher\")\n        self.url = self.data[\"url\"]\n        self.http_client = hs.get_proxied_blacklisted_http_client()\n        self.data_minus_url = {}\n        self.data_minus_url.update(self.data)\n        del self.data_minus_url[\"url\"]\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def log_request(handler):\n    \"\"\"log a bit more information about each request than tornado's default\n\n    - move static file get success to debug-level (reduces noise)\n    - get proxied IP instead of proxy IP\n    - log referer for redirect and failed requests\n    - log user-agent for failed requests\n    \"\"\"\n    status = handler.get_status()\n    request = handler.request\n    try:\n        logger = handler.log\n    except AttributeError:\n        logger = access_log\n\n    if status < 300 or status == 304:\n        # Successes (or 304 FOUND) are debug-level\n        log_method = logger.debug\n    elif status < 400:\n        log_method = logger.info\n    elif status < 500:\n        log_method = logger.warning\n    else:\n        log_method = logger.error\n\n    request_time = 1000.0 * handler.request.request_time()\n    ns = dict(\n        status=status,\n        method=request.method,\n        ip=request.remote_ip,\n        uri=request.uri,\n        request_time=request_time,\n    )\n    msg = \"{status} {method} {uri} ({ip}) {request_time:.2f}ms\"\n    if status >= 400:\n        # log bad referers\n        ns[\"referer\"] = request.headers.get(\"Referer\", \"None\")\n        msg = msg + \" referer={referer}\"\n    if status >= 500 and status != 502:\n        # Log a subset of the headers if it caused an error.\n        headers = {}\n        for header in ['Host', 'Accept', 'Referer', 'User-Agent']:\n            if header in request.headers:\n                headers[header] = request.headers[header]\n        log_method(json.dumps(headers, indent=2))\n    log_method(msg.format(**ns))\n    prometheus_log_method(handler)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def redirect(redirect_path, redirect_params=None, **kw):\n    \"\"\"Redirect (via cherrypy.HTTPRedirect).\n\n    Raises the exception instead of returning it, this to allow\n    users to both call it as a function or to raise it as an exception.\n\n    \"\"\"\n    if not isinstance(redirect_path, basestring):\n        redirect_path = '/'.join(list(redirect_path))\n    if not redirect_path.startswith('/'):\n        path = request.path_info\n        check_app_root()\n        if path.startswith(request.app_root):\n            path = path[len(request.app_root):]\n        redirect_path = urlparse.urljoin(path, redirect_path)\n    if set(redirect_path).intersection({'\\r', '\\n'}):\n        raise InvalidRedirectException('Invalid redirect: {}'.format(redirect_path))\n    raise cherrypy.HTTPRedirect(url(tgpath=redirect_path,\n        tgparams=redirect_params, **kw))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& indices = ctx->input(0);\n    const auto values = ctx->input(1).flat<Tidx>();\n    const Tensor& dense_shape = ctx->input(2);\n    const Tensor& size_t = ctx->input(3);\n    const auto weights = ctx->input(4).flat<T>();\n    const int64_t weights_size = weights.size();\n\n    Tidx size = size_t.scalar<Tidx>()();\n    OP_REQUIRES(\n        ctx, size >= 0,\n        errors::InvalidArgument(\"size (\", size, \") must be non-negative\"));\n\n    bool is_1d = dense_shape.NumElements() == 1;\n\n    Tensor* out_t;\n    functor::SetZeroFunctor<Device, T> fill;\n    if (is_1d) {\n      OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({size}), &out_t));\n      auto out = out_t->flat<T>();\n      fill(ctx->eigen_device<Device>(), out);\n      if (binary_output_) {\n        OP_REQUIRES_OK(ctx,\n                       functor::BincountFunctor<Device, Tidx, T, true>::Compute(\n                           ctx, values, weights, out, size));\n      } else {\n        OP_REQUIRES_OK(\n            ctx, functor::BincountFunctor<Device, Tidx, T, false>::Compute(\n                     ctx, values, weights, out, size));\n      }\n    } else {\n      const auto shape = dense_shape.flat<int64_t>();\n      const int64_t num_rows = shape(0);\n      OP_REQUIRES_OK(\n          ctx, ctx->allocate_output(0, TensorShape({num_rows, size}), &out_t));\n      const auto out = out_t->matrix<T>();\n      fill(ctx->eigen_device<Device>(), out_t->flat<T>());\n      const auto indices_mat = indices.matrix<int64_t>();\n      for (int64_t i = 0; i < indices_mat.dimension(0); ++i) {\n        const int64_t batch = indices_mat(i, 0);\n        const Tidx bin = values(i);\n        OP_REQUIRES(\n            ctx, batch < out.dimension(0),\n            errors::InvalidArgument(\"Index out of bound. `batch` (\", batch,\n                                    \") must be less than the dimension size (\",\n                                    out.dimension(0), \").\"));\n        OP_REQUIRES(\n            ctx, bin < out.dimension(1),\n            errors::InvalidArgument(\"Index out ouf bound. `bin` (\", bin,\n                                    \") must be less then the dimension size (\",\n                                    out.dimension(1), \").\"));\n        if (bin < size) {\n          if (binary_output_) {\n            out(batch, bin) = T(1);\n          } else {\n            if (weights_size) {\n              out(batch, bin) += weights(i);\n            } else {\n              out(batch, bin) += T(1);\n            }\n          }\n        }\n      }\n    }\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def _extract_tar_file(tar, filename, b_dest, b_temp_path, expected_hash=None):\n    n_filename = to_native(filename, errors='surrogate_or_strict')\n    try:\n        member = tar.getmember(n_filename)\n    except KeyError:\n        raise AnsibleError(\"Collection tar at '%s' does not contain the expected file '%s'.\" % (to_native(tar.name),\n                                                                                                n_filename))\n\n    with tempfile.NamedTemporaryFile(dir=b_temp_path, delete=False) as tmpfile_obj:\n        bufsize = 65536\n        sha256_digest = sha256()\n        with _tarfile_extract(tar, member) as tar_obj:\n            data = tar_obj.read(bufsize)\n            while data:\n                tmpfile_obj.write(data)\n                tmpfile_obj.flush()\n                sha256_digest.update(data)\n                data = tar_obj.read(bufsize)\n\n        actual_hash = sha256_digest.hexdigest()\n\n        if expected_hash and actual_hash != expected_hash:\n            raise AnsibleError(\"Checksum mismatch for '%s' inside collection at '%s'\"\n                               % (n_filename, to_native(tar.name)))\n\n        b_dest_filepath = os.path.abspath(os.path.join(b_dest, to_bytes(filename, errors='surrogate_or_strict')))\n        b_parent_dir = os.path.dirname(b_dest_filepath)\n        if b_parent_dir != b_dest and not b_parent_dir.startswith(b_dest + to_bytes(os.path.sep)):\n            raise AnsibleError(\"Cannot extract tar entry '%s' as it will be placed outside the collection directory\"\n                               % to_native(filename, errors='surrogate_or_strict'))\n\n        if not os.path.exists(b_parent_dir):\n            # Seems like Galaxy does not validate if all file entries have a corresponding dir ftype entry. This check\n            # makes sure we create the parent directory even if it wasn't set in the metadata.\n            os.makedirs(b_parent_dir, mode=0o0755)\n\n        shutil.move(to_bytes(tmpfile_obj.name, errors='surrogate_or_strict'), b_dest_filepath)\n\n        # Default to rw-r--r-- and only add execute if the tar file has execute.\n        new_mode = 0o644\n        if stat.S_IMODE(member.mode) & stat.S_IXUSR:\n            new_mode |= 0o0111\n\n        os.chmod(b_dest_filepath, new_mode)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def logout(self, message, relaystate=None, samlresponse=None):\n        \"\"\"\n        Handle HTTP logout. The supported logout methods are stored\n        in each session. First all the SOAP sessions are logged out\n        then the HTTP Redirect method is used for any remaining\n        sessions.\n\n        The basic process is this:\n         1. A logout request is received. It is processed and the response\n            cached.\n         2. If any other SP's have also logged in as this user then the\n            first such session is popped off and a logout request is\n            generated and forwarded to the SP.\n         3. If a logout response is received then the user is marked\n            as logged out from that SP.\n         Repeat steps 2-3 until only the initial logout request is\n         left unhandled, at which time the pre-generated response is sent\n         back to the SP that originated the logout request.\n\n        The final logout response is always a redirect.\n        \"\"\"\n        logout = self.cfg.idp.get_logout_handler()\n\n        us = UserSession()\n\n        saml_sessions = self.cfg.idp.sessionfactory\n\n        logout_type = None\n        try:\n            if lasso.SAML2_FIELD_REQUEST in message:\n                logout_type = \"request\"\n                self._handle_logout_request(us, logout, saml_sessions,\n                                            message)\n            elif samlresponse:\n                logout_type = \"response\"\n                self._handle_logout_response(us, logout, saml_sessions,\n                                             message, samlresponse)\n            else:\n                raise cherrypy.HTTPError(400, 'Bad Request. Not a ' +\n                                         'logout request or response.')\n        except InvalidRequest as e:\n            raise cherrypy.HTTPError(400, 'Bad Request. %s' % e)\n        except UnknownProvider as e:\n            raise cherrypy.HTTPError(\n                400, 'Invalid logout %s: %s' % (logout_type, e)\n            )\n\n        # Fall through to handle any remaining sessions.\n\n        # Find the next SP to logout and send a LogoutRequest\n        logout_order = [\n            lasso.SAML2_METADATA_BINDING_SOAP,\n            lasso.SAML2_METADATA_BINDING_REDIRECT,\n        ]\n        (logout_mech, session) = saml_sessions.get_next_logout(\n            logout_mechs=logout_order, user=us.user)\n        while session:\n            self.debug('Going to log out %s' % session.provider_id)\n\n            try:\n                logout.setSessionFromDump(session.login_session)\n            except lasso.ProfileBadSessionDumpError as e:\n                self.error('Failed to load session: %s' % e)\n                raise cherrypy.HTTPRedirect(400, 'Failed to log out user: %s '\n                                            % e)\n            try:\n                if logout_mech == lasso.SAML2_METADATA_BINDING_REDIRECT:\n                    logout.initRequest(session.provider_id,\n                                       lasso.HTTP_METHOD_REDIRECT)\n                else:\n                    logout.initRequest(session.provider_id,\n                                       lasso.HTTP_METHOD_SOAP)\n            except lasso.ServerProviderNotFoundError:\n                self.error(\n                    'Service Provider %s not found. Trying next session' %\n                    session.provider_id\n                )\n                saml_sessions.remove_session(session)\n                (logout_mech, session) = saml_sessions.get_next_logout(\n                    logout_mechs=logout_order, user=us.user)\n                continue\n\n            try:\n                logout.buildRequestMsg()\n            except lasso.Error, e:\n                self.error('failure to build logout request msg: %s' % e)\n                raise cherrypy.HTTPRedirect(400, 'Failed to log out user: %s '\n                                            % e)\n\n            # Set the full list of session indexes for this provider to\n            # log out\n            self.debug('logging out provider id %s' % session.provider_id)\n            indexes = saml_sessions.get_session_id_by_provider_id(\n                session.provider_id, us.user\n            )\n            self.debug('Requesting logout for sessions %s' % (indexes,))\n            req = logout.get_request()\n            req.setSessionIndexes(indexes)\n\n            session.set_logoutstate(relaystate=logout.msgUrl,\n                                    request_id=logout.request.id)\n            saml_sessions.start_logout(session, initial=False)\n\n            self.debug('Request logout ID %s for session ID %s' %\n                       (logout.request.id, session.session_id))\n\n            if logout_mech == lasso.SAML2_METADATA_BINDING_REDIRECT:\n                self.debug('Redirecting to another SP to logout on %s at %s' %\n                           (logout.remoteProviderId, logout.msgUrl))\n                raise cherrypy.HTTPRedirect(logout.msgUrl)\n            else:\n                self.debug('SOAP request to another SP to logout on %s at %s' %\n                           (logout.remoteProviderId, logout.msgUrl))\n                if logout.msgBody:\n                    message = self._soap_logout(logout)\n                    try:\n                        self._handle_logout_response(us,\n                                                     logout,\n                                                     saml_sessions,\n                                                     message,\n                                                     samlresponse)\n                    except Exception as e:  # pylint: disable=broad-except\n                        self.error('SOAP SLO failed %s' % e)\n                else:\n                    self.error('Provider does not support SOAP')\n\n            (logout_mech, session) = saml_sessions.get_next_logout(\n                logout_mechs=logout_order, user=us.user)\n\n        # done while\n\n        # All sessions should be logged out now. Respond to the\n        # original request using the response we cached earlier.\n\n        try:\n            session = saml_sessions.get_initial_logout(us.user)\n        except ValueError:\n            self.debug('SLO get_last_session() unable to find last session')\n            raise cherrypy.HTTPError(400, 'Unable to determine logout state')\n\n        redirect = session.relaystate\n        if not redirect:\n            redirect = self.basepath\n\n        saml_sessions.remove_session(session)\n\n        # Log out of cherrypy session\n        user = us.get_user()\n        self._audit('Logged out user: %s [%s] from %s' %\n                    (user.name, user.fullname,\n                     session.provider_id))\n        us.logout(user)\n\n        self.debug('SLO redirect to %s' % redirect)\n\n        raise cherrypy.HTTPRedirect(redirect)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_header_lines(header):\n    \"\"\"\n    Splits the header into lines, putting multi-line headers together.\n    \"\"\"\n    r = []\n    lines = header.split(b\"\\r\\n\")\n    for line in lines:\n        if b\"\\r\" in line or b\"\\n\" in line:\n            raise ParsingError('Bare CR or LF found in header line \"%s\"' % tostr(line))\n\n        if line.startswith((b\" \", b\"\\t\")):\n            if not r:\n                # https://corte.si/posts/code/pathod/pythonservers/index.html\n                raise ParsingError('Malformed header line \"%s\"' % tostr(line))\n            r[-1] += line\n        else:\n            r.append(line)\n    return r\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "Status Examples::CreateSparseFeatureRepresentation(\n    const DeviceBase::CpuWorkerThreads& worker_threads, const int num_examples,\n    const int num_sparse_features, const ModelWeights& weights,\n    const OpInputList& sparse_example_indices_inputs,\n    const OpInputList& sparse_feature_indices_inputs,\n    const OpInputList& sparse_feature_values_inputs,\n    std::vector<Example>* const examples) {\n  mutex mu;\n  Status result;  // Guarded by mu\n  auto parse_partition = [&](const int64 begin, const int64 end) {\n    // The static_cast here is safe since begin and end can be at most\n    // num_examples which is an int.\n    for (int i = static_cast<int>(begin); i < end; ++i) {\n      auto example_indices =\n          sparse_example_indices_inputs[i].template flat<int64>();\n      auto feature_indices =\n          sparse_feature_indices_inputs[i].template flat<int64>();\n      if (example_indices.size() != feature_indices.size()) {\n        mutex_lock l(mu);\n        result = errors::InvalidArgument(\n            \"Found mismatched example_indices and feature_indices [\",\n            example_indices, \"] vs [\", feature_indices, \"]\");\n        return;\n      }\n\n      // Parse features for each example. Features for a particular example\n      // are at the offsets (start_id, end_id]\n      int start_id = -1;\n      int end_id = 0;\n      for (int example_id = 0; example_id < num_examples; ++example_id) {\n        start_id = end_id;\n        while (end_id < example_indices.size() &&\n               example_indices(end_id) == example_id) {\n          ++end_id;\n        }\n        Example::SparseFeatures* const sparse_features =\n            &(*examples)[example_id].sparse_features_[i];\n        if (start_id < example_indices.size() &&\n            example_indices(start_id) == example_id) {\n          sparse_features->indices.reset(new UnalignedInt64Vector(\n              &(feature_indices(start_id)), end_id - start_id));\n          if (sparse_feature_values_inputs.size() > i) {\n            auto feature_weights =\n                sparse_feature_values_inputs[i].flat<float>();\n            sparse_features->values.reset(new UnalignedFloatVector(\n                &(feature_weights(start_id)), end_id - start_id));\n          }\n          // If features are non empty.\n          if (end_id - start_id > 0) {\n            // TODO(sibyl-Aix6ihai): Write this efficiently using vectorized\n            // operations from eigen.\n            for (int64 k = 0; k < sparse_features->indices->size(); ++k) {\n              const int64 feature_index = (*sparse_features->indices)(k);\n              if (!weights.SparseIndexValid(i, feature_index)) {\n                mutex_lock l(mu);\n                result = errors::InvalidArgument(\n                    \"Found sparse feature indices out of valid range: \",\n                    (*sparse_features->indices)(k));\n                return;\n              }\n            }\n          }\n        } else {\n          // Add a Tensor that has size 0.\n          sparse_features->indices.reset(\n              new UnalignedInt64Vector(&(feature_indices(0)), 0));\n          // If values exist for this feature group.\n          if (sparse_feature_values_inputs.size() > i) {\n            auto feature_weights =\n                sparse_feature_values_inputs[i].flat<float>();\n            sparse_features->values.reset(\n                new UnalignedFloatVector(&(feature_weights(0)), 0));\n          }\n        }\n      }\n    }\n  };\n  // For each column, the cost of parsing it is O(num_examples). We use\n  // num_examples here, as empirically Shard() creates the right amount of\n  // threads based on the problem size.\n  // TODO(sibyl-Aix6ihai): Tune this as a function of dataset size.\n  const int64 kCostPerUnit = num_examples;\n  Shard(worker_threads.num_threads, worker_threads.workers, num_sparse_features,\n        kCostPerUnit, parse_partition);\n  return result;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  Status ValidateInputsGenerateOutputs(\n      OpKernelContext* ctx, const Tensor** inputs, const Tensor** seq_len,\n      Tensor** log_prob, OpOutputList* decoded_indices,\n      OpOutputList* decoded_values, OpOutputList* decoded_shape) const {\n    Status status = ctx->input(\"inputs\", inputs);\n    if (!status.ok()) return status;\n    status = ctx->input(\"sequence_length\", seq_len);\n    if (!status.ok()) return status;\n\n    const TensorShape& inputs_shape = (*inputs)->shape();\n\n    if (inputs_shape.dims() != 3) {\n      return errors::InvalidArgument(\"inputs is not a 3-Tensor\");\n    }\n    if (inputs_shape.num_elements() == 0) {\n      return errors::InvalidArgument(\"inputs must not be empty\");\n    }\n\n    const int64 max_time = inputs_shape.dim_size(0);\n    const int64 batch_size = inputs_shape.dim_size(1);\n\n    if (max_time == 0) {\n      return errors::InvalidArgument(\"max_time is 0\");\n    }\n    if (!TensorShapeUtils::IsVector((*seq_len)->shape())) {\n      return errors::InvalidArgument(\"sequence_length is not a vector\");\n    }\n\n    if (!(batch_size == (*seq_len)->dim_size(0))) {\n      return errors::FailedPrecondition(\n          \"len(sequence_length) != batch_size.  \",\n          \"len(sequence_length):  \", (*seq_len)->dim_size(0),\n          \" batch_size: \", batch_size);\n    }\n\n    auto seq_len_t = (*seq_len)->vec<int32>();\n\n    for (int b = 0; b < batch_size; ++b) {\n      if (!(seq_len_t(b) <= max_time)) {\n        return errors::FailedPrecondition(\"sequence_length(\", b,\n                                          \") <= \", max_time);\n      }\n    }\n\n    Status s = ctx->allocate_output(\n        \"log_probability\", TensorShape({batch_size, top_paths_}), log_prob);\n    if (!s.ok()) return s;\n\n    s = ctx->output_list(\"decoded_indices\", decoded_indices);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_values\", decoded_values);\n    if (!s.ok()) return s;\n    s = ctx->output_list(\"decoded_shape\", decoded_shape);\n    if (!s.ok()) return s;\n\n    return Status::OK();\n  }\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def send_commenting_notifications(self, changes):\n        \"\"\"\n        Sends notifications about any changes to comments to anyone who is subscribed.\n        \"\"\"\n        relevant_comment_ids = []\n        relevant_comment_ids.extend(comment.pk for comment in changes['resolved_comments'])\n        relevant_comment_ids.extend(comment.pk for comment, replies in changes['new_replies'])\n\n        # Skip if no changes were made\n        # Note: We don't email about edited comments so ignore those here\n        if (not changes['new_comments']\n                and not changes['deleted_comments']\n                and not changes['resolved_comments']\n                and not changes['new_replies']):\n            return\n\n        # Get global page comment subscribers\n        subscribers = PageSubscription.objects.filter(page=self.page, comment_notifications=True).select_related('user')\n        global_recipient_users = [subscriber.user for subscriber in subscribers if subscriber.user != self.request.user]\n\n        # Get subscribers to individual threads\n        replies = CommentReply.objects.filter(comment_id__in=relevant_comment_ids)\n        comments = Comment.objects.filter(id__in=relevant_comment_ids)\n        thread_users = get_user_model().objects.exclude(pk=self.request.user.pk).exclude(pk__in=subscribers.values_list('user_id', flat=True)).filter(\n            Q(comment_replies__comment_id__in=relevant_comment_ids) | Q(**{('%s__pk__in' % COMMENTS_RELATION_NAME): relevant_comment_ids})\n        ).prefetch_related(\n            Prefetch('comment_replies', queryset=replies),\n            Prefetch(COMMENTS_RELATION_NAME, queryset=comments)\n        )\n\n        # Skip if no recipients\n        if not (global_recipient_users or thread_users):\n            return\n        thread_users = [(user, set(list(user.comment_replies.values_list('comment_id', flat=True)) + list(getattr(user, COMMENTS_RELATION_NAME).values_list('pk', flat=True)))) for user in thread_users]\n        mailed_users = set()\n\n        for current_user, current_threads in thread_users:\n            # We are trying to avoid calling send_notification for each user for performance reasons\n            # so group the users receiving the same thread notifications together here\n            if current_user in mailed_users:\n                continue\n            users = [current_user]\n            mailed_users.add(current_user)\n            for user, threads in thread_users:\n                if user not in mailed_users and threads == current_threads:\n                    users.append(user)\n                    mailed_users.add(user)\n            send_notification(users, 'updated_comments', {\n                'page': self.page,\n                'editor': self.request.user,\n                'new_comments': [comment for comment in changes['new_comments'] if comment.pk in threads],\n                'resolved_comments': [comment for comment in changes['resolved_comments'] if comment.pk in threads],\n                'deleted_comments': [],\n                'replied_comments': [\n                    {\n                        'comment': comment,\n                        'replies': replies,\n                    }\n                    for comment, replies in changes['new_replies']\n                    if comment.pk in threads\n                ]\n            })\n\n        return send_notification(global_recipient_users, 'updated_comments', {\n            'page': self.page,\n            'editor': self.request.user,\n            'new_comments': changes['new_comments'],\n            'resolved_comments': changes['resolved_comments'],\n            'deleted_comments': changes['deleted_comments'],\n            'replied_comments': [\n                {\n                    'comment': comment,\n                    'replies': replies,\n                }\n                for comment, replies in changes['new_replies']\n            ]\n        })\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "bool ParseAttrValue(StringPiece type, StringPiece text, AttrValue* out) {\n  // Parse type.\n  string field_name;\n  bool is_list = absl::ConsumePrefix(&type, \"list(\");\n  if (absl::ConsumePrefix(&type, \"string\")) {\n    field_name = \"s\";\n  } else if (absl::ConsumePrefix(&type, \"int\")) {\n    field_name = \"i\";\n  } else if (absl::ConsumePrefix(&type, \"float\")) {\n    field_name = \"f\";\n  } else if (absl::ConsumePrefix(&type, \"bool\")) {\n    field_name = \"b\";\n  } else if (absl::ConsumePrefix(&type, \"type\")) {\n    field_name = \"type\";\n  } else if (absl::ConsumePrefix(&type, \"shape\")) {\n    field_name = \"shape\";\n  } else if (absl::ConsumePrefix(&type, \"tensor\")) {\n    field_name = \"tensor\";\n  } else if (absl::ConsumePrefix(&type, \"func\")) {\n    field_name = \"func\";\n  } else if (absl::ConsumePrefix(&type, \"placeholder\")) {\n    field_name = \"placeholder\";\n  } else {\n    return false;\n  }\n  if (is_list && !absl::ConsumePrefix(&type, \")\")) {\n    return false;\n  }\n\n  // Construct a valid text proto message to parse.\n  string to_parse;\n  if (is_list) {\n    // TextFormat parser considers \"i: 7\" to be the same as \"i: [7]\",\n    // but we only want to allow list values with [].\n    StringPiece cleaned = text;\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    str_util::RemoveTrailingWhitespace(&cleaned);\n    if (cleaned.size() < 2 || cleaned[0] != '[' ||\n        cleaned[cleaned.size() - 1] != ']') {\n      return false;\n    }\n    cleaned.remove_prefix(1);\n    str_util::RemoveLeadingWhitespace(&cleaned);\n    if (cleaned.size() == 1) {\n      // User wrote \"[]\", so return empty list without invoking the TextFormat\n      // parse which returns an error for \"i: []\".\n      out->Clear();\n      out->mutable_list();\n      return true;\n    }\n    to_parse = strings::StrCat(\"list { \", field_name, \": \", text, \" }\");\n  } else {\n    to_parse = strings::StrCat(field_name, \": \", text);\n  }\n  if (field_name == \"tensor\") {\n    if (!ParseAttrValueHelper_TensorNestsUnderLimit(kMaxTensorNestDepth,\n                                                    to_parse)) {\n      return false;\n    }\n  }\n  return ProtoParseFromString(to_parse, out);\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def __init__(self, hs):\n        super().__init__(hs)\n\n        # An HTTP client for contacting trusted URLs.\n        self.http_client = SimpleHttpClient(hs)\n        # An HTTP client for contacting identity servers specified by clients.\n        self.blacklisting_http_client = SimpleHttpClient(\n            hs, ip_blacklist=hs.config.federation_ip_range_blacklist\n        )\n        self.federation_http_client = hs.get_federation_http_client()\n        self.hs = hs\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def _on_ssl_errors(self, error):\n        url = error.url()\n        self._insecure_hosts.add(url.host())\n\n        log.webview.debug(\"Certificate error: {}\".format(error))\n\n        if error.is_overridable():\n            error.ignore = shared.ignore_certificate_errors(\n                url, [error], abort_on=[self.abort_questions])\n        else:\n            log.webview.error(\"Non-overridable certificate error: \"\n                              \"{}\".format(error))\n\n        log.webview.debug(\"ignore {}, URL {}, requested {}\".format(\n            error.ignore, url, self.url(requested=True)))\n\n        # WORKAROUND for https://bugreports.qt.io/browse/QTBUG-56207\n        show_cert_error = (\n            not qtutils.version_check('5.9') and\n            not error.ignore\n        )\n        # WORKAROUND for https://codereview.qt-project.org/c/qt/qtwebengine/+/270556\n        show_non_overr_cert_error = (\n            not error.is_overridable() and (\n                # Affected Qt versions:\n                # 5.13 before 5.13.2\n                # 5.12 before 5.12.6\n                # < 5.12\n                (qtutils.version_check('5.13') and\n                 not qtutils.version_check('5.13.2')) or\n                (qtutils.version_check('5.12') and\n                 not qtutils.version_check('5.12.6')) or\n                not qtutils.version_check('5.12')\n            )\n        )\n\n        # We can't really know when to show an error page, as the error might\n        # have happened when loading some resource.\n        # However, self.url() is not available yet and the requested URL\n        # might not match the URL we get from the error - so we just apply a\n        # heuristic here.\n        if ((show_cert_error or show_non_overr_cert_error) and\n                url.matches(self.data.last_navigation.url, QUrl.RemoveScheme)):\n            self._show_error_page(url, str(error))\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "expandrow(UINT8 *dest, UINT8 *src, int n, int z, int xsize, UINT8 *end_of_buffer) {\n    /*\n     * n here is the number of rlechunks\n     * z is the number of channels, for calculating the interleave\n     *   offset to go to RGBA style pixels\n     * xsize is the row width\n     * end_of_buffer is the address of the end of the input buffer\n     */\n\n    UINT8 pixel, count;\n    int x = 0;\n\n    for (; n > 0; n--) {\n        if (src > end_of_buffer) {\n            return -1;\n        }\n        pixel = *src++;\n        if (n == 1 && pixel != 0) {\n            return n;\n        }\n        count = pixel & RLE_MAX_RUN;\n        if (!count) {\n            return count;\n        }\n        if (x + count > xsize) {\n            return -1;\n        }\n        x += count;\n        if (pixel & RLE_COPY_FLAG) {\n            if (src + count > end_of_buffer) {\n                return -1;\n            }\n            while (count--) {\n                *dest = *src++;\n                dest += z;\n            }\n\n        } else {\n            if (src > end_of_buffer) {\n                return -1;\n            }\n            pixel = *src++;\n            while (count--) {\n                *dest = pixel;\n                dest += z;\n            }\n        }\n    }\n    return 0;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (bytes < 8) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "  void ComputeAsync(OpKernelContext* c, DoneCallback done) override {\n    auto col_params = new CollectiveParams();\n    auto done_with_cleanup = [col_params, done = std::move(done)]() {\n      done();\n      col_params->Unref();\n    };\n    core::RefCountPtr<CollectiveGroupResource> resource;\n    OP_REQUIRES_OK_ASYNC(c, LookupResource(c, HandleFromInput(c, 1), &resource),\n                         done_with_cleanup);\n\n    Tensor group_assignment = c->input(2);\n\n    OP_REQUIRES_OK_ASYNC(\n        c,\n        FillCollectiveParams(col_params, group_assignment,\n                             ALL_TO_ALL_COLLECTIVE, resource.get()),\n        done);\n    col_params->instance.shape = c->input(0).shape();\n    VLOG(1) << \"CollectiveAllToAll group_size \" << col_params->group.group_size\n            << \" group_key \" << col_params->group.group_key << \" instance_key \"\n            << col_params->instance.instance_key;\n    // Allocate the output tensor, trying to reuse the input.\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK_ASYNC(c,\n                         c->forward_input_or_allocate_output(\n                             {0}, 0, col_params->instance.shape, &output),\n                         done_with_cleanup);\n    Run(c, col_params, std::move(done_with_cleanup));\n  }\n};"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def get_request_handler(\n    dependant: Dependant,\n    body_field: Optional[ModelField] = None,\n    status_code: int = 200,\n    response_class: Union[Type[Response], DefaultPlaceholder] = Default(JSONResponse),\n    response_field: Optional[ModelField] = None,\n    response_model_include: Optional[Union[SetIntStr, DictIntStrAny]] = None,\n    response_model_exclude: Optional[Union[SetIntStr, DictIntStrAny]] = None,\n    response_model_by_alias: bool = True,\n    response_model_exclude_unset: bool = False,\n    response_model_exclude_defaults: bool = False,\n    response_model_exclude_none: bool = False,\n    dependency_overrides_provider: Optional[Any] = None,\n) -> Callable[[Request], Coroutine[Any, Any, Response]]:\n    assert dependant.call is not None, \"dependant.call must be a function\"\n    is_coroutine = asyncio.iscoroutinefunction(dependant.call)\n    is_body_form = body_field and isinstance(body_field.field_info, params.Form)\n    if isinstance(response_class, DefaultPlaceholder):\n        actual_response_class: Type[Response] = response_class.value\n    else:\n        actual_response_class = response_class\n\n    async def app(request: Request) -> Response:\n        try:\n            body: Any = None\n            if body_field:\n                if is_body_form:\n                    body = await request.form()\n                else:\n                    body_bytes = await request.body()\n                    if body_bytes:\n                        json_body: Any = Undefined\n                        content_type_value = request.headers.get(\"content-type\")\n                        if content_type_value:\n                            message = email.message.Message()\n                            message[\"content-type\"] = content_type_value\n                            if message.get_content_maintype() == \"application\":\n                                subtype = message.get_content_subtype()\n                                if subtype == \"json\" or subtype.endswith(\"+json\"):\n                                    json_body = await request.json()\n                        if json_body != Undefined:\n                            body = json_body\n                        else:\n                            body = body_bytes\n        except json.JSONDecodeError as e:\n            raise RequestValidationError([ErrorWrapper(e, (\"body\", e.pos))], body=e.doc)\n        except Exception as e:\n            raise HTTPException(\n                status_code=400, detail=\"There was an error parsing the body\"\n            ) from e\n        solved_result = await solve_dependencies(\n            request=request,\n            dependant=dependant,\n            body=body,\n            dependency_overrides_provider=dependency_overrides_provider,\n        )\n        values, errors, background_tasks, sub_response, _ = solved_result\n        if errors:\n            raise RequestValidationError(errors, body=body)\n        else:\n            raw_response = await run_endpoint_function(\n                dependant=dependant, values=values, is_coroutine=is_coroutine\n            )\n\n            if isinstance(raw_response, Response):\n                if raw_response.background is None:\n                    raw_response.background = background_tasks\n                return raw_response\n            response_data = await serialize_response(\n                field=response_field,\n                response_content=raw_response,\n                include=response_model_include,\n                exclude=response_model_exclude,\n                by_alias=response_model_by_alias,\n                exclude_unset=response_model_exclude_unset,\n                exclude_defaults=response_model_exclude_defaults,\n                exclude_none=response_model_exclude_none,\n                is_coroutine=is_coroutine,\n            )\n            response = actual_response_class(\n                content=response_data,\n                status_code=status_code,\n                background=background_tasks,  # type: ignore # in Starlette\n            )\n            response.headers.raw.extend(sub_response.headers.raw)\n            if sub_response.status_code:\n                response.status_code = sub_response.status_code\n            return response\n\n    return app\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "handle_keywordonly_args(struct compiling *c, const node *n, int start,\n                        asdl_seq *kwonlyargs, asdl_seq *kwdefaults)\n{\n    PyObject *argname;\n    node *ch;\n    expr_ty expression, annotation;\n    arg_ty arg = NULL;\n    int i = start;\n    int j = 0; /* index for kwdefaults and kwonlyargs */\n\n    if (kwonlyargs == NULL) {\n        ast_error(c, CHILD(n, start), \"named arguments must follow bare *\");\n        return -1;\n    }\n    assert(kwdefaults != NULL);\n    while (i < NCH(n)) {\n        ch = CHILD(n, i);\n        switch (TYPE(ch)) {\n            case vfpdef:\n            case tfpdef:\n                if (i + 1 < NCH(n) && TYPE(CHILD(n, i + 1)) == EQUAL) {\n                    expression = ast_for_expr(c, CHILD(n, i + 2));\n                    if (!expression)\n                        goto error;\n                    asdl_seq_SET(kwdefaults, j, expression);\n                    i += 2; /* '=' and test */\n                }\n                else { /* setting NULL if no default value exists */\n                    asdl_seq_SET(kwdefaults, j, NULL);\n                }\n                if (NCH(ch) == 3) {\n                    /* ch is NAME ':' test */\n                    annotation = ast_for_expr(c, CHILD(ch, 2));\n                    if (!annotation)\n                        goto error;\n                }\n                else {\n                    annotation = NULL;\n                }\n                ch = CHILD(ch, 0);\n                argname = NEW_IDENTIFIER(ch);\n                if (!argname)\n                    goto error;\n                if (forbidden_name(c, argname, ch, 0))\n                    goto error;\n                arg = arg(argname, annotation, NULL, LINENO(ch), ch->n_col_offset,\n                          c->c_arena);\n                if (!arg)\n                    goto error;\n                asdl_seq_SET(kwonlyargs, j++, arg);\n                i += 1; /* the name */\n                if (i < NCH(n) && TYPE(CHILD(n, i)) == COMMA)\n                    i += 1; /* the comma, if present */\n                break;\n            case TYPE_COMMENT:\n                /* arg will be equal to the last argument processed */\n                arg->type_comment = NEW_TYPE_COMMENT(ch);\n                if (!arg->type_comment)\n                    goto error;\n                i += 1;\n                break;\n            case DOUBLESTAR:\n                return i;\n            default:\n                ast_error(c, ch, \"unexpected node\");\n                goto error;\n        }\n    }\n    return i;\n error:\n    return -1;\n}\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "def index():\n    \"\"\" Index handler \"\"\"\n\n    send = prevent_open_redirect(request.vars.send)\n    if DEMO_MODE:\n        session.authorized = True\n        session.last_time = t0\n    if not send:\n        send = URL('site')\n    if session.authorized:\n        redirect(send)\n    elif failed_login_count() >= allowed_number_of_attempts:\n        time.sleep(2 ** allowed_number_of_attempts)\n        raise HTTP(403)\n    elif request.vars.password:\n        if verify_password(request.vars.password[:1024]):\n            session.authorized = True\n            login_record(True)\n\n            if CHECK_VERSION:\n                session.check_version = True\n            else:\n                session.check_version = False\n\n            session.last_time = t0\n            if isinstance(send, list):  # ## why does this happen?\n                send = str(send[0])\n\n            redirect(send)\n        else:\n            times_denied = login_record(False)\n            if times_denied >= allowed_number_of_attempts:\n                response.flash = \\\n                    T('admin disabled because too many invalid login attempts')\n            elif times_denied == allowed_number_of_attempts - 1:\n                response.flash = \\\n                    T('You have one more login attempt before you are locked out')\n            else:\n                response.flash = T('invalid password.')\n    return dict(send=send)\n"}, {"role": "assistant", "content": "False"}]}
{"messages": [{"role": "system", "content": "You are a security expert that is good at static program analysis"}, {"role": "user", "content": "    def post(self):\n        \"\"\"This method handles the POST requests to add agents to the Cloud Verifier.\n\n        Currently, only agents resources are available for POSTing, i.e. /agents. All other POST uri's will return errors.\n        agents requests require a json block sent in the body\n        \"\"\"\n        session = get_session()\n        try:\n            rest_params = web_util.get_restful_params(self.request.uri)\n            if rest_params is None:\n                web_util.echo_json_response(\n                    self, 405, \"Not Implemented: Use /agents/ interface\")\n                return\n\n            if not web_util.validate_api_version(self, rest_params[\"api_version\"], logger):\n                return\n\n            if \"agents\" not in rest_params:\n                web_util.echo_json_response(self, 400, \"uri not supported\")\n                logger.warning('POST returning 400 response. uri not supported: %s', self.request.path)\n                return\n\n            agent_id = rest_params[\"agents\"]\n\n            if agent_id is not None:\n                # If the agent ID is not valid (wrong set of\n                # characters), just do nothing.\n                if not validators.valid_agent_id(agent_id):\n                    web_util.echo_json_response(self, 400, \"agent_id not not valid\")\n                    logger.error(\"POST received an invalid agent ID: %s\", agent_id)\n                    return\n\n                content_length = len(self.request.body)\n                if content_length == 0:\n                    web_util.echo_json_response(\n                        self, 400, \"Expected non zero content length\")\n                    logger.warning('POST returning 400 response. Expected non zero content length.')\n                else:\n                    json_body = json.loads(self.request.body)\n                    agent_data = {}\n                    agent_data['v'] = json_body['v']\n                    agent_data['ip'] = json_body['cloudagent_ip']\n                    agent_data['port'] = int(json_body['cloudagent_port'])\n                    agent_data['operational_state'] = states.START\n                    agent_data['public_key'] = \"\"\n                    agent_data['tpm_policy'] = json_body['tpm_policy']\n                    agent_data['meta_data'] = json_body['metadata']\n                    agent_data['allowlist'] = json_body['allowlist']\n                    agent_data['mb_refstate'] = json_body['mb_refstate']\n                    agent_data['ima_sign_verification_keys'] = json_body['ima_sign_verification_keys']\n                    agent_data['revocation_key'] = json_body['revocation_key']\n                    agent_data['accept_tpm_hash_algs'] = json_body['accept_tpm_hash_algs']\n                    agent_data['accept_tpm_encryption_algs'] = json_body['accept_tpm_encryption_algs']\n                    agent_data['accept_tpm_signing_algs'] = json_body['accept_tpm_signing_algs']\n                    agent_data['supported_version'] = json_body['supported_version']\n                    agent_data['ak_tpm'] = json_body['ak_tpm']\n                    agent_data['mtls_cert'] = json_body.get('mtls_cert', None)\n                    agent_data['hash_alg'] = \"\"\n                    agent_data['enc_alg'] = \"\"\n                    agent_data['sign_alg'] = \"\"\n                    agent_data['agent_id'] = agent_id\n                    agent_data['boottime'] = 0\n                    agent_data['ima_pcrs'] = []\n                    agent_data['pcr10'] = None\n                    agent_data['next_ima_ml_entry'] = 0\n                    agent_data['learned_ima_keyrings'] = {}\n                    agent_data['verifier_id'] = config.get('cloud_verifier', 'cloudverifier_id', fallback=cloud_verifier_common.DEFAULT_VERIFIER_ID)\n                    agent_data['verifier_ip'] = config.get('cloud_verifier', 'cloudverifier_ip')\n                    agent_data['verifier_port'] = config.get('cloud_verifier', 'cloudverifier_port')\n\n                    # TODO: Always error for v1.0 version after initial upgrade\n                    if agent_data['mtls_cert'] is None and agent_data['supported_version'] != \"1.0\":\n                        web_util.echo_json_response(self, 400, \"mTLS certificate for agent is required!\")\n                        return\n\n                    is_valid, err_msg = cloud_verifier_common.validate_agent_data(agent_data)\n                    if not is_valid:\n                        web_util.echo_json_response(self, 400, err_msg)\n                        logger.warning(err_msg)\n                        return\n\n                    try:\n                        new_agent_count = session.query(\n                            VerfierMain).filter_by(agent_id=agent_id).count()\n                    except SQLAlchemyError as e:\n                        logger.error('SQLAlchemy Error: %s', e)\n                        raise e\n\n                    # don't allow overwriting\n\n                    if new_agent_count > 0:\n                        web_util.echo_json_response(\n                            self, 409, f\"Agent of uuid {agent_id} already exists\")\n                        logger.warning(\"Agent of uuid %s already exists\", agent_id)\n                    else:\n                        try:\n                            # Add the agent and data\n                            session.add(VerfierMain(**agent_data))\n                            session.commit()\n                        except SQLAlchemyError as e:\n                            logger.error('SQLAlchemy Error: %s', e)\n                            raise e\n\n                        # add default fields that are ephemeral\n                        for key,val in exclude_db.items():\n                            agent_data[key] = val\n\n                        # Prepare SSLContext for mTLS connections\n                        agent_mtls_cert_enabled = config.getboolean('cloud_verifier', 'agent_mtls_cert_enabled', fallback=False)\n                        mtls_cert = agent_data['mtls_cert']\n                        agent_data['ssl_context'] = None\n                        if agent_mtls_cert_enabled and mtls_cert:\n                            agent_data['ssl_context'] = web_util.generate_agent_mtls_context(mtls_cert, self.mtls_options)\n\n                        if agent_data['ssl_context'] is None:\n                            logger.warning('Connecting to agent without mTLS: %s', agent_id)\n\n                        asyncio.ensure_future(\n                            process_agent(agent_data, states.GET_QUOTE))\n                        web_util.echo_json_response(self, 200, \"Success\")\n                        logger.info('POST returning 200 response for adding agent id: %s', agent_id)\n            else:\n                web_util.echo_json_response(self, 400, \"uri not supported\")\n                logger.warning(\"POST returning 400 response. uri not supported\")\n        except Exception as e:\n            web_util.echo_json_response(self, 400, f\"Exception error: {str(e)}\")\n            logger.warning(\"POST returning 400 response. Exception error: %s\", e)\n            logger.exception(e)\n"}, {"role": "assistant", "content": "False"}]}
